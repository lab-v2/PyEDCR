{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score\n",
    "import tabulate\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import data_preprocessing\n",
    "import EDCR_pipeline\n",
    "import vit_pipeline\n",
    "import utils"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T21:45:46.100482Z",
     "start_time": "2023-12-13T21:45:41.938613Z"
    }
   },
   "id": "9dc68a5fe4ce4ea7",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# EDCR Results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff5d015e77a12310"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def get_metrics(test_true: np.array, \n",
    "                prior_predictions: np.array, \n",
    "                post_predictions: np.array) -> dict:\n",
    "    assert len(prior_predictions) == len(post_predictions)\n",
    "    \n",
    "    return {prior_or_post: ({'acc': accuracy_score(y_true=test_true, \n",
    "                                                       y_pred=(prior_predictions \n",
    "                                                       if prior_or_post == 'prior' else post_predictions))} | \n",
    "                                {metric_name: metric_value(y_true=test_true, \n",
    "                                                           y_pred=(prior_predictions \n",
    "                                                                   if prior_or_post == 'prior' else post_predictions), \n",
    "                                                           average='weighted') \n",
    "                                 for metric_name, metric_value in {'pre': precision_score, 'rec': recall_score, 'f1': f1_score}.items()})\n",
    "                 for prior_or_post in ['prior', 'post']} | {'len': len(prior_predictions)}\n",
    "\n",
    "\n",
    "def gather_EDCR_data() -> dict:\n",
    "    data = {} \n",
    "    \n",
    "    # Iterate through filenames to collect accuracy data\n",
    "    for filename in os.listdir(EDCR_pipeline.figs_folder):\n",
    "        secondary_granularity_match = re.match(\n",
    "            pattern='main_(fine|coarse)_(.+?)_lr(.+?)_secondary_(fine|coarse)_(.+?)_lr(.+)',\n",
    "            string=filename\n",
    "        )\n",
    "        \n",
    "        if secondary_granularity_match:\n",
    "            (   match,\n",
    "                main_granularity,\n",
    "                main_model_name,\n",
    "                main_lr,\n",
    "                secondary_granularity,\n",
    "                secondary_model_name,\n",
    "                secondary_lr\n",
    "            ) = (secondary_granularity_match.group(i) for i in range(7))\n",
    "            \n",
    "            main_suffix = '_coarse' if main_granularity == 'coarse' else ''\n",
    "            test_true = np.load(os.path.join(EDCR_pipeline.data_folder, f'test_true{main_suffix}.npy'))\n",
    "            \n",
    "            prior_predictions = np.load(os.path.join(EDCR_pipeline.data_folder, rf'{main_model_name}_test_pred_lr{main_lr}_e3{main_suffix}.npy'))\n",
    "            \n",
    "            secondary_suffix = '_coarse' if secondary_granularity == 'coarse' else ''\n",
    "            post_predictions = np.load(f'figs/{match}/results{secondary_suffix}.npy')\n",
    "\n",
    "            # Store accuracy data in the data dictionary\n",
    "            if main_granularity not in data:\n",
    "                data[main_granularity] = {}\n",
    "            if main_model_name not in data[main_granularity]:\n",
    "                data[main_granularity][main_model_name] = {}\n",
    "            if secondary_granularity not in data[main_granularity][main_model_name]:\n",
    "                data[main_granularity][main_model_name][secondary_granularity] = {}\n",
    "            if secondary_model_name not in data[main_granularity][main_model_name][secondary_granularity]:\n",
    "                data[main_granularity][main_model_name][secondary_granularity][secondary_model_name] = {}\n",
    "            if main_lr not in data[main_granularity][main_model_name][secondary_granularity][secondary_model_name]:\n",
    "                data[main_granularity][main_model_name][secondary_granularity][secondary_model_name][main_lr] = {}\n",
    "                \n",
    "            data[main_granularity][main_model_name][secondary_granularity][secondary_model_name][main_lr][secondary_lr] = get_metrics(test_true=test_true,\n",
    "                                                                                                                                      prior_predictions=prior_predictions,\n",
    "                                                                                                                                      post_predictions=post_predictions)\n",
    "        else:\n",
    "            no_secondary_granularity_match = re.match(pattern='main_(fine|coarse)_(.+)_lr(.+)_secondary_(.+)_lr(.+)',\n",
    "                                                      string=filename)\n",
    "            \n",
    "            if no_secondary_granularity_match:\n",
    "                \n",
    "                (match,\n",
    "                 main_granularity,\n",
    "                 main_model_name,\n",
    "                 main_lr,\n",
    "                 secondary_model_name,\n",
    "                 secondary_lr \n",
    "                ) = (no_secondary_granularity_match.group(i) for i in range(6))\n",
    "                \n",
    "                main_suffix = '_coarse' if main_granularity == 'coarse' else ''\n",
    "                test_true = np.load(os.path.join(EDCR_pipeline.data_folder, f'test_true{main_suffix}.npy'))\n",
    "                \n",
    "                prior_predictions = np.load(os.path.join(EDCR_pipeline.data_folder, rf'{main_model_name}_test_pred_lr{main_lr}_e3{main_suffix}.npy'))\n",
    "                \n",
    "                try:\n",
    "                    post_predictions = np.load(f'figs/{match}/results.npy')\n",
    "                except FileNotFoundError:\n",
    "                    post_predictions = np.load(f'figs/{match}/results_coarse.npy')\n",
    "                    \n",
    "                if main_granularity not in data:\n",
    "                    data[main_granularity] = {}\n",
    "                if main_model_name not in data[main_granularity]:\n",
    "                    data[main_granularity][main_model_name] = {}\n",
    "                if secondary_model_name not in data[main_granularity][main_model_name]:\n",
    "                    data[main_granularity][main_model_name][secondary_model_name] = {}\n",
    "                if main_lr not in data[main_granularity][main_model_name][secondary_model_name]:\n",
    "                    data[main_granularity][main_model_name][secondary_model_name][main_lr] = {}\n",
    "                \n",
    "                data[main_granularity][main_model_name][secondary_model_name][main_lr][secondary_lr] = get_metrics(test_true=test_true,\n",
    "                                                                                                                   prior_predictions=prior_predictions,\n",
    "                                                                                                                   post_predictions=post_predictions)\n",
    "    return data\n",
    "\n",
    "def get_diff_str(diff: float) -> str:\n",
    "    return f\"({utils.green_text('+') if diff > 0 else ''}{(utils.green_text(f'{diff}%') if diff > 0  else utils.red_text(f'{diff}%'))})\" if abs(diff) > 0 else ''\n",
    "\n",
    "def get_row_addition(secondary_lr: float, \n",
    "                     curr_data: dict,\n",
    "                     max_accuracy: float = None) -> (str, float):\n",
    "    roundoff = 2\n",
    "    curr_prior_data = curr_data['prior']\n",
    "    curr_post_data = curr_data['post']\n",
    "    \n",
    "    curr_prior_accuracy = round(curr_prior_data['acc'] * 100, roundoff)\n",
    "    curr_post_accuracy = round(curr_post_data['acc'] * 100, roundoff)\n",
    "    curr_accuracy_diff = round(curr_post_accuracy - curr_prior_accuracy, roundoff)\n",
    "    \n",
    "    post_acc_str = (utils.blue_text(curr_post_accuracy) \n",
    "                    if max_accuracy is not None and abs(curr_post_accuracy - max_accuracy) < 1e-5 \n",
    "                    else str(curr_post_accuracy))\n",
    "    \n",
    "    curr_prior_average_f1 = round(curr_prior_data['f1'] * 100, roundoff)\n",
    "    curr_post_average_f1 = round(curr_post_data['f1'] * 100, roundoff)\n",
    "    curr_average_f1_diff = round(curr_post_average_f1 - curr_prior_average_f1, roundoff)\n",
    "    \n",
    "    \n",
    "    acc_str = f'acc: {post_acc_str}% {get_diff_str(curr_accuracy_diff)}'\n",
    "    f1_str = f'f1: {curr_post_average_f1}% {get_diff_str(curr_average_f1_diff)}'\n",
    "    row_addition = f\"{secondary_lr}: {acc_str}, {f1_str}\\n\"\n",
    "\n",
    "    return row_addition, curr_prior_accuracy, curr_prior_average_f1\n",
    "\n",
    "\n",
    "def get_row_data(main_lr_data: dict,\n",
    "                 secondary_lr: float) -> (str, float):\n",
    "    curr_data = main_lr_data[secondary_lr]\n",
    "    row_addition, curr_prior_acc, curr_prior_average_f1 = get_row_addition(secondary_lr=secondary_lr, \n",
    "                                                                                   curr_data=curr_data)\n",
    "    \n",
    "    return row_addition, curr_prior_acc, curr_prior_average_f1\n",
    "\n",
    "\n",
    "def print_one_secondary_granularity(main_model_data: dict,\n",
    "                                    secondary_granularity: str,\n",
    "                                    main_granularity: str,\n",
    "                                    main_model_name: str):\n",
    "\n",
    "    secondary_granularity_data = main_model_data[secondary_granularity]\n",
    "    main_learning_rates = sorted(secondary_granularity_data[list(secondary_granularity_data.keys())[0]].keys())\n",
    "    header = [''] + main_learning_rates\n",
    "    table_data = [header]\n",
    "    priors = {}\n",
    "\n",
    "    for secondary_model_name in sorted(secondary_granularity_data.keys()):\n",
    "        secondary_model_data = secondary_granularity_data[secondary_model_name]\n",
    "        row = [secondary_model_name]\n",
    "        \n",
    "        for main_lr in sorted(secondary_model_data.keys()):\n",
    "            main_lr_data = secondary_model_data[main_lr]\n",
    "            row_add = ''\n",
    "            \n",
    "            for secondary_lr in sorted(main_lr_data.keys()):\n",
    "                row_addition, curr_prior_acc, curr_prior_average_f1 = get_row_data(main_lr_data=main_lr_data,\n",
    "                                                                                      secondary_lr=secondary_lr)\n",
    "                row_add += row_addition\n",
    "                priors[main_lr] = {'acc': curr_prior_acc, 'f1': curr_prior_average_f1}\n",
    "                \n",
    "            row += [row_add]\n",
    "        table_data += [row]\n",
    "    \n",
    "    table_data[0] = [''] + [f\"main-lr={main_lr} (acc: {priors[main_lr]['acc']}%, f1: {priors[main_lr]['f1']}%)\" for main_lr in main_learning_rates]\n",
    "    \n",
    "    # Rest of your code to create and print the table remains unchanged\n",
    "    table = tabulate.tabulate(\n",
    "        tabular_data=table_data, \n",
    "        headers='firstrow', \n",
    "        tablefmt='grid'\n",
    "    )\n",
    "    print(f\"Main model: {main_granularity.capitalize()}-grain {main_model_name}, \"\n",
    "          f\"secondary granularity: {secondary_granularity}\")\n",
    "    print(table)\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "def print_two_secondary_granularities(main_model_data: dict,\n",
    "                                      two_secondary_table_data: list,\n",
    "                                      secondary_model_name: str,\n",
    "                                      main_granularity: str,\n",
    "                                      main_model_name: str):\n",
    "    main_learning_rates = sorted(vit_pipeline.lrs)\n",
    "    \n",
    "    priors = {}\n",
    "    \n",
    "    # Initialize the table_data with header if it's empty\n",
    "    if len(two_secondary_table_data) == 0:\n",
    "        header = [''] + main_learning_rates\n",
    "        two_secondary_table_data += [header]\n",
    "        \n",
    "    secondary_model_data = main_model_data[secondary_model_name]\n",
    "    row = [secondary_model_name]\n",
    "    \n",
    "    for main_lr in sorted(secondary_model_data.keys()):\n",
    "        main_lr_data = secondary_model_data[main_lr]\n",
    "        row_add = ''\n",
    "        \n",
    "        for secondary_lr in sorted(main_lr_data.keys()):\n",
    "            row_addition, curr_prior_acc, curr_prior_average_f1 = get_row_data(main_lr_data=main_lr_data,\n",
    "                                                    secondary_lr=secondary_lr)\n",
    "            row_add += row_addition\n",
    "            priors[main_lr] = {'acc': curr_prior_acc, 'f1': curr_prior_average_f1}\n",
    "    \n",
    "        row += [row_add]\n",
    "\n",
    "    two_secondary_table_data += [row]\n",
    "    \n",
    "    # Modify the generated table data to highlight the cell with the maximal accuracy in blue\n",
    "    \n",
    "    if len(two_secondary_table_data) == len(main_learning_rates) + 1:\n",
    "        two_secondary_table_data[0] = [''] + [f\"main-lr={main_lr} (acc: {priors[str(main_lr)]['acc']}%, f1: {priors[str(main_lr)]['f1']}%)\" for main_lr in main_learning_rates]\n",
    "        \n",
    "        # Create the table using tabulate\n",
    "        table = tabulate.tabulate(\n",
    "            tabular_data=two_secondary_table_data,\n",
    "            headers='firstrow',\n",
    "            tablefmt='grid'\n",
    "        )\n",
    "        \n",
    "        # Print the main model name and the corresponding table\n",
    "        print(f\"Main model: {main_granularity.capitalize()}-grain {main_model_name} \"\n",
    "              f\"with both fine and coarse grain secondary models\")\n",
    "        print(table)\n",
    "        print(\"\\n\")\n",
    "    else:\n",
    "        return two_secondary_table_data\n",
    "\n",
    "\n",
    "def print_EDCR_tables():\n",
    "    data = gather_EDCR_data()\n",
    "    \n",
    "    for main_granularity in sorted(data.keys()):\n",
    "        \n",
    "        print('#' * 40 + f' Main granularity: {main_granularity} ' + '#' * 40 + '\\n' + '#' * 104 + '\\n')\n",
    "        main_granularity_data = data[main_granularity]\n",
    "        \n",
    "        for main_model_name in sorted(main_granularity_data.keys()):\n",
    "            main_model_data = main_granularity_data[main_model_name]\n",
    "            two_secondary_table_data = []\n",
    "\n",
    "            for granularity_or_model in (sorted(set(main_model_data.keys()).intersection(data_preprocessing.granularities.values())) + \n",
    "                      sorted(set(main_model_data.keys()).intersection(vit_pipeline.vit_model_names))):\n",
    "            \n",
    "                if granularity_or_model in data_preprocessing.granularities.values():\n",
    "                    print_one_secondary_granularity(main_model_data=main_model_data,\n",
    "                                                    secondary_granularity=granularity_or_model,\n",
    "                                                    main_granularity=main_granularity,\n",
    "                                                    main_model_name=main_model_name)\n",
    "                else:\n",
    "                    two_secondary_table_data = print_two_secondary_granularities(main_model_data=main_model_data,\n",
    "                                                                                 two_secondary_table_data=two_secondary_table_data,\n",
    "                                                                                 secondary_model_name=granularity_or_model,\n",
    "                                                                                 main_granularity=main_granularity,\n",
    "                                                                                 main_model_name=main_model_name)\n",
    "            print('#' * 100)\n",
    "\n",
    "print_EDCR_tables()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T21:45:51.619721Z",
     "start_time": "2023-12-13T21:45:51.196713Z"
    }
   },
   "id": "3f6e34912281d5e",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "best_coarse_main_model = 'vit_l_16'\n",
    "best_coarse_main_lr = '1e-06'\n",
    "best_coarse_secondary_model = 'vit_b_16'\n",
    "best_coarse_secondary_lr = '5e-05'\n",
    "best_coarse_folder = f'main_coarse_{best_coarse_main_model}_lr{best_coarse_main_lr}_secondary_{best_coarse_secondary_model}_lr{best_coarse_secondary_lr}'\n",
    "best_coarse_results = np.load(rf'{EDCR_pipeline.figs_folder}{best_coarse_folder}/results.npy')\n",
    "coarse_test_true = np.load(os.path.join(EDCR_pipeline.data_folder, f'test_true_coarse.npy'))\n",
    "\n",
    "best_fine_main_model = 'vit_l_16'\n",
    "best_fine_main_lr = '1e-06'\n",
    "best_fine_secondary_model = 'vit_b_16'\n",
    "best_fine_secondary_lr = '1e-06'\n",
    "best_fine_folder = f'main_fine_{best_fine_main_model}_lr{best_fine_main_lr}_secondary_{best_fine_secondary_model}_lr{best_fine_secondary_lr}'\n",
    "best_fine_results = np.load(rf'{EDCR_pipeline.figs_folder}{best_fine_folder}/results.npy')\n",
    "fine_test_true = np.load(os.path.join(EDCR_pipeline.data_folder, f'test_true.npy'))\n",
    "\n",
    "with open('fine_to_coarse.json', 'r') as json_file:\n",
    "    image_fine_to_coarse = json.load(json_file)\n",
    "\n",
    "image_fine_to_coarse = {int(fine): int(coarse) for batch_dict in image_fine_to_coarse for fine, coarse in batch_dict.items()}\n",
    "image_fine_to_coarse\n",
    "\n",
    "# def get_num_of_inconsistencies(coarse_results: np.array, \n",
    "#                                fine_results: np.array) -> int:\n",
    "#     num_of_inconsistencies = 0\n",
    "#     for fine_example_num, fine_prediction_index in enumerate(fine_results):\n",
    "#         coarse_example_num = image_fine_to_coarse[fine_example_num]\n",
    "#         coarse_prediction_index = coarse_results[coarse_example_num]\n",
    "#         \n",
    "#         fine_prediction = EDCR_pipeline.get_classes(granularity='fine')[fine_prediction_index]\n",
    "#         coarse_prediction = EDCR_pipeline.get_classes(granularity='coarse')[coarse_prediction_index]\n",
    "#         derived_coarse_prediction = EDCR_pipeline.fine_to_coarse[fine_prediction]\n",
    "# \n",
    "#         if derived_coarse_prediction != coarse_prediction:\n",
    "#             num_of_inconsistencies += 1\n",
    "# \n",
    "#     return num_of_inconsistencies\n",
    "# \n",
    "# get_num_of_inconsistencies(coarse_results=coarse_test_true,\n",
    "#                            fine_results=fine_test_true)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-22T03:55:18.564992Z",
     "start_time": "2023-11-22T03:55:18.544808Z"
    }
   },
   "id": "bdb3d6545a77e534",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "best_coarse_main_model = 'vit_l_16'\n",
    "best_coarse_main_lr = '1e-06'\n",
    "best_coarse_secondary_model = 'vit_b_16'\n",
    "best_coarse_secondary_lr = '5e-05'\n",
    "\n",
    "folder = (f'{EDCR_pipeline.figs_folder}/main_coarse_{best_coarse_main_model}_lr{best_coarse_main_lr}'\n",
    "                  f'_secondary_{best_coarse_secondary_model}_lr{best_coarse_secondary_lr}')\n",
    "\n",
    "with open(f'{folder}/error_detections.json', 'r') as json_file:\n",
    "    error_detections = json.load(json_file)\n",
    "\n",
    "print('Error detections:\\n')\n",
    "for coarse_grain_label, coarse_grain_label_data in error_detections.items():\n",
    "    for fine_grain_label in coarse_grain_label_data.keys():\n",
    "        print(f'error <- predicted_coarse_grain = {coarse_grain_label} '\n",
    "              f'and predicted_fine_grain = {fine_grain_label}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-22T18:17:15.803787Z",
     "start_time": "2023-11-22T18:17:15.783970Z"
    }
   },
   "id": "e513314a85b69eef",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "with open(f'{folder}/corrections.json', 'r') as json_file:\n",
    "    corrections = json.load(json_file)\n",
    "\n",
    "print('Corrections:\\n')\n",
    "for coarse_grain_label, coarse_grain_label_data in corrections.items():\n",
    "    for fine_grain_label in coarse_grain_label_data.keys():\n",
    "        print(f'correct_coarse_grain = {EDCR_pipeline.fine_to_coarse[fine_grain_label]} <- predicted_coarse_grain = {coarse_grain_label} '\n",
    "              f'and predicted_fine_grain = {fine_grain_label}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-22T18:30:47.744654Z",
     "start_time": "2023-11-22T18:30:47.736840Z"
    }
   },
   "id": "7a8321c1362aba3a",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "336def8bebdfc8bb",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
