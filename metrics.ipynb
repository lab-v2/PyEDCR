{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "import tabulate\n",
    "import ansiwrap\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import data_preprocessing\n",
    "import EDCR_pipeline\n",
    "import vit_pipeline\n",
    "import utils"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-10T21:02:09.957422Z",
     "start_time": "2023-11-10T21:02:05.544285Z"
    }
   },
   "id": "9dc68a5fe4ce4ea7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# EDCR Results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff5d015e77a12310"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################## Main granularity: coarse ########################################\n",
      "########################################################################################################\n",
      "\n",
      "Main model: Coarse-grain vit_b_16, secondary granularity: coarse\n",
      "+----------+---------------------+----------------------+---------------------+\n",
      "|          | 1e-05 (80.9%)       | 1e-06 (65.6%)        | 5e-05 (83.7%)       |\n",
      "+==========+=====================+======================+=====================+\n",
      "| vit_b_32 | 1e-05: 81.0%, \u001B[92m+\u001B[0m\u001B[92m0.1%\u001B[0m | 1e-05: 73.0%, \u001B[92m+\u001B[0m\u001B[92m7.4%\u001B[0m  | 1e-05: 82.4%, \u001B[91m-1.3%\u001B[0m |\n",
      "|          | 1e-06: 80.9%, \u001B[91m0.0%\u001B[0m  | 1e-06: 65.3%, \u001B[91m-0.3%\u001B[0m  | 1e-06: 83.7%, \u001B[91m0.0%\u001B[0m  |\n",
      "|          | 5e-05: 81.2%, \u001B[92m+\u001B[0m\u001B[92m0.3%\u001B[0m | 5e-05: 72.5%, \u001B[92m+\u001B[0m\u001B[92m6.9%\u001B[0m  | 5e-05: 83.7%, \u001B[91m0.0%\u001B[0m  |\n",
      "+----------+---------------------+----------------------+---------------------+\n",
      "| vit_l_16 | 1e-05: 83.0%, \u001B[92m+\u001B[0m\u001B[92m2.1%\u001B[0m | 1e-05: 76.8%, \u001B[92m+\u001B[0m\u001B[92m11.2%\u001B[0m | 1e-05: 83.8%, \u001B[92m+\u001B[0m\u001B[92m0.1%\u001B[0m |\n",
      "|          | 1e-06: 78.8%, \u001B[91m-2.1%\u001B[0m | 1e-06: 71.2%, \u001B[92m+\u001B[0m\u001B[92m5.6%\u001B[0m  | 1e-06: 83.7%, \u001B[91m0.0%\u001B[0m  |\n",
      "|          | 5e-05: 82.0%, \u001B[92m+\u001B[0m\u001B[92m1.1%\u001B[0m | 5e-05: 76.1%, \u001B[92m+\u001B[0m\u001B[92m10.5%\u001B[0m | 5e-05: 84.2%, \u001B[92m+\u001B[0m\u001B[92m0.5%\u001B[0m |\n",
      "+----------+---------------------+----------------------+---------------------+\n",
      "| vit_l_32 | 1e-05: 80.8%, \u001B[91m-0.1%\u001B[0m | 1e-05: 74.2%, \u001B[92m+\u001B[0m\u001B[92m8.6%\u001B[0m  | 1e-05: 83.0%, \u001B[91m-0.7%\u001B[0m |\n",
      "|          | 1e-06: 80.9%, \u001B[91m0.0%\u001B[0m  | 1e-06: 66.1%, \u001B[92m+\u001B[0m\u001B[92m0.5%\u001B[0m  | 1e-06: 83.7%, \u001B[91m0.0%\u001B[0m  |\n",
      "|          | 5e-05: 81.4%, \u001B[92m+\u001B[0m\u001B[92m0.5%\u001B[0m | 5e-05: 75.9%, \u001B[92m+\u001B[0m\u001B[92m10.3%\u001B[0m | 5e-05: 83.5%, \u001B[91m-0.2%\u001B[0m |\n",
      "+----------+---------------------+----------------------+---------------------+\n",
      "Maximum prior accuracy: {'max_prior': 83.7, 'main_lr': 5e-05, 'secondary_model_name': 'vit_b_32', 'secondary_lr': 1e-05}\n",
      "\n",
      "\n",
      "Main model: Coarse-grain vit_b_16, secondary granularity: fine\n",
      "+----------+---------------------+---------------------+---------------------+\n",
      "|          | 1e-05 (80.9%)       | 1e-06 (65.6%)       | 5e-05 (83.7%)       |\n",
      "+==========+=====================+=====================+=====================+\n",
      "| vit_b_32 | 1e-05: 78.0%, \u001B[91m-2.9%\u001B[0m | 1e-05: 69.3%, \u001B[92m+\u001B[0m\u001B[92m3.7%\u001B[0m | 1e-05: 83.0%, \u001B[91m-0.7%\u001B[0m |\n",
      "|          | 1e-06: 79.2%, \u001B[91m-1.7%\u001B[0m | 1e-06: 71.0%, \u001B[92m+\u001B[0m\u001B[92m5.4%\u001B[0m | 1e-06: 83.0%, \u001B[91m-0.7%\u001B[0m |\n",
      "|          | 5e-05: 79.5%, \u001B[91m-1.4%\u001B[0m | 5e-05: 68.6%, \u001B[92m+\u001B[0m\u001B[92m3.0%\u001B[0m | 5e-05: 83.8%, \u001B[92m+\u001B[0m\u001B[92m0.1%\u001B[0m |\n",
      "+----------+---------------------+---------------------+---------------------+\n",
      "| vit_l_16 | 1e-05: 80.8%, \u001B[91m-0.1%\u001B[0m | 1e-05: 72.4%, \u001B[92m+\u001B[0m\u001B[92m6.8%\u001B[0m | 1e-05: 84.5%, \u001B[92m+\u001B[0m\u001B[92m0.8%\u001B[0m |\n",
      "|          | 1e-06: 79.5%, \u001B[91m-1.4%\u001B[0m | 1e-06: 73.2%, \u001B[92m+\u001B[0m\u001B[92m7.6%\u001B[0m | 1e-06: 82.7%, \u001B[91m-1.0%\u001B[0m |\n",
      "|          | 5e-05: 81.2%, \u001B[92m+\u001B[0m\u001B[92m0.3%\u001B[0m | 5e-05: 72.3%, \u001B[92m+\u001B[0m\u001B[92m6.7%\u001B[0m | 5e-05: 84.4%, \u001B[92m+\u001B[0m\u001B[92m0.7%\u001B[0m |\n",
      "+----------+---------------------+---------------------+---------------------+\n",
      "| vit_l_32 | 1e-05: 81.6%, \u001B[92m+\u001B[0m\u001B[92m0.7%\u001B[0m | 1e-05: 68.7%, \u001B[92m+\u001B[0m\u001B[92m3.1%\u001B[0m | 1e-05: 83.5%, \u001B[91m-0.2%\u001B[0m |\n",
      "|          | 1e-06: 80.6%, \u001B[91m-0.3%\u001B[0m | 1e-06: 71.7%, \u001B[92m+\u001B[0m\u001B[92m6.1%\u001B[0m | 1e-06: 83.0%, \u001B[91m-0.7%\u001B[0m |\n",
      "|          | 5e-05: 79.3%, \u001B[91m-1.6%\u001B[0m | 5e-05: 70.6%, \u001B[92m+\u001B[0m\u001B[92m5.0%\u001B[0m | 5e-05: 82.5%, \u001B[91m-1.2%\u001B[0m |\n",
      "+----------+---------------------+---------------------+---------------------+\n",
      "Maximum prior accuracy: {'max_prior': 83.7, 'main_lr': 5e-05, 'secondary_model_name': 'vit_b_32', 'secondary_lr': 1e-05}\n",
      "\n",
      "\n",
      "Main model: Coarse-grain vit_b_16 with both fine and coarse grain secondary models\n",
      "+----------+---------------------+---------------------+---------------------+\n",
      "|          | 1e-06 (65.6%)       | 1e-05 (80.9%)       | 5e-05 (83.7%)       |\n",
      "+==========+=====================+=====================+=====================+\n",
      "| vit_b_32 | 1e-05: 78.0%, \u001B[91m-2.9%\u001B[0m | 1e-05: 70.1%, \u001B[92m+\u001B[0m\u001B[92m4.5%\u001B[0m | 1e-05: 82.4%, \u001B[91m-1.3%\u001B[0m |\n",
      "|          | 1e-06: 79.2%, \u001B[91m-1.7%\u001B[0m | 1e-06: 69.3%, \u001B[92m+\u001B[0m\u001B[92m3.7%\u001B[0m | 1e-06: 83.0%, \u001B[91m-0.7%\u001B[0m |\n",
      "|          | 5e-05: 79.7%, \u001B[91m-1.2%\u001B[0m | 5e-05: 70.6%, \u001B[92m+\u001B[0m\u001B[92m5.0%\u001B[0m | 5e-05: 83.8%, \u001B[92m+\u001B[0m\u001B[92m0.1%\u001B[0m |\n",
      "+----------+---------------------+---------------------+---------------------+\n",
      "| vit_l_16 | 1e-05: 81.1%, \u001B[92m+\u001B[0m\u001B[92m0.2%\u001B[0m | 1e-05: 69.2%, \u001B[92m+\u001B[0m\u001B[92m3.6%\u001B[0m | 1e-05: 85.3%, \u001B[92m+\u001B[0m\u001B[92m1.6%\u001B[0m |\n",
      "|          | 1e-06: 79.8%, \u001B[91m-1.1%\u001B[0m | 1e-06: 69.4%, \u001B[92m+\u001B[0m\u001B[92m3.8%\u001B[0m | 1e-06: 82.7%, \u001B[91m-1.0%\u001B[0m |\n",
      "|          | 5e-05: 81.6%, \u001B[92m+\u001B[0m\u001B[92m0.7%\u001B[0m | 5e-05: 74.0%, \u001B[92m+\u001B[0m\u001B[92m8.4%\u001B[0m | 5e-05: 84.5%, \u001B[92m+\u001B[0m\u001B[92m0.8%\u001B[0m |\n",
      "+----------+---------------------+---------------------+---------------------+\n",
      "| vit_l_32 | 1e-05: 81.8%, \u001B[92m+\u001B[0m\u001B[92m0.9%\u001B[0m | 1e-05: 70.8%, \u001B[92m+\u001B[0m\u001B[92m5.2%\u001B[0m | 1e-05: 83.4%, \u001B[91m-0.3%\u001B[0m |\n",
      "|          | 1e-06: 80.6%, \u001B[91m-0.3%\u001B[0m | 1e-06: 71.7%, \u001B[92m+\u001B[0m\u001B[92m6.1%\u001B[0m | 1e-06: 83.0%, \u001B[91m-0.7%\u001B[0m |\n",
      "|          | 5e-05: 80.6%, \u001B[91m-0.3%\u001B[0m | 5e-05: 74.0%, \u001B[92m+\u001B[0m\u001B[92m8.4%\u001B[0m | 5e-05: 83.2%, \u001B[91m-0.5%\u001B[0m |\n",
      "+----------+---------------------+---------------------+---------------------+\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Main model: Coarse-grain vit_b_32, secondary granularity: coarse\n",
      "+----------+---------------------+----------------------+---------------------+\n",
      "|          | 1e-05 (77.1%)       | 1e-06 (63.0%)        | 5e-05 (76.0%)       |\n",
      "+==========+=====================+======================+=====================+\n",
      "| vit_b_16 | 1e-05: 79.6%, \u001B[92m+\u001B[0m\u001B[92m2.5%\u001B[0m | 1e-05: 74.3%, \u001B[92m+\u001B[0m\u001B[92m11.3%\u001B[0m | 1e-05: 78.7%, \u001B[92m+\u001B[0m\u001B[92m2.7%\u001B[0m |\n",
      "|          | 1e-06: 77.1%, \u001B[91m0.0%\u001B[0m  | 1e-06: 64.2%, \u001B[92m+\u001B[0m\u001B[92m1.2%\u001B[0m  | 1e-06: 75.3%, \u001B[91m-0.7%\u001B[0m |\n",
      "|          | 5e-05: 82.2%, \u001B[92m+\u001B[0m\u001B[92m5.1%\u001B[0m | 5e-05: 76.3%, \u001B[92m+\u001B[0m\u001B[92m13.3%\u001B[0m | 5e-05: 82.0%, \u001B[92m+\u001B[0m\u001B[92m6.0%\u001B[0m |\n",
      "+----------+---------------------+----------------------+---------------------+\n",
      "| vit_l_16 | 1e-05: 82.4%, \u001B[92m+\u001B[0m\u001B[92m5.3%\u001B[0m | 1e-05: 76.7%, \u001B[92m+\u001B[0m\u001B[92m13.7%\u001B[0m | 1e-05: 80.7%, \u001B[92m+\u001B[0m\u001B[92m4.7%\u001B[0m |\n",
      "|          | 1e-06: 76.2%, \u001B[91m-0.9%\u001B[0m | 1e-06: 71.4%, \u001B[92m+\u001B[0m\u001B[92m8.4%\u001B[0m  | 1e-06: 75.6%, \u001B[91m-0.4%\u001B[0m |\n",
      "|          | 5e-05: 81.6%, \u001B[92m+\u001B[0m\u001B[92m4.5%\u001B[0m | 5e-05: 75.9%, \u001B[92m+\u001B[0m\u001B[92m12.9%\u001B[0m | 5e-05: 79.4%, \u001B[92m+\u001B[0m\u001B[92m3.4%\u001B[0m |\n",
      "+----------+---------------------+----------------------+---------------------+\n",
      "| vit_l_32 | 1e-05: 77.7%, \u001B[92m+\u001B[0m\u001B[92m0.6%\u001B[0m | 1e-05: 72.4%, \u001B[92m+\u001B[0m\u001B[92m9.4%\u001B[0m  | 1e-05: 77.5%, \u001B[92m+\u001B[0m\u001B[92m1.5%\u001B[0m |\n",
      "|          | 1e-06: 77.1%, \u001B[91m0.0%\u001B[0m  | 1e-06: 63.6%, \u001B[92m+\u001B[0m\u001B[92m0.6%\u001B[0m  | 1e-06: 74.3%, \u001B[91m-1.7%\u001B[0m |\n",
      "|          | 5e-05: 81.3%, \u001B[92m+\u001B[0m\u001B[92m4.2%\u001B[0m | 5e-05: 75.0%, \u001B[92m+\u001B[0m\u001B[92m12.0%\u001B[0m | 5e-05: 78.8%, \u001B[92m+\u001B[0m\u001B[92m2.8%\u001B[0m |\n",
      "+----------+---------------------+----------------------+---------------------+\n",
      "Maximum prior accuracy: {'max_prior': 77.1, 'main_lr': 1e-05, 'secondary_model_name': 'vit_b_16', 'secondary_lr': 1e-05}\n",
      "\n",
      "\n",
      "Main model: Coarse-grain vit_b_32, secondary granularity: fine\n",
      "+----------+---------------------+---------------------+---------------------+\n",
      "|          | 1e-05 (77.1%)       | 1e-06 (63.0%)       | 5e-05 (76.0%)       |\n",
      "+==========+=====================+=====================+=====================+\n",
      "| vit_b_16 | 1e-05: 77.9%, \u001B[92m+\u001B[0m\u001B[92m0.8%\u001B[0m | 1e-05: 69.8%, \u001B[92m+\u001B[0m\u001B[92m6.8%\u001B[0m | 1e-05: 76.8%, \u001B[92m+\u001B[0m\u001B[92m0.8%\u001B[0m |\n",
      "|          | 1e-06: 77.7%, \u001B[92m+\u001B[0m\u001B[92m0.6%\u001B[0m | 1e-06: 72.7%, \u001B[92m+\u001B[0m\u001B[92m9.7%\u001B[0m | 1e-06: 78.5%, \u001B[92m+\u001B[0m\u001B[92m2.5%\u001B[0m |\n",
      "|          | 5e-05: 78.7%, \u001B[92m+\u001B[0m\u001B[92m1.6%\u001B[0m | 5e-05: 70.9%, \u001B[92m+\u001B[0m\u001B[92m7.9%\u001B[0m | 5e-05: 78.1%, \u001B[92m+\u001B[0m\u001B[92m2.1%\u001B[0m |\n",
      "+----------+---------------------+---------------------+---------------------+\n",
      "| vit_l_16 | 1e-05: 78.6%, \u001B[92m+\u001B[0m\u001B[92m1.5%\u001B[0m | 1e-05: 70.6%, \u001B[92m+\u001B[0m\u001B[92m7.6%\u001B[0m | 1e-05: 78.5%, \u001B[92m+\u001B[0m\u001B[92m2.5%\u001B[0m |\n",
      "|          | 1e-06: 78.6%, \u001B[92m+\u001B[0m\u001B[92m1.5%\u001B[0m | 1e-06: 70.0%, \u001B[92m+\u001B[0m\u001B[92m7.0%\u001B[0m | 1e-06: 77.9%, \u001B[92m+\u001B[0m\u001B[92m1.9%\u001B[0m |\n",
      "|          | 5e-05: 78.7%, \u001B[92m+\u001B[0m\u001B[92m1.6%\u001B[0m | 5e-05: 70.7%, \u001B[92m+\u001B[0m\u001B[92m7.7%\u001B[0m | 5e-05: 78.6%, \u001B[92m+\u001B[0m\u001B[92m2.6%\u001B[0m |\n",
      "+----------+---------------------+---------------------+---------------------+\n",
      "| vit_l_32 | 1e-05: 78.1%, \u001B[92m+\u001B[0m\u001B[92m1.0%\u001B[0m | 1e-05: 68.2%, \u001B[92m+\u001B[0m\u001B[92m5.2%\u001B[0m | 1e-05: 75.4%, \u001B[91m-0.6%\u001B[0m |\n",
      "|          | 1e-06: 77.2%, \u001B[92m+\u001B[0m\u001B[92m0.1%\u001B[0m | 1e-06: 70.4%, \u001B[92m+\u001B[0m\u001B[92m7.4%\u001B[0m | 1e-06: 76.6%, \u001B[92m+\u001B[0m\u001B[92m0.6%\u001B[0m |\n",
      "|          | 5e-05: 76.4%, \u001B[91m-0.7%\u001B[0m | 5e-05: 69.4%, \u001B[92m+\u001B[0m\u001B[92m6.4%\u001B[0m | 5e-05: 75.3%, \u001B[91m-0.7%\u001B[0m |\n",
      "+----------+---------------------+---------------------+---------------------+\n",
      "Maximum prior accuracy: {'max_prior': 77.1, 'main_lr': 1e-05, 'secondary_model_name': 'vit_b_16', 'secondary_lr': 1e-05}\n",
      "\n",
      "\n",
      "Main model: Coarse-grain vit_b_32 with both fine and coarse grain secondary models\n",
      "+----------+---------------------+----------------------+---------------------+\n",
      "|          | 1e-06 (63.0%)       | 1e-05 (77.1%)        | 5e-05 (76.0%)       |\n",
      "+==========+=====================+======================+=====================+\n",
      "| vit_b_16 | 1e-05: 79.5%, \u001B[92m+\u001B[0m\u001B[92m2.4%\u001B[0m | 1e-05: 70.3%, \u001B[92m+\u001B[0m\u001B[92m7.3%\u001B[0m  | 1e-05: 78.6%, \u001B[92m+\u001B[0m\u001B[92m2.6%\u001B[0m |\n",
      "|          | 1e-06: 77.7%, \u001B[92m+\u001B[0m\u001B[92m0.6%\u001B[0m | 1e-06: 65.9%, \u001B[92m+\u001B[0m\u001B[92m2.9%\u001B[0m  | 1e-06: 77.5%, \u001B[92m+\u001B[0m\u001B[92m1.5%\u001B[0m |\n",
      "|          | 5e-05: 83.4%, \u001B[92m+\u001B[0m\u001B[92m6.3%\u001B[0m | 5e-05: 75.8%, \u001B[92m+\u001B[0m\u001B[92m12.8%\u001B[0m | 5e-05: 81.9%, \u001B[92m+\u001B[0m\u001B[92m5.9%\u001B[0m |\n",
      "+----------+---------------------+----------------------+---------------------+\n",
      "| vit_l_16 | 1e-05: 81.4%, \u001B[92m+\u001B[0m\u001B[92m4.3%\u001B[0m | 1e-05: 68.2%, \u001B[92m+\u001B[0m\u001B[92m5.2%\u001B[0m  | 1e-05: 79.0%, \u001B[92m+\u001B[0m\u001B[92m3.0%\u001B[0m |\n",
      "|          | 1e-06: 78.6%, \u001B[92m+\u001B[0m\u001B[92m1.5%\u001B[0m | 1e-06: 68.7%, \u001B[92m+\u001B[0m\u001B[92m5.7%\u001B[0m  | 1e-06: 77.4%, \u001B[92m+\u001B[0m\u001B[92m1.4%\u001B[0m |\n",
      "|          | 5e-05: 81.6%, \u001B[92m+\u001B[0m\u001B[92m4.5%\u001B[0m | 5e-05: 70.6%, \u001B[92m+\u001B[0m\u001B[92m7.6%\u001B[0m  | 5e-05: 81.9%, \u001B[92m+\u001B[0m\u001B[92m5.9%\u001B[0m |\n",
      "+----------+---------------------+----------------------+---------------------+\n",
      "| vit_l_32 | 1e-05: 78.1%, \u001B[92m+\u001B[0m\u001B[92m1.0%\u001B[0m | 1e-05: 69.3%, \u001B[92m+\u001B[0m\u001B[92m6.3%\u001B[0m  | 1e-05: 76.7%, \u001B[92m+\u001B[0m\u001B[92m0.7%\u001B[0m |\n",
      "|          | 1e-06: 77.2%, \u001B[92m+\u001B[0m\u001B[92m0.1%\u001B[0m | 1e-06: 69.9%, \u001B[92m+\u001B[0m\u001B[92m6.9%\u001B[0m  | 1e-06: 76.3%, \u001B[92m+\u001B[0m\u001B[92m0.3%\u001B[0m |\n",
      "|          | 5e-05: 81.2%, \u001B[92m+\u001B[0m\u001B[92m4.1%\u001B[0m | 5e-05: 73.5%, \u001B[92m+\u001B[0m\u001B[92m10.5%\u001B[0m | 5e-05: 77.7%, \u001B[92m+\u001B[0m\u001B[92m1.7%\u001B[0m |\n",
      "+----------+---------------------+----------------------+---------------------+\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Main model: Coarse-grain vit_l_16, secondary granularity: coarse\n",
      "+----------+---------------------+\n",
      "|          | 1e-05 (84.3%)       |\n",
      "+==========+=====================+\n",
      "| vit_b_16 | 1e-05: 83.8%, \u001B[91m-0.5%\u001B[0m |\n",
      "|          | 1e-06: 84.3%, \u001B[91m0.0%\u001B[0m  |\n",
      "|          | 5e-05: 84.3%, \u001B[91m0.0%\u001B[0m  |\n",
      "+----------+---------------------+\n",
      "| vit_b_32 | 1e-05: 83.7%, \u001B[91m-0.6%\u001B[0m |\n",
      "|          | 1e-06: 84.3%, \u001B[91m0.0%\u001B[0m  |\n",
      "|          | 5e-05: 84.2%, \u001B[91m-0.1%\u001B[0m |\n",
      "+----------+---------------------+\n",
      "| vit_l_32 | 1e-05: 83.6%, \u001B[91m-0.7%\u001B[0m |\n",
      "|          | 1e-06: 84.3%, \u001B[91m0.0%\u001B[0m  |\n",
      "|          | 5e-05: 84.6%, \u001B[92m+\u001B[0m\u001B[92m0.3%\u001B[0m |\n",
      "+----------+---------------------+\n",
      "Maximum prior accuracy: {'max_prior': 84.3, 'main_lr': 1e-05, 'secondary_model_name': 'vit_b_16', 'secondary_lr': 1e-05}\n",
      "\n",
      "\n",
      "Main model: Coarse-grain vit_l_16, secondary granularity: fine\n",
      "+----------+---------------------+---------------------+---------------------+\n",
      "|          | 1e-05 (84.3%)       | 1e-06 (74.0%)       | 5e-05 (83.7%)       |\n",
      "+==========+=====================+=====================+=====================+\n",
      "| vit_b_16 | 1e-05: 84.1%, \u001B[91m-0.2%\u001B[0m | 1e-05: 76.0%, \u001B[92m+\u001B[0m\u001B[92m2.0%\u001B[0m | 1e-05: 83.5%, \u001B[91m-0.2%\u001B[0m |\n",
      "|          | 1e-06: 84.4%, \u001B[92m+\u001B[0m\u001B[92m0.1%\u001B[0m | 1e-06: 77.5%, \u001B[92m+\u001B[0m\u001B[92m3.5%\u001B[0m | 1e-06: 83.8%, \u001B[92m+\u001B[0m\u001B[92m0.1%\u001B[0m |\n",
      "|          | 5e-05: 85.4%, \u001B[92m+\u001B[0m\u001B[92m1.1%\u001B[0m | 5e-05: 76.5%, \u001B[92m+\u001B[0m\u001B[92m2.5%\u001B[0m | 5e-05: 84.7%, \u001B[92m+\u001B[0m\u001B[92m1.0%\u001B[0m |\n",
      "+----------+---------------------+---------------------+---------------------+\n",
      "| vit_b_32 | 1e-05: 83.6%, \u001B[91m-0.7%\u001B[0m | 1e-05: 74.2%, \u001B[92m+\u001B[0m\u001B[92m0.2%\u001B[0m | 1e-05: 83.2%, \u001B[91m-0.5%\u001B[0m |\n",
      "|          | 1e-06: 84.6%, \u001B[92m+\u001B[0m\u001B[92m0.3%\u001B[0m | 1e-06: 75.8%, \u001B[92m+\u001B[0m\u001B[92m1.8%\u001B[0m | 1e-06: 84.0%, \u001B[92m+\u001B[0m\u001B[92m0.3%\u001B[0m |\n",
      "|          | 5e-05: 84.5%, \u001B[92m+\u001B[0m\u001B[92m0.2%\u001B[0m | 5e-05: 75.1%, \u001B[92m+\u001B[0m\u001B[92m1.1%\u001B[0m | 5e-05: 83.7%, \u001B[91m0.0%\u001B[0m  |\n",
      "+----------+---------------------+---------------------+---------------------+\n",
      "| vit_l_32 | 1e-05: 84.9%, \u001B[92m+\u001B[0m\u001B[92m0.6%\u001B[0m | 1e-05: 75.2%, \u001B[92m+\u001B[0m\u001B[92m1.2%\u001B[0m | 1e-05: 83.9%, \u001B[92m+\u001B[0m\u001B[92m0.2%\u001B[0m |\n",
      "|          | 1e-06: 84.3%, \u001B[91m0.0%\u001B[0m  | 1e-06: 76.7%, \u001B[92m+\u001B[0m\u001B[92m2.7%\u001B[0m | 1e-06: 83.5%, \u001B[91m-0.2%\u001B[0m |\n",
      "|          | 5e-05: 84.1%, \u001B[91m-0.2%\u001B[0m | 5e-05: 74.6%, \u001B[92m+\u001B[0m\u001B[92m0.6%\u001B[0m | 5e-05: 82.2%, \u001B[91m-1.5%\u001B[0m |\n",
      "+----------+---------------------+---------------------+---------------------+\n",
      "Maximum prior accuracy: {'max_prior': 84.3, 'main_lr': 1e-05, 'secondary_model_name': 'vit_b_16', 'secondary_lr': 1e-05}\n",
      "\n",
      "\n",
      "Main model: Coarse-grain vit_l_16 with both fine and coarse grain secondary models\n",
      "+----------+---------------------+---------------------+---------------------+\n",
      "|          | 1e-06 (74.0%)       | 1e-05 (84.3%)       | 5e-05 (83.7%)       |\n",
      "+==========+=====================+=====================+=====================+\n",
      "| vit_b_16 | 1e-05: 84.1%, \u001B[91m-0.2%\u001B[0m | 1e-05: 78.1%, \u001B[92m+\u001B[0m\u001B[92m4.1%\u001B[0m | 1e-05: 83.4%, \u001B[91m-0.3%\u001B[0m |\n",
      "|          | 1e-06: 84.4%, \u001B[92m+\u001B[0m\u001B[92m0.1%\u001B[0m | 1e-06: 77.5%, \u001B[92m+\u001B[0m\u001B[92m3.5%\u001B[0m | 1e-06: 83.8%, \u001B[92m+\u001B[0m\u001B[92m0.1%\u001B[0m |\n",
      "|          | 5e-05: 84.9%, \u001B[92m+\u001B[0m\u001B[92m0.6%\u001B[0m | 5e-05: 83.8%, \u001B[92m+\u001B[0m\u001B[92m9.8%\u001B[0m | 5e-05: 85.4%, \u001B[92m+\u001B[0m\u001B[92m1.7%\u001B[0m |\n",
      "+----------+---------------------+---------------------+---------------------+\n",
      "| vit_b_32 | 1e-05: 83.3%, \u001B[91m-1.0%\u001B[0m | 1e-05: 76.8%, \u001B[92m+\u001B[0m\u001B[92m2.8%\u001B[0m | 1e-05: 82.7%, \u001B[91m-1.0%\u001B[0m |\n",
      "|          | 1e-06: 84.6%, \u001B[92m+\u001B[0m\u001B[92m0.3%\u001B[0m | 1e-06: 75.8%, \u001B[92m+\u001B[0m\u001B[92m1.8%\u001B[0m | 1e-06: 84.0%, \u001B[92m+\u001B[0m\u001B[92m0.3%\u001B[0m |\n",
      "|          | 5e-05: 84.5%, \u001B[92m+\u001B[0m\u001B[92m0.2%\u001B[0m | 5e-05: 76.4%, \u001B[92m+\u001B[0m\u001B[92m2.4%\u001B[0m | 5e-05: 83.3%, \u001B[91m-0.4%\u001B[0m |\n",
      "+----------+---------------------+---------------------+---------------------+\n",
      "| vit_l_32 | 1e-05: 84.1%, \u001B[91m-0.2%\u001B[0m | 1e-05: 76.7%, \u001B[92m+\u001B[0m\u001B[92m2.7%\u001B[0m | 1e-05: 84.5%, \u001B[92m+\u001B[0m\u001B[92m0.8%\u001B[0m |\n",
      "|          | 1e-06: 84.3%, \u001B[91m0.0%\u001B[0m  | 1e-06: 75.9%, \u001B[92m+\u001B[0m\u001B[92m1.9%\u001B[0m | 1e-06: 83.5%, \u001B[91m-0.2%\u001B[0m |\n",
      "|          | 5e-05: 84.9%, \u001B[92m+\u001B[0m\u001B[92m0.6%\u001B[0m | 5e-05: 78.3%, \u001B[92m+\u001B[0m\u001B[92m4.3%\u001B[0m | 5e-05: 83.5%, \u001B[91m-0.2%\u001B[0m |\n",
      "+----------+---------------------+---------------------+---------------------+\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Main model: Coarse-grain vit_l_32, secondary granularity: coarse\n",
      "+----------+---------------------+----------------------+\n",
      "|          | 1e-05 (79.2%)       | 1e-06 (59.5%)        |\n",
      "+==========+=====================+======================+\n",
      "| vit_b_16 | 1e-05: 80.4%, \u001B[92m+\u001B[0m\u001B[92m1.2%\u001B[0m | 1e-06: 63.2%, \u001B[92m+\u001B[0m\u001B[92m3.7%\u001B[0m  |\n",
      "|          | 1e-06: 79.2%, \u001B[91m0.0%\u001B[0m  | 5e-05: 76.2%, \u001B[92m+\u001B[0m\u001B[92m16.7%\u001B[0m |\n",
      "|          | 5e-05: 79.8%, \u001B[92m+\u001B[0m\u001B[92m0.6%\u001B[0m |                      |\n",
      "+----------+---------------------+----------------------+\n",
      "| vit_b_32 | 1e-05: 78.9%, \u001B[91m-0.3%\u001B[0m | 1e-05: 72.8%, \u001B[92m+\u001B[0m\u001B[92m13.3%\u001B[0m |\n",
      "|          | 1e-06: 77.6%, \u001B[91m-1.6%\u001B[0m | 5e-05: 70.6%, \u001B[92m+\u001B[0m\u001B[92m11.1%\u001B[0m |\n",
      "|          | 5e-05: 79.1%, \u001B[91m-0.1%\u001B[0m |                      |\n",
      "+----------+---------------------+----------------------+\n",
      "| vit_l_16 | 1e-05: 80.5%, \u001B[92m+\u001B[0m\u001B[92m1.3%\u001B[0m | 1e-05: 76.7%, \u001B[92m+\u001B[0m\u001B[92m17.2%\u001B[0m |\n",
      "|          | 1e-06: 78.3%, \u001B[91m-0.9%\u001B[0m | 1e-06: 68.1%, \u001B[92m+\u001B[0m\u001B[92m8.6%\u001B[0m  |\n",
      "|          | 5e-05: 82.7%, \u001B[92m+\u001B[0m\u001B[92m3.5%\u001B[0m | 5e-05: 75.9%, \u001B[92m+\u001B[0m\u001B[92m16.4%\u001B[0m |\n",
      "+----------+---------------------+----------------------+\n",
      "Maximum prior accuracy: {'max_prior': 79.2, 'main_lr': 1e-05, 'secondary_model_name': 'vit_b_16', 'secondary_lr': 1e-05}\n",
      "\n",
      "\n",
      "Main model: Coarse-grain vit_l_32, secondary granularity: fine\n",
      "+----------+---------------------+----------------------+---------------------+\n",
      "|          | 1e-05 (79.2%)       | 1e-06 (59.5%)        | 5e-05 (80.8%)       |\n",
      "+==========+=====================+======================+=====================+\n",
      "| vit_b_16 | 1e-05: 79.8%, \u001B[92m+\u001B[0m\u001B[92m0.6%\u001B[0m | 1e-05: 68.9%, \u001B[92m+\u001B[0m\u001B[92m9.4%\u001B[0m  | 1e-05: 78.7%, \u001B[91m-2.1%\u001B[0m |\n",
      "|          | 1e-06: 80.0%, \u001B[92m+\u001B[0m\u001B[92m0.8%\u001B[0m | 1e-06: 71.5%, \u001B[92m+\u001B[0m\u001B[92m12.0%\u001B[0m | 1e-06: 80.1%, \u001B[91m-0.7%\u001B[0m |\n",
      "|          | 5e-05: 80.3%, \u001B[92m+\u001B[0m\u001B[92m1.1%\u001B[0m | 5e-05: 68.9%, \u001B[92m+\u001B[0m\u001B[92m9.4%\u001B[0m  | 5e-05: 79.8%, \u001B[91m-1.0%\u001B[0m |\n",
      "+----------+---------------------+----------------------+---------------------+\n",
      "| vit_b_32 | 1e-05: 79.0%, \u001B[91m-0.2%\u001B[0m | 1e-05: 66.3%, \u001B[92m+\u001B[0m\u001B[92m6.8%\u001B[0m  | 1e-05: 79.3%, \u001B[91m-1.5%\u001B[0m |\n",
      "|          | 1e-06: 78.8%, \u001B[91m-0.4%\u001B[0m | 1e-06: 69.0%, \u001B[92m+\u001B[0m\u001B[92m9.5%\u001B[0m  | 1e-06: 79.6%, \u001B[91m-1.2%\u001B[0m |\n",
      "|          | 5e-05: 79.6%, \u001B[92m+\u001B[0m\u001B[92m0.4%\u001B[0m | 5e-05: 65.8%, \u001B[92m+\u001B[0m\u001B[92m6.3%\u001B[0m  | 5e-05: 79.8%, \u001B[91m-1.0%\u001B[0m |\n",
      "+----------+---------------------+----------------------+---------------------+\n",
      "| vit_l_16 | 1e-05: 80.2%, \u001B[92m+\u001B[0m\u001B[92m1.0%\u001B[0m | 1e-05: 70.0%, \u001B[92m+\u001B[0m\u001B[92m10.5%\u001B[0m | 1e-05: 80.6%, \u001B[91m-0.2%\u001B[0m |\n",
      "|          | 1e-06: 79.8%, \u001B[92m+\u001B[0m\u001B[92m0.6%\u001B[0m | 1e-06: 69.5%, \u001B[92m+\u001B[0m\u001B[92m10.0%\u001B[0m | 1e-06: 78.9%, \u001B[91m-1.9%\u001B[0m |\n",
      "|          | 5e-05: 80.7%, \u001B[92m+\u001B[0m\u001B[92m1.5%\u001B[0m | 5e-05: 70.3%, \u001B[92m+\u001B[0m\u001B[92m10.8%\u001B[0m | 5e-05: 79.7%, \u001B[91m-1.1%\u001B[0m |\n",
      "+----------+---------------------+----------------------+---------------------+\n",
      "Maximum prior accuracy: {'max_prior': 80.8, 'main_lr': 5e-05, 'secondary_model_name': 'vit_b_16', 'secondary_lr': 1e-05}\n",
      "\n",
      "\n",
      "Main model: Coarse-grain vit_l_32 with both fine and coarse grain secondary models\n",
      "+----------+---------------------+----------------------+---------------------+\n",
      "|          | 1e-06 (59.5%)       | 1e-05 (79.2%)        | 5e-05 (80.8%)       |\n",
      "+==========+=====================+======================+=====================+\n",
      "| vit_b_16 | 1e-05: 81.2%, \u001B[92m+\u001B[0m\u001B[92m2.0%\u001B[0m | 1e-05: 68.3%, \u001B[92m+\u001B[0m\u001B[92m8.8%\u001B[0m  | 1e-05: 79.5%, \u001B[91m-1.3%\u001B[0m |\n",
      "|          | 1e-06: 80.0%, \u001B[92m+\u001B[0m\u001B[92m0.8%\u001B[0m | 1e-06: 65.1%, \u001B[92m+\u001B[0m\u001B[92m5.6%\u001B[0m  | 1e-06: 80.1%, \u001B[91m-0.7%\u001B[0m |\n",
      "|          | 5e-05: 81.6%, \u001B[92m+\u001B[0m\u001B[92m2.4%\u001B[0m | 5e-05: 75.5%, \u001B[92m+\u001B[0m\u001B[92m16.0%\u001B[0m | 5e-05: 81.2%, \u001B[92m+\u001B[0m\u001B[92m0.4%\u001B[0m |\n",
      "+----------+---------------------+----------------------+---------------------+\n",
      "| vit_b_32 | 1e-05: 79.4%, \u001B[92m+\u001B[0m\u001B[92m0.2%\u001B[0m | 1e-05: 67.0%, \u001B[92m+\u001B[0m\u001B[92m7.5%\u001B[0m  | 1e-05: 79.3%, \u001B[91m-1.5%\u001B[0m |\n",
      "|          | 1e-06: 78.5%, \u001B[91m-0.7%\u001B[0m | 1e-06: 63.0%, \u001B[92m+\u001B[0m\u001B[92m3.5%\u001B[0m  | 1e-06: 79.6%, \u001B[91m-1.2%\u001B[0m |\n",
      "|          | 5e-05: 80.0%, \u001B[92m+\u001B[0m\u001B[92m0.8%\u001B[0m | 5e-05: 69.4%, \u001B[92m+\u001B[0m\u001B[92m9.9%\u001B[0m  | 5e-05: 79.4%, \u001B[91m-1.4%\u001B[0m |\n",
      "+----------+---------------------+----------------------+---------------------+\n",
      "| vit_l_16 | 1e-05: 79.5%, \u001B[92m+\u001B[0m\u001B[92m0.3%\u001B[0m | 1e-05: 67.8%, \u001B[92m+\u001B[0m\u001B[92m8.3%\u001B[0m  | 1e-05: 80.4%, \u001B[91m-0.4%\u001B[0m |\n",
      "|          | 1e-06: 79.9%, \u001B[92m+\u001B[0m\u001B[92m0.7%\u001B[0m | 1e-06: 67.8%, \u001B[92m+\u001B[0m\u001B[92m8.3%\u001B[0m  | 1e-06: 78.9%, \u001B[91m-1.9%\u001B[0m |\n",
      "|          | 5e-05: 82.2%, \u001B[92m+\u001B[0m\u001B[92m3.0%\u001B[0m | 5e-05: 70.5%, \u001B[92m+\u001B[0m\u001B[92m11.0%\u001B[0m | 5e-05: 80.5%, \u001B[91m-0.3%\u001B[0m |\n",
      "+----------+---------------------+----------------------+---------------------+\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "######################################## Main granularity: fine ########################################\n",
      "########################################################################################################\n",
      "\n",
      "Main model: Fine-grain vit_b_16, secondary granularity: coarse\n",
      "+----------+--------------------+--------------------+--------------------+\n",
      "|          | 1e-05 (63.9%)      | 1e-06 (70.0%)      | 5e-05 (64.5%)      |\n",
      "+==========+====================+====================+====================+\n",
      "| vit_b_32 | 1e-05: 63.9%, \u001B[91m0.0%\u001B[0m | 1e-05: 70.0%, \u001B[91m0.0%\u001B[0m | 1e-05: 64.5%, \u001B[91m0.0%\u001B[0m |\n",
      "|          | 1e-06: 63.9%, \u001B[91m0.0%\u001B[0m | 1e-06: 70.0%, \u001B[91m0.0%\u001B[0m | 1e-06: 64.5%, \u001B[91m0.0%\u001B[0m |\n",
      "|          | 5e-05: 63.9%, \u001B[91m0.0%\u001B[0m | 5e-05: 70.0%, \u001B[91m0.0%\u001B[0m | 5e-05: 64.5%, \u001B[91m0.0%\u001B[0m |\n",
      "+----------+--------------------+--------------------+--------------------+\n",
      "| vit_l_16 | 1e-05: 63.9%, \u001B[91m0.0%\u001B[0m | 1e-05: 70.0%, \u001B[91m0.0%\u001B[0m | 1e-05: 64.5%, \u001B[91m0.0%\u001B[0m |\n",
      "|          | 1e-06: 63.9%, \u001B[91m0.0%\u001B[0m | 1e-06: 70.0%, \u001B[91m0.0%\u001B[0m | 1e-06: 64.5%, \u001B[91m0.0%\u001B[0m |\n",
      "|          | 5e-05: 63.9%, \u001B[91m0.0%\u001B[0m | 5e-05: 70.0%, \u001B[91m0.0%\u001B[0m | 5e-05: 64.5%, \u001B[91m0.0%\u001B[0m |\n",
      "+----------+--------------------+--------------------+--------------------+\n",
      "| vit_l_32 | 1e-05: 63.9%, \u001B[91m0.0%\u001B[0m | 1e-05: 70.0%, \u001B[91m0.0%\u001B[0m | 1e-05: 64.5%, \u001B[91m0.0%\u001B[0m |\n",
      "|          | 1e-06: 63.9%, \u001B[91m0.0%\u001B[0m | 1e-06: 70.0%, \u001B[91m0.0%\u001B[0m | 1e-06: 64.5%, \u001B[91m0.0%\u001B[0m |\n",
      "|          | 5e-05: 63.9%, \u001B[91m0.0%\u001B[0m | 5e-05: 70.0%, \u001B[91m0.0%\u001B[0m | 5e-05: 64.5%, \u001B[91m0.0%\u001B[0m |\n",
      "+----------+--------------------+--------------------+--------------------+\n",
      "Maximum prior accuracy: {'max_prior': 70.0, 'main_lr': 1e-06, 'secondary_model_name': 'vit_b_32', 'secondary_lr': 1e-05}\n",
      "\n",
      "\n",
      "Main model: Fine-grain vit_b_16, secondary granularity: fine\n",
      "+----------+---------------------+---------------------+---------------------+\n",
      "|          | 1e-05 (63.9%)       | 1e-06 (70.0%)       | 5e-05 (64.5%)       |\n",
      "+==========+=====================+=====================+=====================+\n",
      "| vit_b_32 | 1e-05: 63.7%, \u001B[91m-0.2%\u001B[0m | 1e-05: 70.0%, \u001B[91m0.0%\u001B[0m  | 1e-05: 64.5%, \u001B[91m0.0%\u001B[0m  |\n",
      "|          | 1e-06: 65.0%, \u001B[92m+\u001B[0m\u001B[92m1.1%\u001B[0m | 1e-06: 70.0%, \u001B[91m0.0%\u001B[0m  | 1e-06: 64.3%, \u001B[91m-0.2%\u001B[0m |\n",
      "|          | 5e-05: 63.8%, \u001B[91m-0.1%\u001B[0m | 5e-05: 69.8%, \u001B[91m-0.2%\u001B[0m | 5e-05: 64.1%, \u001B[91m-0.4%\u001B[0m |\n",
      "+----------+---------------------+---------------------+---------------------+\n",
      "| vit_l_16 | 1e-05: 65.5%, \u001B[92m+\u001B[0m\u001B[92m1.6%\u001B[0m | 1e-05: 70.0%, \u001B[91m0.0%\u001B[0m  | 1e-05: 65.0%, \u001B[92m+\u001B[0m\u001B[92m0.5%\u001B[0m |\n",
      "|          | 1e-06: 66.1%, \u001B[92m+\u001B[0m\u001B[92m2.2%\u001B[0m | 1e-06: 70.3%, \u001B[92m+\u001B[0m\u001B[92m0.3%\u001B[0m | 1e-06: 64.6%, \u001B[92m+\u001B[0m\u001B[92m0.1%\u001B[0m |\n",
      "|          | 5e-05: 65.8%, \u001B[92m+\u001B[0m\u001B[92m1.9%\u001B[0m | 5e-05: 70.6%, \u001B[92m+\u001B[0m\u001B[92m0.6%\u001B[0m | 5e-05: 65.7%, \u001B[92m+\u001B[0m\u001B[92m1.2%\u001B[0m |\n",
      "+----------+---------------------+---------------------+---------------------+\n",
      "| vit_l_32 | 1e-05: 64.2%, \u001B[92m+\u001B[0m\u001B[92m0.3%\u001B[0m | 1e-05: 69.9%, \u001B[91m-0.1%\u001B[0m | 1e-05: 64.7%, \u001B[92m+\u001B[0m\u001B[92m0.2%\u001B[0m |\n",
      "|          | 1e-06: 64.9%, \u001B[92m+\u001B[0m\u001B[92m1.0%\u001B[0m | 1e-06: 70.0%, \u001B[91m0.0%\u001B[0m  | 1e-06: 64.8%, \u001B[92m+\u001B[0m\u001B[92m0.3%\u001B[0m |\n",
      "|          | 5e-05: 64.2%, \u001B[92m+\u001B[0m\u001B[92m0.3%\u001B[0m | 5e-05: 69.9%, \u001B[91m-0.1%\u001B[0m | 5e-05: 64.3%, \u001B[91m-0.2%\u001B[0m |\n",
      "+----------+---------------------+---------------------+---------------------+\n",
      "Maximum prior accuracy: {'max_prior': 70.0, 'main_lr': 1e-06, 'secondary_model_name': 'vit_b_32', 'secondary_lr': 1e-05}\n",
      "\n",
      "\n",
      "Main model: Fine-grain vit_b_16 with both fine and coarse grain secondary models\n",
      "+----------+---------------------+---------------------+---------------------+\n",
      "|          | 1e-06 (70.0%)       | 1e-05 (63.9%)       | 5e-05 (64.5%)       |\n",
      "+==========+=====================+=====================+=====================+\n",
      "| vit_b_32 | 1e-05: 63.0%, \u001B[91m-0.9%\u001B[0m | 1e-05: 69.5%, \u001B[91m-0.5%\u001B[0m | 1e-05: 64.4%, \u001B[91m-0.1%\u001B[0m |\n",
      "|          | 1e-06: 65.2%, \u001B[92m+\u001B[0m\u001B[92m1.3%\u001B[0m | 1e-06: 69.8%, \u001B[91m-0.2%\u001B[0m | 1e-06: 63.7%, \u001B[91m-0.8%\u001B[0m |\n",
      "|          | 5e-05: 63.0%, \u001B[91m-0.9%\u001B[0m | 5e-05: 69.8%, \u001B[91m-0.2%\u001B[0m | 5e-05: 62.8%, \u001B[91m-1.7%\u001B[0m |\n",
      "+----------+---------------------+---------------------+---------------------+\n",
      "| vit_l_16 | 1e-05: 66.9%, \u001B[92m+\u001B[0m\u001B[92m3.0%\u001B[0m | 1e-05: 70.8%, \u001B[92m+\u001B[0m\u001B[92m0.8%\u001B[0m | 1e-05: 64.8%, \u001B[92m+\u001B[0m\u001B[92m0.3%\u001B[0m |\n",
      "|          | 1e-06: 68.2%, \u001B[92m+\u001B[0m\u001B[92m4.3%\u001B[0m | 1e-06: 70.7%, \u001B[92m+\u001B[0m\u001B[92m0.7%\u001B[0m | 1e-06: 65.1%, \u001B[92m+\u001B[0m\u001B[92m0.6%\u001B[0m |\n",
      "|          | 5e-05: 67.7%, \u001B[92m+\u001B[0m\u001B[92m3.8%\u001B[0m | 5e-05: 71.7%, \u001B[92m+\u001B[0m\u001B[92m1.7%\u001B[0m | 5e-05: 64.8%, \u001B[92m+\u001B[0m\u001B[92m0.3%\u001B[0m |\n",
      "+----------+---------------------+---------------------+---------------------+\n",
      "| vit_l_32 | 1e-05: 64.2%, \u001B[92m+\u001B[0m\u001B[92m0.3%\u001B[0m | 1e-05: 69.5%, \u001B[91m-0.5%\u001B[0m | 1e-05: 64.0%, \u001B[91m-0.5%\u001B[0m |\n",
      "|          | 1e-06: 65.3%, \u001B[92m+\u001B[0m\u001B[92m1.4%\u001B[0m | 1e-06: 69.8%, \u001B[91m-0.2%\u001B[0m | 1e-06: 65.1%, \u001B[92m+\u001B[0m\u001B[92m0.6%\u001B[0m |\n",
      "|          | 5e-05: 64.3%, \u001B[92m+\u001B[0m\u001B[92m0.4%\u001B[0m | 5e-05: 69.2%, \u001B[91m-0.8%\u001B[0m | 5e-05: 64.0%, \u001B[91m-0.5%\u001B[0m |\n",
      "+----------+---------------------+---------------------+---------------------+\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Main model: Fine-grain vit_b_32, secondary granularity: coarse\n",
      "+----------+---------------------+---------------------+--------------------+\n",
      "|          | 1e-05 (55.9%)       | 1e-06 (63.7%)       | 5e-05 (53.7%)      |\n",
      "+==========+=====================+=====================+====================+\n",
      "| vit_b_16 | 1e-05: 55.9%, \u001B[91m0.0%\u001B[0m  | 1e-05: 63.7%, \u001B[91m0.0%\u001B[0m  | 1e-05: 53.7%, \u001B[91m0.0%\u001B[0m |\n",
      "|          | 1e-06: 55.9%, \u001B[91m0.0%\u001B[0m  | 1e-06: 63.7%, \u001B[91m0.0%\u001B[0m  | 1e-06: 53.7%, \u001B[91m0.0%\u001B[0m |\n",
      "|          | 5e-05: 55.9%, \u001B[91m0.0%\u001B[0m  | 5e-05: 63.7%, \u001B[91m0.0%\u001B[0m  | 5e-05: 53.7%, \u001B[91m0.0%\u001B[0m |\n",
      "+----------+---------------------+---------------------+--------------------+\n",
      "| vit_l_16 | 1e-05: 55.9%, \u001B[91m0.0%\u001B[0m  | 1e-05: 63.7%, \u001B[91m0.0%\u001B[0m  | 1e-05: 53.7%, \u001B[91m0.0%\u001B[0m |\n",
      "|          | 1e-06: 55.9%, \u001B[91m0.0%\u001B[0m  | 1e-06: 63.7%, \u001B[91m0.0%\u001B[0m  | 1e-06: 53.7%, \u001B[91m0.0%\u001B[0m |\n",
      "|          | 5e-05: 55.1%, \u001B[91m-0.8%\u001B[0m | 5e-05: 62.7%, \u001B[91m-1.0%\u001B[0m | 5e-05: 53.7%, \u001B[91m0.0%\u001B[0m |\n",
      "+----------+---------------------+---------------------+--------------------+\n",
      "| vit_l_32 | 1e-05: 55.9%, \u001B[91m0.0%\u001B[0m  | 1e-05: 63.7%, \u001B[91m0.0%\u001B[0m  | 1e-05: 53.7%, \u001B[91m0.0%\u001B[0m |\n",
      "|          | 1e-06: 55.9%, \u001B[91m0.0%\u001B[0m  | 1e-06: 63.7%, \u001B[91m0.0%\u001B[0m  | 1e-06: 53.7%, \u001B[91m0.0%\u001B[0m |\n",
      "|          | 5e-05: 55.2%, \u001B[91m-0.7%\u001B[0m | 5e-05: 63.0%, \u001B[91m-0.7%\u001B[0m | 5e-05: 53.7%, \u001B[91m0.0%\u001B[0m |\n",
      "+----------+---------------------+---------------------+--------------------+\n",
      "Maximum prior accuracy: {'max_prior': 63.7, 'main_lr': 1e-06, 'secondary_model_name': 'vit_b_16', 'secondary_lr': 1e-05}\n",
      "\n",
      "\n",
      "Main model: Fine-grain vit_b_32, secondary granularity: fine\n",
      "+----------+---------------------+---------------------+---------------------+\n",
      "|          | 1e-05 (55.9%)       | 1e-06 (63.7%)       | 5e-05 (53.7%)       |\n",
      "+==========+=====================+=====================+=====================+\n",
      "| vit_b_16 | 1e-05: 58.2%, \u001B[92m+\u001B[0m\u001B[92m2.3%\u001B[0m | 1e-05: 63.8%, \u001B[92m+\u001B[0m\u001B[92m0.1%\u001B[0m | 1e-05: 55.0%, \u001B[92m+\u001B[0m\u001B[92m1.3%\u001B[0m |\n",
      "|          | 1e-06: 59.7%, \u001B[92m+\u001B[0m\u001B[92m3.8%\u001B[0m | 1e-06: 65.8%, \u001B[92m+\u001B[0m\u001B[92m2.1%\u001B[0m | 1e-06: 56.3%, \u001B[92m+\u001B[0m\u001B[92m2.6%\u001B[0m |\n",
      "|          | 5e-05: 58.5%, \u001B[92m+\u001B[0m\u001B[92m2.6%\u001B[0m | 5e-05: 65.6%, \u001B[92m+\u001B[0m\u001B[92m1.9%\u001B[0m | 5e-05: 58.2%, \u001B[92m+\u001B[0m\u001B[92m4.5%\u001B[0m |\n",
      "+----------+---------------------+---------------------+---------------------+\n",
      "| vit_l_16 | 1e-05: 60.1%, \u001B[92m+\u001B[0m\u001B[92m4.2%\u001B[0m | 1e-05: 64.3%, \u001B[92m+\u001B[0m\u001B[92m0.6%\u001B[0m | 1e-05: 55.9%, \u001B[92m+\u001B[0m\u001B[92m2.2%\u001B[0m |\n",
      "|          | 1e-06: 59.8%, \u001B[92m+\u001B[0m\u001B[92m3.9%\u001B[0m | 1e-06: 64.3%, \u001B[92m+\u001B[0m\u001B[92m0.6%\u001B[0m | 1e-06: 58.5%, \u001B[92m+\u001B[0m\u001B[92m4.8%\u001B[0m |\n",
      "|          | 5e-05: 58.9%, \u001B[92m+\u001B[0m\u001B[92m3.0%\u001B[0m | 5e-05: 64.8%, \u001B[92m+\u001B[0m\u001B[92m1.1%\u001B[0m | 5e-05: 56.8%, \u001B[92m+\u001B[0m\u001B[92m3.1%\u001B[0m |\n",
      "+----------+---------------------+---------------------+---------------------+\n",
      "| vit_l_32 | 1e-05: 57.4%, \u001B[92m+\u001B[0m\u001B[92m1.5%\u001B[0m | 1e-05: 63.8%, \u001B[92m+\u001B[0m\u001B[92m0.1%\u001B[0m | 1e-05: 54.7%, \u001B[92m+\u001B[0m\u001B[92m1.0%\u001B[0m |\n",
      "|          | 1e-06: 58.3%, \u001B[92m+\u001B[0m\u001B[92m2.4%\u001B[0m | 1e-06: 64.1%, \u001B[92m+\u001B[0m\u001B[92m0.4%\u001B[0m | 1e-06: 55.0%, \u001B[92m+\u001B[0m\u001B[92m1.3%\u001B[0m |\n",
      "|          | 5e-05: 56.4%, \u001B[92m+\u001B[0m\u001B[92m0.5%\u001B[0m | 5e-05: 63.7%, \u001B[91m0.0%\u001B[0m  | 5e-05: 54.7%, \u001B[92m+\u001B[0m\u001B[92m1.0%\u001B[0m |\n",
      "+----------+---------------------+---------------------+---------------------+\n",
      "Maximum prior accuracy: {'max_prior': 63.7, 'main_lr': 1e-06, 'secondary_model_name': 'vit_b_16', 'secondary_lr': 1e-05}\n",
      "\n",
      "\n",
      "Main model: Fine-grain vit_b_32 with both fine and coarse grain secondary models\n",
      "+----------+----------------------+---------------------+----------------------+\n",
      "|          | 1e-06 (63.7%)        | 1e-05 (55.9%)       | 5e-05 (53.7%)        |\n",
      "+==========+======================+=====================+======================+\n",
      "| vit_b_16 | 1e-05: 60.8%, \u001B[92m+\u001B[0m\u001B[92m4.9%\u001B[0m  | 1e-05: 63.8%, \u001B[92m+\u001B[0m\u001B[92m0.1%\u001B[0m | 1e-05: 57.1%, \u001B[92m+\u001B[0m\u001B[92m3.4%\u001B[0m  |\n",
      "|          | 1e-06: 69.2%, \u001B[92m+\u001B[0m\u001B[92m13.3%\u001B[0m | 1e-06: 69.1%, \u001B[92m+\u001B[0m\u001B[92m5.4%\u001B[0m | 1e-06: 61.9%, \u001B[92m+\u001B[0m\u001B[92m8.2%\u001B[0m  |\n",
      "|          | 5e-05: 62.8%, \u001B[92m+\u001B[0m\u001B[92m6.9%\u001B[0m  | 5e-05: 67.2%, \u001B[92m+\u001B[0m\u001B[92m3.5%\u001B[0m | 5e-05: 63.7%, \u001B[92m+\u001B[0m\u001B[92m10.0%\u001B[0m |\n",
      "+----------+----------------------+---------------------+----------------------+\n",
      "| vit_l_16 | 1e-05: 65.7%, \u001B[92m+\u001B[0m\u001B[92m9.8%\u001B[0m  | 1e-05: 67.7%, \u001B[92m+\u001B[0m\u001B[92m4.0%\u001B[0m | 1e-05: 61.5%, \u001B[92m+\u001B[0m\u001B[92m7.8%\u001B[0m  |\n",
      "|          | 1e-06: 69.2%, \u001B[92m+\u001B[0m\u001B[92m13.3%\u001B[0m | 1e-06: 68.7%, \u001B[92m+\u001B[0m\u001B[92m5.0%\u001B[0m | 1e-06: 64.8%, \u001B[92m+\u001B[0m\u001B[92m11.1%\u001B[0m |\n",
      "|          | 5e-05: 65.6%, \u001B[92m+\u001B[0m\u001B[92m9.7%\u001B[0m  | 5e-05: 67.2%, \u001B[92m+\u001B[0m\u001B[92m3.5%\u001B[0m | 5e-05: 62.1%, \u001B[92m+\u001B[0m\u001B[92m8.4%\u001B[0m  |\n",
      "+----------+----------------------+---------------------+----------------------+\n",
      "| vit_l_32 | 1e-05: 58.9%, \u001B[92m+\u001B[0m\u001B[92m3.0%\u001B[0m  | 1e-05: 63.7%, \u001B[91m0.0%\u001B[0m  | 1e-05: 55.5%, \u001B[92m+\u001B[0m\u001B[92m1.8%\u001B[0m  |\n",
      "|          | 1e-06: 63.2%, \u001B[92m+\u001B[0m\u001B[92m7.3%\u001B[0m  | 1e-06: 65.9%, \u001B[92m+\u001B[0m\u001B[92m2.2%\u001B[0m | 1e-06: 59.5%, \u001B[92m+\u001B[0m\u001B[92m5.8%\u001B[0m  |\n",
      "|          | 5e-05: 59.7%, \u001B[92m+\u001B[0m\u001B[92m3.8%\u001B[0m  | 5e-05: 64.2%, \u001B[92m+\u001B[0m\u001B[92m0.5%\u001B[0m | 5e-05: 56.9%, \u001B[92m+\u001B[0m\u001B[92m3.2%\u001B[0m  |\n",
      "+----------+----------------------+---------------------+----------------------+\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Main model: Fine-grain vit_l_16, secondary granularity: coarse\n",
      "+----------+--------------------+---------------------+---------------------+\n",
      "|          | 1e-05 (70.0%)      | 1e-06 (70.3%)       | 5e-05 (66.2%)       |\n",
      "+==========+====================+=====================+=====================+\n",
      "| vit_b_16 | 1e-05: 70.0%, \u001B[91m0.0%\u001B[0m | 1e-05: 70.3%, \u001B[91m0.0%\u001B[0m  | 1e-05: 65.0%, \u001B[91m-1.2%\u001B[0m |\n",
      "|          | 1e-06: 70.0%, \u001B[91m0.0%\u001B[0m | 1e-06: 70.3%, \u001B[91m0.0%\u001B[0m  | 1e-06: 66.2%, \u001B[91m0.0%\u001B[0m  |\n",
      "|          | 5e-05: 70.0%, \u001B[91m0.0%\u001B[0m | 5e-05: 70.3%, \u001B[91m0.0%\u001B[0m  | 5e-05: 66.2%, \u001B[91m0.0%\u001B[0m  |\n",
      "+----------+--------------------+---------------------+---------------------+\n",
      "| vit_b_32 | 1e-05: 70.0%, \u001B[91m0.0%\u001B[0m | 1e-05: 70.3%, \u001B[91m0.0%\u001B[0m  | 1e-05: 65.4%, \u001B[91m-0.8%\u001B[0m |\n",
      "|          | 1e-06: 70.0%, \u001B[91m0.0%\u001B[0m | 1e-06: 70.3%, \u001B[91m0.0%\u001B[0m  | 1e-06: 66.2%, \u001B[91m0.0%\u001B[0m  |\n",
      "|          | 5e-05: 70.0%, \u001B[91m0.0%\u001B[0m | 5e-05: 69.6%, \u001B[91m-0.7%\u001B[0m | 5e-05: 65.6%, \u001B[91m-0.6%\u001B[0m |\n",
      "+----------+--------------------+---------------------+---------------------+\n",
      "| vit_l_32 | 1e-05: 70.0%, \u001B[91m0.0%\u001B[0m | 1e-05: 70.3%, \u001B[91m0.0%\u001B[0m  | 1e-05: 66.2%, \u001B[91m0.0%\u001B[0m  |\n",
      "|          | 1e-06: 70.0%, \u001B[91m0.0%\u001B[0m | 1e-06: 70.3%, \u001B[91m0.0%\u001B[0m  | 1e-06: 66.2%, \u001B[91m0.0%\u001B[0m  |\n",
      "|          | 5e-05: 70.0%, \u001B[91m0.0%\u001B[0m | 5e-05: 70.3%, \u001B[91m0.0%\u001B[0m  | 5e-05: 65.2%, \u001B[91m-1.0%\u001B[0m |\n",
      "+----------+--------------------+---------------------+---------------------+\n",
      "Maximum prior accuracy: {'max_prior': 70.3, 'main_lr': 1e-06, 'secondary_model_name': 'vit_b_16', 'secondary_lr': 1e-05}\n",
      "\n",
      "\n",
      "Main model: Fine-grain vit_l_16, secondary granularity: fine\n",
      "+----------+---------------------+---------------------+---------------------+\n",
      "|          | 1e-05 (70.0%)       | 1e-06 (70.3%)       | 5e-05 (66.2%)       |\n",
      "+==========+=====================+=====================+=====================+\n",
      "| vit_b_16 | 1e-05: 70.0%, \u001B[91m0.0%\u001B[0m  | 1e-05: 70.0%, \u001B[91m-0.3%\u001B[0m | 1e-05: 66.5%, \u001B[92m+\u001B[0m\u001B[92m0.3%\u001B[0m |\n",
      "|          | 1e-06: 69.9%, \u001B[91m-0.1%\u001B[0m | 1e-06: 71.4%, \u001B[92m+\u001B[0m\u001B[92m1.1%\u001B[0m | 1e-06: 67.1%, \u001B[92m+\u001B[0m\u001B[92m0.9%\u001B[0m |\n",
      "|          | 5e-05: 70.1%, \u001B[92m+\u001B[0m\u001B[92m0.1%\u001B[0m | 5e-05: 70.9%, \u001B[92m+\u001B[0m\u001B[92m0.6%\u001B[0m | 5e-05: 67.2%, \u001B[92m+\u001B[0m\u001B[92m1.0%\u001B[0m |\n",
      "+----------+---------------------+---------------------+---------------------+\n",
      "| vit_b_32 | 1e-05: 70.0%, \u001B[91m0.0%\u001B[0m  | 1e-05: 70.3%, \u001B[91m0.0%\u001B[0m  | 1e-05: 65.6%, \u001B[91m-0.6%\u001B[0m |\n",
      "|          | 1e-06: 70.0%, \u001B[91m0.0%\u001B[0m  | 1e-06: 71.1%, \u001B[92m+\u001B[0m\u001B[92m0.8%\u001B[0m | 1e-06: 65.7%, \u001B[91m-0.5%\u001B[0m |\n",
      "|          | 5e-05: 69.8%, \u001B[91m-0.2%\u001B[0m | 5e-05: 70.4%, \u001B[92m+\u001B[0m\u001B[92m0.1%\u001B[0m | 5e-05: 65.8%, \u001B[91m-0.4%\u001B[0m |\n",
      "+----------+---------------------+---------------------+---------------------+\n",
      "| vit_l_32 | 1e-05: 70.0%, \u001B[91m0.0%\u001B[0m  | 1e-05: 71.2%, \u001B[92m+\u001B[0m\u001B[92m0.9%\u001B[0m | 1e-05: 66.6%, \u001B[92m+\u001B[0m\u001B[92m0.4%\u001B[0m |\n",
      "|          | 1e-06: 70.2%, \u001B[92m+\u001B[0m\u001B[92m0.2%\u001B[0m | 1e-06: 70.7%, \u001B[92m+\u001B[0m\u001B[92m0.4%\u001B[0m | 1e-06: 66.7%, \u001B[92m+\u001B[0m\u001B[92m0.5%\u001B[0m |\n",
      "|          | 5e-05: 69.7%, \u001B[91m-0.3%\u001B[0m | 5e-05: 70.6%, \u001B[92m+\u001B[0m\u001B[92m0.3%\u001B[0m | 5e-05: 66.1%, \u001B[91m-0.1%\u001B[0m |\n",
      "+----------+---------------------+---------------------+---------------------+\n",
      "Maximum prior accuracy: {'max_prior': 70.3, 'main_lr': 1e-06, 'secondary_model_name': 'vit_b_16', 'secondary_lr': 1e-05}\n",
      "\n",
      "\n",
      "Main model: Fine-grain vit_l_16 with both fine and coarse grain secondary models\n",
      "+----------+---------------------+---------------------+---------------------+\n",
      "|          | 1e-06 (70.3%)       | 1e-05 (70.0%)       | 5e-05 (66.2%)       |\n",
      "+==========+=====================+=====================+=====================+\n",
      "| vit_b_16 | 1e-05: 69.5%, \u001B[91m-0.5%\u001B[0m | 1e-05: 69.3%, \u001B[91m-1.0%\u001B[0m | 1e-05: 65.5%, \u001B[91m-0.7%\u001B[0m |\n",
      "|          | 1e-06: 70.7%, \u001B[92m+\u001B[0m\u001B[92m0.7%\u001B[0m | 1e-06: 71.7%, \u001B[92m+\u001B[0m\u001B[92m1.4%\u001B[0m | 1e-06: 68.0%, \u001B[92m+\u001B[0m\u001B[92m1.8%\u001B[0m |\n",
      "|          | 5e-05: 70.3%, \u001B[92m+\u001B[0m\u001B[92m0.3%\u001B[0m | 5e-05: 70.8%, \u001B[92m+\u001B[0m\u001B[92m0.5%\u001B[0m | 5e-05: 67.2%, \u001B[92m+\u001B[0m\u001B[92m1.0%\u001B[0m |\n",
      "+----------+---------------------+---------------------+---------------------+\n",
      "| vit_b_32 | 1e-05: 70.0%, \u001B[91m0.0%\u001B[0m  | 1e-05: 69.5%, \u001B[91m-0.8%\u001B[0m | 1e-05: 64.8%, \u001B[91m-1.4%\u001B[0m |\n",
      "|          | 1e-06: 69.8%, \u001B[91m-0.2%\u001B[0m | 1e-06: 69.9%, \u001B[91m-0.4%\u001B[0m | 1e-06: 64.7%, \u001B[91m-1.5%\u001B[0m |\n",
      "|          | 5e-05: 69.8%, \u001B[91m-0.2%\u001B[0m | 5e-05: 69.6%, \u001B[91m-0.7%\u001B[0m | 5e-05: 64.2%, \u001B[91m-2.0%\u001B[0m |\n",
      "+----------+---------------------+---------------------+---------------------+\n",
      "| vit_l_32 | 1e-05: 70.0%, \u001B[91m0.0%\u001B[0m  | 1e-05: 70.7%, \u001B[92m+\u001B[0m\u001B[92m0.4%\u001B[0m | 1e-05: 65.1%, \u001B[91m-1.1%\u001B[0m |\n",
      "|          | 1e-06: 69.8%, \u001B[91m-0.2%\u001B[0m | 1e-06: 70.0%, \u001B[91m-0.3%\u001B[0m | 1e-06: 65.9%, \u001B[91m-0.3%\u001B[0m |\n",
      "|          | 5e-05: 69.2%, \u001B[91m-0.8%\u001B[0m | 5e-05: 70.2%, \u001B[91m-0.1%\u001B[0m | 5e-05: 63.7%, \u001B[91m-2.5%\u001B[0m |\n",
      "+----------+---------------------+---------------------+---------------------+\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Main model: Fine-grain vit_l_32, secondary granularity: coarse\n",
      "+----------+---------------------+---------------------+--------------------+\n",
      "|          | 1e-05 (58.2%)       | 1e-06 (67.3%)       | 5e-05 (62.4%)      |\n",
      "+==========+=====================+=====================+====================+\n",
      "| vit_b_16 | 1e-05: 57.9%, \u001B[91m-0.3%\u001B[0m | 1e-05: 67.3%, \u001B[91m0.0%\u001B[0m  | 1e-05: 62.4%, \u001B[91m0.0%\u001B[0m |\n",
      "|          | 1e-06: 58.2%, \u001B[91m0.0%\u001B[0m  | 1e-06: 67.3%, \u001B[91m0.0%\u001B[0m  | 1e-06: 62.4%, \u001B[91m0.0%\u001B[0m |\n",
      "|          | 5e-05: 57.9%, \u001B[91m-0.3%\u001B[0m | 5e-05: 67.3%, \u001B[91m0.0%\u001B[0m  | 5e-05: 62.4%, \u001B[91m0.0%\u001B[0m |\n",
      "+----------+---------------------+---------------------+--------------------+\n",
      "| vit_b_32 | 1e-05: 58.0%, \u001B[91m-0.2%\u001B[0m | 1e-05: 67.3%, \u001B[91m0.0%\u001B[0m  | 1e-05: 62.4%, \u001B[91m0.0%\u001B[0m |\n",
      "|          | 1e-06: 58.2%, \u001B[91m0.0%\u001B[0m  | 1e-06: 67.3%, \u001B[91m0.0%\u001B[0m  | 1e-06: 62.4%, \u001B[91m0.0%\u001B[0m |\n",
      "|          | 5e-05: 58.2%, \u001B[91m0.0%\u001B[0m  | 5e-05: 66.7%, \u001B[91m-0.6%\u001B[0m | 5e-05: 62.4%, \u001B[91m0.0%\u001B[0m |\n",
      "+----------+---------------------+---------------------+--------------------+\n",
      "| vit_l_16 | 1e-05: 57.4%, \u001B[91m-0.8%\u001B[0m | 1e-05: 67.3%, \u001B[91m0.0%\u001B[0m  | 1e-05: 62.4%, \u001B[91m0.0%\u001B[0m |\n",
      "|          | 1e-06: 58.2%, \u001B[91m0.0%\u001B[0m  | 1e-06: 67.3%, \u001B[91m0.0%\u001B[0m  | 1e-06: 62.4%, \u001B[91m0.0%\u001B[0m |\n",
      "|          | 5e-05: 57.7%, \u001B[91m-0.5%\u001B[0m | 5e-05: 67.3%, \u001B[91m0.0%\u001B[0m  | 5e-05: 62.4%, \u001B[91m0.0%\u001B[0m |\n",
      "+----------+---------------------+---------------------+--------------------+\n",
      "Maximum prior accuracy: {'max_prior': 67.3, 'main_lr': 1e-06, 'secondary_model_name': 'vit_b_16', 'secondary_lr': 1e-05}\n",
      "\n",
      "\n",
      "Main model: Fine-grain vit_l_32, secondary granularity: fine\n",
      "+----------+---------------------+---------------------+---------------------+\n",
      "|          | 1e-05 (58.2%)       | 1e-06 (67.3%)       | 5e-05 (62.4%)       |\n",
      "+==========+=====================+=====================+=====================+\n",
      "| vit_b_16 | 1e-05: 58.5%, \u001B[92m+\u001B[0m\u001B[92m0.3%\u001B[0m | 1e-05: 67.4%, \u001B[92m+\u001B[0m\u001B[92m0.1%\u001B[0m | 1e-05: 62.7%, \u001B[92m+\u001B[0m\u001B[92m0.3%\u001B[0m |\n",
      "|          | 1e-06: 61.1%, \u001B[92m+\u001B[0m\u001B[92m2.9%\u001B[0m | 1e-06: 68.0%, \u001B[92m+\u001B[0m\u001B[92m0.7%\u001B[0m | 1e-06: 65.0%, \u001B[92m+\u001B[0m\u001B[92m2.6%\u001B[0m |\n",
      "|          | 5e-05: 60.1%, \u001B[92m+\u001B[0m\u001B[92m1.9%\u001B[0m | 5e-05: 67.6%, \u001B[92m+\u001B[0m\u001B[92m0.3%\u001B[0m | 5e-05: 63.9%, \u001B[92m+\u001B[0m\u001B[92m1.5%\u001B[0m |\n",
      "+----------+---------------------+---------------------+---------------------+\n",
      "| vit_b_32 | 1e-05: 58.0%, \u001B[91m-0.2%\u001B[0m | 1e-05: 67.1%, \u001B[91m-0.2%\u001B[0m | 1e-05: 61.7%, \u001B[91m-0.7%\u001B[0m |\n",
      "|          | 1e-06: 59.4%, \u001B[92m+\u001B[0m\u001B[92m1.2%\u001B[0m | 1e-06: 67.1%, \u001B[91m-0.2%\u001B[0m | 1e-06: 63.9%, \u001B[92m+\u001B[0m\u001B[92m1.5%\u001B[0m |\n",
      "|          | 5e-05: 58.6%, \u001B[92m+\u001B[0m\u001B[92m0.4%\u001B[0m | 5e-05: 67.1%, \u001B[91m-0.2%\u001B[0m | 5e-05: 62.7%, \u001B[92m+\u001B[0m\u001B[92m0.3%\u001B[0m |\n",
      "+----------+---------------------+---------------------+---------------------+\n",
      "| vit_l_16 | 1e-05: 60.5%, \u001B[92m+\u001B[0m\u001B[92m2.3%\u001B[0m | 1e-05: 67.8%, \u001B[92m+\u001B[0m\u001B[92m0.5%\u001B[0m | 1e-05: 63.6%, \u001B[92m+\u001B[0m\u001B[92m1.2%\u001B[0m |\n",
      "|          | 1e-06: 60.6%, \u001B[92m+\u001B[0m\u001B[92m2.4%\u001B[0m | 1e-06: 68.3%, \u001B[92m+\u001B[0m\u001B[92m1.0%\u001B[0m | 1e-06: 63.7%, \u001B[92m+\u001B[0m\u001B[92m1.3%\u001B[0m |\n",
      "|          | 5e-05: 61.1%, \u001B[92m+\u001B[0m\u001B[92m2.9%\u001B[0m | 5e-05: 67.4%, \u001B[92m+\u001B[0m\u001B[92m0.1%\u001B[0m | 5e-05: 64.3%, \u001B[92m+\u001B[0m\u001B[92m1.9%\u001B[0m |\n",
      "+----------+---------------------+---------------------+---------------------+\n",
      "Maximum prior accuracy: {'max_prior': 67.3, 'main_lr': 1e-06, 'secondary_model_name': 'vit_b_16', 'secondary_lr': 1e-05}\n",
      "\n",
      "\n",
      "Main model: Fine-grain vit_l_32 with both fine and coarse grain secondary models\n",
      "+----------+---------------------+---------------------+---------------------+\n",
      "|          | 1e-06 (67.3%)       | 1e-05 (58.2%)       | 5e-05 (62.4%)       |\n",
      "+==========+=====================+=====================+=====================+\n",
      "| vit_b_16 | 1e-05: 58.6%, \u001B[92m+\u001B[0m\u001B[92m0.4%\u001B[0m | 1e-05: 67.6%, \u001B[92m+\u001B[0m\u001B[92m0.3%\u001B[0m | 1e-05: 63.5%, \u001B[92m+\u001B[0m\u001B[92m1.1%\u001B[0m |\n",
      "|          | 1e-06: 66.9%, \u001B[92m+\u001B[0m\u001B[92m8.7%\u001B[0m | 1e-06: 69.8%, \u001B[92m+\u001B[0m\u001B[92m2.5%\u001B[0m | 1e-06: 68.0%, \u001B[92m+\u001B[0m\u001B[92m5.6%\u001B[0m |\n",
      "|          | 5e-05: 64.3%, \u001B[92m+\u001B[0m\u001B[92m6.1%\u001B[0m | 5e-05: 67.9%, \u001B[92m+\u001B[0m\u001B[92m0.6%\u001B[0m | 5e-05: 63.7%, \u001B[92m+\u001B[0m\u001B[92m1.3%\u001B[0m |\n",
      "+----------+---------------------+---------------------+---------------------+\n",
      "| vit_b_32 | 1e-05: 58.3%, \u001B[92m+\u001B[0m\u001B[92m0.1%\u001B[0m | 1e-05: 66.9%, \u001B[91m-0.4%\u001B[0m | 1e-05: 61.6%, \u001B[91m-0.8%\u001B[0m |\n",
      "|          | 1e-06: 61.0%, \u001B[92m+\u001B[0m\u001B[92m2.8%\u001B[0m | 1e-06: 67.2%, \u001B[91m-0.1%\u001B[0m | 1e-06: 64.5%, \u001B[92m+\u001B[0m\u001B[92m2.1%\u001B[0m |\n",
      "|          | 5e-05: 58.9%, \u001B[92m+\u001B[0m\u001B[92m0.7%\u001B[0m | 5e-05: 66.1%, \u001B[91m-1.2%\u001B[0m | 5e-05: 62.0%, \u001B[91m-0.4%\u001B[0m |\n",
      "+----------+---------------------+---------------------+---------------------+\n",
      "| vit_l_16 | 1e-05: 66.9%, \u001B[92m+\u001B[0m\u001B[92m8.7%\u001B[0m | 1e-05: 69.8%, \u001B[92m+\u001B[0m\u001B[92m2.5%\u001B[0m | 1e-05: 66.4%, \u001B[92m+\u001B[0m\u001B[92m4.0%\u001B[0m |\n",
      "|          | 1e-06: 66.7%, \u001B[92m+\u001B[0m\u001B[92m8.5%\u001B[0m | 1e-06: 71.1%, \u001B[92m+\u001B[0m\u001B[92m3.8%\u001B[0m | 1e-06: 66.6%, \u001B[92m+\u001B[0m\u001B[92m4.2%\u001B[0m |\n",
      "|          | 5e-05: 66.9%, \u001B[92m+\u001B[0m\u001B[92m8.7%\u001B[0m | 5e-05: 68.9%, \u001B[92m+\u001B[0m\u001B[92m1.6%\u001B[0m | 5e-05: 65.7%, \u001B[92m+\u001B[0m\u001B[92m3.3%\u001B[0m |\n",
      "+----------+---------------------+---------------------+---------------------+\n",
      "\n",
      "\n",
      "####################################################################################################\n"
     ]
    }
   ],
   "source": [
    "def gather_EDCR_data() -> dict:\n",
    "    data = {} \n",
    "    \n",
    "    # Iterate through filenames to collect accuracy data\n",
    "    for filename in os.listdir(EDCR_pipeline.figs_folder):\n",
    "        secondary_granularity_match = re.match(\n",
    "            pattern='main_(fine|coarse)_(.+?)_lr(.+?)_secondary_(fine|coarse)_(.+?)_lr(.+)',\n",
    "            string=filename\n",
    "        )\n",
    "        \n",
    "        if secondary_granularity_match:\n",
    "            (   match,\n",
    "                main_granularity,\n",
    "                main_model_name,\n",
    "                main_lr,\n",
    "                secondary_granularity,\n",
    "                secondary_model_name,\n",
    "                secondary_lr\n",
    "            ) = (secondary_granularity_match.group(i) for i in range(7))\n",
    "            \n",
    "            main_suffix = '_coarse' if main_granularity == 'coarse' else ''\n",
    "            test_true = np.load(os.path.join(EDCR_pipeline.data_folder, f'test_true{main_suffix}.npy'))\n",
    "            \n",
    "            prior_predictions = np.load(os.path.join(EDCR_pipeline.data_folder, rf'{main_model_name}_test_pred_lr{main_lr}_e3{main_suffix}.npy'))\n",
    "            prior_acc = accuracy_score(y_true=test_true, \n",
    "                                       y_pred=prior_predictions)\n",
    "            \n",
    "            secondary_suffix = '_coarse' if secondary_granularity == 'coarse' else ''\n",
    "            post_predictions = np.load(f'figs/{match}/results{secondary_suffix}.npy')\n",
    "            posterior_acc = accuracy_score(y_true=test_true, \n",
    "                                           y_pred=post_predictions)\n",
    "\n",
    "            # Store accuracy data in the data dictionary\n",
    "            if main_granularity not in data:\n",
    "                data[main_granularity] = {}\n",
    "            if main_model_name not in data[main_granularity]:\n",
    "                data[main_granularity][main_model_name] = {}\n",
    "            if secondary_granularity not in data[main_granularity][main_model_name]:\n",
    "                data[main_granularity][main_model_name][secondary_granularity] = {}\n",
    "            if secondary_model_name not in data[main_granularity][main_model_name][secondary_granularity]:\n",
    "                data[main_granularity][main_model_name][secondary_granularity][secondary_model_name] = {}\n",
    "            if main_lr not in data[main_granularity][main_model_name][secondary_granularity][secondary_model_name]:\n",
    "                data[main_granularity][main_model_name][secondary_granularity][secondary_model_name][main_lr] = {}\n",
    "                \n",
    "            data[main_granularity][main_model_name][secondary_granularity][secondary_model_name][main_lr][secondary_lr] = \\\n",
    "                {'prior': prior_acc, 'post': posterior_acc}\n",
    "        \n",
    "        else:\n",
    "            no_secondary_granularity_match = re.match(pattern='main_(fine|coarse)_(.+)_lr(.+)_secondary_(.+)_lr(.+)',\n",
    "                                                      string=filename)\n",
    "            \n",
    "            if no_secondary_granularity_match:\n",
    "                \n",
    "                (\n",
    "                    match,\n",
    "                    main_granularity,\n",
    "                    main_model_name,\n",
    "                    main_lr,\n",
    "                    secondary_model_name,\n",
    "                    secondary_lr \n",
    "                ) = (no_secondary_granularity_match.group(i) for i in range(6))\n",
    "                \n",
    "                main_suffix = '_coarse' if main_granularity == 'coarse' else ''\n",
    "                test_true = np.load(os.path.join(EDCR_pipeline.data_folder, f'test_true{main_suffix}.npy'))\n",
    "                \n",
    "                prior_predictions = np.load(os.path.join(EDCR_pipeline.data_folder, rf'{main_model_name}_test_pred_lr{main_lr}_e3{main_suffix}.npy'))\n",
    "                prior_acc = accuracy_score(y_true=test_true, \n",
    "                                           y_pred=prior_predictions)\n",
    "                \n",
    "                try:\n",
    "                    post_predictions = np.load(f'figs/{match}/results.npy')\n",
    "                except FileNotFoundError:\n",
    "                    post_predictions = np.load(f'figs/{match}/results_coarse.npy')\n",
    "                    \n",
    "                posterior_acc = accuracy_score(y_true=test_true, \n",
    "                                               y_pred=post_predictions)\n",
    "    \n",
    "                if main_granularity not in data:\n",
    "                    data[main_granularity] = {}\n",
    "                if main_model_name not in data[main_granularity]:\n",
    "                    data[main_granularity][main_model_name] = {}\n",
    "                if secondary_model_name not in data[main_granularity][main_model_name]:\n",
    "                    data[main_granularity][main_model_name][secondary_model_name] = {}\n",
    "                if main_lr not in data[main_granularity][main_model_name][secondary_model_name]:\n",
    "                    data[main_granularity][main_model_name][secondary_model_name][main_lr] = {}\n",
    "                \n",
    "                data[main_granularity][main_model_name][secondary_model_name][main_lr][secondary_lr] = \\\n",
    "                    {'prior': prior_acc, 'post': posterior_acc}\n",
    "                \n",
    "    return data\n",
    "\n",
    "\n",
    "def get_row_addition(secondary_lr: float, \n",
    "                     curr_post: float, \n",
    "                     curr_diff: float,\n",
    "                     max_accuracy: float = None) -> str:\n",
    "    return (f\"{secondary_lr}: \"\n",
    "            + (utils.blue_text(curr_post) if max_accuracy is not None and abs(curr_post - max_accuracy) < 1e-5\n",
    "               else str(curr_post)) + '%, ' + \n",
    "            (utils.green_text('+') if curr_diff > 0 else '') + (utils.green_text(f'{curr_diff}%') if curr_diff > 0 \n",
    "                                                     else utils.red_text(f'{curr_diff}%')) + '\\n')\n",
    "\n",
    "\n",
    "def get_row_data(main_lr_data: dict,\n",
    "                 secondary_lr: float):\n",
    "    curr_data = main_lr_data[secondary_lr]\n",
    "    curr_post = round(curr_data['post'] * 100, 1)\n",
    "    curr_prior = round(curr_data['prior'] * 100, 1)\n",
    "    curr_diff = round(curr_post - curr_prior, 1)\n",
    "    row_additions = get_row_addition(secondary_lr=secondary_lr, \n",
    "                                     curr_post=curr_post, \n",
    "                                     curr_diff=curr_diff)\n",
    "    \n",
    "    return row_additions, curr_prior\n",
    "\n",
    "\n",
    "def highlight_max(table_data: list):\n",
    "    # Find the maximum accuracy value\n",
    "    max_accuracy = 0.0\n",
    "    cell_pattern = ('(.+): (.+)%, [+]*(.+)%\\n'\n",
    "                    '(.+): (.+)%, [+]*(.+)%\\n'\n",
    "                    '(.+): (.+)%, [+]*(.+)%')\n",
    "    \n",
    "    for row in table_data[1:]:  # Skip the header row\n",
    "        for cell in row[1:]:  # Skip the first element in each row (model names)\n",
    "            match = re.match(\n",
    "                    pattern=cell_pattern,\n",
    "                    string=ansiwrap.strip_color(cell))\n",
    "            \n",
    "            if match:\n",
    "                post_accuracies = [float(match.group(2 * i)) for i in range (1, 4)]\n",
    "                for post_accuracy in post_accuracies:\n",
    "                    if post_accuracy > max_accuracy:\n",
    "                        max_accuracy = post_accuracy\n",
    "\n",
    "    # Highlight the maximum accuracy value in blue\n",
    "    for i, row in enumerate(table_data):\n",
    "        if i > 0:\n",
    "            for j, cell in enumerate(row):\n",
    "                if j > 0:  # Skip the first element in each row (model names)\n",
    "                    match = re.match(\n",
    "                        pattern=cell_pattern,\n",
    "                        string=ansiwrap.strip_color(cell))\n",
    "                    \n",
    "                    if match:\n",
    "                        new_cell = ''\n",
    "                        for secondary_lr, curr_post, curr_diff in [(float(match.group(3 * i + j)) for j in range(1, 4)) \n",
    "                                                                   for i in range(3)]:\n",
    "                            new_cell += get_row_addition(secondary_lr=secondary_lr,\n",
    "                                                         curr_post=curr_post,\n",
    "                                                         curr_diff=curr_diff,\n",
    "                                                         max_accuracy=max_accuracy)\n",
    "                        \n",
    "                        table_data[i][j] = new_cell\n",
    "    \n",
    "    return table_data\n",
    "\n",
    "\n",
    "def print_one_secondary_granularity(main_model_data: dict,\n",
    "                                    k: str,\n",
    "                                    main_granularity: str,\n",
    "                                    main_model_name: str):\n",
    "\n",
    "    secondary_granularity_data = main_model_data[k]\n",
    "    main_learning_rates = sorted(secondary_granularity_data[list(secondary_granularity_data.keys())[0]].keys())\n",
    "    header = [''] + main_learning_rates\n",
    "    table_data = [header]\n",
    "    priors = {}\n",
    "\n",
    "    for secondary_model_name in sorted(secondary_granularity_data.keys()):\n",
    "        secondary_model_data = secondary_granularity_data[secondary_model_name]\n",
    "        row = [secondary_model_name]\n",
    "        \n",
    "        for main_lr in sorted(secondary_model_data.keys()):\n",
    "            main_lr_data = secondary_model_data[main_lr]\n",
    "            row_add = ''\n",
    "            \n",
    "            for secondary_lr in sorted(main_lr_data.keys()):\n",
    "                row_addition, curr_prior = get_row_data(main_lr_data=main_lr_data,\n",
    "                                                        secondary_lr=secondary_lr)\n",
    "                row_add += row_addition\n",
    "                priors[main_lr] = curr_prior\n",
    "                \n",
    "                    \n",
    "            row += [row_add]\n",
    "        table_data += [row]\n",
    "    \n",
    "    table_data[0] = [''] + [f'{main_lr} ({priors[main_lr]}%)' for main_lr in main_learning_rates]\n",
    "    # Rest of your code to create and print the table remains unchanged\n",
    "    table = tabulate.tabulate(\n",
    "        tabular_data=table_data, \n",
    "        headers='firstrow', \n",
    "        tablefmt='grid'\n",
    "    )\n",
    "    print(f\"Main model: {main_granularity.capitalize()}-grain {main_model_name}, \"\n",
    "          f\"secondary granularity: {k}\")\n",
    "    print(table)\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "def print_two_secondary_granularities(main_model_data: dict,\n",
    "                                      two_secondary_table_data: list,\n",
    "                                      k: str,\n",
    "                                      main_granularity: str,\n",
    "                                      main_model_name: str):\n",
    "    main_learning_rates = sorted(vit_pipeline.lrs)\n",
    "    \n",
    "    priors = {}\n",
    "    \n",
    "    # Initialize the table_data with header if it's empty\n",
    "    if len(two_secondary_table_data) == 0:\n",
    "        header = [''] + main_learning_rates\n",
    "        two_secondary_table_data += [header]\n",
    "        \n",
    "    secondary_model_data = main_model_data[k]\n",
    "    row = [k]\n",
    "    \n",
    "    for main_lr in sorted(secondary_model_data.keys()):\n",
    "        main_lr_data = secondary_model_data[main_lr]\n",
    "        row_add = ''\n",
    "        \n",
    "        for secondary_lr in sorted(main_lr_data.keys()):\n",
    "            row_addition, curr_prior = get_row_data(main_lr_data=main_lr_data,\n",
    "                                                    secondary_lr=secondary_lr)\n",
    "            row_add += row_addition\n",
    "            priors[main_lr] = curr_prior\n",
    "    \n",
    "        row += [row_add]\n",
    "\n",
    "    two_secondary_table_data += [row]\n",
    "    \n",
    "    # Modify the generated table data to highlight the cell with the maximal accuracy in blue\n",
    "    \n",
    "    if len(two_secondary_table_data) == len(main_learning_rates) + 1:\n",
    "        \n",
    "        two_secondary_table_data[0] = [''] + [f'{main_lr} ({priors[str(main_lr)]}%)' for main_lr in main_learning_rates]\n",
    "        \n",
    "        # Create the table using tabulate\n",
    "        table = tabulate.tabulate(\n",
    "            tabular_data=two_secondary_table_data,\n",
    "            headers='firstrow',\n",
    "            tablefmt='grid'\n",
    "        )\n",
    "        \n",
    "        # Print the main model name and the corresponding table\n",
    "        print(f\"Main model: {main_granularity.capitalize()}-grain {main_model_name} \"\n",
    "              f\"with both fine and coarse grain secondary models\")\n",
    "        print(table)\n",
    "        print(\"\\n\")\n",
    "    else:\n",
    "        return two_secondary_table_data\n",
    "\n",
    "\n",
    "def print_EDCR_tables():\n",
    "    data = gather_EDCR_data()\n",
    "    \n",
    "    for main_granularity in sorted(data.keys()):\n",
    "        \n",
    "        print('#' * 40 + f' Main granularity: {main_granularity} ' + '#' * 40 + '\\n' + '#' * 104 + '\\n')\n",
    "        main_granularity_data = data[main_granularity]\n",
    "        \n",
    "        for main_model_name in sorted(main_granularity_data.keys()):\n",
    "            main_model_data = main_granularity_data[main_model_name]\n",
    "            two_secondary_table_data = []\n",
    "\n",
    "            for k in (sorted(set(main_model_data.keys()).intersection(data_preprocessing.granularities.values())) + \n",
    "                      sorted(set(main_model_data.keys()).intersection(vit_pipeline.vit_model_names))):\n",
    "            \n",
    "                if k in data_preprocessing.granularities.values():\n",
    "                    print_one_secondary_granularity(main_model_data=main_model_data,\n",
    "                        k=k,\n",
    "                        main_granularity=main_granularity,\n",
    "                        main_model_name=main_model_name)\n",
    "                else:\n",
    "                    two_secondary_table_data = print_two_secondary_granularities(main_model_data=main_model_data,\n",
    "                                                      two_secondary_table_data=two_secondary_table_data,\n",
    "                                                      k=k,\n",
    "                                                      main_granularity=main_granularity,\n",
    "                                                      main_model_name=main_model_name)\n",
    "            print('#' * 100)\n",
    "\n",
    "print_EDCR_tables()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-09T23:47:04.949322Z",
     "start_time": "2023-11-09T23:47:04.520682Z"
    }
   },
   "id": "3f6e34912281d5e"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T11:41:53.904820Z",
     "start_time": "2023-11-08T11:41:53.894494Z"
    }
   },
   "id": "eaa3ab38ecb4940b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
