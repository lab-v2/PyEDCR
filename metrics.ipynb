{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "import termcolor\n",
    "from tabulate import tabulate\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from data_preprocessing import granularities\n",
    "from EDCR_pipeline import n_coarse_grain_classes\n",
    "from vit_pipeline import vit_model_names\n",
    "from context import Plot"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T03:03:53.051036Z",
     "start_time": "2023-11-08T03:03:49.205226Z"
    }
   },
   "id": "9dc68a5fe4ce4ea7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9fa39b654f694621"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-08T03:03:53.412758Z",
     "start_time": "2023-11-08T03:03:53.055911Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data(data_dir: str) -> dict[str, dict]:\n",
    "    all_data = {}\n",
    "    \n",
    "    for granularity in granularities.values():\n",
    "        \n",
    "        suffix = '_coarse' if granularity == 'coarse' else ''\n",
    "        # Initialize dictionaries to store training and test accuracy data for each model\n",
    "        train_data = {}\n",
    "        test_data = {}\n",
    "        \n",
    "        test_true = np.load(os.path.join(data_dir, f'test_true{suffix}.npy'))\n",
    "        \n",
    "        # Loop through all files in the directory\n",
    "        for filename in os.listdir(data_dir):\n",
    "            train_match = re.match(pattern=rf'(.+?)_train_(loss|acc)_lr(.+?)_e(\\d+?){suffix}.npy',\n",
    "                                   string=filename)\n",
    "            test_match = re.match(pattern=rf'(.+?)_test_pred_lr(.+?)_e(\\d+?){suffix}.npy',\n",
    "                                  string=filename)\n",
    "        \n",
    "            if train_match:\n",
    "                model_name = train_match.group(1)\n",
    "                metric = train_match.group(2)\n",
    "                lr_value = float(train_match.group(3))\n",
    "                num_epochs = int(train_match.group(4)) + 1\n",
    "        \n",
    "                # Load the data from the .npy file\n",
    "                data = np.load(os.path.join(data_dir, filename))\n",
    "        \n",
    "                # Store the data in the model_data dictionary\n",
    "                if model_name not in train_data:\n",
    "                    train_data[model_name] = {}\n",
    "                if metric not in train_data[model_name]:\n",
    "                    train_data[model_name][metric] = {}\n",
    "                if lr_value not in train_data[model_name][metric]:\n",
    "                    train_data[model_name][metric][lr_value] = {}\n",
    "        \n",
    "                train_data[model_name][metric][lr_value][num_epochs] = data[-1]\n",
    "            elif test_match:\n",
    "                model_name = test_match.group(1)\n",
    "                lr_value = float(test_match.group(2))\n",
    "                num_epochs = int(test_match.group(3)) + 1\n",
    "        \n",
    "                # Load the test data from the .npy file\n",
    "                test_pred = np.load(os.path.join(data_dir, filename))\n",
    "        \n",
    "                # Store the data in the model_test_data dictionary\n",
    "                if model_name not in test_data:\n",
    "                    test_data[model_name] = {}\n",
    "                if lr_value not in test_data[model_name]:\n",
    "                    test_data[model_name][lr_value] = {}\n",
    "        \n",
    "                test_data[model_name][lr_value][num_epochs] = \\\n",
    "                    {'acc': accuracy_score(y_true=test_true, \n",
    "                                           y_pred=test_pred), \n",
    "                     'cm': confusion_matrix(y_true=test_true, \n",
    "                                            y_pred=test_pred),\n",
    "                     'pre': precision_score(y_true=test_true, \n",
    "                                            y_pred=test_pred, \n",
    "                                            labels=range(n_coarse_grain_classes), \n",
    "                                            average=None),\n",
    "                     'rec': recall_score(y_true=test_true, \n",
    "                                         y_pred=test_pred, \n",
    "                                         labels=range(n_coarse_grain_classes), \n",
    "                                         average=None),\n",
    "                     'f1': f1_score(y_true=test_true, \n",
    "                                    y_pred=test_pred, \n",
    "                                    labels=range(n_coarse_grain_classes), \n",
    "                                    average=None)}\n",
    "                \n",
    "        all_data[granularity] = {'train': train_data, 'test': test_data}\n",
    "    \n",
    "    return all_data\n",
    "    \n",
    "    \n",
    "def plot_train_metrics(all_data: dict[str, dict]):\n",
    "    for granularity in granularities.values():\n",
    "        for model_name, model_data in sorted(all_data[granularity]['train'].items()):\n",
    "            print('\\n' + '#'* (100 + len(model_name)))\n",
    "            print('#'* 50 + f'{model_name}' + '#'* 50)\n",
    "            print('#'* (100 + len(model_name)) + '\\n')\n",
    "            for metric, metric_data in model_data.items():\n",
    "                with Plot():\n",
    "                    plt.title(f\"{model_name} {granularity}-grain training {metric} vs. epoch\")\n",
    "                    plt.xlabel('Epoch')\n",
    "                    plt.ylabel(metric.capitalize())\n",
    "        \n",
    "                    for lr_value, lr_data in sorted(metric_data.items()):\n",
    "                        epochs, data = zip(*sorted(lr_data.items())) # Sort the data based on the number of epochs\n",
    "                        plt.plot(epochs, data, label=f'lr={lr_value}')\n",
    "                        plt.xticks(np.arange(min(epochs), max(epochs)+1, 1)) # Set the x-axis ticks to be integers\n",
    "        \n",
    "                    plt.legend()\n",
    "                    plt.grid()\n",
    "                    \n",
    "data_dir = 'results/'  # Set the directory where your .npy files are located\n",
    "all_data = load_data(data_dir=data_dir)\n",
    "# plot_train_metrics(all_data=all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test accuracies"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1b4fda72717cd425"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Pre-EDCR Coarse Grain Test Accuracies         \n",
      "╒══════════════╤════════════╤════════════╤════════════╕\n",
      "│ Model Name   │   lr=1e-05 │   lr=1e-06 │   lr=5e-05 │\n",
      "╞══════════════╪════════════╪════════════╪════════════╡\n",
      "│ vit_b_16     │   0.809377 │   0.656385 │   \u001B[92m0.837138\u001B[0m │\n",
      "├──────────────┼────────────┼────────────┼────────────┤\n",
      "│ vit_b_32     │   \u001B[92m0.770512\u001B[0m │   0.630475 │   0.760025 │\n",
      "├──────────────┼────────────┼────────────┼────────────┤\n",
      "│ vit_l_16     │   \u001B[92m0.84269\u001B[0m  │   0.739667 │   0.837138 │\n",
      "├──────────────┼────────────┼────────────┼────────────┤\n",
      "│ vit_l_32     │   0.792104 │   0.595312 │   \u001B[92m0.807526\u001B[0m │\n",
      "╘══════════════╧════════════╧════════════╧════════════╛\n",
      "Max Accuracy for Coarse Grain: 0.8426896977174584 for Model: vit_l_16, lr=1e-05\n",
      "\n",
      "          Pre-EDCR Fine Grain Test Accuracies          \n",
      "╒══════════════╤════════════╤════════════╤════════════╕\n",
      "│ Model Name   │   lr=1e-05 │   lr=1e-06 │   lr=5e-05 │\n",
      "╞══════════════╪════════════╪════════════╪════════════╡\n",
      "│ vit_b_16     │   0.639112 │   \u001B[92m0.699568\u001B[0m │   0.645281 │\n",
      "├──────────────┼────────────┼────────────┼────────────┤\n",
      "│ vit_b_32     │   0.558914 │   \u001B[92m0.636644\u001B[0m │   0.537323 │\n",
      "├──────────────┼────────────┼────────────┼────────────┤\n",
      "│ vit_l_16     │   0.699568 │   \u001B[92m0.702653\u001B[0m │   0.661937 │\n",
      "├──────────────┼────────────┼────────────┼────────────┤\n",
      "│ vit_l_32     │   0.582357 │   \u001B[92m0.673041\u001B[0m │   0.624306 │\n",
      "╘══════════════╧════════════╧════════════╧════════════╛\n",
      "Max Accuracy for Fine Grain: 0.702652683528686 for Model: vit_l_16, lr=1e-06\n"
     ]
    }
   ],
   "source": [
    "def plot_test_metrics():\n",
    "    for granularity in granularities.values():\n",
    "        # Create a dictionary to store accuracy values for each model and learning rate\n",
    "        accuracy_data = {}\n",
    "\n",
    "        # Now, create plots for test accuracy vs. epoch for each model\n",
    "        for model_name, model_data in sorted(all_data[granularity]['test'].items()):\n",
    "            for lr_value, lr_data in sorted(model_data.items()):\n",
    "                # Collect the accuracy after the last epoch\n",
    "                last_epoch = sorted(lr_data.items())[-1][1]\n",
    "                accuracy = last_epoch['acc']\n",
    "\n",
    "                # Store the accuracy in the dictionary\n",
    "                if model_name not in accuracy_data:\n",
    "                    accuracy_data[model_name] = {}\n",
    "                accuracy_data[model_name][f'lr={lr_value}'] = accuracy\n",
    "\n",
    "        # Get a list of all learning rates in the data\n",
    "        all_learning_rates = sorted(set(lr for model_data in accuracy_data.values() for lr in model_data))\n",
    "\n",
    "        # Generate the 2-D table with manual headers\n",
    "        headers = [\"Model Name\"] + all_learning_rates\n",
    "        table = []\n",
    "\n",
    "        for model_name, lr_data in accuracy_data.items():\n",
    "            max_accuracy = max(lr_data.values())\n",
    "            row = [model_name]\n",
    "            for lr in all_learning_rates:\n",
    "                acc = lr_data.get(lr, \"N/A\")\n",
    "                if acc == max_accuracy:\n",
    "                    acc = f\"\\033[92m{acc}\\033[0m\"  # Highlight in green for maximum accuracy\n",
    "                row.append(acc)\n",
    "            if \"N/A\" not in row:\n",
    "                table.append(row)\n",
    "\n",
    "        # Adding a title to the table\n",
    "        title = f\"Pre-EDCR {granularity.capitalize()} Grain Test Accuracies\"\n",
    "\n",
    "        # Generate the table using tabulate\n",
    "        table_str = tabulate(table, headers=headers, tablefmt=\"fancy_grid\")\n",
    "\n",
    "        # Insert the title in the middle of the table\n",
    "        lines = table_str.split('\\n')\n",
    "        lines.insert(0, title.center(len(lines[0])))\n",
    "        updated_table = '\\n'.join(lines)\n",
    "\n",
    "        # Print the updated table with the title\n",
    "        print(updated_table)\n",
    "\n",
    "        # Calculate and print the maximum accuracy across all models and learning rates for each granularity\n",
    "        max_accuracy = max(acc for model_data in accuracy_data.values() for acc in model_data.values())\n",
    "        max_model, max_lr = [(model, lr) for model, lr_data in accuracy_data.items() \n",
    "                             for lr, acc in lr_data.items() if acc == max_accuracy][0]\n",
    "\n",
    "        print(f\"Max Accuracy for {granularity.capitalize()} Grain: {max_accuracy} for Model: {max_model}, {max_lr}\\n\")\n",
    "\n",
    "plot_test_metrics()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T03:03:53.423333Z",
     "start_time": "2023-11-08T03:03:53.412118Z"
    }
   },
   "id": "473ad4b8260120a1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# EDCR Results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff5d015e77a12310"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def gather_EDCR_data() -> dict:\n",
    "    data = {}  # Create an empty dictionary to store the accuracy data\n",
    "    \n",
    "    # Track the maximal accuracy value across all tables\n",
    "    # max_accuracy = -1.0\n",
    "    # max_data = {}\n",
    "    \n",
    "    models_and_lrs_folders = os.listdir(f'figs')\n",
    "    \n",
    "    # Iterate through filenames to collect accuracy data\n",
    "    for filename in models_and_lrs_folders:\n",
    "        secondary_granularity_match = re.match(\n",
    "            pattern='main_(fine|coarse)_(.+?)_lr(.+?)_secondary_(fine|coarse)_(.+?)_lr(.+)',\n",
    "            string=filename\n",
    "        )\n",
    "        \n",
    "        if secondary_granularity_match:\n",
    "            (   \n",
    "                match,\n",
    "                main_granularity,\n",
    "                main_model_name,\n",
    "                main_lr,\n",
    "                secondary_granularity,\n",
    "                secondary_model_name,\n",
    "                secondary_lr\n",
    "            ) = (secondary_granularity_match.group(i) for i in range(7))\n",
    "            \n",
    "            main_suffix = '_coarse' if main_granularity == 'coarse' else ''\n",
    "            test_true = np.load(os.path.join(data_dir, f'test_true{main_suffix}.npy'))\n",
    "            \n",
    "            prior_predictions = np.load(os.path.join(data_dir, rf'{main_model_name}_test_pred_lr{main_lr}_e3{main_suffix}.npy'))\n",
    "            prior_acc = accuracy_score(y_true=test_true, \n",
    "                                       y_pred=prior_predictions)\n",
    "            \n",
    "            secondary_suffix = '_coarse' if secondary_granularity == 'coarse' else ''\n",
    "            post_predictions = np.load(f'figs/{match}/results{secondary_suffix}.npy')\n",
    "            posterior_acc = accuracy_score(y_true=test_true, \n",
    "                                           y_pred=post_predictions)\n",
    "\n",
    "            # Store accuracy data in the data dictionary\n",
    "            if main_granularity not in data:\n",
    "                data[main_granularity] = {}\n",
    "            if main_model_name not in data[main_granularity]:\n",
    "                data[main_granularity][main_model_name] = {}\n",
    "            if secondary_granularity not in data[main_granularity][main_model_name]:\n",
    "                data[main_granularity][main_model_name][secondary_granularity] = {}\n",
    "                \n",
    "            if secondary_model_name not in data[main_granularity][main_model_name][secondary_granularity]:\n",
    "                data[main_granularity][main_model_name][secondary_granularity][secondary_model_name] = {}\n",
    "                \n",
    "            if main_lr not in data[main_granularity][main_model_name][secondary_granularity][secondary_model_name]:\n",
    "                data[main_granularity][main_model_name][secondary_granularity][secondary_model_name][main_lr] = {}\n",
    "                \n",
    "            data[main_granularity][main_model_name][secondary_granularity][secondary_model_name][main_lr][secondary_lr] = \\\n",
    "                {'prior': prior_acc, 'post': posterior_acc}\n",
    "        \n",
    "        else:\n",
    "            no_secondary_granularity_match = re.match(\n",
    "            pattern='main_(fine|coarse)_(.+)_lr(.+)_secondary_(.+)_lr(.+)',\n",
    "            string=filename)\n",
    "            \n",
    "            if no_secondary_granularity_match:\n",
    "                \n",
    "                (\n",
    "                    match,\n",
    "                    main_granularity,\n",
    "                    main_model_name,\n",
    "                    main_lr,\n",
    "                    secondary_model_name,\n",
    "                    secondary_lr \n",
    "                ) = (no_secondary_granularity_match.group(i) for i in range(6))\n",
    "                \n",
    "                main_suffix = '_coarse' if main_granularity == 'coarse' else ''\n",
    "                test_true = np.load(os.path.join(data_dir, f'test_true{main_suffix}.npy'))\n",
    "                \n",
    "                prior_predictions = np.load(os.path.join(data_dir, rf'{main_model_name}_test_pred_lr{main_lr}_e3{main_suffix}.npy'))\n",
    "                prior_acc = accuracy_score(y_true=test_true, \n",
    "                                           y_pred=prior_predictions)\n",
    "                \n",
    "                try:\n",
    "                    post_predictions = np.load(f'figs/{match}/results.npy')\n",
    "                except:\n",
    "                    post_predictions = np.load(f'figs/{match}/results_coarse.npy')\n",
    "                    \n",
    "                posterior_acc = accuracy_score(y_true=test_true, \n",
    "                                               y_pred=post_predictions)\n",
    "    \n",
    "                # Store accuracy data in the data dictionary\n",
    "                if main_granularity not in data:\n",
    "                    data[main_granularity] = {}\n",
    "                if main_model_name not in data[main_granularity]:\n",
    "                    data[main_granularity][main_model_name] = {}\n",
    "                if secondary_model_name not in data[main_granularity][main_model_name]:\n",
    "                    data[main_granularity][main_model_name][secondary_model_name] = {}\n",
    "                if main_lr not in data[main_granularity][main_model_name][secondary_model_name]:\n",
    "                    data[main_granularity][main_model_name][secondary_model_name][main_lr] = {}\n",
    "                \n",
    "                data[main_granularity][main_model_name][secondary_model_name][main_lr][secondary_lr] = \\\n",
    "                    {'prior': prior_acc, 'post': posterior_acc}\n",
    "                \n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T03:51:39.011946Z",
     "start_time": "2023-11-08T03:51:39.008514Z"
    }
   },
   "id": "5887761748721ce8"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################## Main granularity: coarse ########################################\n",
      "########################################################################################################\n",
      "\n",
      "Main model: Coarse-grain vit_b_16, secondary granularity: coarse\n",
      "+----------+-----------------------------+------------------------------+-----------------------------+\n",
      "|          | 1e-05                       | 1e-06                        | 5e-05                       |\n",
      "+==========+=============================+==============================+=============================+\n",
      "| vit_b_32 | 1e-05: 81.0% (80.9%, \u001B[32m+\u001B[0m\u001B[32m0.1%)\u001B[0m | 1e-05: 73.0% (65.6%, \u001B[32m+\u001B[0m\u001B[32m7.4%)\u001B[0m  | 1e-05: 82.4% (83.7%, \u001B[32m\u001B[0m\u001B[31m-1.4%)\u001B[0m |\n",
      "|          | 1e-06: 80.9% (80.9%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m  | 1e-06: 65.3% (65.6%, \u001B[32m\u001B[0m\u001B[31m-0.3%)\u001B[0m  | 1e-06: 83.7% (83.7%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m  |\n",
      "|          | 5e-05: 81.2% (80.9%, \u001B[32m+\u001B[0m\u001B[32m0.2%)\u001B[0m | 5e-05: 72.5% (65.6%, \u001B[32m+\u001B[0m\u001B[32m6.9%)\u001B[0m  | 5e-05: 83.7% (83.7%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m  |\n",
      "+----------+-----------------------------+------------------------------+-----------------------------+\n",
      "| vit_l_16 | 1e-05: 83.0% (80.9%, \u001B[32m+\u001B[0m\u001B[32m2.0%)\u001B[0m | 1e-05: 76.8% (65.6%, \u001B[32m+\u001B[0m\u001B[32m11.2%)\u001B[0m | \u001B[34m1e-05: 83.8% (83.7%, \u001B[32m+\u001B[0m\u001B[32m0.1%)\u001B[0m |\n",
      "|          | 1e-06: 78.8% (80.9%, \u001B[32m\u001B[0m\u001B[31m-2.2%)\u001B[0m | 1e-06: 71.2% (65.6%, \u001B[32m+\u001B[0m\u001B[32m5.6%)\u001B[0m  | 1e-06: 83.7% (83.7%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m  |\n",
      "|          | 5e-05: 82.0% (80.9%, \u001B[32m+\u001B[0m\u001B[32m1.0%)\u001B[0m | 5e-05: 76.1% (65.6%, \u001B[32m+\u001B[0m\u001B[32m10.4%)\u001B[0m | 5e-05: 84.2% (83.7%, \u001B[32m+\u001B[0m\u001B[32m0.5%)\u001B[0m |\n",
      "|          |                             |                              | \u001B[0m                            |\n",
      "+----------+-----------------------------+------------------------------+-----------------------------+\n",
      "| vit_l_32 | 1e-05: 80.8% (80.9%, \u001B[32m\u001B[0m\u001B[31m-0.1%)\u001B[0m | 1e-05: 74.2% (65.6%, \u001B[32m+\u001B[0m\u001B[32m8.5%)\u001B[0m  | 1e-05: 83.0% (83.7%, \u001B[32m\u001B[0m\u001B[31m-0.7%)\u001B[0m |\n",
      "|          | 1e-06: 80.9% (80.9%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m  | 1e-06: 66.1% (65.6%, \u001B[32m+\u001B[0m\u001B[32m0.4%)\u001B[0m  | 1e-06: 83.7% (83.7%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m  |\n",
      "|          | 5e-05: 81.4% (80.9%, \u001B[32m+\u001B[0m\u001B[32m0.5%)\u001B[0m | 5e-05: 75.9% (65.6%, \u001B[32m+\u001B[0m\u001B[32m10.3%)\u001B[0m | 5e-05: 83.5% (83.7%, \u001B[32m\u001B[0m\u001B[31m-0.2%)\u001B[0m |\n",
      "+----------+-----------------------------+------------------------------+-----------------------------+\n",
      "\n",
      "\n",
      "Main model: Coarse-grain vit_b_16, secondary granularity: fine\n",
      "+----------+-----------------------------+-----------------------------+-----------------------------+\n",
      "|          | 1e-05                       | 1e-06                       | 5e-05                       |\n",
      "+==========+=============================+=============================+=============================+\n",
      "| vit_b_32 | 1e-05: 78.0% (80.9%, \u001B[32m\u001B[0m\u001B[31m-2.9%)\u001B[0m | 1e-05: 69.3% (65.6%, \u001B[32m+\u001B[0m\u001B[32m3.7%)\u001B[0m | 1e-05: 83.0% (83.7%, \u001B[32m\u001B[0m\u001B[31m-0.7%)\u001B[0m |\n",
      "|          | 1e-06: 79.2% (80.9%, \u001B[32m\u001B[0m\u001B[31m-1.7%)\u001B[0m | 1e-06: 71.0% (65.6%, \u001B[32m+\u001B[0m\u001B[32m5.4%)\u001B[0m | 1e-06: 83.0% (83.7%, \u001B[32m\u001B[0m\u001B[31m-0.7%)\u001B[0m |\n",
      "|          | 5e-05: 79.5% (80.9%, \u001B[32m\u001B[0m\u001B[31m-1.5%)\u001B[0m | 5e-05: 68.6% (65.6%, \u001B[32m+\u001B[0m\u001B[32m3.0%)\u001B[0m | 5e-05: 83.8% (83.7%, \u001B[32m+\u001B[0m\u001B[32m0.1%)\u001B[0m |\n",
      "+----------+-----------------------------+-----------------------------+-----------------------------+\n",
      "| vit_l_16 | 1e-05: 80.8% (80.9%, \u001B[32m\u001B[0m\u001B[31m-0.1%)\u001B[0m | 1e-05: 72.4% (65.6%, \u001B[32m+\u001B[0m\u001B[32m6.8%)\u001B[0m | \u001B[34m1e-05: 84.5% (83.7%, \u001B[32m+\u001B[0m\u001B[32m0.7%)\u001B[0m |\n",
      "|          | 1e-06: 79.5% (80.9%, \u001B[32m\u001B[0m\u001B[31m-1.4%)\u001B[0m | 1e-06: 73.2% (65.6%, \u001B[32m+\u001B[0m\u001B[32m7.5%)\u001B[0m | 1e-06: 82.7% (83.7%, \u001B[32m\u001B[0m\u001B[31m-1.0%)\u001B[0m |\n",
      "|          | 5e-05: 81.2% (80.9%, \u001B[32m+\u001B[0m\u001B[32m0.3%)\u001B[0m | 5e-05: 72.3% (65.6%, \u001B[32m+\u001B[0m\u001B[32m6.7%)\u001B[0m | 5e-05: 84.4% (83.7%, \u001B[32m+\u001B[0m\u001B[32m0.7%)\u001B[0m |\n",
      "|          |                             |                             | \u001B[0m                            |\n",
      "+----------+-----------------------------+-----------------------------+-----------------------------+\n",
      "| vit_l_32 | 1e-05: 81.6% (80.9%, \u001B[32m+\u001B[0m\u001B[32m0.7%)\u001B[0m | 1e-05: 68.7% (65.6%, \u001B[32m+\u001B[0m\u001B[32m3.0%)\u001B[0m | 1e-05: 83.5% (83.7%, \u001B[32m\u001B[0m\u001B[31m-0.2%)\u001B[0m |\n",
      "|          | 1e-06: 80.6% (80.9%, \u001B[32m\u001B[0m\u001B[31m-0.4%)\u001B[0m | 1e-06: 71.7% (65.6%, \u001B[32m+\u001B[0m\u001B[32m6.1%)\u001B[0m | 1e-06: 83.0% (83.7%, \u001B[32m\u001B[0m\u001B[31m-0.7%)\u001B[0m |\n",
      "|          | 5e-05: 79.3% (80.9%, \u001B[32m\u001B[0m\u001B[31m-1.7%)\u001B[0m | 5e-05: 70.6% (65.6%, \u001B[32m+\u001B[0m\u001B[32m4.9%)\u001B[0m | 5e-05: 82.5% (83.7%, \u001B[32m\u001B[0m\u001B[31m-1.2%)\u001B[0m |\n",
      "+----------+-----------------------------+-----------------------------+-----------------------------+\n",
      "\n",
      "\n",
      "Main model: Coarse-grain vit_b_16 with both fine and coarse grain secondary models\n",
      "+----------+-----------------------------+-----------------------------+-----------------------------+\n",
      "|          | vit_b_32                    | vit_l_16                    | vit_l_32                    |\n",
      "+==========+=============================+=============================+=============================+\n",
      "| vit_b_32 | 1e-05: 78.0% (80.9%, \u001B[32m\u001B[0m\u001B[31m-2.9%)\u001B[0m | 1e-05: 70.1% (65.6%, \u001B[32m+\u001B[0m\u001B[32m4.4%)\u001B[0m | 1e-05: 82.4% (83.7%, \u001B[32m\u001B[0m\u001B[31m-1.3%)\u001B[0m |\n",
      "|          | 1e-06: 79.2% (80.9%, \u001B[32m\u001B[0m\u001B[31m-1.7%)\u001B[0m | 1e-06: 69.3% (65.6%, \u001B[32m+\u001B[0m\u001B[32m3.6%)\u001B[0m | 1e-06: 83.0% (83.7%, \u001B[32m\u001B[0m\u001B[31m-0.7%)\u001B[0m |\n",
      "|          | 5e-05: 79.7% (80.9%, \u001B[32m\u001B[0m\u001B[31m-1.2%)\u001B[0m | 5e-05: 70.6% (65.6%, \u001B[32m+\u001B[0m\u001B[32m5.0%)\u001B[0m | 5e-05: 83.8% (83.7%, \u001B[32m+\u001B[0m\u001B[32m0.1%)\u001B[0m |\n",
      "+----------+-----------------------------+-----------------------------+-----------------------------+\n",
      "\n",
      "\n",
      "Main model: Coarse-grain vit_b_16 with both fine and coarse grain secondary models\n",
      "+----------+-----------------------------+-----------------------------+-----------------------------+\n",
      "|          | vit_b_32                    | vit_l_16                    | vit_l_32                    |\n",
      "+==========+=============================+=============================+=============================+\n",
      "| vit_l_16 | 1e-05: 81.1% (80.9%, \u001B[32m+\u001B[0m\u001B[32m0.1%)\u001B[0m | 1e-05: 69.2% (65.6%, \u001B[32m+\u001B[0m\u001B[32m3.6%)\u001B[0m | 1e-05: 85.3% (83.7%, \u001B[32m+\u001B[0m\u001B[32m1.6%)\u001B[0m |\n",
      "|          | 1e-06: 79.8% (80.9%, \u001B[32m\u001B[0m\u001B[31m-1.2%)\u001B[0m | 1e-06: 69.4% (65.6%, \u001B[32m+\u001B[0m\u001B[32m3.8%)\u001B[0m | 1e-06: 82.7% (83.7%, \u001B[32m\u001B[0m\u001B[31m-1.0%)\u001B[0m |\n",
      "|          | 5e-05: 81.6% (80.9%, \u001B[32m+\u001B[0m\u001B[32m0.6%)\u001B[0m | 5e-05: 74.0% (65.6%, \u001B[32m+\u001B[0m\u001B[32m8.4%)\u001B[0m | 5e-05: 84.5% (83.7%, \u001B[32m+\u001B[0m\u001B[32m0.7%)\u001B[0m |\n",
      "+----------+-----------------------------+-----------------------------+-----------------------------+\n",
      "\n",
      "\n",
      "Main model: Coarse-grain vit_b_16 with both fine and coarse grain secondary models\n",
      "+----------+-----------------------------+-----------------------------+-----------------------------+\n",
      "|          | vit_b_32                    | vit_l_16                    | vit_l_32                    |\n",
      "+==========+=============================+=============================+=============================+\n",
      "| vit_l_32 | 1e-05: 81.8% (80.9%, \u001B[32m+\u001B[0m\u001B[32m0.9%)\u001B[0m | 1e-05: 70.8% (65.6%, \u001B[32m+\u001B[0m\u001B[32m5.2%)\u001B[0m | 1e-05: 83.4% (83.7%, \u001B[32m\u001B[0m\u001B[31m-0.3%)\u001B[0m |\n",
      "|          | 1e-06: 80.6% (80.9%, \u001B[32m\u001B[0m\u001B[31m-0.4%)\u001B[0m | 1e-06: 71.7% (65.6%, \u001B[32m+\u001B[0m\u001B[32m6.0%)\u001B[0m | 1e-06: 83.0% (83.7%, \u001B[32m\u001B[0m\u001B[31m-0.7%)\u001B[0m |\n",
      "|          | 5e-05: 80.6% (80.9%, \u001B[32m\u001B[0m\u001B[31m-0.4%)\u001B[0m | 5e-05: 74.0% (65.6%, \u001B[32m+\u001B[0m\u001B[32m8.4%)\u001B[0m | 5e-05: 83.2% (83.7%, \u001B[32m\u001B[0m\u001B[31m-0.5%)\u001B[0m |\n",
      "+----------+-----------------------------+-----------------------------+-----------------------------+\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Main model: Coarse-grain vit_b_32, secondary granularity: coarse\n",
      "+----------+-----------------------------+------------------------------+-----------------------------+\n",
      "|          | 1e-05                       | 1e-06                        | 5e-05                       |\n",
      "+==========+=============================+==============================+=============================+\n",
      "| vit_b_16 | 1e-05: 79.6% (77.1%, \u001B[32m+\u001B[0m\u001B[32m2.6%)\u001B[0m | 1e-05: 74.3% (63.0%, \u001B[32m+\u001B[0m\u001B[32m11.3%)\u001B[0m | 1e-05: 78.7% (76.0%, \u001B[32m+\u001B[0m\u001B[32m2.7%)\u001B[0m |\n",
      "|          | 1e-06: 77.1% (77.1%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m  | 1e-06: 64.2% (63.0%, \u001B[32m+\u001B[0m\u001B[32m1.2%)\u001B[0m  | 1e-06: 75.3% (76.0%, \u001B[32m\u001B[0m\u001B[31m-0.7%)\u001B[0m |\n",
      "|          | 5e-05: 82.2% (77.1%, \u001B[32m+\u001B[0m\u001B[32m5.2%)\u001B[0m | 5e-05: 76.3% (63.0%, \u001B[32m+\u001B[0m\u001B[32m13.3%)\u001B[0m | 5e-05: 82.0% (76.0%, \u001B[32m+\u001B[0m\u001B[32m6.0%)\u001B[0m |\n",
      "+----------+-----------------------------+------------------------------+-----------------------------+\n",
      "| vit_l_16 | \u001B[34m1e-05: 82.4% (77.1%, \u001B[32m+\u001B[0m\u001B[32m5.3%)\u001B[0m | 1e-05: 76.7% (63.0%, \u001B[32m+\u001B[0m\u001B[32m13.7%)\u001B[0m | 1e-05: 80.7% (76.0%, \u001B[32m+\u001B[0m\u001B[32m4.7%)\u001B[0m |\n",
      "|          | 1e-06: 76.2% (77.1%, \u001B[32m\u001B[0m\u001B[31m-0.9%)\u001B[0m | 1e-06: 71.4% (63.0%, \u001B[32m+\u001B[0m\u001B[32m8.4%)\u001B[0m  | 1e-06: 75.6% (76.0%, \u001B[32m\u001B[0m\u001B[31m-0.4%)\u001B[0m |\n",
      "|          | 5e-05: 81.6% (77.1%, \u001B[32m+\u001B[0m\u001B[32m4.6%)\u001B[0m | 5e-05: 75.9% (63.0%, \u001B[32m+\u001B[0m\u001B[32m12.8%)\u001B[0m | 5e-05: 79.4% (76.0%, \u001B[32m+\u001B[0m\u001B[32m3.4%)\u001B[0m |\n",
      "|          | \u001B[0m                            |                              |                             |\n",
      "+----------+-----------------------------+------------------------------+-----------------------------+\n",
      "| vit_l_32 | 1e-05: 77.7% (77.1%, \u001B[32m+\u001B[0m\u001B[32m0.7%)\u001B[0m | 1e-05: 72.4% (63.0%, \u001B[32m+\u001B[0m\u001B[32m9.4%)\u001B[0m  | 1e-05: 77.5% (76.0%, \u001B[32m+\u001B[0m\u001B[32m1.5%)\u001B[0m |\n",
      "|          | 1e-06: 77.1% (77.1%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m  | 1e-06: 63.6% (63.0%, \u001B[32m+\u001B[0m\u001B[32m0.6%)\u001B[0m  | 1e-06: 74.3% (76.0%, \u001B[32m\u001B[0m\u001B[31m-1.7%)\u001B[0m |\n",
      "|          | 5e-05: 81.3% (77.1%, \u001B[32m+\u001B[0m\u001B[32m4.3%)\u001B[0m | 5e-05: 75.0% (63.0%, \u001B[32m+\u001B[0m\u001B[32m12.0%)\u001B[0m | 5e-05: 78.8% (76.0%, \u001B[32m+\u001B[0m\u001B[32m2.8%)\u001B[0m |\n",
      "+----------+-----------------------------+------------------------------+-----------------------------+\n",
      "\n",
      "\n",
      "Main model: Coarse-grain vit_b_32, secondary granularity: fine\n",
      "+----------+-----------------------------+-----------------------------+-----------------------------+\n",
      "|          | 1e-05                       | 1e-06                       | 5e-05                       |\n",
      "+==========+=============================+=============================+=============================+\n",
      "| vit_b_16 | \u001B[34m1e-05: 77.9% (77.1%, \u001B[32m+\u001B[0m\u001B[32m0.8%)\u001B[0m | 1e-05: 69.8% (63.0%, \u001B[32m+\u001B[0m\u001B[32m6.8%)\u001B[0m | 1e-05: 76.8% (76.0%, \u001B[32m+\u001B[0m\u001B[32m0.8%)\u001B[0m |\n",
      "|          | 1e-06: 77.7% (77.1%, \u001B[32m+\u001B[0m\u001B[32m0.7%)\u001B[0m | 1e-06: 72.7% (63.0%, \u001B[32m+\u001B[0m\u001B[32m9.7%)\u001B[0m | 1e-06: 78.5% (76.0%, \u001B[32m+\u001B[0m\u001B[32m2.5%)\u001B[0m |\n",
      "|          | 5e-05: 78.7% (77.1%, \u001B[32m+\u001B[0m\u001B[32m1.7%)\u001B[0m | 5e-05: 70.9% (63.0%, \u001B[32m+\u001B[0m\u001B[32m7.8%)\u001B[0m | 5e-05: 78.1% (76.0%, \u001B[32m+\u001B[0m\u001B[32m2.1%)\u001B[0m |\n",
      "|          | \u001B[0m                            |                             |                             |\n",
      "+----------+-----------------------------+-----------------------------+-----------------------------+\n",
      "| vit_l_16 | 1e-05: 78.6% (77.1%, \u001B[32m+\u001B[0m\u001B[32m1.5%)\u001B[0m | 1e-05: 70.6% (63.0%, \u001B[32m+\u001B[0m\u001B[32m7.6%)\u001B[0m | 1e-05: 78.5% (76.0%, \u001B[32m+\u001B[0m\u001B[32m2.5%)\u001B[0m |\n",
      "|          | 1e-06: 78.6% (77.1%, \u001B[32m+\u001B[0m\u001B[32m1.5%)\u001B[0m | 1e-06: 70.0% (63.0%, \u001B[32m+\u001B[0m\u001B[32m7.0%)\u001B[0m | 1e-06: 77.9% (76.0%, \u001B[32m+\u001B[0m\u001B[32m1.9%)\u001B[0m |\n",
      "|          | 5e-05: 78.7% (77.1%, \u001B[32m+\u001B[0m\u001B[32m1.6%)\u001B[0m | 5e-05: 70.7% (63.0%, \u001B[32m+\u001B[0m\u001B[32m7.6%)\u001B[0m | 5e-05: 78.6% (76.0%, \u001B[32m+\u001B[0m\u001B[32m2.6%)\u001B[0m |\n",
      "+----------+-----------------------------+-----------------------------+-----------------------------+\n",
      "| vit_l_32 | 1e-05: 78.1% (77.1%, \u001B[32m+\u001B[0m\u001B[32m1.0%)\u001B[0m | 1e-05: 68.2% (63.0%, \u001B[32m+\u001B[0m\u001B[32m5.1%)\u001B[0m | 1e-05: 75.4% (76.0%, \u001B[32m\u001B[0m\u001B[31m-0.6%)\u001B[0m |\n",
      "|          | 1e-06: 77.2% (77.1%, \u001B[32m+\u001B[0m\u001B[32m0.1%)\u001B[0m | 1e-06: 70.4% (63.0%, \u001B[32m+\u001B[0m\u001B[32m7.3%)\u001B[0m | 1e-06: 76.6% (76.0%, \u001B[32m+\u001B[0m\u001B[32m0.6%)\u001B[0m |\n",
      "|          | 5e-05: 76.4% (77.1%, \u001B[32m\u001B[0m\u001B[31m-0.6%)\u001B[0m | 5e-05: 69.4% (63.0%, \u001B[32m+\u001B[0m\u001B[32m6.4%)\u001B[0m | 5e-05: 75.3% (76.0%, \u001B[32m\u001B[0m\u001B[31m-0.7%)\u001B[0m |\n",
      "+----------+-----------------------------+-----------------------------+-----------------------------+\n",
      "\n",
      "\n",
      "Main model: Coarse-grain vit_b_32 with both fine and coarse grain secondary models\n",
      "+----------+-----------------------------+------------------------------+-----------------------------+\n",
      "|          | vit_b_16                    | vit_l_16                     | vit_l_32                    |\n",
      "+==========+=============================+==============================+=============================+\n",
      "| vit_b_16 | 1e-05: 79.5% (77.1%, \u001B[32m+\u001B[0m\u001B[32m2.5%)\u001B[0m | 1e-05: 70.3% (63.0%, \u001B[32m+\u001B[0m\u001B[32m7.3%)\u001B[0m  | 1e-05: 78.6% (76.0%, \u001B[32m+\u001B[0m\u001B[32m2.6%)\u001B[0m |\n",
      "|          | 1e-06: 77.7% (77.1%, \u001B[32m+\u001B[0m\u001B[32m0.7%)\u001B[0m | 1e-06: 65.9% (63.0%, \u001B[32m+\u001B[0m\u001B[32m2.9%)\u001B[0m  | 1e-06: 77.5% (76.0%, \u001B[32m+\u001B[0m\u001B[32m1.5%)\u001B[0m |\n",
      "|          | 5e-05: 83.4% (77.1%, \u001B[32m+\u001B[0m\u001B[32m6.4%)\u001B[0m | 5e-05: 75.8% (63.0%, \u001B[32m+\u001B[0m\u001B[32m12.8%)\u001B[0m | 5e-05: 81.9% (76.0%, \u001B[32m+\u001B[0m\u001B[32m5.9%)\u001B[0m |\n",
      "+----------+-----------------------------+------------------------------+-----------------------------+\n",
      "\n",
      "\n",
      "Main model: Coarse-grain vit_b_32 with both fine and coarse grain secondary models\n",
      "+----------+-----------------------------+-----------------------------+-----------------------------+\n",
      "|          | vit_b_16                    | vit_l_16                    | vit_l_32                    |\n",
      "+==========+=============================+=============================+=============================+\n",
      "| vit_l_16 | 1e-05: 81.4% (77.1%, \u001B[32m+\u001B[0m\u001B[32m4.3%)\u001B[0m | 1e-05: 68.2% (63.0%, \u001B[32m+\u001B[0m\u001B[32m5.2%)\u001B[0m | 1e-05: 79.0% (76.0%, \u001B[32m+\u001B[0m\u001B[32m3.0%)\u001B[0m |\n",
      "|          | 1e-06: 78.6% (77.1%, \u001B[32m+\u001B[0m\u001B[32m1.5%)\u001B[0m | 1e-06: 68.7% (63.0%, \u001B[32m+\u001B[0m\u001B[32m5.7%)\u001B[0m | 1e-06: 77.4% (76.0%, \u001B[32m+\u001B[0m\u001B[32m1.4%)\u001B[0m |\n",
      "|          | 5e-05: 81.6% (77.1%, \u001B[32m+\u001B[0m\u001B[32m4.5%)\u001B[0m | 5e-05: 70.6% (63.0%, \u001B[32m+\u001B[0m\u001B[32m7.5%)\u001B[0m | 5e-05: 81.9% (76.0%, \u001B[32m+\u001B[0m\u001B[32m5.9%)\u001B[0m |\n",
      "+----------+-----------------------------+-----------------------------+-----------------------------+\n",
      "\n",
      "\n",
      "Main model: Coarse-grain vit_b_32 with both fine and coarse grain secondary models\n",
      "+----------+-----------------------------+------------------------------+-----------------------------+\n",
      "|          | vit_b_16                    | vit_l_16                     | vit_l_32                    |\n",
      "+==========+=============================+==============================+=============================+\n",
      "| vit_l_32 | 1e-05: 78.1% (77.1%, \u001B[32m+\u001B[0m\u001B[32m1.0%)\u001B[0m | 1e-05: 69.3% (63.0%, \u001B[32m+\u001B[0m\u001B[32m6.2%)\u001B[0m  | 1e-05: 76.7% (76.0%, \u001B[32m+\u001B[0m\u001B[32m0.7%)\u001B[0m |\n",
      "|          | 1e-06: 77.2% (77.1%, \u001B[32m+\u001B[0m\u001B[32m0.1%)\u001B[0m | 1e-06: 69.9% (63.0%, \u001B[32m+\u001B[0m\u001B[32m6.8%)\u001B[0m  | 1e-06: 76.3% (76.0%, \u001B[32m+\u001B[0m\u001B[32m0.3%)\u001B[0m |\n",
      "|          | 5e-05: 81.2% (77.1%, \u001B[32m+\u001B[0m\u001B[32m4.1%)\u001B[0m | 5e-05: 73.5% (63.0%, \u001B[32m+\u001B[0m\u001B[32m10.5%)\u001B[0m | 5e-05: 77.7% (76.0%, \u001B[32m+\u001B[0m\u001B[32m1.7%)\u001B[0m |\n",
      "+----------+-----------------------------+------------------------------+-----------------------------+\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Main model: Coarse-grain vit_l_16, secondary granularity: coarse\n",
      "+----------+-----------------------------+\n",
      "|          | 1e-05                       |\n",
      "+==========+=============================+\n",
      "| vit_b_16 | 1e-05: 83.8% (84.3%, \u001B[32m\u001B[0m\u001B[31m-0.5%)\u001B[0m |\n",
      "|          | 1e-06: 84.3% (84.3%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m  |\n",
      "|          | 5e-05: 84.3% (84.3%, \u001B[32m+\u001B[0m\u001B[32m0.1%)\u001B[0m |\n",
      "+----------+-----------------------------+\n",
      "| vit_b_32 | 1e-05: 83.7% (84.3%, \u001B[32m\u001B[0m\u001B[31m-0.6%)\u001B[0m |\n",
      "|          | 1e-06: 84.3% (84.3%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m  |\n",
      "|          | 5e-05: 84.2% (84.3%, \u001B[32m\u001B[0m\u001B[31m-0.1%)\u001B[0m |\n",
      "+----------+-----------------------------+\n",
      "| vit_l_32 | \u001B[34m1e-05: 83.6% (84.3%, \u001B[32m\u001B[0m\u001B[31m-0.7%)\u001B[0m |\n",
      "|          | 1e-06: 84.3% (84.3%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m  |\n",
      "|          | 5e-05: 84.6% (84.3%, \u001B[32m+\u001B[0m\u001B[32m0.3%)\u001B[0m |\n",
      "|          | \u001B[0m                            |\n",
      "+----------+-----------------------------+\n",
      "\n",
      "\n",
      "Main model: Coarse-grain vit_l_16, secondary granularity: fine\n",
      "+----------+-----------------------------+-----------------------------+-----------------------------+\n",
      "|          | 1e-05                       | 1e-06                       | 5e-05                       |\n",
      "+==========+=============================+=============================+=============================+\n",
      "| vit_b_16 | \u001B[34m1e-05: 84.1% (84.3%, \u001B[32m\u001B[0m\u001B[31m-0.1%)\u001B[0m | 1e-05: 76.0% (74.0%, \u001B[32m+\u001B[0m\u001B[32m2.0%)\u001B[0m | 1e-05: 83.5% (83.7%, \u001B[32m\u001B[0m\u001B[31m-0.2%)\u001B[0m |\n",
      "|          | 1e-06: 84.4% (84.3%, \u001B[32m+\u001B[0m\u001B[32m0.1%)\u001B[0m | 1e-06: 77.5% (74.0%, \u001B[32m+\u001B[0m\u001B[32m3.5%)\u001B[0m | 1e-06: 83.8% (83.7%, \u001B[32m+\u001B[0m\u001B[32m0.1%)\u001B[0m |\n",
      "|          | 5e-05: 85.4% (84.3%, \u001B[32m+\u001B[0m\u001B[32m1.1%)\u001B[0m | 5e-05: 76.5% (74.0%, \u001B[32m+\u001B[0m\u001B[32m2.5%)\u001B[0m | 5e-05: 84.7% (83.7%, \u001B[32m+\u001B[0m\u001B[32m1.0%)\u001B[0m |\n",
      "|          | \u001B[0m                            |                             |                             |\n",
      "+----------+-----------------------------+-----------------------------+-----------------------------+\n",
      "| vit_b_32 | 1e-05: 83.6% (84.3%, \u001B[32m\u001B[0m\u001B[31m-0.7%)\u001B[0m | 1e-05: 74.2% (74.0%, \u001B[32m+\u001B[0m\u001B[32m0.2%)\u001B[0m | 1e-05: 83.2% (83.7%, \u001B[32m\u001B[0m\u001B[31m-0.6%)\u001B[0m |\n",
      "|          | 1e-06: 84.6% (84.3%, \u001B[32m+\u001B[0m\u001B[32m0.4%)\u001B[0m | 1e-06: 75.8% (74.0%, \u001B[32m+\u001B[0m\u001B[32m1.9%)\u001B[0m | 1e-06: 84.0% (83.7%, \u001B[32m+\u001B[0m\u001B[32m0.3%)\u001B[0m |\n",
      "|          | 5e-05: 84.5% (84.3%, \u001B[32m+\u001B[0m\u001B[32m0.2%)\u001B[0m | 5e-05: 75.1% (74.0%, \u001B[32m+\u001B[0m\u001B[32m1.2%)\u001B[0m | 5e-05: 83.7% (83.7%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m  |\n",
      "+----------+-----------------------------+-----------------------------+-----------------------------+\n",
      "| vit_l_32 | 1e-05: 84.9% (84.3%, \u001B[32m+\u001B[0m\u001B[32m0.6%)\u001B[0m | 1e-05: 75.2% (74.0%, \u001B[32m+\u001B[0m\u001B[32m1.2%)\u001B[0m | 1e-05: 83.9% (83.7%, \u001B[32m+\u001B[0m\u001B[32m0.2%)\u001B[0m |\n",
      "|          | 1e-06: 84.3% (84.3%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m  | 1e-06: 76.7% (74.0%, \u001B[32m+\u001B[0m\u001B[32m2.8%)\u001B[0m | 1e-06: 83.5% (83.7%, \u001B[32m\u001B[0m\u001B[31m-0.2%)\u001B[0m |\n",
      "|          | 5e-05: 84.1% (84.3%, \u001B[32m\u001B[0m\u001B[31m-0.1%)\u001B[0m | 5e-05: 74.6% (74.0%, \u001B[32m+\u001B[0m\u001B[32m0.6%)\u001B[0m | 5e-05: 82.2% (83.7%, \u001B[32m\u001B[0m\u001B[31m-1.5%)\u001B[0m |\n",
      "+----------+-----------------------------+-----------------------------+-----------------------------+\n",
      "\n",
      "\n",
      "Main model: Coarse-grain vit_l_16 with both fine and coarse grain secondary models\n",
      "+----------+-----------------------------+-----------------------------+-----------------------------+\n",
      "|          | 1e-05                       | 1e-06                       | 5e-05                       |\n",
      "+==========+=============================+=============================+=============================+\n",
      "| vit_b_16 | 1e-05: 84.1% (84.3%, \u001B[32m\u001B[0m\u001B[31m-0.2%)\u001B[0m | 1e-05: 78.1% (74.0%, \u001B[32m+\u001B[0m\u001B[32m4.1%)\u001B[0m | 1e-05: 83.4% (83.7%, \u001B[32m\u001B[0m\u001B[31m-0.3%)\u001B[0m |\n",
      "|          | 1e-06: 84.4% (84.3%, \u001B[32m+\u001B[0m\u001B[32m0.1%)\u001B[0m | 1e-06: 77.5% (74.0%, \u001B[32m+\u001B[0m\u001B[32m3.5%)\u001B[0m | 1e-06: 83.8% (83.7%, \u001B[32m+\u001B[0m\u001B[32m0.1%)\u001B[0m |\n",
      "|          | 5e-05: 84.9% (84.3%, \u001B[32m+\u001B[0m\u001B[32m0.6%)\u001B[0m | 5e-05: 83.8% (74.0%, \u001B[32m+\u001B[0m\u001B[32m9.8%)\u001B[0m | 5e-05: 85.4% (83.7%, \u001B[32m+\u001B[0m\u001B[32m1.7%)\u001B[0m |\n",
      "+----------+-----------------------------+-----------------------------+-----------------------------+\n",
      "\n",
      "\n",
      "Main model: Coarse-grain vit_l_16 with both fine and coarse grain secondary models\n",
      "+----------+-----------------------------+-----------------------------+-----------------------------+\n",
      "|          | 1e-05                       | 1e-06                       | 5e-05                       |\n",
      "+==========+=============================+=============================+=============================+\n",
      "| vit_b_32 | 1e-05: 83.3% (84.3%, \u001B[32m\u001B[0m\u001B[31m-0.9%)\u001B[0m | 1e-05: 76.8% (74.0%, \u001B[32m+\u001B[0m\u001B[32m2.8%)\u001B[0m | 1e-05: 82.7% (83.7%, \u001B[32m\u001B[0m\u001B[31m-1.0%)\u001B[0m |\n",
      "|          | 1e-06: 84.6% (84.3%, \u001B[32m+\u001B[0m\u001B[32m0.4%)\u001B[0m | 1e-06: 75.8% (74.0%, \u001B[32m+\u001B[0m\u001B[32m1.9%)\u001B[0m | 1e-06: 84.0% (83.7%, \u001B[32m+\u001B[0m\u001B[32m0.3%)\u001B[0m |\n",
      "|          | 5e-05: 84.5% (84.3%, \u001B[32m+\u001B[0m\u001B[32m0.2%)\u001B[0m | 5e-05: 76.4% (74.0%, \u001B[32m+\u001B[0m\u001B[32m2.4%)\u001B[0m | 5e-05: 83.3% (83.7%, \u001B[32m\u001B[0m\u001B[31m-0.4%)\u001B[0m |\n",
      "+----------+-----------------------------+-----------------------------+-----------------------------+\n",
      "\n",
      "\n",
      "Main model: Coarse-grain vit_l_16 with both fine and coarse grain secondary models\n",
      "+----------+-----------------------------+-----------------------------+-----------------------------+\n",
      "|          | 1e-05                       | 1e-06                       | 5e-05                       |\n",
      "+==========+=============================+=============================+=============================+\n",
      "| vit_l_32 | 1e-05: 84.1% (84.3%, \u001B[32m\u001B[0m\u001B[31m-0.1%)\u001B[0m | 1e-05: 76.7% (74.0%, \u001B[32m+\u001B[0m\u001B[32m2.7%)\u001B[0m | 1e-05: 84.5% (83.7%, \u001B[32m+\u001B[0m\u001B[32m0.8%)\u001B[0m |\n",
      "|          | 1e-06: 84.3% (84.3%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m  | 1e-06: 75.9% (74.0%, \u001B[32m+\u001B[0m\u001B[32m2.0%)\u001B[0m | 1e-06: 83.5% (83.7%, \u001B[32m\u001B[0m\u001B[31m-0.2%)\u001B[0m |\n",
      "|          | 5e-05: 84.9% (84.3%, \u001B[32m+\u001B[0m\u001B[32m0.7%)\u001B[0m | 5e-05: 78.3% (74.0%, \u001B[32m+\u001B[0m\u001B[32m4.3%)\u001B[0m | 5e-05: 83.5% (83.7%, \u001B[32m\u001B[0m\u001B[31m-0.2%)\u001B[0m |\n",
      "+----------+-----------------------------+-----------------------------+-----------------------------+\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Main model: Coarse-grain vit_l_32, secondary granularity: coarse\n",
      "+----------+-----------------------------+------------------------------+\n",
      "|          | 1e-05                       | 1e-06                        |\n",
      "+==========+=============================+==============================+\n",
      "| vit_b_16 | 1e-05: 80.4% (79.2%, \u001B[32m+\u001B[0m\u001B[32m1.2%)\u001B[0m | 1e-06: 63.2% (59.5%, \u001B[32m+\u001B[0m\u001B[32m3.7%)\u001B[0m  |\n",
      "|          | 1e-06: 79.2% (79.2%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m  | 5e-05: 76.2% (59.5%, \u001B[32m+\u001B[0m\u001B[32m16.7%)\u001B[0m |\n",
      "|          | 5e-05: 79.8% (79.2%, \u001B[32m+\u001B[0m\u001B[32m0.6%)\u001B[0m |                              |\n",
      "+----------+-----------------------------+------------------------------+\n",
      "| vit_b_32 | 1e-05: 78.9% (79.2%, \u001B[32m\u001B[0m\u001B[31m-0.3%)\u001B[0m | 1e-05: 72.8% (59.5%, \u001B[32m+\u001B[0m\u001B[32m13.3%)\u001B[0m |\n",
      "|          | 1e-06: 77.6% (79.2%, \u001B[32m\u001B[0m\u001B[31m-1.6%)\u001B[0m | 5e-05: 70.6% (59.5%, \u001B[32m+\u001B[0m\u001B[32m11.0%)\u001B[0m |\n",
      "|          | 5e-05: 79.1% (79.2%, \u001B[32m\u001B[0m\u001B[31m-0.1%)\u001B[0m |                              |\n",
      "+----------+-----------------------------+------------------------------+\n",
      "| vit_l_16 | \u001B[34m1e-05: 80.5% (79.2%, \u001B[32m+\u001B[0m\u001B[32m1.3%)\u001B[0m | 1e-05: 76.7% (59.5%, \u001B[32m+\u001B[0m\u001B[32m17.1%)\u001B[0m |\n",
      "|          | 1e-06: 78.3% (79.2%, \u001B[32m\u001B[0m\u001B[31m-0.9%)\u001B[0m | 1e-06: 68.1% (59.5%, \u001B[32m+\u001B[0m\u001B[32m8.6%)\u001B[0m  |\n",
      "|          | 5e-05: 82.7% (79.2%, \u001B[32m+\u001B[0m\u001B[32m3.5%)\u001B[0m | 5e-05: 75.9% (59.5%, \u001B[32m+\u001B[0m\u001B[32m16.3%)\u001B[0m |\n",
      "|          | \u001B[0m                            |                              |\n",
      "+----------+-----------------------------+------------------------------+\n",
      "\n",
      "\n",
      "Main model: Coarse-grain vit_l_32, secondary granularity: fine\n",
      "+----------+-----------------------------+------------------------------+-----------------------------+\n",
      "|          | 1e-05                       | 1e-06                        | 5e-05                       |\n",
      "+==========+=============================+==============================+=============================+\n",
      "| vit_b_16 | 1e-05: 79.8% (79.2%, \u001B[32m+\u001B[0m\u001B[32m0.6%)\u001B[0m | 1e-05: 68.9% (59.5%, \u001B[32m+\u001B[0m\u001B[32m9.4%)\u001B[0m  | 1e-05: 78.7% (80.8%, \u001B[32m\u001B[0m\u001B[31m-2.0%)\u001B[0m |\n",
      "|          | 1e-06: 80.0% (79.2%, \u001B[32m+\u001B[0m\u001B[32m0.7%)\u001B[0m | 1e-06: 71.5% (59.5%, \u001B[32m+\u001B[0m\u001B[32m12.0%)\u001B[0m | 1e-06: 80.1% (80.8%, \u001B[32m\u001B[0m\u001B[31m-0.6%)\u001B[0m |\n",
      "|          | 5e-05: 80.3% (79.2%, \u001B[32m+\u001B[0m\u001B[32m1.1%)\u001B[0m | 5e-05: 68.9% (59.5%, \u001B[32m+\u001B[0m\u001B[32m9.4%)\u001B[0m  | 5e-05: 79.8% (80.8%, \u001B[32m\u001B[0m\u001B[31m-1.0%)\u001B[0m |\n",
      "+----------+-----------------------------+------------------------------+-----------------------------+\n",
      "| vit_b_32 | 1e-05: 79.0% (79.2%, \u001B[32m\u001B[0m\u001B[31m-0.2%)\u001B[0m | 1e-05: 66.3% (59.5%, \u001B[32m+\u001B[0m\u001B[32m6.8%)\u001B[0m  | 1e-05: 79.3% (80.8%, \u001B[32m\u001B[0m\u001B[31m-1.5%)\u001B[0m |\n",
      "|          | 1e-06: 78.8% (79.2%, \u001B[32m\u001B[0m\u001B[31m-0.4%)\u001B[0m | 1e-06: 69.0% (59.5%, \u001B[32m+\u001B[0m\u001B[32m9.4%)\u001B[0m  | 1e-06: 79.6% (80.8%, \u001B[32m\u001B[0m\u001B[31m-1.1%)\u001B[0m |\n",
      "|          | 5e-05: 79.6% (79.2%, \u001B[32m+\u001B[0m\u001B[32m0.4%)\u001B[0m | 5e-05: 65.8% (59.5%, \u001B[32m+\u001B[0m\u001B[32m6.3%)\u001B[0m  | 5e-05: 79.8% (80.8%, \u001B[32m\u001B[0m\u001B[31m-0.9%)\u001B[0m |\n",
      "+----------+-----------------------------+------------------------------+-----------------------------+\n",
      "| vit_l_16 | \u001B[34m1e-05: 80.2% (79.2%, \u001B[32m+\u001B[0m\u001B[32m1.0%)\u001B[0m | 1e-05: 70.0% (59.5%, \u001B[32m+\u001B[0m\u001B[32m10.4%)\u001B[0m | 1e-05: 80.6% (80.8%, \u001B[32m\u001B[0m\u001B[31m-0.1%)\u001B[0m |\n",
      "|          | 1e-06: 79.8% (79.2%, \u001B[32m+\u001B[0m\u001B[32m0.6%)\u001B[0m | 1e-06: 69.5% (59.5%, \u001B[32m+\u001B[0m\u001B[32m9.9%)\u001B[0m  | 1e-06: 78.9% (80.8%, \u001B[32m\u001B[0m\u001B[31m-1.9%)\u001B[0m |\n",
      "|          | 5e-05: 80.7% (79.2%, \u001B[32m+\u001B[0m\u001B[32m1.5%)\u001B[0m | 5e-05: 70.3% (59.5%, \u001B[32m+\u001B[0m\u001B[32m10.8%)\u001B[0m | 5e-05: 79.7% (80.8%, \u001B[32m\u001B[0m\u001B[31m-1.0%)\u001B[0m |\n",
      "|          | \u001B[0m                            |                              |                             |\n",
      "+----------+-----------------------------+------------------------------+-----------------------------+\n",
      "\n",
      "\n",
      "Main model: Coarse-grain vit_l_32 with both fine and coarse grain secondary models\n",
      "+----------+-----------------------------+------------------------------+-----------------------------+\n",
      "|          | vit_b_16                    | vit_b_32                     | vit_l_16                    |\n",
      "+==========+=============================+==============================+=============================+\n",
      "| vit_b_16 | 1e-05: 81.2% (79.2%, \u001B[32m+\u001B[0m\u001B[32m2.0%)\u001B[0m | 1e-05: 68.3% (59.5%, \u001B[32m+\u001B[0m\u001B[32m8.8%)\u001B[0m  | 1e-05: 79.5% (80.8%, \u001B[32m\u001B[0m\u001B[31m-1.3%)\u001B[0m |\n",
      "|          | 1e-06: 80.0% (79.2%, \u001B[32m+\u001B[0m\u001B[32m0.7%)\u001B[0m | 1e-06: 65.1% (59.5%, \u001B[32m+\u001B[0m\u001B[32m5.6%)\u001B[0m  | 1e-06: 80.1% (80.8%, \u001B[32m\u001B[0m\u001B[31m-0.6%)\u001B[0m |\n",
      "|          | 5e-05: 81.6% (79.2%, \u001B[32m+\u001B[0m\u001B[32m2.4%)\u001B[0m | 5e-05: 75.5% (59.5%, \u001B[32m+\u001B[0m\u001B[32m16.0%)\u001B[0m | 5e-05: 81.2% (80.8%, \u001B[32m+\u001B[0m\u001B[32m0.4%)\u001B[0m |\n",
      "+----------+-----------------------------+------------------------------+-----------------------------+\n",
      "\n",
      "\n",
      "Main model: Coarse-grain vit_l_32 with both fine and coarse grain secondary models\n",
      "+----------+-----------------------------+-----------------------------+-----------------------------+\n",
      "|          | vit_b_16                    | vit_b_32                    | vit_l_16                    |\n",
      "+==========+=============================+=============================+=============================+\n",
      "| vit_b_32 | 1e-05: 79.4% (79.2%, \u001B[32m+\u001B[0m\u001B[32m0.2%)\u001B[0m | 1e-05: 67.0% (59.5%, \u001B[32m+\u001B[0m\u001B[32m7.5%)\u001B[0m | 1e-05: 79.3% (80.8%, \u001B[32m\u001B[0m\u001B[31m-1.5%)\u001B[0m |\n",
      "|          | 1e-06: 78.5% (79.2%, \u001B[32m\u001B[0m\u001B[31m-0.7%)\u001B[0m | 1e-06: 63.0% (59.5%, \u001B[32m+\u001B[0m\u001B[32m3.5%)\u001B[0m | 1e-06: 79.6% (80.8%, \u001B[32m\u001B[0m\u001B[31m-1.1%)\u001B[0m |\n",
      "|          | 5e-05: 80.0% (79.2%, \u001B[32m+\u001B[0m\u001B[32m0.8%)\u001B[0m | 5e-05: 69.4% (59.5%, \u001B[32m+\u001B[0m\u001B[32m9.9%)\u001B[0m | 5e-05: 79.4% (80.8%, \u001B[32m\u001B[0m\u001B[31m-1.4%)\u001B[0m |\n",
      "+----------+-----------------------------+-----------------------------+-----------------------------+\n",
      "\n",
      "\n",
      "Main model: Coarse-grain vit_l_32 with both fine and coarse grain secondary models\n",
      "+----------+-----------------------------+------------------------------+-----------------------------+\n",
      "|          | vit_b_16                    | vit_b_32                     | vit_l_16                    |\n",
      "+==========+=============================+==============================+=============================+\n",
      "| vit_l_16 | 1e-05: 79.5% (79.2%, \u001B[32m+\u001B[0m\u001B[32m0.2%)\u001B[0m | 1e-05: 67.8% (59.5%, \u001B[32m+\u001B[0m\u001B[32m8.3%)\u001B[0m  | 1e-05: 80.4% (80.8%, \u001B[32m\u001B[0m\u001B[31m-0.4%)\u001B[0m |\n",
      "|          | 1e-06: 79.9% (79.2%, \u001B[32m+\u001B[0m\u001B[32m0.7%)\u001B[0m | 1e-06: 67.8% (59.5%, \u001B[32m+\u001B[0m\u001B[32m8.3%)\u001B[0m  | 1e-06: 78.9% (80.8%, \u001B[32m\u001B[0m\u001B[31m-1.9%)\u001B[0m |\n",
      "|          | 5e-05: 82.2% (79.2%, \u001B[32m+\u001B[0m\u001B[32m3.0%)\u001B[0m | 5e-05: 70.5% (59.5%, \u001B[32m+\u001B[0m\u001B[32m11.0%)\u001B[0m | 5e-05: 80.5% (80.8%, \u001B[32m\u001B[0m\u001B[31m-0.2%)\u001B[0m |\n",
      "+----------+-----------------------------+------------------------------+-----------------------------+\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "######################################## Main granularity: fine ########################################\n",
      "########################################################################################################\n",
      "\n",
      "Main model: Fine-grain vit_b_16, secondary granularity: coarse\n",
      "+----------+----------------------------+----------------------------+----------------------------+\n",
      "|          | 1e-05                      | 1e-06                      | 5e-05                      |\n",
      "+==========+============================+============================+============================+\n",
      "| vit_b_32 | 1e-05: 63.9% (63.9%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m | \u001B[34m1e-05: 70.0% (70.0%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m | 1e-05: 64.5% (64.5%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m |\n",
      "|          | 1e-06: 63.9% (63.9%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m | 1e-06: 70.0% (70.0%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m | 1e-06: 64.5% (64.5%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m |\n",
      "|          | 5e-05: 63.9% (63.9%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m | 5e-05: 70.0% (70.0%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m | 5e-05: 64.5% (64.5%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m |\n",
      "|          |                            | \u001B[0m                           |                            |\n",
      "+----------+----------------------------+----------------------------+----------------------------+\n",
      "| vit_l_16 | 1e-05: 63.9% (63.9%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m | 1e-05: 70.0% (70.0%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m | 1e-05: 64.5% (64.5%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m |\n",
      "|          | 1e-06: 63.9% (63.9%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m | 1e-06: 70.0% (70.0%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m | 1e-06: 64.5% (64.5%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m |\n",
      "|          | 5e-05: 63.9% (63.9%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m | 5e-05: 70.0% (70.0%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m | 5e-05: 64.5% (64.5%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m |\n",
      "+----------+----------------------------+----------------------------+----------------------------+\n",
      "| vit_l_32 | 1e-05: 63.9% (63.9%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m | 1e-05: 70.0% (70.0%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m | 1e-05: 64.5% (64.5%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m |\n",
      "|          | 1e-06: 63.9% (63.9%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m | 1e-06: 70.0% (70.0%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m | 1e-06: 64.5% (64.5%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m |\n",
      "|          | 5e-05: 63.9% (63.9%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m | 5e-05: 70.0% (70.0%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m | 5e-05: 64.5% (64.5%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m |\n",
      "+----------+----------------------------+----------------------------+----------------------------+\n",
      "\n",
      "\n",
      "Main model: Fine-grain vit_b_16, secondary granularity: fine\n",
      "+----------+-----------------------------+-----------------------------+-----------------------------+\n",
      "|          | 1e-05                       | 1e-06                       | 5e-05                       |\n",
      "+==========+=============================+=============================+=============================+\n",
      "| vit_b_32 | 1e-05: 63.7% (63.9%, \u001B[32m\u001B[0m\u001B[31m-0.2%)\u001B[0m | 1e-05: 70.0% (70.0%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m  | 1e-05: 64.5% (64.5%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m  |\n",
      "|          | 1e-06: 65.0% (63.9%, \u001B[32m+\u001B[0m\u001B[32m1.1%)\u001B[0m | 1e-06: 70.0% (70.0%, \u001B[32m+\u001B[0m\u001B[32m0.1%)\u001B[0m | 1e-06: 64.3% (64.5%, \u001B[32m\u001B[0m\u001B[31m-0.2%)\u001B[0m |\n",
      "|          | 5e-05: 63.8% (63.9%, \u001B[32m\u001B[0m\u001B[31m-0.1%)\u001B[0m | 5e-05: 69.8% (70.0%, \u001B[32m\u001B[0m\u001B[31m-0.1%)\u001B[0m | 5e-05: 64.1% (64.5%, \u001B[32m\u001B[0m\u001B[31m-0.4%)\u001B[0m |\n",
      "+----------+-----------------------------+-----------------------------+-----------------------------+\n",
      "| vit_l_16 | 1e-05: 65.5% (63.9%, \u001B[32m+\u001B[0m\u001B[32m1.5%)\u001B[0m | \u001B[34m1e-05: 70.0% (70.0%, \u001B[32m+\u001B[0m\u001B[32m0.1%)\u001B[0m | 1e-05: 65.0% (64.5%, \u001B[32m+\u001B[0m\u001B[32m0.4%)\u001B[0m |\n",
      "|          | 1e-06: 66.1% (63.9%, \u001B[32m+\u001B[0m\u001B[32m2.2%)\u001B[0m | 1e-06: 70.3% (70.0%, \u001B[32m+\u001B[0m\u001B[32m0.4%)\u001B[0m | 1e-06: 64.6% (64.5%, \u001B[32m+\u001B[0m\u001B[32m0.1%)\u001B[0m |\n",
      "|          | 5e-05: 65.8% (63.9%, \u001B[32m+\u001B[0m\u001B[32m1.9%)\u001B[0m | 5e-05: 70.6% (70.0%, \u001B[32m+\u001B[0m\u001B[32m0.6%)\u001B[0m | 5e-05: 65.7% (64.5%, \u001B[32m+\u001B[0m\u001B[32m1.2%)\u001B[0m |\n",
      "|          |                             | \u001B[0m                            |                             |\n",
      "+----------+-----------------------------+-----------------------------+-----------------------------+\n",
      "| vit_l_32 | 1e-05: 64.2% (63.9%, \u001B[32m+\u001B[0m\u001B[32m0.3%)\u001B[0m | 1e-05: 69.9% (70.0%, \u001B[32m\u001B[0m\u001B[31m-0.1%)\u001B[0m | 1e-05: 64.7% (64.5%, \u001B[32m+\u001B[0m\u001B[32m0.2%)\u001B[0m |\n",
      "|          | 1e-06: 64.9% (63.9%, \u001B[32m+\u001B[0m\u001B[32m1.0%)\u001B[0m | 1e-06: 70.0% (70.0%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m  | 1e-06: 64.8% (64.5%, \u001B[32m+\u001B[0m\u001B[32m0.2%)\u001B[0m |\n",
      "|          | 5e-05: 64.2% (63.9%, \u001B[32m+\u001B[0m\u001B[32m0.3%)\u001B[0m | 5e-05: 69.9% (70.0%, \u001B[32m\u001B[0m\u001B[31m-0.1%)\u001B[0m | 5e-05: 64.3% (64.5%, \u001B[32m\u001B[0m\u001B[31m-0.2%)\u001B[0m |\n",
      "+----------+-----------------------------+-----------------------------+-----------------------------+\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Main model: Fine-grain vit_b_32, secondary granularity: coarse\n",
      "+----------+-----------------------------+-----------------------------+----------------------------+\n",
      "|          | 1e-05                       | 1e-06                       | 5e-05                      |\n",
      "+==========+=============================+=============================+============================+\n",
      "| vit_b_16 | 1e-05: 55.9% (55.9%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m  | \u001B[34m1e-05: 63.7% (63.7%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m  | 1e-05: 53.7% (53.7%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m |\n",
      "|          | 1e-06: 55.9% (55.9%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m  | 1e-06: 63.7% (63.7%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m  | 1e-06: 53.7% (53.7%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m |\n",
      "|          | 5e-05: 55.9% (55.9%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m  | 5e-05: 63.7% (63.7%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m  | 5e-05: 53.7% (53.7%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m |\n",
      "|          |                             | \u001B[0m                            |                            |\n",
      "+----------+-----------------------------+-----------------------------+----------------------------+\n",
      "| vit_l_16 | 1e-05: 55.9% (55.9%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m  | 1e-05: 63.7% (63.7%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m  | 1e-05: 53.7% (53.7%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m |\n",
      "|          | 1e-06: 55.9% (55.9%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m  | 1e-06: 63.7% (63.7%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m  | 1e-06: 53.7% (53.7%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m |\n",
      "|          | 5e-05: 55.1% (55.9%, \u001B[32m\u001B[0m\u001B[31m-0.8%)\u001B[0m | 5e-05: 62.7% (63.7%, \u001B[32m\u001B[0m\u001B[31m-1.0%)\u001B[0m | 5e-05: 53.7% (53.7%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m |\n",
      "+----------+-----------------------------+-----------------------------+----------------------------+\n",
      "| vit_l_32 | 1e-05: 55.9% (55.9%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m  | 1e-05: 63.7% (63.7%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m  | 1e-05: 53.7% (53.7%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m |\n",
      "|          | 1e-06: 55.9% (55.9%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m  | 1e-06: 63.7% (63.7%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m  | 1e-06: 53.7% (53.7%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m |\n",
      "|          | 5e-05: 55.2% (55.9%, \u001B[32m\u001B[0m\u001B[31m-0.7%)\u001B[0m | 5e-05: 63.0% (63.7%, \u001B[32m\u001B[0m\u001B[31m-0.7%)\u001B[0m | 5e-05: 53.7% (53.7%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m |\n",
      "+----------+-----------------------------+-----------------------------+----------------------------+\n",
      "\n",
      "\n",
      "Main model: Fine-grain vit_b_32, secondary granularity: fine\n",
      "+----------+-----------------------------+-----------------------------+-----------------------------+\n",
      "|          | 1e-05                       | 1e-06                       | 5e-05                       |\n",
      "+==========+=============================+=============================+=============================+\n",
      "| vit_b_16 | 1e-05: 58.2% (55.9%, \u001B[32m+\u001B[0m\u001B[32m2.3%)\u001B[0m | \u001B[34m1e-05: 63.8% (63.7%, \u001B[32m+\u001B[0m\u001B[32m0.2%)\u001B[0m | 1e-05: 55.0% (53.7%, \u001B[32m+\u001B[0m\u001B[32m1.3%)\u001B[0m |\n",
      "|          | 1e-06: 59.7% (55.9%, \u001B[32m+\u001B[0m\u001B[32m3.8%)\u001B[0m | 1e-06: 65.8% (63.7%, \u001B[32m+\u001B[0m\u001B[32m2.2%)\u001B[0m | 1e-06: 56.3% (53.7%, \u001B[32m+\u001B[0m\u001B[32m2.5%)\u001B[0m |\n",
      "|          | 5e-05: 58.5% (55.9%, \u001B[32m+\u001B[0m\u001B[32m2.6%)\u001B[0m | 5e-05: 65.6% (63.7%, \u001B[32m+\u001B[0m\u001B[32m2.0%)\u001B[0m | 5e-05: 58.2% (53.7%, \u001B[32m+\u001B[0m\u001B[32m4.4%)\u001B[0m |\n",
      "|          |                             | \u001B[0m                            |                             |\n",
      "+----------+-----------------------------+-----------------------------+-----------------------------+\n",
      "| vit_l_16 | 1e-05: 60.1% (55.9%, \u001B[32m+\u001B[0m\u001B[32m4.2%)\u001B[0m | 1e-05: 64.3% (63.7%, \u001B[32m+\u001B[0m\u001B[32m0.7%)\u001B[0m | 1e-05: 55.9% (53.7%, \u001B[32m+\u001B[0m\u001B[32m2.2%)\u001B[0m |\n",
      "|          | 1e-06: 59.8% (55.9%, \u001B[32m+\u001B[0m\u001B[32m3.9%)\u001B[0m | 1e-06: 64.3% (63.7%, \u001B[32m+\u001B[0m\u001B[32m0.6%)\u001B[0m | 1e-06: 58.5% (53.7%, \u001B[32m+\u001B[0m\u001B[32m4.8%)\u001B[0m |\n",
      "|          | 5e-05: 58.9% (55.9%, \u001B[32m+\u001B[0m\u001B[32m3.0%)\u001B[0m | 5e-05: 64.8% (63.7%, \u001B[32m+\u001B[0m\u001B[32m1.1%)\u001B[0m | 5e-05: 56.8% (53.7%, \u001B[32m+\u001B[0m\u001B[32m3.1%)\u001B[0m |\n",
      "+----------+-----------------------------+-----------------------------+-----------------------------+\n",
      "| vit_l_32 | 1e-05: 57.4% (55.9%, \u001B[32m+\u001B[0m\u001B[32m1.5%)\u001B[0m | 1e-05: 63.8% (63.7%, \u001B[32m+\u001B[0m\u001B[32m0.2%)\u001B[0m | 1e-05: 54.7% (53.7%, \u001B[32m+\u001B[0m\u001B[32m1.0%)\u001B[0m |\n",
      "|          | 1e-06: 58.3% (55.9%, \u001B[32m+\u001B[0m\u001B[32m2.4%)\u001B[0m | 1e-06: 64.1% (63.7%, \u001B[32m+\u001B[0m\u001B[32m0.4%)\u001B[0m | 1e-06: 55.0% (53.7%, \u001B[32m+\u001B[0m\u001B[32m1.2%)\u001B[0m |\n",
      "|          | 5e-05: 56.4% (55.9%, \u001B[32m+\u001B[0m\u001B[32m0.6%)\u001B[0m | 5e-05: 63.7% (63.7%, \u001B[32m+\u001B[0m\u001B[32m0.1%)\u001B[0m | 5e-05: 54.7% (53.7%, \u001B[32m+\u001B[0m\u001B[32m0.9%)\u001B[0m |\n",
      "+----------+-----------------------------+-----------------------------+-----------------------------+\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Main model: Fine-grain vit_l_16, secondary granularity: coarse\n",
      "+----------+----------------------------+-----------------------------+-----------------------------+\n",
      "|          | 1e-05                      | 1e-06                       | 5e-05                       |\n",
      "+==========+============================+=============================+=============================+\n",
      "| vit_b_16 | 1e-05: 70.0% (70.0%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m | \u001B[34m1e-05: 70.3% (70.3%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m  | 1e-05: 65.0% (66.2%, \u001B[32m\u001B[0m\u001B[31m-1.2%)\u001B[0m |\n",
      "|          | 1e-06: 70.0% (70.0%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m | 1e-06: 70.3% (70.3%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m  | 1e-06: 66.2% (66.2%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m  |\n",
      "|          | 5e-05: 70.0% (70.0%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m | 5e-05: 70.3% (70.3%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m  | 5e-05: 66.2% (66.2%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m  |\n",
      "|          |                            | \u001B[0m                            |                             |\n",
      "+----------+----------------------------+-----------------------------+-----------------------------+\n",
      "| vit_b_32 | 1e-05: 70.0% (70.0%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m | 1e-05: 70.3% (70.3%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m  | 1e-05: 65.4% (66.2%, \u001B[32m\u001B[0m\u001B[31m-0.8%)\u001B[0m |\n",
      "|          | 1e-06: 70.0% (70.0%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m | 1e-06: 70.3% (70.3%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m  | 1e-06: 66.2% (66.2%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m  |\n",
      "|          | 5e-05: 70.0% (70.0%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m | 5e-05: 69.6% (70.3%, \u001B[32m\u001B[0m\u001B[31m-0.7%)\u001B[0m | 5e-05: 65.6% (66.2%, \u001B[32m\u001B[0m\u001B[31m-0.6%)\u001B[0m |\n",
      "+----------+----------------------------+-----------------------------+-----------------------------+\n",
      "| vit_l_32 | 1e-05: 70.0% (70.0%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m | 1e-05: 70.3% (70.3%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m  | 1e-05: 66.2% (66.2%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m  |\n",
      "|          | 1e-06: 70.0% (70.0%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m | 1e-06: 70.3% (70.3%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m  | 1e-06: 66.2% (66.2%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m  |\n",
      "|          | 5e-05: 70.0% (70.0%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m | 5e-05: 70.3% (70.3%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m  | 5e-05: 65.2% (66.2%, \u001B[32m\u001B[0m\u001B[31m-1.0%)\u001B[0m |\n",
      "+----------+----------------------------+-----------------------------+-----------------------------+\n",
      "\n",
      "\n",
      "Main model: Fine-grain vit_l_16, secondary granularity: fine\n",
      "+----------+-----------------------------+-----------------------------+-----------------------------+\n",
      "|          | 1e-05                       | 1e-06                       | 5e-05                       |\n",
      "+==========+=============================+=============================+=============================+\n",
      "| vit_b_16 | 1e-05: 70.0% (70.0%, \u001B[32m+\u001B[0m\u001B[32m0.1%)\u001B[0m | \u001B[34m1e-05: 70.0% (70.3%, \u001B[32m\u001B[0m\u001B[31m-0.2%)\u001B[0m | 1e-05: 66.5% (66.2%, \u001B[32m+\u001B[0m\u001B[32m0.3%)\u001B[0m |\n",
      "|          | 1e-06: 69.9% (70.0%, \u001B[32m\u001B[0m\u001B[31m-0.1%)\u001B[0m | 1e-06: 71.4% (70.3%, \u001B[32m+\u001B[0m\u001B[32m1.2%)\u001B[0m | 1e-06: 67.1% (66.2%, \u001B[32m+\u001B[0m\u001B[32m0.9%)\u001B[0m |\n",
      "|          | 5e-05: 70.1% (70.0%, \u001B[32m+\u001B[0m\u001B[32m0.2%)\u001B[0m | 5e-05: 70.9% (70.3%, \u001B[32m+\u001B[0m\u001B[32m0.7%)\u001B[0m | 5e-05: 67.2% (66.2%, \u001B[32m+\u001B[0m\u001B[32m1.0%)\u001B[0m |\n",
      "|          |                             | \u001B[0m                            |                             |\n",
      "+----------+-----------------------------+-----------------------------+-----------------------------+\n",
      "| vit_b_32 | 1e-05: 70.0% (70.0%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m  | 1e-05: 70.3% (70.3%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m  | 1e-05: 65.6% (66.2%, \u001B[32m\u001B[0m\u001B[31m-0.6%)\u001B[0m |\n",
      "|          | 1e-06: 70.0% (70.0%, \u001B[32m+\u001B[0m\u001B[32m0.1%)\u001B[0m | 1e-06: 71.1% (70.3%, \u001B[32m+\u001B[0m\u001B[32m0.8%)\u001B[0m | 1e-06: 65.7% (66.2%, \u001B[32m\u001B[0m\u001B[31m-0.5%)\u001B[0m |\n",
      "|          | 5e-05: 69.8% (70.0%, \u001B[32m\u001B[0m\u001B[31m-0.1%)\u001B[0m | 5e-05: 70.4% (70.3%, \u001B[32m+\u001B[0m\u001B[32m0.1%)\u001B[0m | 5e-05: 65.8% (66.2%, \u001B[32m\u001B[0m\u001B[31m-0.4%)\u001B[0m |\n",
      "+----------+-----------------------------+-----------------------------+-----------------------------+\n",
      "| vit_l_32 | 1e-05: 70.0% (70.0%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m  | 1e-05: 71.2% (70.3%, \u001B[32m+\u001B[0m\u001B[32m0.9%)\u001B[0m | 1e-05: 66.6% (66.2%, \u001B[32m+\u001B[0m\u001B[32m0.4%)\u001B[0m |\n",
      "|          | 1e-06: 70.2% (70.0%, \u001B[32m+\u001B[0m\u001B[32m0.2%)\u001B[0m | 1e-06: 70.7% (70.3%, \u001B[32m+\u001B[0m\u001B[32m0.4%)\u001B[0m | 1e-06: 66.7% (66.2%, \u001B[32m+\u001B[0m\u001B[32m0.5%)\u001B[0m |\n",
      "|          | 5e-05: 69.7% (70.0%, \u001B[32m\u001B[0m\u001B[31m-0.2%)\u001B[0m | 5e-05: 70.6% (70.3%, \u001B[32m+\u001B[0m\u001B[32m0.3%)\u001B[0m | 5e-05: 66.1% (66.2%, \u001B[32m\u001B[0m\u001B[31m-0.1%)\u001B[0m |\n",
      "+----------+-----------------------------+-----------------------------+-----------------------------+\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Main model: Fine-grain vit_l_32, secondary granularity: coarse\n",
      "+----------+-----------------------------+-----------------------------+----------------------------+\n",
      "|          | 1e-05                       | 1e-06                       | 5e-05                      |\n",
      "+==========+=============================+=============================+============================+\n",
      "| vit_b_16 | 1e-05: 57.9% (58.2%, \u001B[32m\u001B[0m\u001B[31m-0.4%)\u001B[0m | \u001B[34m1e-05: 67.3% (67.3%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m  | 1e-05: 62.4% (62.4%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m |\n",
      "|          | 1e-06: 58.2% (58.2%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m  | 1e-06: 67.3% (67.3%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m  | 1e-06: 62.4% (62.4%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m |\n",
      "|          | 5e-05: 57.9% (58.2%, \u001B[32m\u001B[0m\u001B[31m-0.4%)\u001B[0m | 5e-05: 67.3% (67.3%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m  | 5e-05: 62.4% (62.4%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m |\n",
      "|          |                             | \u001B[0m                            |                            |\n",
      "+----------+-----------------------------+-----------------------------+----------------------------+\n",
      "| vit_b_32 | 1e-05: 58.0% (58.2%, \u001B[32m\u001B[0m\u001B[31m-0.2%)\u001B[0m | 1e-05: 67.3% (67.3%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m  | 1e-05: 62.4% (62.4%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m |\n",
      "|          | 1e-06: 58.2% (58.2%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m  | 1e-06: 67.3% (67.3%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m  | 1e-06: 62.4% (62.4%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m |\n",
      "|          | 5e-05: 58.2% (58.2%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m  | 5e-05: 66.7% (67.3%, \u001B[32m\u001B[0m\u001B[31m-0.6%)\u001B[0m | 5e-05: 62.4% (62.4%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m |\n",
      "+----------+-----------------------------+-----------------------------+----------------------------+\n",
      "| vit_l_16 | 1e-05: 57.4% (58.2%, \u001B[32m\u001B[0m\u001B[31m-0.9%)\u001B[0m | 1e-05: 67.3% (67.3%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m  | 1e-05: 62.4% (62.4%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m |\n",
      "|          | 1e-06: 58.2% (58.2%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m  | 1e-06: 67.3% (67.3%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m  | 1e-06: 62.4% (62.4%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m |\n",
      "|          | 5e-05: 57.7% (58.2%, \u001B[32m\u001B[0m\u001B[31m-0.5%)\u001B[0m | 5e-05: 67.3% (67.3%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m  | 5e-05: 62.4% (62.4%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m |\n",
      "+----------+-----------------------------+-----------------------------+----------------------------+\n",
      "\n",
      "\n",
      "Main model: Fine-grain vit_l_32, secondary granularity: fine\n",
      "+----------+-----------------------------+-----------------------------+-----------------------------+\n",
      "|          | 1e-05                       | 1e-06                       | 5e-05                       |\n",
      "+==========+=============================+=============================+=============================+\n",
      "| vit_b_16 | 1e-05: 58.5% (58.2%, \u001B[32m+\u001B[0m\u001B[32m0.2%)\u001B[0m | 1e-05: 67.4% (67.3%, \u001B[32m+\u001B[0m\u001B[32m0.1%)\u001B[0m | 1e-05: 62.7% (62.4%, \u001B[32m+\u001B[0m\u001B[32m0.3%)\u001B[0m |\n",
      "|          | 1e-06: 61.1% (58.2%, \u001B[32m+\u001B[0m\u001B[32m2.8%)\u001B[0m | 1e-06: 68.0% (67.3%, \u001B[32m+\u001B[0m\u001B[32m0.7%)\u001B[0m | 1e-06: 65.0% (62.4%, \u001B[32m+\u001B[0m\u001B[32m2.6%)\u001B[0m |\n",
      "|          | 5e-05: 60.1% (58.2%, \u001B[32m+\u001B[0m\u001B[32m1.9%)\u001B[0m | 5e-05: 67.6% (67.3%, \u001B[32m+\u001B[0m\u001B[32m0.2%)\u001B[0m | 5e-05: 63.9% (62.4%, \u001B[32m+\u001B[0m\u001B[32m1.5%)\u001B[0m |\n",
      "+----------+-----------------------------+-----------------------------+-----------------------------+\n",
      "| vit_b_32 | 1e-05: 58.0% (58.2%, \u001B[32m\u001B[0m\u001B[31m-0.2%)\u001B[0m | 1e-05: 67.1% (67.3%, \u001B[32m\u001B[0m\u001B[31m-0.2%)\u001B[0m | 1e-05: 61.7% (62.4%, \u001B[32m\u001B[0m\u001B[31m-0.7%)\u001B[0m |\n",
      "|          | 1e-06: 59.4% (58.2%, \u001B[32m+\u001B[0m\u001B[32m1.2%)\u001B[0m | 1e-06: 67.1% (67.3%, \u001B[32m\u001B[0m\u001B[31m-0.2%)\u001B[0m | 1e-06: 63.9% (62.4%, \u001B[32m+\u001B[0m\u001B[32m1.5%)\u001B[0m |\n",
      "|          | 5e-05: 58.6% (58.2%, \u001B[32m+\u001B[0m\u001B[32m0.4%)\u001B[0m | 5e-05: 67.1% (67.3%, \u001B[32m\u001B[0m\u001B[31m-0.2%)\u001B[0m | 5e-05: 62.7% (62.4%, \u001B[32m+\u001B[0m\u001B[32m0.2%)\u001B[0m |\n",
      "+----------+-----------------------------+-----------------------------+-----------------------------+\n",
      "| vit_l_16 | 1e-05: 60.5% (58.2%, \u001B[32m+\u001B[0m\u001B[32m2.2%)\u001B[0m | \u001B[34m1e-05: 67.8% (67.3%, \u001B[32m+\u001B[0m\u001B[32m0.5%)\u001B[0m | 1e-05: 63.6% (62.4%, \u001B[32m+\u001B[0m\u001B[32m1.2%)\u001B[0m |\n",
      "|          | 1e-06: 60.6% (58.2%, \u001B[32m+\u001B[0m\u001B[32m2.4%)\u001B[0m | 1e-06: 68.3% (67.3%, \u001B[32m+\u001B[0m\u001B[32m1.0%)\u001B[0m | 1e-06: 63.7% (62.4%, \u001B[32m+\u001B[0m\u001B[32m1.3%)\u001B[0m |\n",
      "|          | 5e-05: 61.1% (58.2%, \u001B[32m+\u001B[0m\u001B[32m2.8%)\u001B[0m | 5e-05: 67.4% (67.3%, \u001B[32m+\u001B[0m\u001B[32m0.1%)\u001B[0m | 5e-05: 64.3% (62.4%, \u001B[32m+\u001B[0m\u001B[32m1.9%)\u001B[0m |\n",
      "|          |                             | \u001B[0m                            |                             |\n",
      "+----------+-----------------------------+-----------------------------+-----------------------------+\n",
      "\n",
      "\n",
      "####################################################################################################\n"
     ]
    }
   ],
   "source": [
    "def print_one_secondary_granularity(main_model_data: dict,\n",
    "                                    k: str,\n",
    "                                    main_granularity: str,\n",
    "                                    main_model_name: str):\n",
    "    table_data = []\n",
    "\n",
    "    # Get a list of learning rates from the first model\n",
    "    secondary_granularity_data = main_model_data[k]\n",
    "    main_learning_rates = sorted(secondary_granularity_data[\n",
    "                                     list(secondary_granularity_data.keys())[0]].keys())\n",
    "\n",
    "    header = [''] + main_learning_rates\n",
    "    table_data += [header]\n",
    "\n",
    "\n",
    "    # Keep track of maximal accuracy and its position\n",
    "    max_accuracy = 0.0\n",
    "    max_accuracy_position = None\n",
    "    \n",
    "    for secondary_model_name in sorted(secondary_granularity_data.keys()):\n",
    "        secondary_model_data = secondary_granularity_data[secondary_model_name]\n",
    "        row = [secondary_model_name]\n",
    "        \n",
    "        for main_lr in sorted(secondary_model_data.keys()):\n",
    "            main_lr_data = secondary_model_data[main_lr]\n",
    "            row_add = ''\n",
    "            for secondary_lr in sorted(main_lr_data.keys()):\n",
    "                curr_data = main_lr_data[secondary_lr]\n",
    "                curr_post = curr_data['post']\n",
    "                curr_prior = curr_data['prior']\n",
    "                curr_diff = curr_post - curr_prior\n",
    "    \n",
    "                # Highlight the cell with maximal accuracy in blue\n",
    "                if curr_post > max_accuracy:\n",
    "                    max_accuracy = curr_post\n",
    "                    max_accuracy_position = (len(table_data), len(row))\n",
    "    \n",
    "                row_add += (\n",
    "                    f\"{secondary_lr}: {round(curr_post * 100, 1)}% \" +\n",
    "                    f\"({round(curr_prior * 100, 1)}%, \" +\n",
    "                    termcolor.colored(\n",
    "                        f\"{'+' if curr_post > curr_prior else ''}\",\n",
    "                        color='green'\n",
    "                    ) +\n",
    "                    termcolor.colored(\n",
    "                        f\"{round(curr_diff * 100, 1)}%)\",\n",
    "                        color='green' if curr_post > curr_prior else 'red'\n",
    "                    ) + '\\n'\n",
    "                )\n",
    "    \n",
    "            row += [row_add]\n",
    "        table_data.append(row)\n",
    "    \n",
    "    # Modify the generated table data to highlight the cell with the maximal accuracy in blue\n",
    "    if max_accuracy_position is not None:\n",
    "        max_row, max_col = max_accuracy_position\n",
    "        table_data[max_row][max_col] = termcolor.colored(\n",
    "            table_data[max_row][max_col], color='blue'\n",
    "        )\n",
    "    \n",
    "    # Rest of your code to create and print the table remains unchanged\n",
    "    table = tabulate(\n",
    "        tabular_data=table_data, headers='firstrow', tablefmt='grid'\n",
    "    )\n",
    "    print(f\"Main model: {main_granularity.capitalize()}-grain {main_model_name}, \"\n",
    "          f\"secondary granularity: {k}\")\n",
    "    print(table)\n",
    "    print(\"\\n\")\n",
    "\n",
    "def print_two_secondary_granularities(main_model_data: dict,\n",
    "                                      k: str,\n",
    "                                      main_granularity: str,\n",
    "                                      main_model_name: str):\n",
    "    table_data = []\n",
    "        \n",
    "    # Get a list of learning rates from the first model\n",
    "    main_learning_rates = sorted(main_model_data[list(main_model_data.keys())[0]].keys())\n",
    "    \n",
    "    header = [''] + main_learning_rates\n",
    "    table_data += [header]\n",
    "    \n",
    "    secondary_model_data = main_model_data[k]\n",
    "    row = [k]\n",
    "    \n",
    "    for main_lr in sorted(secondary_model_data.keys()):\n",
    "        main_lr_data = secondary_model_data[main_lr]\n",
    "        row_add = ''\n",
    "        for secondary_lr in sorted(main_lr_data.keys()):\n",
    "            curr_data = main_lr_data[secondary_lr]\n",
    "            curr_post = curr_data['post']\n",
    "            curr_prior = curr_data['prior']\n",
    "            curr_diff = curr_post - curr_prior\n",
    "            \n",
    "            row_add += (f\"{secondary_lr}: {round(curr_post*100, 1)}% \" + \n",
    "                        f\"({round(curr_prior*100, 1)}%, \" + \n",
    "                        termcolor.colored(f\"{'+' if curr_post > curr_prior else ''}\", color='green') + \n",
    "                        termcolor.colored(f\"{round(curr_diff*100, 1)}%)\", \n",
    "                                          color='green' if curr_post > curr_prior \n",
    "                                          else 'red') + '\\n')\n",
    "        \n",
    "        row += [row_add]\n",
    "    table_data += [row]\n",
    "\n",
    "    # Create the table using tabulate\n",
    "    table = tabulate(tabular_data=table_data, \n",
    "                     headers='firstrow', \n",
    "                     tablefmt='grid')\n",
    "\n",
    "    # Print the main model name and the corresponding table\n",
    "    print(f\"Main model: {main_granularity.capitalize()}-grain {main_model_name} \"\n",
    "          f\"with both fine and coarse grain secondary models\")\n",
    "    print(table)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "def print_EDCR_table():\n",
    "    data = gather_EDCR_data()\n",
    "    \n",
    "    for main_granularity in sorted(data.keys()):\n",
    "        \n",
    "        print('#' * 40 + f' Main granularity: {main_granularity} ' + '#' * 40 + '\\n' + '#' * 104 + '\\n')\n",
    "        main_granularity_data = data[main_granularity]\n",
    "        \n",
    "        for main_model_name in sorted(main_granularity_data.keys()):\n",
    "            main_model_data = main_granularity_data[main_model_name]\n",
    "            \n",
    "            for k in (sorted(set(main_model_data.keys()).intersection(granularities.values())) + \n",
    "                      sorted(set(main_model_data.keys()).intersection(vit_model_names))):\n",
    "                handler = print_one_secondary_granularity \\\n",
    "                    if k in granularities.values() else print_two_secondary_granularities\n",
    "                \n",
    "                handler(main_model_data=main_model_data,\n",
    "                        k=k,\n",
    "                        main_granularity=main_granularity,\n",
    "                        main_model_name=main_model_name)\n",
    "                    \n",
    "            print('#' * 100)\n",
    "\n",
    "print_EDCR_table()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T04:04:02.975960Z",
     "start_time": "2023-11-08T04:04:02.645409Z"
    }
   },
   "id": "3f6e34912281d5e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "||# Histograms"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "75dd627d1ecc97d8"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "{'30N6E_13.jpg': 1,\n '30N6E_2.jpg': 1,\n '30N6E_5.jpg': 1,\n '30N6E_8.jpg': 1,\n 'BM-30_112.jpg': 1,\n 'BM-30_18.jpg': 1,\n 'BM-30_89.jpg': 1,\n 'BM-30_92.jpg': 1,\n 'BMD_3.jpg': 1,\n 'BMD_5.jpg': 1,\n 'BMD_83.jpg': 1,\n 'BMD_9.jpg': 1,\n 'BMP-1_18.jpg': 1,\n 'BMP-1_2.jpg': 1,\n 'BMP-1_7.jpg': 1,\n 'BMP-2_0.jpg': 1,\n 'BMP-2_24.jpg': 1,\n 'BMP-2_33.jpg': 1,\n 'BMP-2_5.jpg': 1,\n 'BMP-T15_19.jpg': 1,\n 'BMP-T15_48.jpg': 1,\n 'BMP-T15_75.jpg': 1,\n 'BMP-T15_80.jpg': 1,\n 'BRDM_17.jpg': 1,\n 'BRDM_27.jpg': 1,\n 'BRDM_35.jpg': 1,\n 'BRDM_44.jpg': 1,\n 'BTR-60_103.jpg': 1,\n 'BTR-60_151.jpg': 1,\n 'BTR-60_50.jpg': 1,\n 'BTR-60_70.jpg': 1,\n 'BTR-70_17.jpg': 1,\n 'BTR-70_24.jpg': 1,\n 'BTR-70_5.jpg': 1,\n 'BTR-70_8.jpg': 1,\n 'BTR-80_34.jpg': 1,\n 'BTR-80_37.jpg': 1,\n 'BTR-80_73.jpg': 1,\n 'BTR-80_8.jpg': 1,\n 'D-30_2.jpg': 0,\n 'D-30_50.jpg': 0,\n 'D-30_51.jpg': 1,\n 'D-30_62.jpg': 0,\n 'Iskander_31.jpg': 1,\n 'Iskander_58.jpg': 1,\n 'Iskander_75.jpg': 0,\n 'Iskander_87.jpg': 1,\n 'MT_LB_1.jpg': 1,\n 'MT_LB_27.jpg': 1,\n 'MT_LB_6.jpg': 1,\n 'MT_LB_72.jpg': 1,\n 'Pantsir-S1_12.jpg': 1,\n 'Pantsir-S1_14.jpg': 1,\n 'Pantsir-S1_24.jpg': 1,\n 'Pantsir-S1_4.jpg': 1,\n 'Rs-24_100.jpg': 1,\n 'Rs-24_55.jpg': 1,\n 'Rs-24_73.jpg': 1,\n 'Rs-24_75.jpg': 1,\n 'T-14_12.jpg': 1,\n 'T-14_25.jpg': 0,\n 'T-14_29.jpg': 1,\n 'T-14_43.jpg': 1,\n 'T-62_12.jpg': 1,\n 'T-62_41.jpg': 1,\n 'T-62_45.jpg': 1,\n 'T-62_57.jpg': 1,\n 'T-64_1.jpg': 1,\n 'T-64_13.jpg': 1,\n 'T-64_2.jpg': 1,\n 'T-64_20.jpg': 0,\n 'T-72_0.jpg': 1,\n 'T-72_8.jpg': 0,\n 'T-80_23.jpg': 0,\n 'T-80_29.jpg': 0,\n 'T-80_32.jpg': 0,\n 'T-80_43.jpg': 1,\n 'T-90_16.jpg': 0,\n 'T-90_18.jpg': 1,\n 'T-90_22.jpg': 1,\n 'T-90_42.jpg': 0,\n 'TOS-1_22.jpg': 1,\n 'TOS-1_3.jpg': 1,\n 'TOS-1_30.jpg': 1,\n 'TOS-1_7.jpg': 1,\n 'Tornado_20.jpg': 1,\n 'Tornado_27.jpg': 1,\n 'Tornado_3.jpg': 1,\n '2S19_0.jpg': 0,\n '2S19_1.jpg': 0,\n '2S19_10.jpg': 0,\n '2S19_11.jpg': 0,\n '2S19_12.jpg': 0,\n '2S19_13.jpg': 0,\n '2S19_14.jpg': 0,\n '2S19_15.jpg': 0,\n '2S19_16.jpg': 0,\n '2S19_17.jpg': 0,\n '2S19_18.jpg': 0,\n '2S19_19.jpg': 0,\n '2S19_2.jpg': 0,\n '2S19_20.jpg': 0,\n '2S19_21.jpg': 0,\n '2S19_22.jpg': 0,\n '2S19_23.jpg': 0,\n '2S19_24.jpg': 0,\n '2S19_25.jpg': 0,\n '2S19_26.jpg': 0,\n '2S19_27.jpg': 0,\n '2S19_28.jpg': 0,\n '2S19_29.jpg': 0,\n '2S19_3.jpg': 0,\n '2S19_30.jpg': 0,\n '2S19_31.jpg': 0,\n '2S19_32.jpg': 0,\n '2S19_33.jpg': 0,\n '2S19_34.jpg': 1,\n '2S19_35.jpg': 0,\n '2S19_36.jpg': 0,\n '2S19_37.jpg': 0,\n '2S19_38.jpg': 0,\n '2S19_39.jpg': 0,\n '2S19_4.jpg': 0,\n '2S19_40.jpg': 0,\n '2S19_41.jpg': 0,\n '2S19_42.jpg': 0,\n '2S19_43.jpg': 1,\n '2S19_44.jpg': 0,\n '2S19_45.jpg': 0,\n '2S19_46.jpg': 0,\n '2S19_47.jpg': 0,\n '2S19_48.jpg': 0,\n '2S19_49.jpg': 0,\n '2S19_5.jpg': 0,\n '2S19_50.jpg': 0,\n '2S19_51.jpg': 0,\n '2S19_52.jpg': 0,\n '2S19_53.jpg': 1,\n '2S19_54.jpg': 1,\n '2S19_55.jpg': 0,\n '2S19_56.jpg': 0,\n '2S19_57.jpg': 0,\n '2S19_58.jpg': 0,\n '2S19_6.jpg': 0,\n '2S19_7.jpg': 0,\n '2S19_8.jpg': 0,\n '2S19_9.jpg': 0}"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('json_predictions/2S19_predictions.json') as f:\n",
    "    first = json.load(f)\n",
    "\n",
    "first"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T02:11:43.699176Z",
     "start_time": "2023-10-31T02:11:43.638507Z"
    }
   },
   "id": "f5df57b45a12b970"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3206f04f92a0b498"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
