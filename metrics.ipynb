{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score\n",
    "import tabulate\n",
    "import warnings\n",
    "import torch\n",
    "import multiprocessing as mp\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import data_preprocessing\n",
    "import EDCR_pipeline\n",
    "import vit_pipeline\n",
    "import utils"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T21:34:18.967579Z",
     "start_time": "2023-11-21T21:34:18.962786Z"
    }
   },
   "id": "9dc68a5fe4ce4ea7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# EDCR Results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff5d015e77a12310"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################## Main granularity: coarse ########################################\n",
      "########################################################################################################\n",
      "\n",
      "Main model: Coarse-grain vit_b_16, secondary granularity: coarse\n",
      "+----------+--------------------------------------------------+----------------------------------------------------+--------------------------------------------------+\n",
      "|          | 1e-05 (acc: 80.94%, f1: 80.89%)                  | 1e-06 (acc: 65.64%, f1: 61.96%)                    | 5e-05 (acc: 83.71%, f1: 83.48%)                  |\n",
      "+==========+==================================================+====================================================+==================================================+\n",
      "| vit_b_32 | 1e-05: acc: 81.0%, (\u001B[92m+\u001B[0m\u001B[92m0.06%\u001B[0m), f1: 80.94% (\u001B[92m+\u001B[0m0.05)  | 1e-05: acc: 73.04%, (\u001B[92m+\u001B[0m\u001B[92m7.4%\u001B[0m), f1: 68.94% (\u001B[92m+\u001B[0m6.98)    | 1e-05: acc: 82.36%, (\u001B[91m-1.35%\u001B[0m), f1: 82.0% (-1.48)  |\n",
      "|          | 1e-06: acc: 80.94%, (\u001B[91m0.0%\u001B[0m), f1: 80.89% (0.0)     | 1e-06: acc: 65.33%, (\u001B[91m-0.31%\u001B[0m), f1: 61.84% (-0.12)   | 1e-06: acc: 83.71%, (\u001B[91m0.0%\u001B[0m), f1: 83.48% (0.0)     |\n",
      "|          | 5e-05: acc: 81.18%, (\u001B[92m+\u001B[0m\u001B[92m0.24%\u001B[0m), f1: 81.16% (\u001B[92m+\u001B[0m0.27) | 5e-05: acc: 72.55%, (\u001B[92m+\u001B[0m\u001B[92m6.91%\u001B[0m), f1: 68.9% (\u001B[92m+\u001B[0m6.94)    | 5e-05: acc: 83.71%, (\u001B[91m0.0%\u001B[0m), f1: 83.48% (0.0)     |\n",
      "+----------+--------------------------------------------------+----------------------------------------------------+--------------------------------------------------+\n",
      "| vit_l_16 | 1e-05: acc: 82.97%, (\u001B[92m+\u001B[0m\u001B[92m2.03%\u001B[0m), f1: 82.71% (\u001B[92m+\u001B[0m1.82) | 1e-05: acc: 76.8%, (\u001B[92m+\u001B[0m\u001B[92m11.16%\u001B[0m), f1: 72.95% (\u001B[92m+\u001B[0m10.99)  | 1e-05: acc: 83.78%, (\u001B[92m+\u001B[0m\u001B[92m0.07%\u001B[0m), f1: 83.48% (0.0)   |\n",
      "|          | 1e-06: acc: 78.78%, (\u001B[91m-2.16%\u001B[0m), f1: 78.87% (-2.02) | 1e-06: acc: 71.19%, (\u001B[92m+\u001B[0m\u001B[92m5.55%\u001B[0m), f1: 67.45% (\u001B[92m+\u001B[0m5.49)   | 1e-06: acc: 83.71%, (\u001B[91m0.0%\u001B[0m), f1: 83.48% (0.0)     |\n",
      "|          | 5e-05: acc: 81.99%, (\u001B[92m+\u001B[0m\u001B[92m1.05%\u001B[0m), f1: 82.03% (\u001B[92m+\u001B[0m1.14) | 5e-05: acc: 76.06%, (\u001B[92m+\u001B[0m\u001B[92m10.42%\u001B[0m), f1: 72.01% (\u001B[92m+\u001B[0m10.05) | 5e-05: acc: 84.21%, (\u001B[92m+\u001B[0m\u001B[92m0.5%\u001B[0m), f1: 84.09% (\u001B[92m+\u001B[0m0.61)  |\n",
      "+----------+--------------------------------------------------+----------------------------------------------------+--------------------------------------------------+\n",
      "| vit_l_32 | 1e-05: acc: 80.81%, (\u001B[91m-0.13%\u001B[0m), f1: 80.69% (-0.2)  | 1e-05: acc: 74.15%, (\u001B[92m+\u001B[0m\u001B[92m8.51%\u001B[0m), f1: 70.28% (\u001B[92m+\u001B[0m8.32)   | 1e-05: acc: 83.04%, (\u001B[91m-0.67%\u001B[0m), f1: 82.72% (-0.76) |\n",
      "|          | 1e-06: acc: 80.94%, (\u001B[91m0.0%\u001B[0m), f1: 80.89% (0.0)     | 1e-06: acc: 66.07%, (\u001B[92m+\u001B[0m\u001B[92m0.43%\u001B[0m), f1: 62.49% (\u001B[92m+\u001B[0m0.53)   | 1e-06: acc: 83.71%, (\u001B[91m0.0%\u001B[0m), f1: 83.48% (0.0)     |\n",
      "|          | 5e-05: acc: 81.43%, (\u001B[92m+\u001B[0m\u001B[92m0.49%\u001B[0m), f1: 81.53% (\u001B[92m+\u001B[0m0.64) | 5e-05: acc: 75.94%, (\u001B[92m+\u001B[0m\u001B[92m10.3%\u001B[0m), f1: 71.93% (\u001B[92m+\u001B[0m9.97)   | 5e-05: acc: 83.53%, (\u001B[91m-0.18%\u001B[0m), f1: 83.39% (-0.09) |\n",
      "+----------+--------------------------------------------------+----------------------------------------------------+--------------------------------------------------+\n",
      "\n",
      "\n",
      "Main model: Coarse-grain vit_b_16, secondary granularity: fine\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "|          | 1e-05 (acc: 80.94%, f1: 80.89%)                  | 1e-06 (acc: 65.64%, f1: 61.96%)                  | 5e-05 (acc: 83.71%, f1: 83.48%)                  |\n",
      "+==========+==================================================+==================================================+==================================================+\n",
      "| vit_b_32 | 1e-05: acc: 78.04%, (\u001B[91m-2.9%\u001B[0m), f1: 78.27% (-2.62)  | 1e-05: acc: 69.34%, (\u001B[92m+\u001B[0m\u001B[92m3.7%\u001B[0m), f1: 65.68% (\u001B[92m+\u001B[0m3.72)  | 1e-05: acc: 82.97%, (\u001B[91m-0.74%\u001B[0m), f1: 82.74% (-0.74) |\n",
      "|          | 1e-06: acc: 79.21%, (\u001B[91m-1.73%\u001B[0m), f1: 79.37% (-1.52) | 1e-06: acc: 71.01%, (\u001B[92m+\u001B[0m\u001B[92m5.37%\u001B[0m), f1: 67.08% (\u001B[92m+\u001B[0m5.12) | 1e-06: acc: 82.97%, (\u001B[91m-0.74%\u001B[0m), f1: 82.66% (-0.82) |\n",
      "|          | 5e-05: acc: 79.46%, (\u001B[91m-1.48%\u001B[0m), f1: 79.57% (-1.32) | 5e-05: acc: 68.6%, (\u001B[92m+\u001B[0m\u001B[92m2.96%\u001B[0m), f1: 64.58% (\u001B[92m+\u001B[0m2.62)  | 5e-05: acc: 83.84%, (\u001B[92m+\u001B[0m\u001B[92m0.13%\u001B[0m), f1: 83.62% (\u001B[92m+\u001B[0m0.14) |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "| vit_l_16 | 1e-05: acc: 80.81%, (\u001B[91m-0.13%\u001B[0m), f1: 80.87% (-0.02) | 1e-05: acc: 72.42%, (\u001B[92m+\u001B[0m\u001B[92m6.78%\u001B[0m), f1: 68.44% (\u001B[92m+\u001B[0m6.48) | 1e-05: acc: 84.45%, (\u001B[92m+\u001B[0m\u001B[92m0.74%\u001B[0m), f1: 84.29% (\u001B[92m+\u001B[0m0.81) |\n",
      "|          | 1e-06: acc: 79.52%, (\u001B[91m-1.42%\u001B[0m), f1: 79.58% (-1.31) | 1e-06: acc: 73.16%, (\u001B[92m+\u001B[0m\u001B[92m7.52%\u001B[0m), f1: 69.18% (\u001B[92m+\u001B[0m7.22) | 1e-06: acc: 82.67%, (\u001B[91m-1.04%\u001B[0m), f1: 82.31% (-1.17) |\n",
      "|          | 5e-05: acc: 81.25%, (\u001B[92m+\u001B[0m\u001B[92m0.31%\u001B[0m), f1: 81.3% (\u001B[92m+\u001B[0m0.41)  | 5e-05: acc: 72.3%, (\u001B[92m+\u001B[0m\u001B[92m6.66%\u001B[0m), f1: 68.28% (\u001B[92m+\u001B[0m6.32)  | 5e-05: acc: 84.39%, (\u001B[92m+\u001B[0m\u001B[92m0.68%\u001B[0m), f1: 84.27% (\u001B[92m+\u001B[0m0.79) |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "| vit_l_32 | 1e-05: acc: 81.62%, (\u001B[92m+\u001B[0m\u001B[92m0.68%\u001B[0m), f1: 81.84% (\u001B[92m+\u001B[0m0.95) | 1e-05: acc: 68.66%, (\u001B[92m+\u001B[0m\u001B[92m3.02%\u001B[0m), f1: 64.44% (\u001B[92m+\u001B[0m2.48) | 1e-05: acc: 83.53%, (\u001B[91m-0.18%\u001B[0m), f1: 83.27% (-0.21) |\n",
      "|          | 1e-06: acc: 80.57%, (\u001B[91m-0.37%\u001B[0m), f1: 80.83% (-0.06) | 1e-06: acc: 71.75%, (\u001B[92m+\u001B[0m\u001B[92m6.11%\u001B[0m), f1: 67.63% (\u001B[92m+\u001B[0m5.67) | 1e-06: acc: 83.04%, (\u001B[91m-0.67%\u001B[0m), f1: 82.77% (-0.71) |\n",
      "|          | 5e-05: acc: 79.27%, (\u001B[91m-1.67%\u001B[0m), f1: 79.35% (-1.54) | 5e-05: acc: 70.57%, (\u001B[92m+\u001B[0m\u001B[92m4.93%\u001B[0m), f1: 66.63% (\u001B[92m+\u001B[0m4.67) | 5e-05: acc: 82.54%, (\u001B[91m-1.17%\u001B[0m), f1: 82.23% (-1.25) |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "\n",
      "\n",
      "Main model: Coarse-grain vit_b_16 with both fine and coarse grain secondary models\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "|          | 1e-06 acc: (65.64%)                              | 1e-05 acc: (80.94%)                              | 5e-05 acc: (83.71%)                              |\n",
      "+==========+==================================================+==================================================+==================================================+\n",
      "| vit_b_32 | 1e-05: acc: 78.04%, (\u001B[91m-2.9%\u001B[0m), f1: 78.27% (-2.62)  | 1e-05: acc: 70.08%, (\u001B[92m+\u001B[0m\u001B[92m4.44%\u001B[0m), f1: 66.21% (\u001B[92m+\u001B[0m4.25) | 1e-05: acc: 82.42%, (\u001B[91m-1.29%\u001B[0m), f1: 82.11% (-1.37) |\n",
      "|          | 1e-06: acc: 79.21%, (\u001B[91m-1.73%\u001B[0m), f1: 79.37% (-1.52) | 1e-06: acc: 69.28%, (\u001B[92m+\u001B[0m\u001B[92m3.64%\u001B[0m), f1: 65.83% (\u001B[92m+\u001B[0m3.87) | 1e-06: acc: 82.97%, (\u001B[91m-0.74%\u001B[0m), f1: 82.66% (-0.82) |\n",
      "|          | 5e-05: acc: 79.7%, (\u001B[91m-1.24%\u001B[0m), f1: 79.78% (-1.11)  | 5e-05: acc: 70.64%, (\u001B[92m+\u001B[0m\u001B[92m5.0%\u001B[0m), f1: 66.81% (\u001B[92m+\u001B[0m4.85)  | 5e-05: acc: 83.84%, (\u001B[92m+\u001B[0m\u001B[92m0.13%\u001B[0m), f1: 83.62% (\u001B[92m+\u001B[0m0.14) |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "| vit_l_16 | 1e-05: acc: 81.06%, (\u001B[92m+\u001B[0m\u001B[92m0.12%\u001B[0m), f1: 81.08% (\u001B[92m+\u001B[0m0.19) | 1e-05: acc: 69.22%, (\u001B[92m+\u001B[0m\u001B[92m3.58%\u001B[0m), f1: 65.47% (\u001B[92m+\u001B[0m3.51) | 1e-05: acc: 85.32%, (\u001B[92m+\u001B[0m\u001B[92m1.61%\u001B[0m), f1: 85.12% (\u001B[92m+\u001B[0m1.64) |\n",
      "|          | 1e-06: acc: 79.77%, (\u001B[91m-1.17%\u001B[0m), f1: 79.75% (-1.14) | 1e-06: acc: 69.4%, (\u001B[92m+\u001B[0m\u001B[92m3.76%\u001B[0m), f1: 65.89% (\u001B[92m+\u001B[0m3.93)  | 1e-06: acc: 82.67%, (\u001B[91m-1.04%\u001B[0m), f1: 82.31% (-1.17) |\n",
      "|          | 5e-05: acc: 81.55%, (\u001B[92m+\u001B[0m\u001B[92m0.61%\u001B[0m), f1: 81.57% (\u001B[92m+\u001B[0m0.68) | 5e-05: acc: 74.03%, (\u001B[92m+\u001B[0m\u001B[92m8.39%\u001B[0m), f1: 70.0% (\u001B[92m+\u001B[0m8.04)  | 5e-05: acc: 84.45%, (\u001B[92m+\u001B[0m\u001B[92m0.74%\u001B[0m), f1: 84.39% (\u001B[92m+\u001B[0m0.91) |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "| vit_l_32 | 1e-05: acc: 81.8%, (\u001B[92m+\u001B[0m\u001B[92m0.86%\u001B[0m), f1: 81.75% (\u001B[92m+\u001B[0m0.86)  | 1e-05: acc: 70.82%, (\u001B[92m+\u001B[0m\u001B[92m5.18%\u001B[0m), f1: 66.64% (\u001B[92m+\u001B[0m4.68) | 1e-05: acc: 83.41%, (\u001B[91m-0.3%\u001B[0m), f1: 83.12% (-0.36)  |\n",
      "|          | 1e-06: acc: 80.57%, (\u001B[91m-0.37%\u001B[0m), f1: 80.83% (-0.06) | 1e-06: acc: 71.68%, (\u001B[92m+\u001B[0m\u001B[92m6.04%\u001B[0m), f1: 67.57% (\u001B[92m+\u001B[0m5.61) | 1e-06: acc: 83.04%, (\u001B[91m-0.67%\u001B[0m), f1: 82.77% (-0.71) |\n",
      "|          | 5e-05: acc: 80.57%, (\u001B[91m-0.37%\u001B[0m), f1: 80.59% (-0.3)  | 5e-05: acc: 74.03%, (\u001B[92m+\u001B[0m\u001B[92m8.39%\u001B[0m), f1: 69.85% (\u001B[92m+\u001B[0m7.89) | 5e-05: acc: 83.22%, (\u001B[91m-0.49%\u001B[0m), f1: 82.88% (-0.6)  |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Main model: Coarse-grain vit_b_32, secondary granularity: coarse\n",
      "+----------+--------------------------------------------------+----------------------------------------------------+--------------------------------------------------+\n",
      "|          | 1e-05 (acc: 77.05%, f1: 76.3%)                   | 1e-06 (acc: 63.05%, f1: 59.7%)                     | 5e-05 (acc: 76.0%, f1: 75.05%)                   |\n",
      "+==========+==================================================+====================================================+==================================================+\n",
      "| vit_b_16 | 1e-05: acc: 79.64%, (\u001B[92m+\u001B[0m\u001B[92m2.59%\u001B[0m), f1: 79.21% (\u001B[92m+\u001B[0m2.91) | 1e-05: acc: 74.34%, (\u001B[92m+\u001B[0m\u001B[92m11.29%\u001B[0m), f1: 70.26% (\u001B[92m+\u001B[0m10.56) | 1e-05: acc: 78.66%, (\u001B[92m+\u001B[0m\u001B[92m2.66%\u001B[0m), f1: 77.86% (\u001B[92m+\u001B[0m2.81) |\n",
      "|          | 1e-06: acc: 77.05%, (\u001B[91m0.0%\u001B[0m), f1: 76.3% (0.0)      | 1e-06: acc: 64.22%, (\u001B[92m+\u001B[0m\u001B[92m1.17%\u001B[0m), f1: 60.84% (\u001B[92m+\u001B[0m1.14)   | 1e-06: acc: 75.26%, (\u001B[91m-0.74%\u001B[0m), f1: 74.13% (-0.92) |\n",
      "|          | 5e-05: acc: 82.23%, (\u001B[92m+\u001B[0m\u001B[92m5.18%\u001B[0m), f1: 82.03% (\u001B[92m+\u001B[0m5.73) | 5e-05: acc: 76.31%, (\u001B[92m+\u001B[0m\u001B[92m13.26%\u001B[0m), f1: 72.09% (\u001B[92m+\u001B[0m12.39) | 5e-05: acc: 81.99%, (\u001B[92m+\u001B[0m\u001B[92m5.99%\u001B[0m), f1: 81.41% (\u001B[92m+\u001B[0m6.36) |\n",
      "+----------+--------------------------------------------------+----------------------------------------------------+--------------------------------------------------+\n",
      "| vit_l_16 | 1e-05: acc: 82.36%, (\u001B[92m+\u001B[0m\u001B[92m5.31%\u001B[0m), f1: 81.63% (\u001B[92m+\u001B[0m5.33) | 1e-05: acc: 76.74%, (\u001B[92m+\u001B[0m\u001B[92m13.69%\u001B[0m), f1: 72.77% (\u001B[92m+\u001B[0m13.07) | 1e-05: acc: 80.69%, (\u001B[92m+\u001B[0m\u001B[92m4.69%\u001B[0m), f1: 79.77% (\u001B[92m+\u001B[0m4.72) |\n",
      "|          | 1e-06: acc: 76.19%, (\u001B[91m-0.86%\u001B[0m), f1: 75.55% (-0.75) | 1e-06: acc: 71.44%, (\u001B[92m+\u001B[0m\u001B[92m8.39%\u001B[0m), f1: 67.6% (\u001B[92m+\u001B[0m7.9)     | 1e-06: acc: 75.63%, (\u001B[91m-0.37%\u001B[0m), f1: 74.36% (-0.69) |\n",
      "|          | 5e-05: acc: 81.62%, (\u001B[92m+\u001B[0m\u001B[92m4.57%\u001B[0m), f1: 81.36% (\u001B[92m+\u001B[0m5.06) | 5e-05: acc: 75.88%, (\u001B[92m+\u001B[0m\u001B[92m12.83%\u001B[0m), f1: 71.79% (\u001B[92m+\u001B[0m12.09) | 5e-05: acc: 79.4%, (\u001B[92m+\u001B[0m\u001B[92m3.4%\u001B[0m), f1: 78.8% (\u001B[92m+\u001B[0m3.75)    |\n",
      "+----------+--------------------------------------------------+----------------------------------------------------+--------------------------------------------------+\n",
      "| vit_l_32 | 1e-05: acc: 77.73%, (\u001B[92m+\u001B[0m\u001B[92m0.68%\u001B[0m), f1: 77.26% (\u001B[92m+\u001B[0m0.96) | 1e-05: acc: 72.42%, (\u001B[92m+\u001B[0m\u001B[92m9.37%\u001B[0m), f1: 68.76% (\u001B[92m+\u001B[0m9.06)   | 1e-05: acc: 77.48%, (\u001B[92m+\u001B[0m\u001B[92m1.48%\u001B[0m), f1: 76.78% (\u001B[92m+\u001B[0m1.73) |\n",
      "|          | 1e-06: acc: 77.05%, (\u001B[91m0.0%\u001B[0m), f1: 76.3% (0.0)      | 1e-06: acc: 63.6%, (\u001B[92m+\u001B[0m\u001B[92m0.55%\u001B[0m), f1: 60.25% (\u001B[92m+\u001B[0m0.55)    | 1e-06: acc: 74.34%, (\u001B[91m-1.66%\u001B[0m), f1: 73.06% (-1.99) |\n",
      "|          | 5e-05: acc: 81.31%, (\u001B[92m+\u001B[0m\u001B[92m4.26%\u001B[0m), f1: 80.94% (\u001B[92m+\u001B[0m4.64) | 5e-05: acc: 75.02%, (\u001B[92m+\u001B[0m\u001B[92m11.97%\u001B[0m), f1: 71.06% (\u001B[92m+\u001B[0m11.36) | 5e-05: acc: 78.84%, (\u001B[92m+\u001B[0m\u001B[92m2.84%\u001B[0m), f1: 78.28% (\u001B[92m+\u001B[0m3.23) |\n",
      "+----------+--------------------------------------------------+----------------------------------------------------+--------------------------------------------------+\n",
      "\n",
      "\n",
      "Main model: Coarse-grain vit_b_32, secondary granularity: fine\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "|          | 1e-05 (acc: 77.05%, f1: 76.3%)                   | 1e-06 (acc: 63.05%, f1: 59.7%)                   | 5e-05 (acc: 76.0%, f1: 75.05%)                   |\n",
      "+==========+==================================================+==================================================+==================================================+\n",
      "| vit_b_16 | 1e-05: acc: 77.85%, (\u001B[92m+\u001B[0m\u001B[92m0.8%\u001B[0m), f1: 76.8% (\u001B[92m+\u001B[0m0.5)    | 1e-05: acc: 69.83%, (\u001B[92m+\u001B[0m\u001B[92m6.78%\u001B[0m), f1: 65.93% (\u001B[92m+\u001B[0m6.23) | 1e-05: acc: 76.8%, (\u001B[92m+\u001B[0m\u001B[92m0.8%\u001B[0m), f1: 75.74% (\u001B[92m+\u001B[0m0.69)   |\n",
      "|          | 1e-06: acc: 77.73%, (\u001B[92m+\u001B[0m\u001B[92m0.68%\u001B[0m), f1: 76.45% (\u001B[92m+\u001B[0m0.15) | 1e-06: acc: 72.73%, (\u001B[92m+\u001B[0m\u001B[92m9.68%\u001B[0m), f1: 68.74% (\u001B[92m+\u001B[0m9.04) | 1e-06: acc: 78.53%, (\u001B[92m+\u001B[0m\u001B[92m2.53%\u001B[0m), f1: 77.53% (\u001B[92m+\u001B[0m2.48) |\n",
      "|          | 5e-05: acc: 78.72%, (\u001B[92m+\u001B[0m\u001B[92m1.67%\u001B[0m), f1: 77.64% (\u001B[92m+\u001B[0m1.34) | 5e-05: acc: 70.88%, (\u001B[92m+\u001B[0m\u001B[92m7.83%\u001B[0m), f1: 66.56% (\u001B[92m+\u001B[0m6.86) | 5e-05: acc: 78.1%, (\u001B[92m+\u001B[0m\u001B[92m2.1%\u001B[0m), f1: 76.96% (\u001B[92m+\u001B[0m1.91)   |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "| vit_l_16 | 1e-05: acc: 78.59%, (\u001B[92m+\u001B[0m\u001B[92m1.54%\u001B[0m), f1: 77.69% (\u001B[92m+\u001B[0m1.39) | 1e-05: acc: 70.64%, (\u001B[92m+\u001B[0m\u001B[92m7.59%\u001B[0m), f1: 66.71% (\u001B[92m+\u001B[0m7.01) | 1e-05: acc: 78.47%, (\u001B[92m+\u001B[0m\u001B[92m2.47%\u001B[0m), f1: 77.4% (\u001B[92m+\u001B[0m2.35)  |\n",
      "|          | 1e-06: acc: 78.59%, (\u001B[92m+\u001B[0m\u001B[92m1.54%\u001B[0m), f1: 77.66% (\u001B[92m+\u001B[0m1.36) | 1e-06: acc: 70.02%, (\u001B[92m+\u001B[0m\u001B[92m6.97%\u001B[0m), f1: 65.81% (\u001B[92m+\u001B[0m6.11) | 1e-06: acc: 77.85%, (\u001B[92m+\u001B[0m\u001B[92m1.85%\u001B[0m), f1: 76.82% (\u001B[92m+\u001B[0m1.77) |\n",
      "|          | 5e-05: acc: 78.66%, (\u001B[92m+\u001B[0m\u001B[92m1.61%\u001B[0m), f1: 77.64% (\u001B[92m+\u001B[0m1.34) | 5e-05: acc: 70.7%, (\u001B[92m+\u001B[0m\u001B[92m7.65%\u001B[0m), f1: 66.67% (\u001B[92m+\u001B[0m6.97)  | 5e-05: acc: 78.59%, (\u001B[92m+\u001B[0m\u001B[92m2.59%\u001B[0m), f1: 77.52% (\u001B[92m+\u001B[0m2.47) |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "| vit_l_32 | 1e-05: acc: 78.1%, (\u001B[92m+\u001B[0m\u001B[92m1.05%\u001B[0m), f1: 77.28% (\u001B[92m+\u001B[0m0.98)  | 1e-05: acc: 68.17%, (\u001B[92m+\u001B[0m\u001B[92m5.12%\u001B[0m), f1: 64.38% (\u001B[92m+\u001B[0m4.68) | 1e-05: acc: 75.39%, (\u001B[91m-0.61%\u001B[0m), f1: 74.16% (-0.89) |\n",
      "|          | 1e-06: acc: 77.17%, (\u001B[92m+\u001B[0m\u001B[92m0.12%\u001B[0m), f1: 76.23% (-0.07) | 1e-06: acc: 70.39%, (\u001B[92m+\u001B[0m\u001B[92m7.34%\u001B[0m), f1: 66.6% (\u001B[92m+\u001B[0m6.9)   | 1e-06: acc: 76.56%, (\u001B[92m+\u001B[0m\u001B[92m0.56%\u001B[0m), f1: 75.33% (\u001B[92m+\u001B[0m0.28) |\n",
      "|          | 5e-05: acc: 76.43%, (\u001B[91m-0.62%\u001B[0m), f1: 75.36% (-0.94) | 5e-05: acc: 69.4%, (\u001B[92m+\u001B[0m\u001B[92m6.35%\u001B[0m), f1: 65.8% (\u001B[92m+\u001B[0m6.1)    | 5e-05: acc: 75.26%, (\u001B[91m-0.74%\u001B[0m), f1: 73.94% (-1.11) |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "\n",
      "\n",
      "Main model: Coarse-grain vit_b_32 with both fine and coarse grain secondary models\n",
      "+----------+--------------------------------------------------+----------------------------------------------------+--------------------------------------------------+\n",
      "|          | 1e-06 acc: (63.05%)                              | 1e-05 acc: (77.05%)                                | 5e-05 acc: (76.0%)                               |\n",
      "+==========+==================================================+====================================================+==================================================+\n",
      "| vit_b_16 | 1e-05: acc: 79.52%, (\u001B[92m+\u001B[0m\u001B[92m2.47%\u001B[0m), f1: 79.08% (\u001B[92m+\u001B[0m2.78) | 1e-05: acc: 70.33%, (\u001B[92m+\u001B[0m\u001B[92m7.28%\u001B[0m), f1: 66.5% (\u001B[92m+\u001B[0m6.8)     | 1e-05: acc: 78.59%, (\u001B[92m+\u001B[0m\u001B[92m2.59%\u001B[0m), f1: 77.78% (\u001B[92m+\u001B[0m2.73) |\n",
      "|          | 1e-06: acc: 77.73%, (\u001B[92m+\u001B[0m\u001B[92m0.68%\u001B[0m), f1: 76.45% (\u001B[92m+\u001B[0m0.15) | 1e-06: acc: 65.95%, (\u001B[92m+\u001B[0m\u001B[92m2.9%\u001B[0m), f1: 62.36% (\u001B[92m+\u001B[0m2.66)    | 1e-06: acc: 77.48%, (\u001B[92m+\u001B[0m\u001B[92m1.48%\u001B[0m), f1: 76.35% (\u001B[92m+\u001B[0m1.3)  |\n",
      "|          | 5e-05: acc: 83.41%, (\u001B[92m+\u001B[0m\u001B[92m6.36%\u001B[0m), f1: 83.29% (\u001B[92m+\u001B[0m6.99) | 5e-05: acc: 75.82%, (\u001B[92m+\u001B[0m\u001B[92m12.77%\u001B[0m), f1: 71.72% (\u001B[92m+\u001B[0m12.02) | 5e-05: acc: 81.86%, (\u001B[92m+\u001B[0m\u001B[92m5.86%\u001B[0m), f1: 81.29% (\u001B[92m+\u001B[0m6.24) |\n",
      "+----------+--------------------------------------------------+----------------------------------------------------+--------------------------------------------------+\n",
      "| vit_l_16 | 1e-05: acc: 81.37%, (\u001B[92m+\u001B[0m\u001B[92m4.32%\u001B[0m), f1: 80.87% (\u001B[92m+\u001B[0m4.57) | 1e-05: acc: 68.23%, (\u001B[92m+\u001B[0m\u001B[92m5.18%\u001B[0m), f1: 64.37% (\u001B[92m+\u001B[0m4.67)   | 1e-05: acc: 78.96%, (\u001B[92m+\u001B[0m\u001B[92m2.96%\u001B[0m), f1: 78.05% (\u001B[92m+\u001B[0m3.0)  |\n",
      "|          | 1e-06: acc: 78.59%, (\u001B[92m+\u001B[0m\u001B[92m1.54%\u001B[0m), f1: 77.62% (\u001B[92m+\u001B[0m1.32) | 1e-06: acc: 68.72%, (\u001B[92m+\u001B[0m\u001B[92m5.67%\u001B[0m), f1: 65.01% (\u001B[92m+\u001B[0m5.31)   | 1e-06: acc: 77.42%, (\u001B[92m+\u001B[0m\u001B[92m1.42%\u001B[0m), f1: 76.2% (\u001B[92m+\u001B[0m1.15)  |\n",
      "|          | 5e-05: acc: 81.55%, (\u001B[92m+\u001B[0m\u001B[92m4.5%\u001B[0m), f1: 81.32% (\u001B[92m+\u001B[0m5.02)  | 5e-05: acc: 70.57%, (\u001B[92m+\u001B[0m\u001B[92m7.52%\u001B[0m), f1: 66.43% (\u001B[92m+\u001B[0m6.73)   | 5e-05: acc: 81.86%, (\u001B[92m+\u001B[0m\u001B[92m5.86%\u001B[0m), f1: 81.24% (\u001B[92m+\u001B[0m6.19) |\n",
      "+----------+--------------------------------------------------+----------------------------------------------------+--------------------------------------------------+\n",
      "| vit_l_32 | 1e-05: acc: 78.1%, (\u001B[92m+\u001B[0m\u001B[92m1.05%\u001B[0m), f1: 77.7% (\u001B[92m+\u001B[0m1.4)    | 1e-05: acc: 69.28%, (\u001B[92m+\u001B[0m\u001B[92m6.23%\u001B[0m), f1: 65.48% (\u001B[92m+\u001B[0m5.78)   | 1e-05: acc: 76.68%, (\u001B[92m+\u001B[0m\u001B[92m0.68%\u001B[0m), f1: 76.09% (\u001B[92m+\u001B[0m1.04) |\n",
      "|          | 1e-06: acc: 77.17%, (\u001B[92m+\u001B[0m\u001B[92m0.12%\u001B[0m), f1: 76.23% (-0.07) | 1e-06: acc: 69.9%, (\u001B[92m+\u001B[0m\u001B[92m6.85%\u001B[0m), f1: 66.06% (\u001B[92m+\u001B[0m6.36)    | 1e-06: acc: 76.31%, (\u001B[92m+\u001B[0m\u001B[92m0.31%\u001B[0m), f1: 74.79% (-0.26) |\n",
      "|          | 5e-05: acc: 81.18%, (\u001B[92m+\u001B[0m\u001B[92m4.13%\u001B[0m), f1: 80.54% (\u001B[92m+\u001B[0m4.24) | 5e-05: acc: 73.53%, (\u001B[92m+\u001B[0m\u001B[92m10.48%\u001B[0m), f1: 69.51% (\u001B[92m+\u001B[0m9.81)  | 5e-05: acc: 77.67%, (\u001B[92m+\u001B[0m\u001B[92m1.67%\u001B[0m), f1: 76.72% (\u001B[92m+\u001B[0m1.67) |\n",
      "+----------+--------------------------------------------------+----------------------------------------------------+--------------------------------------------------+\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Main model: Coarse-grain vit_l_16, secondary granularity: coarse\n",
      "+----------+--------------------------------------------------+\n",
      "|          | 1e-05 (acc: 84.27%, f1: 84.33%)                  |\n",
      "+==========+==================================================+\n",
      "| vit_b_16 | 1e-05: acc: 83.78%, (\u001B[91m-0.49%\u001B[0m), f1: 83.84% (-0.49) |\n",
      "|          | 1e-06: acc: 84.27%, (\u001B[91m0.0%\u001B[0m), f1: 84.33% (0.0)     |\n",
      "|          | 5e-05: acc: 84.33%, (\u001B[92m+\u001B[0m\u001B[92m0.06%\u001B[0m), f1: 84.5% (\u001B[92m+\u001B[0m0.17)  |\n",
      "+----------+--------------------------------------------------+\n",
      "| vit_b_32 | 1e-05: acc: 83.65%, (\u001B[91m-0.62%\u001B[0m), f1: 83.73% (-0.6)  |\n",
      "|          | 1e-06: acc: 84.27%, (\u001B[91m0.0%\u001B[0m), f1: 84.33% (0.0)     |\n",
      "|          | 5e-05: acc: 84.21%, (\u001B[91m-0.06%\u001B[0m), f1: 84.27% (-0.06) |\n",
      "+----------+--------------------------------------------------+\n",
      "| vit_l_32 | 1e-05: acc: 83.59%, (\u001B[91m-0.68%\u001B[0m), f1: 83.57% (-0.76) |\n",
      "|          | 1e-06: acc: 84.27%, (\u001B[91m0.0%\u001B[0m), f1: 84.33% (0.0)     |\n",
      "|          | 5e-05: acc: 84.58%, (\u001B[92m+\u001B[0m\u001B[92m0.31%\u001B[0m), f1: 84.64% (\u001B[92m+\u001B[0m0.31) |\n",
      "+----------+--------------------------------------------------+\n",
      "\n",
      "\n",
      "Main model: Coarse-grain vit_l_16, secondary granularity: fine\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "|          | 1e-05 (acc: 84.27%, f1: 84.33%)                  | 1e-06 (acc: 73.97%, f1: 72.73%)                  | 5e-05 (acc: 83.71%, f1: 83.7%)                   |\n",
      "+==========+==================================================+==================================================+==================================================+\n",
      "| vit_b_16 | 1e-05: acc: 84.15%, (\u001B[91m-0.12%\u001B[0m), f1: 84.3% (-0.03)  | 1e-05: acc: 76.0%, (\u001B[92m+\u001B[0m\u001B[92m2.03%\u001B[0m), f1: 74.49% (\u001B[92m+\u001B[0m1.76)  | 1e-05: acc: 83.47%, (\u001B[91m-0.24%\u001B[0m), f1: 83.44% (-0.26) |\n",
      "|          | 1e-06: acc: 84.39%, (\u001B[92m+\u001B[0m\u001B[92m0.12%\u001B[0m), f1: 84.52% (\u001B[92m+\u001B[0m0.19) | 1e-06: acc: 77.48%, (\u001B[92m+\u001B[0m\u001B[92m3.51%\u001B[0m), f1: 75.74% (\u001B[92m+\u001B[0m3.01) | 1e-06: acc: 83.84%, (\u001B[92m+\u001B[0m\u001B[92m0.13%\u001B[0m), f1: 83.78% (\u001B[92m+\u001B[0m0.08) |\n",
      "|          | 5e-05: acc: 85.38%, (\u001B[92m+\u001B[0m\u001B[92m1.11%\u001B[0m), f1: 85.49% (\u001B[92m+\u001B[0m1.16) | 5e-05: acc: 76.5%, (\u001B[92m+\u001B[0m\u001B[92m2.53%\u001B[0m), f1: 74.78% (\u001B[92m+\u001B[0m2.05)  | 5e-05: acc: 84.7%, (\u001B[92m+\u001B[0m\u001B[92m0.99%\u001B[0m), f1: 84.71% (\u001B[92m+\u001B[0m1.01)  |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "| vit_b_32 | 1e-05: acc: 83.59%, (\u001B[91m-0.68%\u001B[0m), f1: 83.77% (-0.56) | 1e-05: acc: 74.15%, (\u001B[92m+\u001B[0m\u001B[92m0.18%\u001B[0m), f1: 72.82% (\u001B[92m+\u001B[0m0.09) | 1e-05: acc: 83.16%, (\u001B[91m-0.55%\u001B[0m), f1: 83.13% (-0.57) |\n",
      "|          | 1e-06: acc: 84.64%, (\u001B[92m+\u001B[0m\u001B[92m0.37%\u001B[0m), f1: 84.82% (\u001B[92m+\u001B[0m0.49) | 1e-06: acc: 75.82%, (\u001B[92m+\u001B[0m\u001B[92m1.85%\u001B[0m), f1: 74.15% (\u001B[92m+\u001B[0m1.42) | 1e-06: acc: 84.02%, (\u001B[92m+\u001B[0m\u001B[92m0.31%\u001B[0m), f1: 84.0% (\u001B[92m+\u001B[0m0.3)   |\n",
      "|          | 5e-05: acc: 84.52%, (\u001B[92m+\u001B[0m\u001B[92m0.25%\u001B[0m), f1: 84.6% (\u001B[92m+\u001B[0m0.27)  | 5e-05: acc: 75.14%, (\u001B[92m+\u001B[0m\u001B[92m1.17%\u001B[0m), f1: 73.62% (\u001B[92m+\u001B[0m0.89) | 5e-05: acc: 83.71%, (\u001B[91m0.0%\u001B[0m), f1: 83.72% (\u001B[92m+\u001B[0m0.02)   |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "| vit_l_32 | 1e-05: acc: 84.89%, (\u001B[92m+\u001B[0m\u001B[92m0.62%\u001B[0m), f1: 84.98% (\u001B[92m+\u001B[0m0.65) | 1e-05: acc: 75.2%, (\u001B[92m+\u001B[0m\u001B[92m1.23%\u001B[0m), f1: 73.57% (\u001B[92m+\u001B[0m0.84)  | 1e-05: acc: 83.9%, (\u001B[92m+\u001B[0m\u001B[92m0.19%\u001B[0m), f1: 83.91% (\u001B[92m+\u001B[0m0.21)  |\n",
      "|          | 1e-06: acc: 84.27%, (\u001B[91m0.0%\u001B[0m), f1: 84.39% (\u001B[92m+\u001B[0m0.06)   | 1e-06: acc: 76.74%, (\u001B[92m+\u001B[0m\u001B[92m2.77%\u001B[0m), f1: 75.17% (\u001B[92m+\u001B[0m2.44) | 1e-06: acc: 83.47%, (\u001B[91m-0.24%\u001B[0m), f1: 83.48% (-0.22) |\n",
      "|          | 5e-05: acc: 84.15%, (\u001B[91m-0.12%\u001B[0m), f1: 84.23% (-0.1)  | 5e-05: acc: 74.58%, (\u001B[92m+\u001B[0m\u001B[92m0.61%\u001B[0m), f1: 73.19% (\u001B[92m+\u001B[0m0.46) | 5e-05: acc: 82.23%, (\u001B[91m-1.48%\u001B[0m), f1: 82.22% (-1.48) |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "\n",
      "\n",
      "Main model: Coarse-grain vit_l_16 with both fine and coarse grain secondary models\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "|          | 1e-06 acc: (73.97%)                              | 1e-05 acc: (84.27%)                              | 5e-05 acc: (83.71%)                              |\n",
      "+==========+==================================================+==================================================+==================================================+\n",
      "| vit_b_16 | 1e-05: acc: 84.08%, (\u001B[91m-0.19%\u001B[0m), f1: 84.11% (-0.22) | 1e-05: acc: 78.1%, (\u001B[92m+\u001B[0m\u001B[92m4.13%\u001B[0m), f1: 77.3% (\u001B[92m+\u001B[0m4.57)   | 1e-05: acc: 83.41%, (\u001B[91m-0.3%\u001B[0m), f1: 83.35% (-0.35)  |\n",
      "|          | 1e-06: acc: 84.39%, (\u001B[92m+\u001B[0m\u001B[92m0.12%\u001B[0m), f1: 84.52% (\u001B[92m+\u001B[0m0.19) | 1e-06: acc: 77.48%, (\u001B[92m+\u001B[0m\u001B[92m3.51%\u001B[0m), f1: 75.74% (\u001B[92m+\u001B[0m3.01) | 1e-06: acc: 83.84%, (\u001B[92m+\u001B[0m\u001B[92m0.13%\u001B[0m), f1: 83.78% (\u001B[92m+\u001B[0m0.08) |\n",
      "|          | 5e-05: acc: 84.89%, (\u001B[92m+\u001B[0m\u001B[92m0.62%\u001B[0m), f1: 85.04% (\u001B[92m+\u001B[0m0.71) | 5e-05: acc: 83.78%, (\u001B[92m+\u001B[0m\u001B[92m9.81%\u001B[0m), f1: 83.63% (\u001B[92m+\u001B[0m10.9) | 5e-05: acc: 85.38%, (\u001B[92m+\u001B[0m\u001B[92m1.67%\u001B[0m), f1: 85.38% (\u001B[92m+\u001B[0m1.68) |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "| vit_b_32 | 1e-05: acc: 83.34%, (\u001B[91m-0.93%\u001B[0m), f1: 83.52% (-0.81) | 1e-05: acc: 76.8%, (\u001B[92m+\u001B[0m\u001B[92m2.83%\u001B[0m), f1: 75.96% (\u001B[92m+\u001B[0m3.23)  | 1e-05: acc: 82.67%, (\u001B[91m-1.04%\u001B[0m), f1: 82.57% (-1.13) |\n",
      "|          | 1e-06: acc: 84.64%, (\u001B[92m+\u001B[0m\u001B[92m0.37%\u001B[0m), f1: 84.82% (\u001B[92m+\u001B[0m0.49) | 1e-06: acc: 75.82%, (\u001B[92m+\u001B[0m\u001B[92m1.85%\u001B[0m), f1: 74.15% (\u001B[92m+\u001B[0m1.42) | 1e-06: acc: 84.02%, (\u001B[92m+\u001B[0m\u001B[92m0.31%\u001B[0m), f1: 84.0% (\u001B[92m+\u001B[0m0.3)   |\n",
      "|          | 5e-05: acc: 84.52%, (\u001B[92m+\u001B[0m\u001B[92m0.25%\u001B[0m), f1: 84.6% (\u001B[92m+\u001B[0m0.27)  | 5e-05: acc: 76.37%, (\u001B[92m+\u001B[0m\u001B[92m2.4%\u001B[0m), f1: 75.85% (\u001B[92m+\u001B[0m3.12)  | 5e-05: acc: 83.28%, (\u001B[91m-0.43%\u001B[0m), f1: 83.31% (-0.39) |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "| vit_l_32 | 1e-05: acc: 84.15%, (\u001B[91m-0.12%\u001B[0m), f1: 84.19% (-0.14) | 1e-05: acc: 76.68%, (\u001B[92m+\u001B[0m\u001B[92m2.71%\u001B[0m), f1: 75.79% (\u001B[92m+\u001B[0m3.06) | 1e-05: acc: 84.52%, (\u001B[92m+\u001B[0m\u001B[92m0.81%\u001B[0m), f1: 84.54% (\u001B[92m+\u001B[0m0.84) |\n",
      "|          | 1e-06: acc: 84.27%, (\u001B[91m0.0%\u001B[0m), f1: 84.39% (\u001B[92m+\u001B[0m0.06)   | 1e-06: acc: 75.94%, (\u001B[92m+\u001B[0m\u001B[92m1.97%\u001B[0m), f1: 74.07% (\u001B[92m+\u001B[0m1.34) | 1e-06: acc: 83.47%, (\u001B[91m-0.24%\u001B[0m), f1: 83.48% (-0.22) |\n",
      "|          | 5e-05: acc: 84.95%, (\u001B[92m+\u001B[0m\u001B[92m0.68%\u001B[0m), f1: 84.95% (\u001B[92m+\u001B[0m0.62) | 5e-05: acc: 78.29%, (\u001B[92m+\u001B[0m\u001B[92m4.32%\u001B[0m), f1: 77.32% (\u001B[92m+\u001B[0m4.59) | 5e-05: acc: 83.47%, (\u001B[91m-0.24%\u001B[0m), f1: 83.4% (-0.3)   |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Main model: Coarse-grain vit_l_32, secondary granularity: coarse\n",
      "+----------+--------------------------------------------------+----------------------------------------------------+\n",
      "|          | 1e-05 (acc: 79.21%, f1: 78.9%)                   | 1e-06 (acc: 59.53%, f1: 55.66%)                    |\n",
      "+==========+==================================================+====================================================+\n",
      "| vit_b_16 | 1e-05: acc: 80.44%, (\u001B[92m+\u001B[0m\u001B[92m1.23%\u001B[0m), f1: 80.11% (\u001B[92m+\u001B[0m1.21) | 1e-06: acc: 63.23%, (\u001B[92m+\u001B[0m\u001B[92m3.7%\u001B[0m), f1: 58.56% (\u001B[92m+\u001B[0m2.9)     |\n",
      "|          | 1e-06: acc: 79.21%, (\u001B[91m0.0%\u001B[0m), f1: 78.9% (0.0)      | 5e-05: acc: 76.19%, (\u001B[92m+\u001B[0m\u001B[92m16.66%\u001B[0m), f1: 71.9% (\u001B[92m+\u001B[0m16.24)  |\n",
      "|          | 5e-05: acc: 79.83%, (\u001B[92m+\u001B[0m\u001B[92m0.62%\u001B[0m), f1: 79.58% (\u001B[92m+\u001B[0m0.68) |                                                    |\n",
      "+----------+--------------------------------------------------+----------------------------------------------------+\n",
      "| vit_b_32 | 1e-05: acc: 78.9%, (\u001B[91m-0.31%\u001B[0m), f1: 78.39% (-0.51)  | 1e-05: acc: 72.79%, (\u001B[92m+\u001B[0m\u001B[92m13.26%\u001B[0m), f1: 68.64% (\u001B[92m+\u001B[0m12.98) |\n",
      "|          | 1e-06: acc: 77.61%, (\u001B[91m-1.6%\u001B[0m), f1: 77.13% (-1.77)  | 5e-05: acc: 70.57%, (\u001B[92m+\u001B[0m\u001B[92m11.04%\u001B[0m), f1: 66.77% (\u001B[92m+\u001B[0m11.11) |\n",
      "|          | 5e-05: acc: 79.15%, (\u001B[91m-0.06%\u001B[0m), f1: 78.86% (-0.04) |                                                    |\n",
      "+----------+--------------------------------------------------+----------------------------------------------------+\n",
      "| vit_l_16 | 1e-05: acc: 80.51%, (\u001B[92m+\u001B[0m\u001B[92m1.3%\u001B[0m), f1: 80.45% (\u001B[92m+\u001B[0m1.55)  | 1e-05: acc: 76.68%, (\u001B[92m+\u001B[0m\u001B[92m17.15%\u001B[0m), f1: 72.5% (\u001B[92m+\u001B[0m16.84)  |\n",
      "|          | 1e-06: acc: 78.35%, (\u001B[91m-0.86%\u001B[0m), f1: 77.82% (-1.08) | 1e-06: acc: 68.11%, (\u001B[92m+\u001B[0m\u001B[92m8.58%\u001B[0m), f1: 63.25% (\u001B[92m+\u001B[0m7.59)   |\n",
      "|          | 5e-05: acc: 82.73%, (\u001B[92m+\u001B[0m\u001B[92m3.52%\u001B[0m), f1: 82.83% (\u001B[92m+\u001B[0m3.93) | 5e-05: acc: 75.88%, (\u001B[92m+\u001B[0m\u001B[92m16.35%\u001B[0m), f1: 71.7% (\u001B[92m+\u001B[0m16.04)  |\n",
      "+----------+--------------------------------------------------+----------------------------------------------------+\n",
      "\n",
      "\n",
      "Main model: Coarse-grain vit_l_32, secondary granularity: fine\n",
      "+----------+--------------------------------------------------+----------------------------------------------------+--------------------------------------------------+\n",
      "|          | 1e-05 (acc: 79.21%, f1: 78.9%)                   | 1e-06 (acc: 59.53%, f1: 55.66%)                    | 5e-05 (acc: 80.75%, f1: 80.96%)                  |\n",
      "+==========+==================================================+====================================================+==================================================+\n",
      "| vit_b_16 | 1e-05: acc: 79.77%, (\u001B[92m+\u001B[0m\u001B[92m0.56%\u001B[0m), f1: 79.37% (\u001B[92m+\u001B[0m0.47) | 1e-05: acc: 68.91%, (\u001B[92m+\u001B[0m\u001B[92m9.38%\u001B[0m), f1: 64.98% (\u001B[92m+\u001B[0m9.32)   | 1e-05: acc: 78.72%, (\u001B[91m-2.03%\u001B[0m), f1: 79.11% (-1.85) |\n",
      "|          | 1e-06: acc: 79.95%, (\u001B[92m+\u001B[0m\u001B[92m0.74%\u001B[0m), f1: 79.58% (\u001B[92m+\u001B[0m0.68) | 1e-06: acc: 71.5%, (\u001B[92m+\u001B[0m\u001B[92m11.97%\u001B[0m), f1: 67.46% (\u001B[92m+\u001B[0m11.8)   | 1e-06: acc: 80.14%, (\u001B[91m-0.61%\u001B[0m), f1: 80.49% (-0.47) |\n",
      "|          | 5e-05: acc: 80.32%, (\u001B[92m+\u001B[0m\u001B[92m1.11%\u001B[0m), f1: 80.01% (\u001B[92m+\u001B[0m1.11) | 5e-05: acc: 68.91%, (\u001B[92m+\u001B[0m\u001B[92m9.38%\u001B[0m), f1: 64.76% (\u001B[92m+\u001B[0m9.1)    | 5e-05: acc: 79.77%, (\u001B[91m-0.98%\u001B[0m), f1: 80.14% (-0.82) |\n",
      "+----------+--------------------------------------------------+----------------------------------------------------+--------------------------------------------------+\n",
      "| vit_b_32 | 1e-05: acc: 78.96%, (\u001B[91m-0.25%\u001B[0m), f1: 78.72% (-0.18) | 1e-05: acc: 66.32%, (\u001B[92m+\u001B[0m\u001B[92m6.79%\u001B[0m), f1: 62.32% (\u001B[92m+\u001B[0m6.66)   | 1e-05: acc: 79.27%, (\u001B[91m-1.48%\u001B[0m), f1: 79.65% (-1.31) |\n",
      "|          | 1e-06: acc: 78.84%, (\u001B[91m-0.37%\u001B[0m), f1: 78.44% (-0.46) | 1e-06: acc: 68.97%, (\u001B[92m+\u001B[0m\u001B[92m9.44%\u001B[0m), f1: 64.98% (\u001B[92m+\u001B[0m9.32)   | 1e-06: acc: 79.64%, (\u001B[91m-1.11%\u001B[0m), f1: 80.1% (-0.86)  |\n",
      "|          | 5e-05: acc: 79.64%, (\u001B[92m+\u001B[0m\u001B[92m0.43%\u001B[0m), f1: 79.33% (\u001B[92m+\u001B[0m0.43) | 5e-05: acc: 65.82%, (\u001B[92m+\u001B[0m\u001B[92m6.29%\u001B[0m), f1: 61.87% (\u001B[92m+\u001B[0m6.21)   | 5e-05: acc: 79.83%, (\u001B[91m-0.92%\u001B[0m), f1: 80.19% (-0.77) |\n",
      "+----------+--------------------------------------------------+----------------------------------------------------+--------------------------------------------------+\n",
      "| vit_l_16 | 1e-05: acc: 80.2%, (\u001B[92m+\u001B[0m\u001B[92m0.99%\u001B[0m), f1: 79.78% (\u001B[92m+\u001B[0m0.88)  | 1e-05: acc: 69.96%, (\u001B[92m+\u001B[0m\u001B[92m10.43%\u001B[0m), f1: 65.89% (\u001B[92m+\u001B[0m10.23) | 1e-05: acc: 80.63%, (\u001B[91m-0.12%\u001B[0m), f1: 80.92% (-0.04) |\n",
      "|          | 1e-06: acc: 79.83%, (\u001B[92m+\u001B[0m\u001B[92m0.62%\u001B[0m), f1: 79.49% (\u001B[92m+\u001B[0m0.59) | 1e-06: acc: 69.46%, (\u001B[92m+\u001B[0m\u001B[92m9.93%\u001B[0m), f1: 65.2% (\u001B[92m+\u001B[0m9.54)    | 1e-06: acc: 78.9%, (\u001B[91m-1.85%\u001B[0m), f1: 79.29% (-1.67)  |\n",
      "|          | 5e-05: acc: 80.69%, (\u001B[92m+\u001B[0m\u001B[92m1.48%\u001B[0m), f1: 80.42% (\u001B[92m+\u001B[0m1.52) | 5e-05: acc: 70.33%, (\u001B[92m+\u001B[0m\u001B[92m10.8%\u001B[0m), f1: 66.26% (\u001B[92m+\u001B[0m10.6)   | 5e-05: acc: 79.7%, (\u001B[91m-1.05%\u001B[0m), f1: 80.04% (-0.92)  |\n",
      "+----------+--------------------------------------------------+----------------------------------------------------+--------------------------------------------------+\n",
      "\n",
      "\n",
      "Main model: Coarse-grain vit_l_32 with both fine and coarse grain secondary models\n",
      "+----------+--------------------------------------------------+----------------------------------------------------+--------------------------------------------------+\n",
      "|          | 1e-06 acc: (59.53%)                              | 1e-05 acc: (79.21%)                                | 5e-05 acc: (80.75%)                              |\n",
      "+==========+==================================================+====================================================+==================================================+\n",
      "| vit_b_16 | 1e-05: acc: 81.18%, (\u001B[92m+\u001B[0m\u001B[92m1.97%\u001B[0m), f1: 80.8% (\u001B[92m+\u001B[0m1.9)   | 1e-05: acc: 68.29%, (\u001B[92m+\u001B[0m\u001B[92m8.76%\u001B[0m), f1: 64.35% (\u001B[92m+\u001B[0m8.69)   | 1e-05: acc: 79.46%, (\u001B[91m-1.29%\u001B[0m), f1: 79.67% (-1.29) |\n",
      "|          | 1e-06: acc: 79.95%, (\u001B[92m+\u001B[0m\u001B[92m0.74%\u001B[0m), f1: 79.58% (\u001B[92m+\u001B[0m0.68) | 1e-06: acc: 65.08%, (\u001B[92m+\u001B[0m\u001B[92m5.55%\u001B[0m), f1: 61.05% (\u001B[92m+\u001B[0m5.39)   | 1e-06: acc: 80.14%, (\u001B[91m-0.61%\u001B[0m), f1: 80.49% (-0.47) |\n",
      "|          | 5e-05: acc: 81.62%, (\u001B[92m+\u001B[0m\u001B[92m2.41%\u001B[0m), f1: 81.3% (\u001B[92m+\u001B[0m2.4)   | 5e-05: acc: 75.51%, (\u001B[92m+\u001B[0m\u001B[92m15.98%\u001B[0m), f1: 71.32% (\u001B[92m+\u001B[0m15.66) | 5e-05: acc: 81.18%, (\u001B[92m+\u001B[0m\u001B[92m0.43%\u001B[0m), f1: 81.35% (\u001B[92m+\u001B[0m0.39) |\n",
      "+----------+--------------------------------------------------+----------------------------------------------------+--------------------------------------------------+\n",
      "| vit_b_32 | 1e-05: acc: 79.4%, (\u001B[92m+\u001B[0m\u001B[92m0.19%\u001B[0m), f1: 78.98% (\u001B[92m+\u001B[0m0.08)  | 1e-05: acc: 67.0%, (\u001B[92m+\u001B[0m\u001B[92m7.47%\u001B[0m), f1: 62.89% (\u001B[92m+\u001B[0m7.23)    | 1e-05: acc: 79.27%, (\u001B[91m-1.48%\u001B[0m), f1: 79.65% (-1.31) |\n",
      "|          | 1e-06: acc: 78.47%, (\u001B[91m-0.74%\u001B[0m), f1: 78.04% (-0.86) | 1e-06: acc: 62.99%, (\u001B[92m+\u001B[0m\u001B[92m3.46%\u001B[0m), f1: 59.13% (\u001B[92m+\u001B[0m3.47)   | 1e-06: acc: 79.64%, (\u001B[91m-1.11%\u001B[0m), f1: 80.1% (-0.86)  |\n",
      "|          | 5e-05: acc: 80.01%, (\u001B[92m+\u001B[0m\u001B[92m0.8%\u001B[0m), f1: 79.69% (\u001B[92m+\u001B[0m0.79)  | 5e-05: acc: 69.4%, (\u001B[92m+\u001B[0m\u001B[92m9.87%\u001B[0m), f1: 65.57% (\u001B[92m+\u001B[0m9.91)    | 5e-05: acc: 79.4%, (\u001B[91m-1.35%\u001B[0m), f1: 79.74% (-1.22)  |\n",
      "+----------+--------------------------------------------------+----------------------------------------------------+--------------------------------------------------+\n",
      "| vit_l_16 | 1e-05: acc: 79.46%, (\u001B[92m+\u001B[0m\u001B[92m0.25%\u001B[0m), f1: 79.2% (\u001B[92m+\u001B[0m0.3)   | 1e-05: acc: 67.8%, (\u001B[92m+\u001B[0m\u001B[92m8.27%\u001B[0m), f1: 63.82% (\u001B[92m+\u001B[0m8.16)    | 1e-05: acc: 80.38%, (\u001B[91m-0.37%\u001B[0m), f1: 80.67% (-0.29) |\n",
      "|          | 1e-06: acc: 79.89%, (\u001B[92m+\u001B[0m\u001B[92m0.68%\u001B[0m), f1: 79.5% (\u001B[92m+\u001B[0m0.6)   | 1e-06: acc: 67.8%, (\u001B[92m+\u001B[0m\u001B[92m8.27%\u001B[0m), f1: 63.81% (\u001B[92m+\u001B[0m8.15)    | 1e-06: acc: 78.9%, (\u001B[91m-1.85%\u001B[0m), f1: 79.29% (-1.67)  |\n",
      "|          | 5e-05: acc: 82.17%, (\u001B[92m+\u001B[0m\u001B[92m2.96%\u001B[0m), f1: 82.14% (\u001B[92m+\u001B[0m3.24) | 5e-05: acc: 70.51%, (\u001B[92m+\u001B[0m\u001B[92m10.98%\u001B[0m), f1: 66.29% (\u001B[92m+\u001B[0m10.63) | 5e-05: acc: 80.51%, (\u001B[91m-0.24%\u001B[0m), f1: 80.74% (-0.22) |\n",
      "+----------+--------------------------------------------------+----------------------------------------------------+--------------------------------------------------+\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "######################################## Main granularity: fine ########################################\n",
      "########################################################################################################\n",
      "\n",
      "Main model: Fine-grain vit_b_16, secondary granularity: coarse\n",
      "+----------+---------------------------------------------+----------------------------------------------+----------------------------------------------+\n",
      "|          | 1e-05 (acc: 63.91%, f1: 63.5%)              | 1e-06 (acc: 69.96%, f1: 70.34%)              | 5e-05 (acc: 64.53%, f1: 65.01%)              |\n",
      "+==========+=============================================+==============================================+==============================================+\n",
      "| vit_b_32 | 1e-05: acc: 63.91%, (\u001B[91m0.0%\u001B[0m), f1: 63.5% (0.0) | 1e-05: acc: 69.96%, (\u001B[91m0.0%\u001B[0m), f1: 70.34% (0.0) | 1e-05: acc: 64.53%, (\u001B[91m0.0%\u001B[0m), f1: 65.01% (0.0) |\n",
      "|          | 1e-06: acc: 63.91%, (\u001B[91m0.0%\u001B[0m), f1: 63.5% (0.0) | 1e-06: acc: 69.96%, (\u001B[91m0.0%\u001B[0m), f1: 70.34% (0.0) | 1e-06: acc: 64.53%, (\u001B[91m0.0%\u001B[0m), f1: 65.01% (0.0) |\n",
      "|          | 5e-05: acc: 63.91%, (\u001B[91m0.0%\u001B[0m), f1: 63.5% (0.0) | 5e-05: acc: 69.96%, (\u001B[91m0.0%\u001B[0m), f1: 70.34% (0.0) | 5e-05: acc: 64.53%, (\u001B[91m0.0%\u001B[0m), f1: 65.01% (0.0) |\n",
      "+----------+---------------------------------------------+----------------------------------------------+----------------------------------------------+\n",
      "| vit_l_16 | 1e-05: acc: 63.91%, (\u001B[91m0.0%\u001B[0m), f1: 63.5% (0.0) | 1e-05: acc: 69.96%, (\u001B[91m0.0%\u001B[0m), f1: 70.34% (0.0) | 1e-05: acc: 64.53%, (\u001B[91m0.0%\u001B[0m), f1: 65.01% (0.0) |\n",
      "|          | 1e-06: acc: 63.91%, (\u001B[91m0.0%\u001B[0m), f1: 63.5% (0.0) | 1e-06: acc: 69.96%, (\u001B[91m0.0%\u001B[0m), f1: 70.34% (0.0) | 1e-06: acc: 64.53%, (\u001B[91m0.0%\u001B[0m), f1: 65.01% (0.0) |\n",
      "|          | 5e-05: acc: 63.91%, (\u001B[91m0.0%\u001B[0m), f1: 63.5% (0.0) | 5e-05: acc: 69.96%, (\u001B[91m0.0%\u001B[0m), f1: 70.34% (0.0) | 5e-05: acc: 64.53%, (\u001B[91m0.0%\u001B[0m), f1: 65.01% (0.0) |\n",
      "+----------+---------------------------------------------+----------------------------------------------+----------------------------------------------+\n",
      "| vit_l_32 | 1e-05: acc: 63.91%, (\u001B[91m0.0%\u001B[0m), f1: 63.5% (0.0) | 1e-05: acc: 69.96%, (\u001B[91m0.0%\u001B[0m), f1: 70.34% (0.0) | 1e-05: acc: 64.53%, (\u001B[91m0.0%\u001B[0m), f1: 65.01% (0.0) |\n",
      "|          | 1e-06: acc: 63.91%, (\u001B[91m0.0%\u001B[0m), f1: 63.5% (0.0) | 1e-06: acc: 69.96%, (\u001B[91m0.0%\u001B[0m), f1: 70.34% (0.0) | 1e-06: acc: 64.53%, (\u001B[91m0.0%\u001B[0m), f1: 65.01% (0.0) |\n",
      "|          | 5e-05: acc: 63.91%, (\u001B[91m0.0%\u001B[0m), f1: 63.5% (0.0) | 5e-05: acc: 69.96%, (\u001B[91m0.0%\u001B[0m), f1: 70.34% (0.0) | 5e-05: acc: 64.53%, (\u001B[91m0.0%\u001B[0m), f1: 65.01% (0.0) |\n",
      "+----------+---------------------------------------------+----------------------------------------------+----------------------------------------------+\n",
      "\n",
      "\n",
      "Main model: Fine-grain vit_b_16, secondary granularity: fine\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "|          | 1e-05 (acc: 63.91%, f1: 63.5%)                   | 1e-06 (acc: 69.96%, f1: 70.34%)                  | 5e-05 (acc: 64.53%, f1: 65.01%)                  |\n",
      "+==========+==================================================+==================================================+==================================================+\n",
      "| vit_b_32 | 1e-05: acc: 63.66%, (\u001B[91m-0.25%\u001B[0m), f1: 63.32% (-0.18) | 1e-05: acc: 69.96%, (\u001B[91m0.0%\u001B[0m), f1: 70.34% (0.0)     | 1e-05: acc: 64.53%, (\u001B[91m0.0%\u001B[0m), f1: 65.01% (0.0)     |\n",
      "|          | 1e-06: acc: 65.02%, (\u001B[92m+\u001B[0m\u001B[92m1.11%\u001B[0m), f1: 64.72% (\u001B[92m+\u001B[0m1.22) | 1e-06: acc: 70.02%, (\u001B[92m+\u001B[0m\u001B[92m0.06%\u001B[0m), f1: 70.36% (\u001B[92m+\u001B[0m0.02) | 1e-06: acc: 64.34%, (\u001B[91m-0.19%\u001B[0m), f1: 64.81% (-0.2)  |\n",
      "|          | 5e-05: acc: 63.85%, (\u001B[91m-0.06%\u001B[0m), f1: 63.47% (-0.03) | 5e-05: acc: 69.83%, (\u001B[91m-0.13%\u001B[0m), f1: 70.2% (-0.14)  | 5e-05: acc: 64.1%, (\u001B[91m-0.43%\u001B[0m), f1: 64.62% (-0.39)  |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "| vit_l_16 | 1e-05: acc: 65.45%, (\u001B[92m+\u001B[0m\u001B[92m1.54%\u001B[0m), f1: 65.01% (\u001B[92m+\u001B[0m1.51) | 1e-05: acc: 70.02%, (\u001B[92m+\u001B[0m\u001B[92m0.06%\u001B[0m), f1: 70.41% (\u001B[92m+\u001B[0m0.07) | 1e-05: acc: 64.96%, (\u001B[92m+\u001B[0m\u001B[92m0.43%\u001B[0m), f1: 65.39% (\u001B[92m+\u001B[0m0.38) |\n",
      "|          | 1e-06: acc: 66.07%, (\u001B[92m+\u001B[0m\u001B[92m2.16%\u001B[0m), f1: 65.72% (\u001B[92m+\u001B[0m2.22) | 1e-06: acc: 70.33%, (\u001B[92m+\u001B[0m\u001B[92m0.37%\u001B[0m), f1: 70.64% (\u001B[92m+\u001B[0m0.3)  | 1e-06: acc: 64.59%, (\u001B[92m+\u001B[0m\u001B[92m0.06%\u001B[0m), f1: 65.04% (\u001B[92m+\u001B[0m0.03) |\n",
      "|          | 5e-05: acc: 65.76%, (\u001B[92m+\u001B[0m\u001B[92m1.85%\u001B[0m), f1: 65.42% (\u001B[92m+\u001B[0m1.92) | 5e-05: acc: 70.57%, (\u001B[92m+\u001B[0m\u001B[92m0.61%\u001B[0m), f1: 71.01% (\u001B[92m+\u001B[0m0.67) | 5e-05: acc: 65.7%, (\u001B[92m+\u001B[0m\u001B[92m1.17%\u001B[0m), f1: 66.49% (\u001B[92m+\u001B[0m1.48)  |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "| vit_l_32 | 1e-05: acc: 64.22%, (\u001B[92m+\u001B[0m\u001B[92m0.31%\u001B[0m), f1: 63.9% (\u001B[92m+\u001B[0m0.4)   | 1e-05: acc: 69.9%, (\u001B[91m-0.06%\u001B[0m), f1: 70.26% (-0.08)  | 1e-05: acc: 64.71%, (\u001B[92m+\u001B[0m\u001B[92m0.18%\u001B[0m), f1: 65.18% (\u001B[92m+\u001B[0m0.17) |\n",
      "|          | 1e-06: acc: 64.9%, (\u001B[92m+\u001B[0m\u001B[92m0.99%\u001B[0m), f1: 64.52% (\u001B[92m+\u001B[0m1.02)  | 1e-06: acc: 69.96%, (\u001B[91m0.0%\u001B[0m), f1: 70.29% (-0.05)   | 1e-06: acc: 64.77%, (\u001B[92m+\u001B[0m\u001B[92m0.24%\u001B[0m), f1: 65.27% (\u001B[92m+\u001B[0m0.26) |\n",
      "|          | 5e-05: acc: 64.22%, (\u001B[92m+\u001B[0m\u001B[92m0.31%\u001B[0m), f1: 63.95% (\u001B[92m+\u001B[0m0.45) | 5e-05: acc: 69.9%, (\u001B[91m-0.06%\u001B[0m), f1: 70.29% (-0.05)  | 5e-05: acc: 64.34%, (\u001B[91m-0.19%\u001B[0m), f1: 64.86% (-0.15) |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "\n",
      "\n",
      "Main model: Fine-grain vit_b_16 with both fine and coarse grain secondary models\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "|          | 1e-06 acc: (69.96%)                              | 1e-05 acc: (63.91%)                              | 5e-05 acc: (64.53%)                              |\n",
      "+==========+==================================================+==================================================+==================================================+\n",
      "| vit_b_32 | 1e-05: acc: 62.99%, (\u001B[91m-0.92%\u001B[0m), f1: 62.68% (-0.82) | 1e-05: acc: 69.46%, (\u001B[91m-0.5%\u001B[0m), f1: 69.91% (-0.43)  | 1e-05: acc: 64.4%, (\u001B[91m-0.13%\u001B[0m), f1: 64.84% (-0.17)  |\n",
      "|          | 1e-06: acc: 65.21%, (\u001B[92m+\u001B[0m\u001B[92m1.3%\u001B[0m), f1: 64.85% (\u001B[92m+\u001B[0m1.35)  | 1e-06: acc: 69.83%, (\u001B[91m-0.13%\u001B[0m), f1: 70.13% (-0.21) | 1e-06: acc: 63.66%, (\u001B[91m-0.87%\u001B[0m), f1: 63.98% (-1.03) |\n",
      "|          | 5e-05: acc: 62.99%, (\u001B[91m-0.92%\u001B[0m), f1: 62.63% (-0.87) | 5e-05: acc: 69.83%, (\u001B[91m-0.13%\u001B[0m), f1: 70.17% (-0.17) | 5e-05: acc: 62.8%, (\u001B[91m-1.73%\u001B[0m), f1: 63.04% (-1.97)  |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "| vit_l_16 | 1e-05: acc: 66.93%, (\u001B[92m+\u001B[0m\u001B[92m3.02%\u001B[0m), f1: 66.61% (\u001B[92m+\u001B[0m3.11) | 1e-05: acc: 70.76%, (\u001B[92m+\u001B[0m\u001B[92m0.8%\u001B[0m), f1: 71.21% (\u001B[92m+\u001B[0m0.87)  | 1e-05: acc: 64.84%, (\u001B[92m+\u001B[0m\u001B[92m0.31%\u001B[0m), f1: 65.21% (\u001B[92m+\u001B[0m0.2)  |\n",
      "|          | 1e-06: acc: 68.17%, (\u001B[92m+\u001B[0m\u001B[92m4.26%\u001B[0m), f1: 67.99% (\u001B[92m+\u001B[0m4.49) | 1e-06: acc: 70.7%, (\u001B[92m+\u001B[0m\u001B[92m0.74%\u001B[0m), f1: 70.89% (\u001B[92m+\u001B[0m0.55)  | 1e-06: acc: 65.14%, (\u001B[92m+\u001B[0m\u001B[92m0.61%\u001B[0m), f1: 65.19% (\u001B[92m+\u001B[0m0.18) |\n",
      "|          | 5e-05: acc: 67.74%, (\u001B[92m+\u001B[0m\u001B[92m3.83%\u001B[0m), f1: 67.53% (\u001B[92m+\u001B[0m4.03) | 5e-05: acc: 71.75%, (\u001B[92m+\u001B[0m\u001B[92m1.79%\u001B[0m), f1: 71.97% (\u001B[92m+\u001B[0m1.63) | 5e-05: acc: 64.84%, (\u001B[92m+\u001B[0m\u001B[92m0.31%\u001B[0m), f1: 65.81% (\u001B[92m+\u001B[0m0.8)  |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "| vit_l_32 | 1e-05: acc: 64.22%, (\u001B[92m+\u001B[0m\u001B[92m0.31%\u001B[0m), f1: 63.92% (\u001B[92m+\u001B[0m0.42) | 1e-05: acc: 69.46%, (\u001B[91m-0.5%\u001B[0m), f1: 69.82% (-0.52)  | 1e-05: acc: 63.97%, (\u001B[91m-0.56%\u001B[0m), f1: 64.4% (-0.61)  |\n",
      "|          | 1e-06: acc: 65.33%, (\u001B[92m+\u001B[0m\u001B[92m1.42%\u001B[0m), f1: 65.07% (\u001B[92m+\u001B[0m1.57) | 1e-06: acc: 69.83%, (\u001B[91m-0.13%\u001B[0m), f1: 70.12% (-0.22) | 1e-06: acc: 65.08%, (\u001B[92m+\u001B[0m\u001B[92m0.55%\u001B[0m), f1: 65.24% (\u001B[92m+\u001B[0m0.23) |\n",
      "|          | 5e-05: acc: 64.34%, (\u001B[92m+\u001B[0m\u001B[92m0.43%\u001B[0m), f1: 64.24% (\u001B[92m+\u001B[0m0.74) | 5e-05: acc: 69.15%, (\u001B[91m-0.81%\u001B[0m), f1: 69.69% (-0.65) | 5e-05: acc: 64.03%, (\u001B[91m-0.5%\u001B[0m), f1: 64.29% (-0.72)  |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Main model: Fine-grain vit_b_32, secondary granularity: coarse\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+----------------------------------------------+\n",
      "|          | 1e-05 (acc: 55.89%, f1: 56.17%)                  | 1e-06 (acc: 63.66%, f1: 64.1%)                   | 5e-05 (acc: 53.73%, f1: 53.66%)              |\n",
      "+==========+==================================================+==================================================+==============================================+\n",
      "| vit_b_16 | 1e-05: acc: 55.89%, (\u001B[91m0.0%\u001B[0m), f1: 56.17% (0.0)     | 1e-05: acc: 63.66%, (\u001B[91m0.0%\u001B[0m), f1: 64.1% (0.0)      | 1e-05: acc: 53.73%, (\u001B[91m0.0%\u001B[0m), f1: 53.66% (0.0) |\n",
      "|          | 1e-06: acc: 55.89%, (\u001B[91m0.0%\u001B[0m), f1: 56.17% (0.0)     | 1e-06: acc: 63.66%, (\u001B[91m0.0%\u001B[0m), f1: 64.1% (0.0)      | 1e-06: acc: 53.73%, (\u001B[91m0.0%\u001B[0m), f1: 53.66% (0.0) |\n",
      "|          | 5e-05: acc: 55.89%, (\u001B[91m0.0%\u001B[0m), f1: 56.17% (0.0)     | 5e-05: acc: 63.66%, (\u001B[91m0.0%\u001B[0m), f1: 64.1% (0.0)      | 5e-05: acc: 53.73%, (\u001B[91m0.0%\u001B[0m), f1: 53.66% (0.0) |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+----------------------------------------------+\n",
      "| vit_l_16 | 1e-05: acc: 55.89%, (\u001B[91m0.0%\u001B[0m), f1: 56.17% (0.0)     | 1e-05: acc: 63.66%, (\u001B[91m0.0%\u001B[0m), f1: 64.1% (0.0)      | 1e-05: acc: 53.73%, (\u001B[91m0.0%\u001B[0m), f1: 53.66% (0.0) |\n",
      "|          | 1e-06: acc: 55.89%, (\u001B[91m0.0%\u001B[0m), f1: 56.17% (0.0)     | 1e-06: acc: 63.66%, (\u001B[91m0.0%\u001B[0m), f1: 64.1% (0.0)      | 1e-06: acc: 53.73%, (\u001B[91m0.0%\u001B[0m), f1: 53.66% (0.0) |\n",
      "|          | 5e-05: acc: 55.09%, (\u001B[91m-0.8%\u001B[0m), f1: 55.55% (-0.62)  | 5e-05: acc: 62.68%, (\u001B[91m-0.98%\u001B[0m), f1: 63.24% (-0.86) | 5e-05: acc: 53.73%, (\u001B[91m0.0%\u001B[0m), f1: 53.66% (0.0) |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+----------------------------------------------+\n",
      "| vit_l_32 | 1e-05: acc: 55.89%, (\u001B[91m0.0%\u001B[0m), f1: 56.17% (0.0)     | 1e-05: acc: 63.66%, (\u001B[91m0.0%\u001B[0m), f1: 64.1% (0.0)      | 1e-05: acc: 53.73%, (\u001B[91m0.0%\u001B[0m), f1: 53.66% (0.0) |\n",
      "|          | 1e-06: acc: 55.89%, (\u001B[91m0.0%\u001B[0m), f1: 56.17% (0.0)     | 1e-06: acc: 63.66%, (\u001B[91m0.0%\u001B[0m), f1: 64.1% (0.0)      | 1e-06: acc: 53.73%, (\u001B[91m0.0%\u001B[0m), f1: 53.66% (0.0) |\n",
      "|          | 5e-05: acc: 55.21%, (\u001B[91m-0.68%\u001B[0m), f1: 55.69% (-0.48) | 5e-05: acc: 62.99%, (\u001B[91m-0.67%\u001B[0m), f1: 63.64% (-0.46) | 5e-05: acc: 53.73%, (\u001B[91m0.0%\u001B[0m), f1: 53.66% (0.0) |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+----------------------------------------------+\n",
      "\n",
      "\n",
      "Main model: Fine-grain vit_b_32, secondary granularity: fine\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "|          | 1e-05 (acc: 55.89%, f1: 56.17%)                  | 1e-06 (acc: 63.66%, f1: 64.1%)                   | 5e-05 (acc: 53.73%, f1: 53.66%)                  |\n",
      "+==========+==================================================+==================================================+==================================================+\n",
      "| vit_b_16 | 1e-05: acc: 58.17%, (\u001B[92m+\u001B[0m\u001B[92m2.28%\u001B[0m), f1: 58.61% (\u001B[92m+\u001B[0m2.44) | 1e-05: acc: 63.85%, (\u001B[92m+\u001B[0m\u001B[92m0.19%\u001B[0m), f1: 64.38% (\u001B[92m+\u001B[0m0.28) | 1e-05: acc: 55.03%, (\u001B[92m+\u001B[0m\u001B[92m1.3%\u001B[0m), f1: 54.68% (\u001B[92m+\u001B[0m1.02)  |\n",
      "|          | 1e-06: acc: 59.65%, (\u001B[92m+\u001B[0m\u001B[92m3.76%\u001B[0m), f1: 59.85% (\u001B[92m+\u001B[0m3.68) | 1e-06: acc: 65.82%, (\u001B[92m+\u001B[0m\u001B[92m2.16%\u001B[0m), f1: 66.46% (\u001B[92m+\u001B[0m2.36) | 1e-06: acc: 56.26%, (\u001B[92m+\u001B[0m\u001B[92m2.53%\u001B[0m), f1: 55.46% (\u001B[92m+\u001B[0m1.8)  |\n",
      "|          | 5e-05: acc: 58.48%, (\u001B[92m+\u001B[0m\u001B[92m2.59%\u001B[0m), f1: 58.81% (\u001B[92m+\u001B[0m2.64) | 5e-05: acc: 65.64%, (\u001B[92m+\u001B[0m\u001B[92m1.98%\u001B[0m), f1: 66.18% (\u001B[92m+\u001B[0m2.08) | 5e-05: acc: 58.17%, (\u001B[92m+\u001B[0m\u001B[92m4.44%\u001B[0m), f1: 58.52% (\u001B[92m+\u001B[0m4.86) |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "| vit_l_16 | 1e-05: acc: 60.09%, (\u001B[92m+\u001B[0m\u001B[92m4.2%\u001B[0m), f1: 60.14% (\u001B[92m+\u001B[0m3.97)  | 1e-05: acc: 64.34%, (\u001B[92m+\u001B[0m\u001B[92m0.68%\u001B[0m), f1: 64.68% (\u001B[92m+\u001B[0m0.58) | 1e-05: acc: 55.89%, (\u001B[92m+\u001B[0m\u001B[92m2.16%\u001B[0m), f1: 55.27% (\u001B[92m+\u001B[0m1.61) |\n",
      "|          | 1e-06: acc: 59.78%, (\u001B[92m+\u001B[0m\u001B[92m3.89%\u001B[0m), f1: 60.01% (\u001B[92m+\u001B[0m3.84) | 1e-06: acc: 64.28%, (\u001B[92m+\u001B[0m\u001B[92m0.62%\u001B[0m), f1: 64.74% (\u001B[92m+\u001B[0m0.64) | 1e-06: acc: 58.48%, (\u001B[92m+\u001B[0m\u001B[92m4.75%\u001B[0m), f1: 57.94% (\u001B[92m+\u001B[0m4.28) |\n",
      "|          | 5e-05: acc: 58.91%, (\u001B[92m+\u001B[0m\u001B[92m3.02%\u001B[0m), f1: 59.08% (\u001B[92m+\u001B[0m2.91) | 5e-05: acc: 64.77%, (\u001B[92m+\u001B[0m\u001B[92m1.11%\u001B[0m), f1: 65.36% (\u001B[92m+\u001B[0m1.26) | 5e-05: acc: 56.82%, (\u001B[92m+\u001B[0m\u001B[92m3.09%\u001B[0m), f1: 57.14% (\u001B[92m+\u001B[0m3.48) |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "| vit_l_32 | 1e-05: acc: 57.37%, (\u001B[92m+\u001B[0m\u001B[92m1.48%\u001B[0m), f1: 57.78% (\u001B[92m+\u001B[0m1.61) | 1e-05: acc: 63.85%, (\u001B[92m+\u001B[0m\u001B[92m0.19%\u001B[0m), f1: 64.2% (\u001B[92m+\u001B[0m0.1)   | 1e-05: acc: 54.72%, (\u001B[92m+\u001B[0m\u001B[92m0.99%\u001B[0m), f1: 54.31% (\u001B[92m+\u001B[0m0.65) |\n",
      "|          | 1e-06: acc: 58.3%, (\u001B[92m+\u001B[0m\u001B[92m2.41%\u001B[0m), f1: 58.74% (\u001B[92m+\u001B[0m2.57)  | 1e-06: acc: 64.1%, (\u001B[92m+\u001B[0m\u001B[92m0.44%\u001B[0m), f1: 64.67% (\u001B[92m+\u001B[0m0.57)  | 1e-06: acc: 54.97%, (\u001B[92m+\u001B[0m\u001B[92m1.24%\u001B[0m), f1: 54.53% (\u001B[92m+\u001B[0m0.87) |\n",
      "|          | 5e-05: acc: 56.45%, (\u001B[92m+\u001B[0m\u001B[92m0.56%\u001B[0m), f1: 56.72% (\u001B[92m+\u001B[0m0.55) | 5e-05: acc: 63.73%, (\u001B[92m+\u001B[0m\u001B[92m0.07%\u001B[0m), f1: 64.15% (\u001B[92m+\u001B[0m0.05) | 5e-05: acc: 54.66%, (\u001B[92m+\u001B[0m\u001B[92m0.93%\u001B[0m), f1: 54.1% (\u001B[92m+\u001B[0m0.44)  |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "\n",
      "\n",
      "Main model: Fine-grain vit_b_32 with both fine and coarse grain secondary models\n",
      "+----------+----------------------------------------------------+--------------------------------------------------+---------------------------------------------------+\n",
      "|          | 1e-06 acc: (63.66%)                                | 1e-05 acc: (55.89%)                              | 5e-05 acc: (53.73%)                               |\n",
      "+==========+====================================================+==================================================+===================================================+\n",
      "| vit_b_16 | 1e-05: acc: 60.76%, (\u001B[92m+\u001B[0m\u001B[92m4.87%\u001B[0m), f1: 60.8% (\u001B[92m+\u001B[0m4.63)    | 1e-05: acc: 63.79%, (\u001B[92m+\u001B[0m\u001B[92m0.13%\u001B[0m), f1: 63.9% (-0.2)   | 1e-05: acc: 57.06%, (\u001B[92m+\u001B[0m\u001B[92m3.33%\u001B[0m), f1: 55.88% (\u001B[92m+\u001B[0m2.22)  |\n",
      "|          | 1e-06: acc: 69.22%, (\u001B[92m+\u001B[0m\u001B[92m13.33%\u001B[0m), f1: 69.42% (\u001B[92m+\u001B[0m13.25) | 1e-06: acc: 69.09%, (\u001B[92m+\u001B[0m\u001B[92m5.43%\u001B[0m), f1: 69.63% (\u001B[92m+\u001B[0m5.53) | 1e-06: acc: 61.88%, (\u001B[92m+\u001B[0m\u001B[92m8.15%\u001B[0m), f1: 60.17% (\u001B[92m+\u001B[0m6.51)  |\n",
      "|          | 5e-05: acc: 62.8%, (\u001B[92m+\u001B[0m\u001B[92m6.91%\u001B[0m), f1: 62.94% (\u001B[92m+\u001B[0m6.77)    | 5e-05: acc: 67.18%, (\u001B[92m+\u001B[0m\u001B[92m3.52%\u001B[0m), f1: 67.61% (\u001B[92m+\u001B[0m3.51) | 5e-05: acc: 63.73%, (\u001B[92m+\u001B[0m\u001B[92m10.0%\u001B[0m), f1: 63.18% (\u001B[92m+\u001B[0m9.52)  |\n",
      "+----------+----------------------------------------------------+--------------------------------------------------+---------------------------------------------------+\n",
      "| vit_l_16 | 1e-05: acc: 65.7%, (\u001B[92m+\u001B[0m\u001B[92m9.81%\u001B[0m), f1: 65.81% (\u001B[92m+\u001B[0m9.64)    | 1e-05: acc: 67.67%, (\u001B[92m+\u001B[0m\u001B[92m4.01%\u001B[0m), f1: 67.72% (\u001B[92m+\u001B[0m3.62) | 1e-05: acc: 61.51%, (\u001B[92m+\u001B[0m\u001B[92m7.78%\u001B[0m), f1: 59.87% (\u001B[92m+\u001B[0m6.21)  |\n",
      "|          | 1e-06: acc: 69.22%, (\u001B[92m+\u001B[0m\u001B[92m13.33%\u001B[0m), f1: 69.55% (\u001B[92m+\u001B[0m13.38) | 1e-06: acc: 68.66%, (\u001B[92m+\u001B[0m\u001B[92m5.0%\u001B[0m), f1: 68.81% (\u001B[92m+\u001B[0m4.71)  | 1e-06: acc: 64.84%, (\u001B[92m+\u001B[0m\u001B[92m11.11%\u001B[0m), f1: 63.61% (\u001B[92m+\u001B[0m9.95) |\n",
      "|          | 5e-05: acc: 65.64%, (\u001B[92m+\u001B[0m\u001B[92m9.75%\u001B[0m), f1: 66.07% (\u001B[92m+\u001B[0m9.9)    | 5e-05: acc: 67.24%, (\u001B[92m+\u001B[0m\u001B[92m3.58%\u001B[0m), f1: 67.55% (\u001B[92m+\u001B[0m3.45) | 5e-05: acc: 62.12%, (\u001B[92m+\u001B[0m\u001B[92m8.39%\u001B[0m), f1: 61.49% (\u001B[92m+\u001B[0m7.83)  |\n",
      "+----------+----------------------------------------------------+--------------------------------------------------+---------------------------------------------------+\n",
      "| vit_l_32 | 1e-05: acc: 58.91%, (\u001B[92m+\u001B[0m\u001B[92m3.02%\u001B[0m), f1: 59.36% (\u001B[92m+\u001B[0m3.19)   | 1e-05: acc: 63.73%, (\u001B[92m+\u001B[0m\u001B[92m0.07%\u001B[0m), f1: 64.04% (-0.06) | 1e-05: acc: 55.52%, (\u001B[92m+\u001B[0m\u001B[92m1.79%\u001B[0m), f1: 54.68% (\u001B[92m+\u001B[0m1.02)  |\n",
      "|          | 1e-06: acc: 63.17%, (\u001B[92m+\u001B[0m\u001B[92m7.28%\u001B[0m), f1: 63.11% (\u001B[92m+\u001B[0m6.94)   | 1e-06: acc: 65.89%, (\u001B[92m+\u001B[0m\u001B[92m2.23%\u001B[0m), f1: 66.09% (\u001B[92m+\u001B[0m1.99) | 1e-06: acc: 59.53%, (\u001B[92m+\u001B[0m\u001B[92m5.8%\u001B[0m), f1: 58.03% (\u001B[92m+\u001B[0m4.37)   |\n",
      "|          | 5e-05: acc: 59.72%, (\u001B[92m+\u001B[0m\u001B[92m3.83%\u001B[0m), f1: 59.48% (\u001B[92m+\u001B[0m3.31)   | 5e-05: acc: 64.16%, (\u001B[92m+\u001B[0m\u001B[92m0.5%\u001B[0m), f1: 64.13% (\u001B[92m+\u001B[0m0.03)  | 5e-05: acc: 56.94%, (\u001B[92m+\u001B[0m\u001B[92m3.21%\u001B[0m), f1: 55.78% (\u001B[92m+\u001B[0m2.12)  |\n",
      "+----------+----------------------------------------------------+--------------------------------------------------+---------------------------------------------------+\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Main model: Fine-grain vit_l_16, secondary granularity: coarse\n",
      "+----------+----------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "|          | 1e-05 (acc: 69.96%, f1: 70.44%)              | 1e-06 (acc: 70.27%, f1: 70.92%)                  | 5e-05 (acc: 66.19%, f1: 67.18%)                  |\n",
      "+==========+==============================================+==================================================+==================================================+\n",
      "| vit_b_16 | 1e-05: acc: 69.96%, (\u001B[91m0.0%\u001B[0m), f1: 70.44% (0.0) | 1e-05: acc: 70.27%, (\u001B[91m0.0%\u001B[0m), f1: 70.92% (0.0)     | 1e-05: acc: 65.02%, (\u001B[91m-1.17%\u001B[0m), f1: 66.25% (-0.93) |\n",
      "|          | 1e-06: acc: 69.96%, (\u001B[91m0.0%\u001B[0m), f1: 70.44% (0.0) | 1e-06: acc: 70.27%, (\u001B[91m0.0%\u001B[0m), f1: 70.92% (0.0)     | 1e-06: acc: 66.19%, (\u001B[91m0.0%\u001B[0m), f1: 67.18% (0.0)     |\n",
      "|          | 5e-05: acc: 69.96%, (\u001B[91m0.0%\u001B[0m), f1: 70.44% (0.0) | 5e-05: acc: 70.27%, (\u001B[91m0.0%\u001B[0m), f1: 70.92% (0.0)     | 5e-05: acc: 66.19%, (\u001B[91m0.0%\u001B[0m), f1: 67.18% (0.0)     |\n",
      "+----------+----------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "| vit_b_32 | 1e-05: acc: 69.96%, (\u001B[91m0.0%\u001B[0m), f1: 70.44% (0.0) | 1e-05: acc: 70.27%, (\u001B[91m0.0%\u001B[0m), f1: 70.92% (0.0)     | 1e-05: acc: 65.39%, (\u001B[91m-0.8%\u001B[0m), f1: 66.56% (-0.62)  |\n",
      "|          | 1e-06: acc: 69.96%, (\u001B[91m0.0%\u001B[0m), f1: 70.44% (0.0) | 1e-06: acc: 70.27%, (\u001B[91m0.0%\u001B[0m), f1: 70.92% (0.0)     | 1e-06: acc: 66.19%, (\u001B[91m0.0%\u001B[0m), f1: 67.18% (0.0)     |\n",
      "|          | 5e-05: acc: 69.96%, (\u001B[91m0.0%\u001B[0m), f1: 70.44% (0.0) | 5e-05: acc: 69.59%, (\u001B[91m-0.68%\u001B[0m), f1: 70.43% (-0.49) | 5e-05: acc: 65.64%, (\u001B[91m-0.55%\u001B[0m), f1: 66.74% (-0.44) |\n",
      "+----------+----------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "| vit_l_32 | 1e-05: acc: 69.96%, (\u001B[91m0.0%\u001B[0m), f1: 70.44% (0.0) | 1e-05: acc: 70.27%, (\u001B[91m0.0%\u001B[0m), f1: 70.92% (0.0)     | 1e-05: acc: 66.19%, (\u001B[91m0.0%\u001B[0m), f1: 67.18% (0.0)     |\n",
      "|          | 1e-06: acc: 69.96%, (\u001B[91m0.0%\u001B[0m), f1: 70.44% (0.0) | 1e-06: acc: 70.27%, (\u001B[91m0.0%\u001B[0m), f1: 70.92% (0.0)     | 1e-06: acc: 66.19%, (\u001B[91m0.0%\u001B[0m), f1: 67.18% (0.0)     |\n",
      "|          | 5e-05: acc: 69.96%, (\u001B[91m0.0%\u001B[0m), f1: 70.44% (0.0) | 5e-05: acc: 70.27%, (\u001B[91m0.0%\u001B[0m), f1: 70.92% (0.0)     | 5e-05: acc: 65.21%, (\u001B[91m-0.98%\u001B[0m), f1: 66.47% (-0.71) |\n",
      "+----------+----------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "\n",
      "\n",
      "Main model: Fine-grain vit_l_16, secondary granularity: fine\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "|          | 1e-05 (acc: 69.96%, f1: 70.44%)                  | 1e-06 (acc: 70.27%, f1: 70.92%)                  | 5e-05 (acc: 66.19%, f1: 67.18%)                  |\n",
      "+==========+==================================================+==================================================+==================================================+\n",
      "| vit_b_16 | 1e-05: acc: 70.02%, (\u001B[92m+\u001B[0m\u001B[92m0.06%\u001B[0m), f1: 70.49% (\u001B[92m+\u001B[0m0.05) | 1e-05: acc: 70.02%, (\u001B[91m-0.25%\u001B[0m), f1: 70.76% (-0.16) | 1e-05: acc: 66.5%, (\u001B[92m+\u001B[0m\u001B[92m0.31%\u001B[0m), f1: 67.49% (\u001B[92m+\u001B[0m0.31)  |\n",
      "|          | 1e-06: acc: 69.9%, (\u001B[91m-0.06%\u001B[0m), f1: 70.38% (-0.06)  | 1e-06: acc: 71.44%, (\u001B[92m+\u001B[0m\u001B[92m1.17%\u001B[0m), f1: 72.08% (\u001B[92m+\u001B[0m1.16) | 1e-06: acc: 67.12%, (\u001B[92m+\u001B[0m\u001B[92m0.93%\u001B[0m), f1: 67.94% (\u001B[92m+\u001B[0m0.76) |\n",
      "|          | 5e-05: acc: 70.14%, (\u001B[92m+\u001B[0m\u001B[92m0.18%\u001B[0m), f1: 70.62% (\u001B[92m+\u001B[0m0.18) | 5e-05: acc: 70.94%, (\u001B[92m+\u001B[0m\u001B[92m0.67%\u001B[0m), f1: 71.56% (\u001B[92m+\u001B[0m0.64) | 5e-05: acc: 67.18%, (\u001B[92m+\u001B[0m\u001B[92m0.99%\u001B[0m), f1: 68.07% (\u001B[92m+\u001B[0m0.89) |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "| vit_b_32 | 1e-05: acc: 69.96%, (\u001B[91m0.0%\u001B[0m), f1: 70.44% (0.0)     | 1e-05: acc: 70.27%, (\u001B[91m0.0%\u001B[0m), f1: 70.92% (0.0)     | 1e-05: acc: 65.64%, (\u001B[91m-0.55%\u001B[0m), f1: 66.66% (-0.52) |\n",
      "|          | 1e-06: acc: 70.02%, (\u001B[92m+\u001B[0m\u001B[92m0.06%\u001B[0m), f1: 70.44% (0.0)   | 1e-06: acc: 71.07%, (\u001B[92m+\u001B[0m\u001B[92m0.8%\u001B[0m), f1: 71.71% (\u001B[92m+\u001B[0m0.79)  | 1e-06: acc: 65.7%, (\u001B[91m-0.49%\u001B[0m), f1: 66.75% (-0.43)  |\n",
      "|          | 5e-05: acc: 69.83%, (\u001B[91m-0.13%\u001B[0m), f1: 70.28% (-0.16) | 5e-05: acc: 70.39%, (\u001B[92m+\u001B[0m\u001B[92m0.12%\u001B[0m), f1: 71.02% (\u001B[92m+\u001B[0m0.1)  | 5e-05: acc: 65.82%, (\u001B[91m-0.37%\u001B[0m), f1: 66.87% (-0.31) |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "| vit_l_32 | 1e-05: acc: 69.96%, (\u001B[91m0.0%\u001B[0m), f1: 70.45% (\u001B[92m+\u001B[0m0.01)   | 1e-05: acc: 71.19%, (\u001B[92m+\u001B[0m\u001B[92m0.92%\u001B[0m), f1: 71.81% (\u001B[92m+\u001B[0m0.89) | 1e-05: acc: 66.63%, (\u001B[92m+\u001B[0m\u001B[92m0.44%\u001B[0m), f1: 67.53% (\u001B[92m+\u001B[0m0.35) |\n",
      "|          | 1e-06: acc: 70.2%, (\u001B[92m+\u001B[0m\u001B[92m0.24%\u001B[0m), f1: 70.68% (\u001B[92m+\u001B[0m0.24)  | 1e-06: acc: 70.7%, (\u001B[92m+\u001B[0m\u001B[92m0.43%\u001B[0m), f1: 71.25% (\u001B[92m+\u001B[0m0.33)  | 1e-06: acc: 66.69%, (\u001B[92m+\u001B[0m\u001B[92m0.5%\u001B[0m), f1: 67.6% (\u001B[92m+\u001B[0m0.42)   |\n",
      "|          | 5e-05: acc: 69.71%, (\u001B[91m-0.25%\u001B[0m), f1: 70.15% (-0.29) | 5e-05: acc: 70.57%, (\u001B[92m+\u001B[0m\u001B[92m0.3%\u001B[0m), f1: 71.27% (\u001B[92m+\u001B[0m0.35)  | 5e-05: acc: 66.07%, (\u001B[91m-0.12%\u001B[0m), f1: 67.03% (-0.15) |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "\n",
      "\n",
      "Main model: Fine-grain vit_l_16 with both fine and coarse grain secondary models\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "|          | 1e-06 acc: (70.27%)                              | 1e-05 acc: (69.96%)                              | 5e-05 acc: (66.19%)                              |\n",
      "+==========+==================================================+==================================================+==================================================+\n",
      "| vit_b_16 | 1e-05: acc: 69.52%, (\u001B[91m-0.44%\u001B[0m), f1: 69.93% (-0.51) | 1e-05: acc: 69.28%, (\u001B[91m-0.99%\u001B[0m), f1: 70.03% (-0.89) | 1e-05: acc: 65.52%, (\u001B[91m-0.67%\u001B[0m), f1: 66.63% (-0.55) |\n",
      "|          | 1e-06: acc: 70.7%, (\u001B[92m+\u001B[0m\u001B[92m0.74%\u001B[0m), f1: 71.17% (\u001B[92m+\u001B[0m0.73)  | 1e-06: acc: 71.75%, (\u001B[92m+\u001B[0m\u001B[92m1.48%\u001B[0m), f1: 72.37% (\u001B[92m+\u001B[0m1.45) | 1e-06: acc: 68.04%, (\u001B[92m+\u001B[0m\u001B[92m1.85%\u001B[0m), f1: 68.73% (\u001B[92m+\u001B[0m1.55) |\n",
      "|          | 5e-05: acc: 70.27%, (\u001B[92m+\u001B[0m\u001B[92m0.31%\u001B[0m), f1: 70.74% (\u001B[92m+\u001B[0m0.3)  | 5e-05: acc: 70.82%, (\u001B[92m+\u001B[0m\u001B[92m0.55%\u001B[0m), f1: 71.4% (\u001B[92m+\u001B[0m0.48)  | 5e-05: acc: 67.18%, (\u001B[92m+\u001B[0m\u001B[92m0.99%\u001B[0m), f1: 67.94% (\u001B[92m+\u001B[0m0.76) |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "| vit_b_32 | 1e-05: acc: 69.96%, (\u001B[91m0.0%\u001B[0m), f1: 70.38% (-0.06)   | 1e-05: acc: 69.46%, (\u001B[91m-0.81%\u001B[0m), f1: 70.19% (-0.73) | 1e-05: acc: 64.84%, (\u001B[91m-1.35%\u001B[0m), f1: 65.72% (-1.46) |\n",
      "|          | 1e-06: acc: 69.83%, (\u001B[91m-0.13%\u001B[0m), f1: 70.28% (-0.16) | 1e-06: acc: 69.9%, (\u001B[91m-0.37%\u001B[0m), f1: 70.66% (-0.26)  | 1e-06: acc: 64.65%, (\u001B[91m-1.54%\u001B[0m), f1: 65.55% (-1.63) |\n",
      "|          | 5e-05: acc: 69.83%, (\u001B[91m-0.13%\u001B[0m), f1: 70.17% (-0.27) | 5e-05: acc: 69.59%, (\u001B[91m-0.68%\u001B[0m), f1: 70.41% (-0.51) | 5e-05: acc: 64.16%, (\u001B[91m-2.03%\u001B[0m), f1: 64.94% (-2.24) |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "| vit_l_32 | 1e-05: acc: 69.96%, (\u001B[91m0.0%\u001B[0m), f1: 70.46% (\u001B[92m+\u001B[0m0.02)   | 1e-05: acc: 70.7%, (\u001B[92m+\u001B[0m\u001B[92m0.43%\u001B[0m), f1: 71.38% (\u001B[92m+\u001B[0m0.46)  | 1e-05: acc: 65.14%, (\u001B[91m-1.05%\u001B[0m), f1: 66.24% (-0.94) |\n",
      "|          | 1e-06: acc: 69.77%, (\u001B[91m-0.19%\u001B[0m), f1: 70.37% (-0.07) | 1e-06: acc: 70.02%, (\u001B[91m-0.25%\u001B[0m), f1: 70.73% (-0.19) | 1e-06: acc: 65.89%, (\u001B[91m-0.3%\u001B[0m), f1: 66.83% (-0.35)  |\n",
      "|          | 5e-05: acc: 69.22%, (\u001B[91m-0.74%\u001B[0m), f1: 69.65% (-0.79) | 5e-05: acc: 70.2%, (\u001B[91m-0.07%\u001B[0m), f1: 70.9% (-0.02)   | 5e-05: acc: 63.66%, (\u001B[91m-2.53%\u001B[0m), f1: 64.86% (-2.32) |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Main model: Fine-grain vit_l_32, secondary granularity: coarse\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+----------------------------------------------+\n",
      "|          | 1e-05 (acc: 58.24%, f1: 58.34%)                  | 1e-06 (acc: 67.3%, f1: 67.79%)                   | 5e-05 (acc: 62.43%, f1: 62.04%)              |\n",
      "+==========+==================================================+==================================================+==============================================+\n",
      "| vit_b_16 | 1e-05: acc: 57.87%, (\u001B[91m-0.37%\u001B[0m), f1: 57.84% (-0.5)  | 1e-05: acc: 67.3%, (\u001B[91m0.0%\u001B[0m), f1: 67.79% (0.0)      | 1e-05: acc: 62.43%, (\u001B[91m0.0%\u001B[0m), f1: 62.04% (0.0) |\n",
      "|          | 1e-06: acc: 58.24%, (\u001B[91m0.0%\u001B[0m), f1: 58.34% (0.0)     | 1e-06: acc: 67.3%, (\u001B[91m0.0%\u001B[0m), f1: 67.79% (0.0)      | 1e-06: acc: 62.43%, (\u001B[91m0.0%\u001B[0m), f1: 62.04% (0.0) |\n",
      "|          | 5e-05: acc: 57.87%, (\u001B[91m-0.37%\u001B[0m), f1: 57.85% (-0.49) | 5e-05: acc: 67.3%, (\u001B[91m0.0%\u001B[0m), f1: 67.79% (0.0)      | 5e-05: acc: 62.43%, (\u001B[91m0.0%\u001B[0m), f1: 62.04% (0.0) |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+----------------------------------------------+\n",
      "| vit_b_32 | 1e-05: acc: 57.99%, (\u001B[91m-0.25%\u001B[0m), f1: 58.07% (-0.27) | 1e-05: acc: 67.3%, (\u001B[91m0.0%\u001B[0m), f1: 67.79% (0.0)      | 1e-05: acc: 62.43%, (\u001B[91m0.0%\u001B[0m), f1: 62.04% (0.0) |\n",
      "|          | 1e-06: acc: 58.24%, (\u001B[91m0.0%\u001B[0m), f1: 58.34% (0.0)     | 1e-06: acc: 67.3%, (\u001B[91m0.0%\u001B[0m), f1: 67.79% (0.0)      | 1e-06: acc: 62.43%, (\u001B[91m0.0%\u001B[0m), f1: 62.04% (0.0) |\n",
      "|          | 5e-05: acc: 58.24%, (\u001B[91m0.0%\u001B[0m), f1: 58.32% (-0.02)   | 5e-05: acc: 66.75%, (\u001B[91m-0.55%\u001B[0m), f1: 67.36% (-0.43) | 5e-05: acc: 62.43%, (\u001B[91m0.0%\u001B[0m), f1: 62.04% (0.0) |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+----------------------------------------------+\n",
      "| vit_l_16 | 1e-05: acc: 57.37%, (\u001B[91m-0.87%\u001B[0m), f1: 57.53% (-0.81) | 1e-05: acc: 67.3%, (\u001B[91m0.0%\u001B[0m), f1: 67.79% (0.0)      | 1e-05: acc: 62.43%, (\u001B[91m0.0%\u001B[0m), f1: 62.04% (0.0) |\n",
      "|          | 1e-06: acc: 58.24%, (\u001B[91m0.0%\u001B[0m), f1: 58.34% (0.0)     | 1e-06: acc: 67.3%, (\u001B[91m0.0%\u001B[0m), f1: 67.79% (0.0)      | 1e-06: acc: 62.43%, (\u001B[91m0.0%\u001B[0m), f1: 62.04% (0.0) |\n",
      "|          | 5e-05: acc: 57.74%, (\u001B[91m-0.5%\u001B[0m), f1: 57.7% (-0.64)   | 5e-05: acc: 67.3%, (\u001B[91m0.0%\u001B[0m), f1: 67.79% (0.0)      | 5e-05: acc: 62.43%, (\u001B[91m0.0%\u001B[0m), f1: 62.04% (0.0) |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+----------------------------------------------+\n",
      "\n",
      "\n",
      "Main model: Fine-grain vit_l_32, secondary granularity: fine\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "|          | 1e-05 (acc: 58.24%, f1: 58.34%)                  | 1e-06 (acc: 67.3%, f1: 67.79%)                   | 5e-05 (acc: 62.43%, f1: 62.04%)                  |\n",
      "+==========+==================================================+==================================================+==================================================+\n",
      "| vit_b_16 | 1e-05: acc: 58.48%, (\u001B[92m+\u001B[0m\u001B[92m0.24%\u001B[0m), f1: 58.51% (\u001B[92m+\u001B[0m0.17) | 1e-05: acc: 67.43%, (\u001B[92m+\u001B[0m\u001B[92m0.13%\u001B[0m), f1: 67.97% (\u001B[92m+\u001B[0m0.18) | 1e-05: acc: 62.74%, (\u001B[92m+\u001B[0m\u001B[92m0.31%\u001B[0m), f1: 62.36% (\u001B[92m+\u001B[0m0.32) |\n",
      "|          | 1e-06: acc: 61.07%, (\u001B[92m+\u001B[0m\u001B[92m2.83%\u001B[0m), f1: 61.12% (\u001B[92m+\u001B[0m2.78) | 1e-06: acc: 68.04%, (\u001B[92m+\u001B[0m\u001B[92m0.74%\u001B[0m), f1: 68.57% (\u001B[92m+\u001B[0m0.78) | 1e-06: acc: 65.02%, (\u001B[92m+\u001B[0m\u001B[92m2.59%\u001B[0m), f1: 64.93% (\u001B[92m+\u001B[0m2.89) |\n",
      "|          | 5e-05: acc: 60.15%, (\u001B[92m+\u001B[0m\u001B[92m1.91%\u001B[0m), f1: 60.28% (\u001B[92m+\u001B[0m1.94) | 5e-05: acc: 67.55%, (\u001B[92m+\u001B[0m\u001B[92m0.25%\u001B[0m), f1: 68.06% (\u001B[92m+\u001B[0m0.27) | 5e-05: acc: 63.91%, (\u001B[92m+\u001B[0m\u001B[92m1.48%\u001B[0m), f1: 63.74% (\u001B[92m+\u001B[0m1.7)  |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "| vit_b_32 | 1e-05: acc: 57.99%, (\u001B[91m-0.25%\u001B[0m), f1: 58.2% (-0.14)  | 1e-05: acc: 67.12%, (\u001B[91m-0.18%\u001B[0m), f1: 67.6% (-0.19)  | 1e-05: acc: 61.69%, (\u001B[91m-0.74%\u001B[0m), f1: 61.36% (-0.68) |\n",
      "|          | 1e-06: acc: 59.41%, (\u001B[92m+\u001B[0m\u001B[92m1.17%\u001B[0m), f1: 59.66% (\u001B[92m+\u001B[0m1.32) | 1e-06: acc: 67.12%, (\u001B[91m-0.18%\u001B[0m), f1: 67.54% (-0.25) | 1e-06: acc: 63.91%, (\u001B[92m+\u001B[0m\u001B[92m1.48%\u001B[0m), f1: 63.75% (\u001B[92m+\u001B[0m1.71) |\n",
      "|          | 5e-05: acc: 58.61%, (\u001B[92m+\u001B[0m\u001B[92m0.37%\u001B[0m), f1: 58.74% (\u001B[92m+\u001B[0m0.4)  | 5e-05: acc: 67.06%, (\u001B[91m-0.24%\u001B[0m), f1: 67.5% (-0.29)  | 5e-05: acc: 62.68%, (\u001B[92m+\u001B[0m\u001B[92m0.25%\u001B[0m), f1: 62.46% (\u001B[92m+\u001B[0m0.42) |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "| vit_l_16 | 1e-05: acc: 60.46%, (\u001B[92m+\u001B[0m\u001B[92m2.22%\u001B[0m), f1: 60.42% (\u001B[92m+\u001B[0m2.08) | 1e-05: acc: 67.8%, (\u001B[92m+\u001B[0m\u001B[92m0.5%\u001B[0m), f1: 68.16% (\u001B[92m+\u001B[0m0.37)   | 1e-05: acc: 63.6%, (\u001B[92m+\u001B[0m\u001B[92m1.17%\u001B[0m), f1: 63.24% (\u001B[92m+\u001B[0m1.2)   |\n",
      "|          | 1e-06: acc: 60.64%, (\u001B[92m+\u001B[0m\u001B[92m2.4%\u001B[0m), f1: 60.6% (\u001B[92m+\u001B[0m2.26)   | 1e-06: acc: 68.29%, (\u001B[92m+\u001B[0m\u001B[92m0.99%\u001B[0m), f1: 68.79% (\u001B[92m+\u001B[0m1.0)  | 1e-06: acc: 63.73%, (\u001B[92m+\u001B[0m\u001B[92m1.3%\u001B[0m), f1: 63.15% (\u001B[92m+\u001B[0m1.11)  |\n",
      "|          | 5e-05: acc: 61.07%, (\u001B[92m+\u001B[0m\u001B[92m2.83%\u001B[0m), f1: 61.16% (\u001B[92m+\u001B[0m2.82) | 5e-05: acc: 67.43%, (\u001B[92m+\u001B[0m\u001B[92m0.13%\u001B[0m), f1: 68.03% (\u001B[92m+\u001B[0m0.24) | 5e-05: acc: 64.28%, (\u001B[92m+\u001B[0m\u001B[92m1.85%\u001B[0m), f1: 64.23% (\u001B[92m+\u001B[0m2.19) |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "\n",
      "\n",
      "Main model: Fine-grain vit_l_32 with both fine and coarse grain secondary models\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "|          | 1e-06 acc: (67.3%)                               | 1e-05 acc: (58.24%)                              | 5e-05 acc: (62.43%)                              |\n",
      "+==========+==================================================+==================================================+==================================================+\n",
      "| vit_b_16 | 1e-05: acc: 58.61%, (\u001B[92m+\u001B[0m\u001B[92m0.37%\u001B[0m), f1: 57.96% (-0.38) | 1e-05: acc: 67.61%, (\u001B[92m+\u001B[0m\u001B[92m0.31%\u001B[0m), f1: 68.1% (\u001B[92m+\u001B[0m0.31)  | 1e-05: acc: 63.48%, (\u001B[92m+\u001B[0m\u001B[92m1.05%\u001B[0m), f1: 62.55% (\u001B[92m+\u001B[0m0.51) |\n",
      "|          | 1e-06: acc: 66.93%, (\u001B[92m+\u001B[0m\u001B[92m8.69%\u001B[0m), f1: 67.3% (\u001B[92m+\u001B[0m8.96)  | 1e-06: acc: 69.83%, (\u001B[92m+\u001B[0m\u001B[92m2.53%\u001B[0m), f1: 70.35% (\u001B[92m+\u001B[0m2.56) | 1e-06: acc: 67.98%, (\u001B[92m+\u001B[0m\u001B[92m5.55%\u001B[0m), f1: 67.73% (\u001B[92m+\u001B[0m5.69) |\n",
      "|          | 5e-05: acc: 64.34%, (\u001B[92m+\u001B[0m\u001B[92m6.1%\u001B[0m), f1: 64.06% (\u001B[92m+\u001B[0m5.72)  | 5e-05: acc: 67.92%, (\u001B[92m+\u001B[0m\u001B[92m0.62%\u001B[0m), f1: 68.49% (\u001B[92m+\u001B[0m0.7)  | 5e-05: acc: 63.66%, (\u001B[92m+\u001B[0m\u001B[92m1.23%\u001B[0m), f1: 63.44% (\u001B[92m+\u001B[0m1.4)  |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "| vit_b_32 | 1e-05: acc: 58.3%, (\u001B[92m+\u001B[0m\u001B[92m0.06%\u001B[0m), f1: 58.47% (\u001B[92m+\u001B[0m0.13)  | 1e-05: acc: 66.93%, (\u001B[91m-0.37%\u001B[0m), f1: 67.35% (-0.44) | 1e-05: acc: 61.57%, (\u001B[91m-0.86%\u001B[0m), f1: 61.0% (-1.04)  |\n",
      "|          | 1e-06: acc: 61.01%, (\u001B[92m+\u001B[0m\u001B[92m2.77%\u001B[0m), f1: 61.07% (\u001B[92m+\u001B[0m2.73) | 1e-06: acc: 67.18%, (\u001B[91m-0.12%\u001B[0m), f1: 67.64% (-0.15) | 1e-06: acc: 64.53%, (\u001B[92m+\u001B[0m\u001B[92m2.1%\u001B[0m), f1: 64.3% (\u001B[92m+\u001B[0m2.26)   |\n",
      "|          | 5e-05: acc: 58.91%, (\u001B[92m+\u001B[0m\u001B[92m0.67%\u001B[0m), f1: 58.76% (\u001B[92m+\u001B[0m0.42) | 5e-05: acc: 66.07%, (\u001B[91m-1.23%\u001B[0m), f1: 66.67% (-1.12) | 5e-05: acc: 62.0%, (\u001B[91m-0.43%\u001B[0m), f1: 61.66% (-0.38)  |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "| vit_l_16 | 1e-05: acc: 66.87%, (\u001B[92m+\u001B[0m\u001B[92m8.63%\u001B[0m), f1: 66.69% (\u001B[92m+\u001B[0m8.35) | 1e-05: acc: 69.77%, (\u001B[92m+\u001B[0m\u001B[92m2.47%\u001B[0m), f1: 70.17% (\u001B[92m+\u001B[0m2.38) | 1e-05: acc: 66.38%, (\u001B[92m+\u001B[0m\u001B[92m3.95%\u001B[0m), f1: 65.95% (\u001B[92m+\u001B[0m3.91) |\n",
      "|          | 1e-06: acc: 66.75%, (\u001B[92m+\u001B[0m\u001B[92m8.51%\u001B[0m), f1: 66.62% (\u001B[92m+\u001B[0m8.28) | 1e-06: acc: 71.07%, (\u001B[92m+\u001B[0m\u001B[92m3.77%\u001B[0m), f1: 71.43% (\u001B[92m+\u001B[0m3.64) | 1e-06: acc: 66.56%, (\u001B[92m+\u001B[0m\u001B[92m4.13%\u001B[0m), f1: 65.71% (\u001B[92m+\u001B[0m3.67) |\n",
      "|          | 5e-05: acc: 66.87%, (\u001B[92m+\u001B[0m\u001B[92m8.63%\u001B[0m), f1: 66.94% (\u001B[92m+\u001B[0m8.6)  | 5e-05: acc: 68.91%, (\u001B[92m+\u001B[0m\u001B[92m1.61%\u001B[0m), f1: 69.42% (\u001B[92m+\u001B[0m1.63) | 5e-05: acc: 65.7%, (\u001B[92m+\u001B[0m\u001B[92m3.27%\u001B[0m), f1: 65.44% (\u001B[92m+\u001B[0m3.4)   |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "\n",
      "\n",
      "####################################################################################################\n"
     ]
    }
   ],
   "source": [
    "def get_metrics(test_true: np.array, \n",
    "                prior_predictions: np.array, \n",
    "                post_predictions: np.array) -> dict:\n",
    "    return {prior_or_post: ({'acc': accuracy_score(y_true=test_true, \n",
    "                                                       y_pred=(prior_predictions \n",
    "                                                       if prior_or_post == 'prior' else post_predictions))} | \n",
    "                                {metric_name: metric_value(y_true=test_true, \n",
    "                                                           y_pred=(prior_predictions \n",
    "                                                                   if prior_or_post == 'prior' else post_predictions), \n",
    "                                                           average='weighted') \n",
    "                                 for metric_name, metric_value in {'pre': precision_score, 'rec': recall_score, 'f1': f1_score}.items()})\n",
    "                 for prior_or_post in ['prior', 'post']}\n",
    "\n",
    "\n",
    "def gather_EDCR_data() -> dict:\n",
    "    data = {} \n",
    "    \n",
    "    # Iterate through filenames to collect accuracy data\n",
    "    for filename in os.listdir(EDCR_pipeline.figs_folder):\n",
    "        secondary_granularity_match = re.match(\n",
    "            pattern='main_(fine|coarse)_(.+?)_lr(.+?)_secondary_(fine|coarse)_(.+?)_lr(.+)',\n",
    "            string=filename\n",
    "        )\n",
    "        \n",
    "        if secondary_granularity_match:\n",
    "            (   match,\n",
    "                main_granularity,\n",
    "                main_model_name,\n",
    "                main_lr,\n",
    "                secondary_granularity,\n",
    "                secondary_model_name,\n",
    "                secondary_lr\n",
    "            ) = (secondary_granularity_match.group(i) for i in range(7))\n",
    "            \n",
    "            main_suffix = '_coarse' if main_granularity == 'coarse' else ''\n",
    "            test_true = np.load(os.path.join(EDCR_pipeline.data_folder, f'test_true{main_suffix}.npy'))\n",
    "            \n",
    "            prior_predictions = np.load(os.path.join(EDCR_pipeline.data_folder, rf'{main_model_name}_test_pred_lr{main_lr}_e3{main_suffix}.npy'))\n",
    "            \n",
    "            \n",
    "            secondary_suffix = '_coarse' if secondary_granularity == 'coarse' else ''\n",
    "            post_predictions = np.load(f'figs/{match}/results{secondary_suffix}.npy')\n",
    "\n",
    "            # Store accuracy data in the data dictionary\n",
    "            if main_granularity not in data:\n",
    "                data[main_granularity] = {}\n",
    "            if main_model_name not in data[main_granularity]:\n",
    "                data[main_granularity][main_model_name] = {}\n",
    "            if secondary_granularity not in data[main_granularity][main_model_name]:\n",
    "                data[main_granularity][main_model_name][secondary_granularity] = {}\n",
    "            if secondary_model_name not in data[main_granularity][main_model_name][secondary_granularity]:\n",
    "                data[main_granularity][main_model_name][secondary_granularity][secondary_model_name] = {}\n",
    "            if main_lr not in data[main_granularity][main_model_name][secondary_granularity][secondary_model_name]:\n",
    "                data[main_granularity][main_model_name][secondary_granularity][secondary_model_name][main_lr] = {}\n",
    "                \n",
    "            data[main_granularity][main_model_name][secondary_granularity][secondary_model_name][main_lr][secondary_lr] = get_metrics(test_true=test_true,\n",
    "                                                                                                                                      prior_predictions=prior_predictions,\n",
    "                                                                                                                                      post_predictions=post_predictions)\n",
    "        else:\n",
    "            no_secondary_granularity_match = re.match(pattern='main_(fine|coarse)_(.+)_lr(.+)_secondary_(.+)_lr(.+)',\n",
    "                                                      string=filename)\n",
    "            \n",
    "            if no_secondary_granularity_match:\n",
    "                \n",
    "                (match,\n",
    "                 main_granularity,\n",
    "                 main_model_name,\n",
    "                 main_lr,\n",
    "                 secondary_model_name,\n",
    "                 secondary_lr \n",
    "                ) = (no_secondary_granularity_match.group(i) for i in range(6))\n",
    "                \n",
    "                main_suffix = '_coarse' if main_granularity == 'coarse' else ''\n",
    "                test_true = np.load(os.path.join(EDCR_pipeline.data_folder, f'test_true{main_suffix}.npy'))\n",
    "                \n",
    "                prior_predictions = np.load(os.path.join(EDCR_pipeline.data_folder, rf'{main_model_name}_test_pred_lr{main_lr}_e3{main_suffix}.npy'))\n",
    "                \n",
    "                try:\n",
    "                    post_predictions = np.load(f'figs/{match}/results.npy')\n",
    "                except FileNotFoundError:\n",
    "                    post_predictions = np.load(f'figs/{match}/results_coarse.npy')\n",
    "                    \n",
    "                if main_granularity not in data:\n",
    "                    data[main_granularity] = {}\n",
    "                if main_model_name not in data[main_granularity]:\n",
    "                    data[main_granularity][main_model_name] = {}\n",
    "                if secondary_model_name not in data[main_granularity][main_model_name]:\n",
    "                    data[main_granularity][main_model_name][secondary_model_name] = {}\n",
    "                if main_lr not in data[main_granularity][main_model_name][secondary_model_name]:\n",
    "                    data[main_granularity][main_model_name][secondary_model_name][main_lr] = {}\n",
    "                \n",
    "                data[main_granularity][main_model_name][secondary_model_name][main_lr][secondary_lr] = get_metrics(test_true=test_true,\n",
    "                                                                                                                   prior_predictions=prior_predictions,\n",
    "                                                                                                                   post_predictions=post_predictions)\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_row_addition(secondary_lr: float, \n",
    "                     curr_data: dict,\n",
    "                     max_accuracy: float = None) -> (str, float):\n",
    "    roundoff = 2\n",
    "    curr_prior_data = curr_data['prior']\n",
    "    curr_post_data = curr_data['post']\n",
    "    \n",
    "    curr_prior_accuracy = round(curr_prior_data['acc'] * 100, roundoff)\n",
    "    curr_post_accuracy = round(curr_post_data['acc'] * 100, roundoff)\n",
    "    curr_accuracy_diff = round(curr_post_accuracy - curr_prior_accuracy, roundoff)\n",
    "    \n",
    "    post_acc_str = (utils.blue_text(curr_post_accuracy) \n",
    "                    if max_accuracy is not None and abs(curr_post_accuracy - max_accuracy) < 1e-5 \n",
    "                    else str(curr_post_accuracy))\n",
    "    acc_diff_sign_str = (utils.green_text('+') if curr_accuracy_diff > 0 else '')\n",
    "    \n",
    "    \n",
    "    curr_prior_average_f1 = round(curr_prior_data['f1'] * 100, roundoff)\n",
    "    curr_post_average_f1 = round(curr_post_data['f1'] * 100, roundoff)\n",
    "    curr_average_f1_diff = round(curr_post_average_f1 - curr_prior_average_f1, roundoff)\n",
    "    average_f1_diff_sign_str = (utils.green_text('+') if curr_average_f1_diff > 0 else '')\n",
    "    \n",
    "    row_addition = (f\"{secondary_lr}: acc: {post_acc_str}%, ({acc_diff_sign_str}\"  + \n",
    "                    (utils.green_text(f'{curr_accuracy_diff}%') if curr_accuracy_diff > 0 \n",
    "                     else utils.red_text(f'{curr_accuracy_diff}%')) + f'), f1: {curr_post_average_f1}% ({average_f1_diff_sign_str}{curr_average_f1_diff})' + '\\n')\n",
    "    \n",
    "    return row_addition, curr_prior_accuracy, curr_prior_average_f1\n",
    "\n",
    "\n",
    "def get_row_data(main_lr_data: dict,\n",
    "                 secondary_lr: float) -> (str, float):\n",
    "    curr_data = main_lr_data[secondary_lr]\n",
    "    row_addition, curr_prior_acc, curr_prior_average_f1 = get_row_addition(secondary_lr=secondary_lr, \n",
    "                                                                                   curr_data=curr_data)\n",
    "    \n",
    "    return row_addition, curr_prior_acc, curr_prior_average_f1\n",
    "\n",
    "\n",
    "def print_one_secondary_granularity(main_model_data: dict,\n",
    "                                    k: str,\n",
    "                                    main_granularity: str,\n",
    "                                    main_model_name: str):\n",
    "\n",
    "    secondary_granularity_data = main_model_data[k]\n",
    "    main_learning_rates = sorted(secondary_granularity_data[list(secondary_granularity_data.keys())[0]].keys())\n",
    "    header = [''] + main_learning_rates\n",
    "    table_data = [header]\n",
    "    priors = {}\n",
    "\n",
    "    for secondary_model_name in sorted(secondary_granularity_data.keys()):\n",
    "        secondary_model_data = secondary_granularity_data[secondary_model_name]\n",
    "        row = [secondary_model_name]\n",
    "        \n",
    "        for main_lr in sorted(secondary_model_data.keys()):\n",
    "            main_lr_data = secondary_model_data[main_lr]\n",
    "            row_add = ''\n",
    "            \n",
    "            for secondary_lr in sorted(main_lr_data.keys()):\n",
    "                row_addition, curr_prior_acc, curr_prior_average_f1 = get_row_data(main_lr_data=main_lr_data,\n",
    "                                                                                      secondary_lr=secondary_lr)\n",
    "                row_add += row_addition\n",
    "                priors[main_lr] = {'acc': curr_prior_acc, 'f1': curr_prior_average_f1}\n",
    "                \n",
    "            row += [row_add]\n",
    "        table_data += [row]\n",
    "    \n",
    "    table_data[0] = [''] + [f\"{main_lr} (acc: {priors[main_lr]['acc']}%, f1: {priors[main_lr]['f1']}%)\" for main_lr in main_learning_rates]\n",
    "    \n",
    "    # Rest of your code to create and print the table remains unchanged\n",
    "    table = tabulate.tabulate(\n",
    "        tabular_data=table_data, \n",
    "        headers='firstrow', \n",
    "        tablefmt='grid'\n",
    "    )\n",
    "    print(f\"Main model: {main_granularity.capitalize()}-grain {main_model_name}, \"\n",
    "          f\"secondary granularity: {k}\")\n",
    "    print(table)\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "def print_two_secondary_granularities(main_model_data: dict,\n",
    "                                      two_secondary_table_data: list,\n",
    "                                      k: str,\n",
    "                                      main_granularity: str,\n",
    "                                      main_model_name: str):\n",
    "    main_learning_rates = sorted(vit_pipeline.lrs)\n",
    "    \n",
    "    priors = {}\n",
    "    \n",
    "    # Initialize the table_data with header if it's empty\n",
    "    if len(two_secondary_table_data) == 0:\n",
    "        header = [''] + main_learning_rates\n",
    "        two_secondary_table_data += [header]\n",
    "        \n",
    "    secondary_model_data = main_model_data[k]\n",
    "    row = [k]\n",
    "    \n",
    "    for main_lr in sorted(secondary_model_data.keys()):\n",
    "        main_lr_data = secondary_model_data[main_lr]\n",
    "        row_add = ''\n",
    "        \n",
    "        for secondary_lr in sorted(main_lr_data.keys()):\n",
    "            row_addition, curr_prior_acc, curr_prior_average_f1 = get_row_data(main_lr_data=main_lr_data,\n",
    "                                                    secondary_lr=secondary_lr)\n",
    "            row_add += row_addition\n",
    "            priors[main_lr] = {'acc': curr_prior_acc, 'f1': curr_prior_average_f1}\n",
    "    \n",
    "        row += [row_add]\n",
    "\n",
    "    two_secondary_table_data += [row]\n",
    "    \n",
    "    # Modify the generated table data to highlight the cell with the maximal accuracy in blue\n",
    "    \n",
    "    if len(two_secondary_table_data) == len(main_learning_rates) + 1:\n",
    "        \n",
    "        two_secondary_table_data[0] = [''] + [f\"{main_lr} acc: ({priors[str(main_lr)]['acc']}%)\" for main_lr in main_learning_rates]\n",
    "        \n",
    "        # Create the table using tabulate\n",
    "        table = tabulate.tabulate(\n",
    "            tabular_data=two_secondary_table_data,\n",
    "            headers='firstrow',\n",
    "            tablefmt='grid'\n",
    "        )\n",
    "        \n",
    "        # Print the main model name and the corresponding table\n",
    "        print(f\"Main model: {main_granularity.capitalize()}-grain {main_model_name} \"\n",
    "              f\"with both fine and coarse grain secondary models\")\n",
    "        print(table)\n",
    "        print(\"\\n\")\n",
    "    else:\n",
    "        return two_secondary_table_data\n",
    "\n",
    "\n",
    "def print_EDCR_tables():\n",
    "    data = gather_EDCR_data()\n",
    "    \n",
    "    for main_granularity in sorted(data.keys()):\n",
    "        \n",
    "        print('#' * 40 + f' Main granularity: {main_granularity} ' + '#' * 40 + '\\n' + '#' * 104 + '\\n')\n",
    "        main_granularity_data = data[main_granularity]\n",
    "        \n",
    "        for main_model_name in sorted(main_granularity_data.keys()):\n",
    "            main_model_data = main_granularity_data[main_model_name]\n",
    "            two_secondary_table_data = []\n",
    "\n",
    "            for k in (sorted(set(main_model_data.keys()).intersection(data_preprocessing.granularities.values())) + \n",
    "                      sorted(set(main_model_data.keys()).intersection(vit_pipeline.vit_model_names))):\n",
    "            \n",
    "                if k in data_preprocessing.granularities.values():\n",
    "                    print_one_secondary_granularity(main_model_data=main_model_data,\n",
    "                        k=k,\n",
    "                        main_granularity=main_granularity,\n",
    "                        main_model_name=main_model_name)\n",
    "                else:\n",
    "                    two_secondary_table_data = print_two_secondary_granularities(main_model_data=main_model_data,\n",
    "                                                      two_secondary_table_data=two_secondary_table_data,\n",
    "                                                      k=k,\n",
    "                                                      main_granularity=main_granularity,\n",
    "                                                      main_model_name=main_model_name)\n",
    "            print('#' * 100)\n",
    "\n",
    "print_EDCR_tables()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T20:40:56.615097Z",
     "start_time": "2023-11-12T20:40:53.119371Z"
    }
   },
   "id": "3f6e34912281d5e"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process SpawnPoolWorker-11:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'm' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-12:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'm' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-13:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'm' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-14:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'm' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-15:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'm' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-16:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'm' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-17:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'm' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-18:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'm' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-19:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'm' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-20:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'm' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-21:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'm' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-22:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'm' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-23:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'm' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-24:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'm' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-25:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'm' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-26:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'm' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-27:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'm' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-28:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'm' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-29:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'm' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-30:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'm' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-31:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'm' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-32:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'm' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-33:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'm' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-34:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'm' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-35:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'm' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-36:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'm' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-39:\n",
      "Process SpawnPoolWorker-45:\n",
      "Process SpawnPoolWorker-42:\n",
      "Process SpawnPoolWorker-46:\n",
      "Process SpawnPoolWorker-43:\n",
      "Process SpawnPoolWorker-44:\n",
      "Process SpawnPoolWorker-40:\n",
      "Process SpawnPoolWorker-38:\n",
      "Process SpawnPoolWorker-41:\n",
      "Process SpawnPoolWorker-37:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/queues.py\", line 365, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/connection.py\", line 221, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/connection.py\", line 419, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/connection.py\", line 384, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 71\u001B[0m\n\u001B[1;32m     65\u001B[0m         pool\u001B[38;5;241m.\u001B[39mmap(m, args_list)\n\u001B[1;32m     66\u001B[0m         \u001B[38;5;66;03m# for fine_data in fine_test_loader:\u001B[39;00m\n\u001B[0;32m---> 71\u001B[0m \u001B[43mget_datasets_correspondence\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcoarse_results\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbest_coarse_results\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfine_results\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbest_fine_results\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[6], line 65\u001B[0m, in \u001B[0;36mget_datasets_correspondence\u001B[0;34m(coarse_results, fine_results)\u001B[0m\n\u001B[1;32m     61\u001B[0m args_list \u001B[38;5;241m=\u001B[39m [(fine_data, coarse_test_loader)\n\u001B[1;32m     62\u001B[0m              \u001B[38;5;28;01mfor\u001B[39;00m fine_data \u001B[38;5;129;01min\u001B[39;00m fine_test_loader]\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m mp\u001B[38;5;241m.\u001B[39mPool(processes\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m pool:\n\u001B[0;32m---> 65\u001B[0m     \u001B[43mpool\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap\u001B[49m\u001B[43m(\u001B[49m\u001B[43mm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs_list\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/pool.py:364\u001B[0m, in \u001B[0;36mPool.map\u001B[0;34m(self, func, iterable, chunksize)\u001B[0m\n\u001B[1;32m    359\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmap\u001B[39m(\u001B[38;5;28mself\u001B[39m, func, iterable, chunksize\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    360\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m'''\u001B[39;00m\n\u001B[1;32m    361\u001B[0m \u001B[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001B[39;00m\n\u001B[1;32m    362\u001B[0m \u001B[38;5;124;03m    in a list that is returned.\u001B[39;00m\n\u001B[1;32m    363\u001B[0m \u001B[38;5;124;03m    '''\u001B[39;00m\n\u001B[0;32m--> 364\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_map_async\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43miterable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapstar\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mchunksize\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/pool.py:765\u001B[0m, in \u001B[0;36mApplyResult.get\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    764\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget\u001B[39m(\u001B[38;5;28mself\u001B[39m, timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m--> 765\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    766\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mready():\n\u001B[1;32m    767\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTimeoutError\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/pool.py:762\u001B[0m, in \u001B[0;36mApplyResult.wait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    761\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwait\u001B[39m(\u001B[38;5;28mself\u001B[39m, timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m--> 762\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_event\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/threading.py:581\u001B[0m, in \u001B[0;36mEvent.wait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    579\u001B[0m signaled \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_flag\n\u001B[1;32m    580\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m signaled:\n\u001B[0;32m--> 581\u001B[0m     signaled \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_cond\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    582\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m signaled\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/threading.py:312\u001B[0m, in \u001B[0;36mCondition.wait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    310\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:    \u001B[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001B[39;00m\n\u001B[1;32m    311\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 312\u001B[0m         \u001B[43mwaiter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    313\u001B[0m         gotit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    314\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "best_coarse_main_model = 'vit_b_16'\n",
    "best_coarse_main_lr = '5e-05'\n",
    "best_coarse_secondary_model = 'vit_l_16'\n",
    "best_coarse_secondary_lr = '1e-05'\n",
    "best_coarse_folder = f'main_coarse_{best_coarse_main_model}_lr{best_coarse_main_lr}_secondary_{best_coarse_secondary_model}_lr{best_coarse_secondary_lr}'\n",
    "best_coarse_results = np.load(rf'{EDCR_pipeline.figs_folder}{best_coarse_folder}/results.npy')\n",
    "coarse_test_true = np.load(os.path.join(EDCR_pipeline.data_folder, f'test_true_coarse.npy'))\n",
    "\n",
    "best_fine_main_model = 'vit_l_16'\n",
    "best_fine_main_lr = '1e-06'\n",
    "best_fine_secondary_model = 'vit_b_16'\n",
    "best_fine_secondary_lr = '1e-06'\n",
    "best_fine_folder = f'main_fine_{best_fine_main_model}_lr{best_fine_main_lr}_secondary_{best_fine_secondary_model}_lr{best_fine_secondary_lr}'\n",
    "best_fine_results = np.load(rf'{EDCR_pipeline.figs_folder}{best_fine_folder}/results.npy')\n",
    "fine_test_true = np.load(os.path.join(EDCR_pipeline.data_folder, f'test_true.npy'))\n",
    "\n",
    "from models import  VITFineTuner\n",
    "from data_preprocessing import get_datasets, get_loaders, granularities\n",
    "from vit_pipeline import cwd, batch_size\n",
    "\n",
    "def m(fine_data, coarse_test_loader):\n",
    "    fine_images, fine_labels, fine_names = fine_data[0], fine_data[1], fine_data[2]\n",
    "        \n",
    "    for fine_image in fine_images:\n",
    "        print(fine_image)\n",
    "        for coarse_data in coarse_test_loader:\n",
    "            coarse_images, coarse_labels, coarse_names = coarse_data[0], coarse_data[1], coarse_data[2]\n",
    "            for coarse_image in coarse_images:\n",
    "                if torch.all(coarse_image == fine_image):\n",
    "                    print('hi')\n",
    "                        \n",
    "def get_datasets_correspondence(coarse_results: np.array, fine_results: np.array):\n",
    "    fine_tuners = {}\n",
    "    loaders = {}\n",
    "    \n",
    "    for granularity in granularities.values():\n",
    "        train_folder_name = f'train_{granularity}'\n",
    "        test_folder_name = f'test_{granularity}'\n",
    "        vit_model_names = [best_coarse_main_model]\n",
    "        datasets, n = get_datasets(model_names=vit_model_names,\n",
    "                                   cwd=cwd,\n",
    "                                   train_folder_name=train_folder_name,\n",
    "                                   test_folder_name=test_folder_name)\n",
    "        granularity_fine_tuners = [VITFineTuner(model_name, vit_model_names, n) for model_name in vit_model_names]\n",
    "        granularity_loaders = get_loaders(datasets=datasets,\n",
    "                              batch_size=batch_size,\n",
    "                              model_names=vit_model_names,\n",
    "                              train_folder_name=train_folder_name,\n",
    "                              test_folder_name=test_folder_name)\n",
    "        \n",
    "        fine_tuners[granularity] = granularity_fine_tuners\n",
    "        loaders[granularity] = granularity_loaders\n",
    "    \n",
    "    fine_fine_tuner = fine_tuners['fine'][0]\n",
    "    coarse_fine_tuner = fine_tuners['coarse'][0]\n",
    "    \n",
    "    fine_test_loader = loaders['fine'][f'{fine_fine_tuner}_test_fine']\n",
    "    coarse_test_loader = loaders['coarse'][f'{coarse_fine_tuner}_test_coarse']\n",
    "    \n",
    "    \n",
    "    args_list = [(fine_data, coarse_test_loader)\n",
    "                 for fine_data in fine_test_loader]\n",
    "    \n",
    "    with mp.Pool(processes=10) as pool:\n",
    "        pool.map(m, args_list)\n",
    "        # for fine_data in fine_test_loader:\n",
    "            \n",
    "          \n",
    "get_datasets_correspondence(coarse_results=best_coarse_results, fine_results=best_fine_results)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T22:13:11.044902Z",
     "start_time": "2023-11-12T22:12:55.455343Z"
    }
   },
   "id": "622654c282461efe"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fine_to_coarse = {}\n",
    "training_df = EDCR_pipeline.dataframes_by_sheet['Training']\n",
    "\n",
    "assert set(training_df['Fine-Grain Ground Truth'].unique().tolist()).intersection(EDCR_pipeline.fine_grain_classes) == set(EDCR_pipeline.fine_grain_classes)\n",
    "\n",
    "for fine_grain_class in EDCR_pipeline.fine_grain_classes:\n",
    "    curr_fine_grain_training_data = training_df[training_df['Fine-Grain Ground Truth'] == fine_grain_class]\n",
    "    assert curr_fine_grain_training_data['Course-Grain Ground Truth'].nunique() == 1\n",
    "    fine_to_coarse[fine_grain_class] = curr_fine_grain_training_data['Course-Grain Ground Truth'].iloc[0]\n",
    "\n",
    "\n",
    "def get_num_of_inconsistencies(coarse_results, \n",
    "                               fine_results):\n",
    "    num_of_inconsistencies = 0\n",
    "    for coarse_prediction_index, fine_prediction_index in zip(coarse_results, fine_results):\n",
    "        fine_prediction = EDCR_pipeline.fine_grain_classes[fine_prediction_index]\n",
    "        coarse_prediction = EDCR_pipeline.coarse_grain_classes[coarse_prediction_index]\n",
    "        if fine_to_coarse[fine_prediction] != coarse_prediction:\n",
    "            num_of_inconsistencies += 1\n",
    "    \n",
    "    return num_of_inconsistencies\n",
    "    \n",
    "get_num_of_inconsistencies(coarse_results=coarse_test_true,\n",
    "                           fine_results=fine_test_true)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bdb3d6545a77e534"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Dictionary: [None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "file_path = 'res.json'\n",
    "with open(file_path, 'r') as json_file:\n",
    "    loaded_dict = json.load(json_file)\n",
    "\n",
    "# Print the loaded dictionary\n",
    "print('Loaded Dictionary:', loaded_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T22:46:38.073962Z",
     "start_time": "2023-11-12T22:46:38.070636Z"
    }
   },
   "id": "c0081c8fbb6f49ee"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "{'2S19_MSTA': 'Self Propelled Artillery',\n '30N6E': 'Air Defense',\n 'BM-30': 'Self Propelled Artillery',\n 'BMD': 'BMD',\n 'BMP-1': 'BMP',\n 'BMP-2': 'BMP',\n 'BMP-T15': 'BMP',\n 'BRDM': 'BTR',\n 'BTR-60': 'BTR',\n 'BTR-70': 'BTR',\n 'BTR-80': 'BTR',\n 'D-30': 'Self Propelled Artillery',\n 'Iskander': 'Air Defense',\n 'MT_LB': 'MT_LB',\n 'Pantsir-S1': 'Air Defense',\n 'Rs-24': 'Air Defense',\n 'T-14': 'Tank',\n 'T-62': 'Tank',\n 'T-64': 'Tank',\n 'T-72': 'Tank',\n 'T-80': 'Tank',\n 'T-90': 'Tank',\n 'Tornado': 'Self Propelled Artillery',\n 'TOS-1': 'Self Propelled Artillery'}"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from EDCR_pipeline import fine_to_coarse\n",
    "fine_to_coarse"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T02:15:22.547763Z",
     "start_time": "2023-11-13T02:15:19.110598Z"
    }
   },
   "id": "60411385fd98e4e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e513314a85b69eef"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
