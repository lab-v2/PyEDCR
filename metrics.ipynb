{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score\n",
    "import tabulate\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import data_preprocessing\n",
    "import EDCR_pipeline\n",
    "import vit_pipeline\n",
    "import utils"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T01:23:04.951214Z",
     "start_time": "2023-11-12T01:23:04.941625Z"
    }
   },
   "id": "9dc68a5fe4ce4ea7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# EDCR Results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff5d015e77a12310"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################## Main granularity: coarse ########################################\n",
      "########################################################################################################\n",
      "\n",
      "Main model: Coarse-grain vit_b_16, secondary granularity: coarse\n",
      "+----------+----------------------------------------+-----------------------------------------+----------------------------------------+\n",
      "|          | 1e-05 (acc: 80.9%, pre: 82.2%)         | 1e-06 (acc: 65.6%, pre: 59.5%)          | 5e-05 (acc: 83.7%, pre: 84.2%)         |\n",
      "+==========+========================================+=========================================+========================================+\n",
      "| vit_b_32 | 1e-05: acc: 81.0%, (\u001B[92m+\u001B[0m\u001B[92m0.1%\u001B[0m), pre: 82.3% | 1e-05: acc: 73.0%, (\u001B[92m+\u001B[0m\u001B[92m7.4%\u001B[0m), pre: 65.9%  | 1e-05: acc: 82.4%, (\u001B[91m-1.3%\u001B[0m), pre: 83.3% |\n",
      "|          | 1e-06: acc: 80.9%, (\u001B[91m0.0%\u001B[0m), pre: 82.2%  | 1e-06: acc: 65.3%, (\u001B[91m-0.3%\u001B[0m), pre: 59.6%  | 1e-06: acc: 83.7%, (\u001B[91m0.0%\u001B[0m), pre: 84.2%  |\n",
      "|          | 5e-05: acc: 81.2%, (\u001B[92m+\u001B[0m\u001B[92m0.3%\u001B[0m), pre: 82.8% | 5e-05: acc: 72.5%, (\u001B[92m+\u001B[0m\u001B[92m6.9%\u001B[0m), pre: 66.4%  | 5e-05: acc: 83.7%, (\u001B[91m0.0%\u001B[0m), pre: 84.2%  |\n",
      "+----------+----------------------------------------+-----------------------------------------+----------------------------------------+\n",
      "| vit_l_16 | 1e-05: acc: 83.0%, (\u001B[92m+\u001B[0m\u001B[92m2.1%\u001B[0m), pre: 84.2% | 1e-05: acc: 76.8%, (\u001B[92m+\u001B[0m\u001B[92m11.2%\u001B[0m), pre: 70.0% | 1e-05: acc: 83.8%, (\u001B[92m+\u001B[0m\u001B[92m0.1%\u001B[0m), pre: 84.4% |\n",
      "|          | 1e-06: acc: 78.8%, (\u001B[91m-2.1%\u001B[0m), pre: 81.4% | 1e-06: acc: 71.2%, (\u001B[92m+\u001B[0m\u001B[92m5.6%\u001B[0m), pre: 64.5%  | 1e-06: acc: 83.7%, (\u001B[91m0.0%\u001B[0m), pre: 84.2%  |\n",
      "|          | 5e-05: acc: 82.0%, (\u001B[92m+\u001B[0m\u001B[92m1.1%\u001B[0m), pre: 83.9% | 5e-05: acc: 76.1%, (\u001B[92m+\u001B[0m\u001B[92m10.5%\u001B[0m), pre: 68.8% | 5e-05: acc: 84.2%, (\u001B[92m+\u001B[0m\u001B[92m0.5%\u001B[0m), pre: 84.8% |\n",
      "+----------+----------------------------------------+-----------------------------------------+----------------------------------------+\n",
      "| vit_l_32 | 1e-05: acc: 80.8%, (\u001B[91m-0.1%\u001B[0m), pre: 82.7% | 1e-05: acc: 74.2%, (\u001B[92m+\u001B[0m\u001B[92m8.6%\u001B[0m), pre: 67.8%  | 1e-05: acc: 83.0%, (\u001B[91m-0.7%\u001B[0m), pre: 83.7% |\n",
      "|          | 1e-06: acc: 80.9%, (\u001B[91m0.0%\u001B[0m), pre: 82.2%  | 1e-06: acc: 66.1%, (\u001B[92m+\u001B[0m\u001B[92m0.5%\u001B[0m), pre: 60.2%  | 1e-06: acc: 83.7%, (\u001B[91m0.0%\u001B[0m), pre: 84.2%  |\n",
      "|          | 5e-05: acc: 81.4%, (\u001B[92m+\u001B[0m\u001B[92m0.5%\u001B[0m), pre: 83.6% | 5e-05: acc: 75.9%, (\u001B[92m+\u001B[0m\u001B[92m10.3%\u001B[0m), pre: 69.0% | 5e-05: acc: 83.5%, (\u001B[91m-0.2%\u001B[0m), pre: 84.2% |\n",
      "+----------+----------------------------------------+-----------------------------------------+----------------------------------------+\n",
      "\n",
      "\n",
      "Main model: Coarse-grain vit_b_16, secondary granularity: fine\n",
      "+----------+----------------------------------------+----------------------------------------+----------------------------------------+\n",
      "|          | 1e-05 (acc: 80.9%, pre: 82.2%)         | 1e-06 (acc: 65.6%, pre: 59.5%)         | 5e-05 (acc: 83.7%, pre: 84.2%)         |\n",
      "+==========+========================================+========================================+========================================+\n",
      "| vit_b_32 | 1e-05: acc: 78.0%, (\u001B[91m-2.9%\u001B[0m), pre: 81.3% | 1e-05: acc: 69.3%, (\u001B[92m+\u001B[0m\u001B[92m3.7%\u001B[0m), pre: 64.2% | 1e-05: acc: 83.0%, (\u001B[91m-0.7%\u001B[0m), pre: 83.9% |\n",
      "|          | 1e-06: acc: 79.2%, (\u001B[91m-1.7%\u001B[0m), pre: 82.9% | 1e-06: acc: 71.0%, (\u001B[92m+\u001B[0m\u001B[92m5.4%\u001B[0m), pre: 65.7% | 1e-06: acc: 83.0%, (\u001B[91m-0.7%\u001B[0m), pre: 84.2% |\n",
      "|          | 5e-05: acc: 79.5%, (\u001B[91m-1.4%\u001B[0m), pre: 82.2% | 5e-05: acc: 68.6%, (\u001B[92m+\u001B[0m\u001B[92m3.0%\u001B[0m), pre: 63.0% | 5e-05: acc: 83.8%, (\u001B[92m+\u001B[0m\u001B[92m0.1%\u001B[0m), pre: 84.7% |\n",
      "+----------+----------------------------------------+----------------------------------------+----------------------------------------+\n",
      "| vit_l_16 | 1e-05: acc: 80.8%, (\u001B[91m-0.1%\u001B[0m), pre: 83.7% | 1e-05: acc: 72.4%, (\u001B[92m+\u001B[0m\u001B[92m6.8%\u001B[0m), pre: 65.9% | 1e-05: acc: 84.5%, (\u001B[92m+\u001B[0m\u001B[92m0.8%\u001B[0m), pre: 85.6% |\n",
      "|          | 1e-06: acc: 79.5%, (\u001B[91m-1.4%\u001B[0m), pre: 82.8% | 1e-06: acc: 73.2%, (\u001B[92m+\u001B[0m\u001B[92m7.6%\u001B[0m), pre: 66.7% | 1e-06: acc: 82.7%, (\u001B[91m-1.0%\u001B[0m), pre: 84.2% |\n",
      "|          | 5e-05: acc: 81.2%, (\u001B[92m+\u001B[0m\u001B[92m0.3%\u001B[0m), pre: 83.5% | 5e-05: acc: 72.3%, (\u001B[92m+\u001B[0m\u001B[92m6.7%\u001B[0m), pre: 66.7% | 5e-05: acc: 84.4%, (\u001B[92m+\u001B[0m\u001B[92m0.7%\u001B[0m), pre: 85.2% |\n",
      "+----------+----------------------------------------+----------------------------------------+----------------------------------------+\n",
      "| vit_l_32 | 1e-05: acc: 81.6%, (\u001B[92m+\u001B[0m\u001B[92m0.7%\u001B[0m), pre: 83.4% | 1e-05: acc: 68.7%, (\u001B[92m+\u001B[0m\u001B[92m3.1%\u001B[0m), pre: 62.6% | 1e-05: acc: 83.5%, (\u001B[91m-0.2%\u001B[0m), pre: 84.4% |\n",
      "|          | 1e-06: acc: 80.6%, (\u001B[91m-0.3%\u001B[0m), pre: 84.1% | 1e-06: acc: 71.7%, (\u001B[92m+\u001B[0m\u001B[92m6.1%\u001B[0m), pre: 65.8% | 1e-06: acc: 83.0%, (\u001B[91m-0.7%\u001B[0m), pre: 83.9% |\n",
      "|          | 5e-05: acc: 79.3%, (\u001B[91m-1.6%\u001B[0m), pre: 82.6% | 5e-05: acc: 70.6%, (\u001B[92m+\u001B[0m\u001B[92m5.0%\u001B[0m), pre: 65.4% | 5e-05: acc: 82.5%, (\u001B[91m-1.2%\u001B[0m), pre: 83.7% |\n",
      "+----------+----------------------------------------+----------------------------------------+----------------------------------------+\n",
      "\n",
      "\n",
      "Main model: Coarse-grain vit_b_16 with both fine and coarse grain secondary models\n",
      "+----------+----------------------------------------+----------------------------------------+----------------------------------------+\n",
      "|          | 1e-06 (65.6%)                          | 1e-05 (80.9%)                          | 5e-05 (83.7%)                          |\n",
      "+==========+========================================+========================================+========================================+\n",
      "| vit_b_32 | 1e-05: acc: 78.0%, (\u001B[91m-2.9%\u001B[0m), pre: 81.3% | 1e-05: acc: 70.1%, (\u001B[92m+\u001B[0m\u001B[92m4.5%\u001B[0m), pre: 63.7% | 1e-05: acc: 82.4%, (\u001B[91m-1.3%\u001B[0m), pre: 83.4% |\n",
      "|          | 1e-06: acc: 79.2%, (\u001B[91m-1.7%\u001B[0m), pre: 82.9% | 1e-06: acc: 69.3%, (\u001B[92m+\u001B[0m\u001B[92m3.7%\u001B[0m), pre: 65.0% | 1e-06: acc: 83.0%, (\u001B[91m-0.7%\u001B[0m), pre: 84.2% |\n",
      "|          | 5e-05: acc: 79.7%, (\u001B[91m-1.2%\u001B[0m), pre: 82.3% | 5e-05: acc: 70.6%, (\u001B[92m+\u001B[0m\u001B[92m5.0%\u001B[0m), pre: 64.1% | 5e-05: acc: 83.8%, (\u001B[92m+\u001B[0m\u001B[92m0.1%\u001B[0m), pre: 84.6% |\n",
      "+----------+----------------------------------------+----------------------------------------+----------------------------------------+\n",
      "| vit_l_16 | 1e-05: acc: 81.1%, (\u001B[92m+\u001B[0m\u001B[92m0.2%\u001B[0m), pre: 83.5% | 1e-05: acc: 69.2%, (\u001B[92m+\u001B[0m\u001B[92m3.6%\u001B[0m), pre: 63.8% | 1e-05: acc: 85.3%, (\u001B[92m+\u001B[0m\u001B[92m1.6%\u001B[0m), pre: 86.2% |\n",
      "|          | 1e-06: acc: 79.8%, (\u001B[91m-1.1%\u001B[0m), pre: 82.5% | 1e-06: acc: 69.4%, (\u001B[92m+\u001B[0m\u001B[92m3.8%\u001B[0m), pre: 64.0% | 1e-06: acc: 82.7%, (\u001B[91m-1.0%\u001B[0m), pre: 84.2% |\n",
      "|          | 5e-05: acc: 81.6%, (\u001B[92m+\u001B[0m\u001B[92m0.7%\u001B[0m), pre: 83.4% | 5e-05: acc: 74.0%, (\u001B[92m+\u001B[0m\u001B[92m8.4%\u001B[0m), pre: 66.8% | 5e-05: acc: 84.5%, (\u001B[92m+\u001B[0m\u001B[92m0.8%\u001B[0m), pre: 84.9% |\n",
      "+----------+----------------------------------------+----------------------------------------+----------------------------------------+\n",
      "| vit_l_32 | 1e-05: acc: 81.8%, (\u001B[92m+\u001B[0m\u001B[92m0.9%\u001B[0m), pre: 83.6% | 1e-05: acc: 70.8%, (\u001B[92m+\u001B[0m\u001B[92m5.2%\u001B[0m), pre: 66.1% | 1e-05: acc: 83.4%, (\u001B[91m-0.3%\u001B[0m), pre: 84.2% |\n",
      "|          | 1e-06: acc: 80.6%, (\u001B[91m-0.3%\u001B[0m), pre: 84.1% | 1e-06: acc: 71.7%, (\u001B[92m+\u001B[0m\u001B[92m6.1%\u001B[0m), pre: 65.8% | 1e-06: acc: 83.0%, (\u001B[91m-0.7%\u001B[0m), pre: 83.9% |\n",
      "|          | 5e-05: acc: 80.6%, (\u001B[91m-0.3%\u001B[0m), pre: 82.7% | 5e-05: acc: 74.0%, (\u001B[92m+\u001B[0m\u001B[92m8.4%\u001B[0m), pre: 67.1% | 5e-05: acc: 83.2%, (\u001B[91m-0.5%\u001B[0m), pre: 84.2% |\n",
      "+----------+----------------------------------------+----------------------------------------+----------------------------------------+\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Main model: Coarse-grain vit_b_32, secondary granularity: coarse\n",
      "+----------+----------------------------------------+-----------------------------------------+----------------------------------------+\n",
      "|          | 1e-05 (acc: 77.1%, pre: 78.2%)         | 1e-06 (acc: 63.0%, pre: 58.0%)          | 5e-05 (acc: 76.0%, pre: 77.6%)         |\n",
      "+==========+========================================+=========================================+========================================+\n",
      "| vit_b_16 | 1e-05: acc: 79.6%, (\u001B[92m+\u001B[0m\u001B[92m2.5%\u001B[0m), pre: 80.7% | 1e-05: acc: 74.3%, (\u001B[92m+\u001B[0m\u001B[92m11.3%\u001B[0m), pre: 67.4% | 1e-05: acc: 78.7%, (\u001B[92m+\u001B[0m\u001B[92m2.7%\u001B[0m), pre: 79.6% |\n",
      "|          | 1e-06: acc: 77.1%, (\u001B[91m0.0%\u001B[0m), pre: 78.2%  | 1e-06: acc: 64.2%, (\u001B[92m+\u001B[0m\u001B[92m1.2%\u001B[0m), pre: 59.7%  | 1e-06: acc: 75.3%, (\u001B[91m-0.7%\u001B[0m), pre: 77.7% |\n",
      "|          | 5e-05: acc: 82.2%, (\u001B[92m+\u001B[0m\u001B[92m5.1%\u001B[0m), pre: 83.4% | 5e-05: acc: 76.3%, (\u001B[92m+\u001B[0m\u001B[92m13.3%\u001B[0m), pre: 69.4% | 5e-05: acc: 82.0%, (\u001B[92m+\u001B[0m\u001B[92m6.0%\u001B[0m), pre: 83.0% |\n",
      "+----------+----------------------------------------+-----------------------------------------+----------------------------------------+\n",
      "| vit_l_16 | 1e-05: acc: 82.4%, (\u001B[92m+\u001B[0m\u001B[92m5.3%\u001B[0m), pre: 83.0% | 1e-05: acc: 76.7%, (\u001B[92m+\u001B[0m\u001B[92m13.7%\u001B[0m), pre: 69.7% | 1e-05: acc: 80.7%, (\u001B[92m+\u001B[0m\u001B[92m4.7%\u001B[0m), pre: 81.9% |\n",
      "|          | 1e-06: acc: 76.2%, (\u001B[91m-0.9%\u001B[0m), pre: 78.4% | 1e-06: acc: 71.4%, (\u001B[92m+\u001B[0m\u001B[92m8.4%\u001B[0m), pre: 64.6%  | 1e-06: acc: 75.6%, (\u001B[91m-0.4%\u001B[0m), pre: 77.9% |\n",
      "|          | 5e-05: acc: 81.6%, (\u001B[92m+\u001B[0m\u001B[92m4.5%\u001B[0m), pre: 83.7% | 5e-05: acc: 75.9%, (\u001B[92m+\u001B[0m\u001B[92m12.9%\u001B[0m), pre: 68.6% | 5e-05: acc: 79.4%, (\u001B[92m+\u001B[0m\u001B[92m3.4%\u001B[0m), pre: 80.7% |\n",
      "+----------+----------------------------------------+-----------------------------------------+----------------------------------------+\n",
      "| vit_l_32 | 1e-05: acc: 77.7%, (\u001B[92m+\u001B[0m\u001B[92m0.6%\u001B[0m), pre: 79.0% | 1e-05: acc: 72.4%, (\u001B[92m+\u001B[0m\u001B[92m9.4%\u001B[0m), pre: 66.8%  | 1e-05: acc: 77.5%, (\u001B[92m+\u001B[0m\u001B[92m1.5%\u001B[0m), pre: 79.4% |\n",
      "|          | 1e-06: acc: 77.1%, (\u001B[91m0.0%\u001B[0m), pre: 78.2%  | 1e-06: acc: 63.6%, (\u001B[92m+\u001B[0m\u001B[92m0.6%\u001B[0m), pre: 57.9%  | 1e-06: acc: 74.3%, (\u001B[91m-1.7%\u001B[0m), pre: 77.4% |\n",
      "|          | 5e-05: acc: 81.3%, (\u001B[92m+\u001B[0m\u001B[92m4.2%\u001B[0m), pre: 82.1% | 5e-05: acc: 75.0%, (\u001B[92m+\u001B[0m\u001B[92m12.0%\u001B[0m), pre: 68.4% | 5e-05: acc: 78.8%, (\u001B[92m+\u001B[0m\u001B[92m2.8%\u001B[0m), pre: 80.0% |\n",
      "+----------+----------------------------------------+-----------------------------------------+----------------------------------------+\n",
      "\n",
      "\n",
      "Main model: Coarse-grain vit_b_32, secondary granularity: fine\n",
      "+----------+----------------------------------------+----------------------------------------+----------------------------------------+\n",
      "|          | 1e-05 (acc: 77.1%, pre: 78.2%)         | 1e-06 (acc: 63.0%, pre: 58.0%)         | 5e-05 (acc: 76.0%, pre: 77.6%)         |\n",
      "+==========+========================================+========================================+========================================+\n",
      "| vit_b_16 | 1e-05: acc: 77.9%, (\u001B[92m+\u001B[0m\u001B[92m0.8%\u001B[0m), pre: 78.9% | 1e-05: acc: 69.8%, (\u001B[92m+\u001B[0m\u001B[92m6.8%\u001B[0m), pre: 64.9% | 1e-05: acc: 76.8%, (\u001B[92m+\u001B[0m\u001B[92m0.8%\u001B[0m), pre: 79.5% |\n",
      "|          | 1e-06: acc: 77.7%, (\u001B[92m+\u001B[0m\u001B[92m0.6%\u001B[0m), pre: 79.7% | 1e-06: acc: 72.7%, (\u001B[92m+\u001B[0m\u001B[92m9.7%\u001B[0m), pre: 66.3% | 1e-06: acc: 78.5%, (\u001B[92m+\u001B[0m\u001B[92m2.5%\u001B[0m), pre: 80.8% |\n",
      "|          | 5e-05: acc: 78.7%, (\u001B[92m+\u001B[0m\u001B[92m1.6%\u001B[0m), pre: 80.9% | 5e-05: acc: 70.9%, (\u001B[92m+\u001B[0m\u001B[92m7.9%\u001B[0m), pre: 65.0% | 5e-05: acc: 78.1%, (\u001B[92m+\u001B[0m\u001B[92m2.1%\u001B[0m), pre: 80.5% |\n",
      "+----------+----------------------------------------+----------------------------------------+----------------------------------------+\n",
      "| vit_l_16 | 1e-05: acc: 78.6%, (\u001B[92m+\u001B[0m\u001B[92m1.5%\u001B[0m), pre: 80.5% | 1e-05: acc: 70.6%, (\u001B[92m+\u001B[0m\u001B[92m7.6%\u001B[0m), pre: 64.7% | 1e-05: acc: 78.5%, (\u001B[92m+\u001B[0m\u001B[92m2.5%\u001B[0m), pre: 80.8% |\n",
      "|          | 1e-06: acc: 78.6%, (\u001B[92m+\u001B[0m\u001B[92m1.5%\u001B[0m), pre: 80.5% | 1e-06: acc: 70.0%, (\u001B[92m+\u001B[0m\u001B[92m7.0%\u001B[0m), pre: 65.7% | 1e-06: acc: 77.9%, (\u001B[92m+\u001B[0m\u001B[92m1.9%\u001B[0m), pre: 80.1% |\n",
      "|          | 5e-05: acc: 78.7%, (\u001B[92m+\u001B[0m\u001B[92m1.6%\u001B[0m), pre: 80.7% | 5e-05: acc: 70.7%, (\u001B[92m+\u001B[0m\u001B[92m7.7%\u001B[0m), pre: 65.5% | 5e-05: acc: 78.6%, (\u001B[92m+\u001B[0m\u001B[92m2.6%\u001B[0m), pre: 80.9% |\n",
      "+----------+----------------------------------------+----------------------------------------+----------------------------------------+\n",
      "| vit_l_32 | 1e-05: acc: 78.1%, (\u001B[92m+\u001B[0m\u001B[92m1.0%\u001B[0m), pre: 79.3% | 1e-05: acc: 68.2%, (\u001B[92m+\u001B[0m\u001B[92m5.2%\u001B[0m), pre: 62.8% | 1e-05: acc: 75.4%, (\u001B[91m-0.6%\u001B[0m), pre: 78.4% |\n",
      "|          | 1e-06: acc: 77.2%, (\u001B[92m+\u001B[0m\u001B[92m0.1%\u001B[0m), pre: 79.8% | 1e-06: acc: 70.4%, (\u001B[92m+\u001B[0m\u001B[92m7.4%\u001B[0m), pre: 64.7% | 1e-06: acc: 76.6%, (\u001B[92m+\u001B[0m\u001B[92m0.6%\u001B[0m), pre: 79.2% |\n",
      "|          | 5e-05: acc: 76.4%, (\u001B[91m-0.7%\u001B[0m), pre: 78.6% | 5e-05: acc: 69.4%, (\u001B[92m+\u001B[0m\u001B[92m6.4%\u001B[0m), pre: 64.4% | 5e-05: acc: 75.3%, (\u001B[91m-0.7%\u001B[0m), pre: 78.2% |\n",
      "+----------+----------------------------------------+----------------------------------------+----------------------------------------+\n",
      "\n",
      "\n",
      "Main model: Coarse-grain vit_b_32 with both fine and coarse grain secondary models\n",
      "+----------+----------------------------------------+-----------------------------------------+----------------------------------------+\n",
      "|          | 1e-06 (63.0%)                          | 1e-05 (77.1%)                           | 5e-05 (76.0%)                          |\n",
      "+==========+========================================+=========================================+========================================+\n",
      "| vit_b_16 | 1e-05: acc: 79.5%, (\u001B[92m+\u001B[0m\u001B[92m2.4%\u001B[0m), pre: 80.7% | 1e-05: acc: 70.3%, (\u001B[92m+\u001B[0m\u001B[92m7.3%\u001B[0m), pre: 64.3%  | 1e-05: acc: 78.6%, (\u001B[92m+\u001B[0m\u001B[92m2.6%\u001B[0m), pre: 79.8% |\n",
      "|          | 1e-06: acc: 77.7%, (\u001B[92m+\u001B[0m\u001B[92m0.6%\u001B[0m), pre: 79.7% | 1e-06: acc: 65.9%, (\u001B[92m+\u001B[0m\u001B[92m2.9%\u001B[0m), pre: 63.1%  | 1e-06: acc: 77.5%, (\u001B[92m+\u001B[0m\u001B[92m1.5%\u001B[0m), pre: 79.7% |\n",
      "|          | 5e-05: acc: 83.4%, (\u001B[92m+\u001B[0m\u001B[92m6.3%\u001B[0m), pre: 84.9% | 5e-05: acc: 75.8%, (\u001B[92m+\u001B[0m\u001B[92m12.8%\u001B[0m), pre: 69.1% | 5e-05: acc: 81.9%, (\u001B[92m+\u001B[0m\u001B[92m5.9%\u001B[0m), pre: 82.7% |\n",
      "+----------+----------------------------------------+-----------------------------------------+----------------------------------------+\n",
      "| vit_l_16 | 1e-05: acc: 81.4%, (\u001B[92m+\u001B[0m\u001B[92m4.3%\u001B[0m), pre: 82.3% | 1e-05: acc: 68.2%, (\u001B[92m+\u001B[0m\u001B[92m5.2%\u001B[0m), pre: 63.4%  | 1e-05: acc: 79.0%, (\u001B[92m+\u001B[0m\u001B[92m3.0%\u001B[0m), pre: 80.6% |\n",
      "|          | 1e-06: acc: 78.6%, (\u001B[92m+\u001B[0m\u001B[92m1.5%\u001B[0m), pre: 80.1% | 1e-06: acc: 68.7%, (\u001B[92m+\u001B[0m\u001B[92m5.7%\u001B[0m), pre: 63.3%  | 1e-06: acc: 77.4%, (\u001B[92m+\u001B[0m\u001B[92m1.4%\u001B[0m), pre: 79.4% |\n",
      "|          | 5e-05: acc: 81.6%, (\u001B[92m+\u001B[0m\u001B[92m4.5%\u001B[0m), pre: 83.5% | 5e-05: acc: 70.6%, (\u001B[92m+\u001B[0m\u001B[92m7.6%\u001B[0m), pre: 65.4%  | 5e-05: acc: 81.9%, (\u001B[92m+\u001B[0m\u001B[92m5.9%\u001B[0m), pre: 82.9% |\n",
      "+----------+----------------------------------------+-----------------------------------------+----------------------------------------+\n",
      "| vit_l_32 | 1e-05: acc: 78.1%, (\u001B[92m+\u001B[0m\u001B[92m1.0%\u001B[0m), pre: 79.8% | 1e-05: acc: 69.3%, (\u001B[92m+\u001B[0m\u001B[92m6.3%\u001B[0m), pre: 62.7%  | 1e-05: acc: 76.7%, (\u001B[92m+\u001B[0m\u001B[92m0.7%\u001B[0m), pre: 78.7% |\n",
      "|          | 1e-06: acc: 77.2%, (\u001B[92m+\u001B[0m\u001B[92m0.1%\u001B[0m), pre: 79.8% | 1e-06: acc: 69.9%, (\u001B[92m+\u001B[0m\u001B[92m6.9%\u001B[0m), pre: 65.2%  | 1e-06: acc: 76.3%, (\u001B[92m+\u001B[0m\u001B[92m0.3%\u001B[0m), pre: 79.0% |\n",
      "|          | 5e-05: acc: 81.2%, (\u001B[92m+\u001B[0m\u001B[92m4.1%\u001B[0m), pre: 81.6% | 5e-05: acc: 73.5%, (\u001B[92m+\u001B[0m\u001B[92m10.5%\u001B[0m), pre: 66.8% | 5e-05: acc: 77.7%, (\u001B[92m+\u001B[0m\u001B[92m1.7%\u001B[0m), pre: 79.8% |\n",
      "+----------+----------------------------------------+-----------------------------------------+----------------------------------------+\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Main model: Coarse-grain vit_l_16, secondary granularity: coarse\n",
      "+----------+----------------------------------------+\n",
      "|          | 1e-05 (acc: 84.3%, pre: 84.6%)         |\n",
      "+==========+========================================+\n",
      "| vit_b_16 | 1e-05: acc: 83.8%, (\u001B[91m-0.5%\u001B[0m), pre: 84.1% |\n",
      "|          | 1e-06: acc: 84.3%, (\u001B[91m0.0%\u001B[0m), pre: 84.6%  |\n",
      "|          | 5e-05: acc: 84.3%, (\u001B[91m0.0%\u001B[0m), pre: 85.0%  |\n",
      "+----------+----------------------------------------+\n",
      "| vit_b_32 | 1e-05: acc: 83.7%, (\u001B[91m-0.6%\u001B[0m), pre: 84.1% |\n",
      "|          | 1e-06: acc: 84.3%, (\u001B[91m0.0%\u001B[0m), pre: 84.6%  |\n",
      "|          | 5e-05: acc: 84.2%, (\u001B[91m-0.1%\u001B[0m), pre: 84.5% |\n",
      "+----------+----------------------------------------+\n",
      "| vit_l_32 | 1e-05: acc: 83.6%, (\u001B[91m-0.7%\u001B[0m), pre: 83.9% |\n",
      "|          | 1e-06: acc: 84.3%, (\u001B[91m0.0%\u001B[0m), pre: 84.6%  |\n",
      "|          | 5e-05: acc: 84.6%, (\u001B[92m+\u001B[0m\u001B[92m0.3%\u001B[0m), pre: 85.0% |\n",
      "+----------+----------------------------------------+\n",
      "\n",
      "\n",
      "Main model: Coarse-grain vit_l_16, secondary granularity: fine\n",
      "+----------+----------------------------------------+----------------------------------------+----------------------------------------+\n",
      "|          | 1e-05 (acc: 84.3%, pre: 84.6%)         | 1e-06 (acc: 74.0%, pre: 74.3%)         | 5e-05 (acc: 83.7%, pre: 84.3%)         |\n",
      "+==========+========================================+========================================+========================================+\n",
      "| vit_b_16 | 1e-05: acc: 84.1%, (\u001B[91m-0.2%\u001B[0m), pre: 85.3% | 1e-05: acc: 76.0%, (\u001B[92m+\u001B[0m\u001B[92m2.0%\u001B[0m), pre: 77.0% | 1e-05: acc: 83.5%, (\u001B[91m-0.2%\u001B[0m), pre: 84.3% |\n",
      "|          | 1e-06: acc: 84.4%, (\u001B[92m+\u001B[0m\u001B[92m0.1%\u001B[0m), pre: 85.5% | 1e-06: acc: 77.5%, (\u001B[92m+\u001B[0m\u001B[92m3.5%\u001B[0m), pre: 79.1% | 1e-06: acc: 83.8%, (\u001B[92m+\u001B[0m\u001B[92m0.1%\u001B[0m), pre: 84.6% |\n",
      "|          | 5e-05: acc: 85.4%, (\u001B[92m+\u001B[0m\u001B[92m1.1%\u001B[0m), pre: 86.0% | 5e-05: acc: 76.5%, (\u001B[92m+\u001B[0m\u001B[92m2.5%\u001B[0m), pre: 77.3% | 5e-05: acc: 84.7%, (\u001B[92m+\u001B[0m\u001B[92m1.0%\u001B[0m), pre: 85.8% |\n",
      "+----------+----------------------------------------+----------------------------------------+----------------------------------------+\n",
      "| vit_b_32 | 1e-05: acc: 83.6%, (\u001B[91m-0.7%\u001B[0m), pre: 84.5% | 1e-05: acc: 74.2%, (\u001B[92m+\u001B[0m\u001B[92m0.2%\u001B[0m), pre: 75.2% | 1e-05: acc: 83.2%, (\u001B[91m-0.5%\u001B[0m), pre: 84.0% |\n",
      "|          | 1e-06: acc: 84.6%, (\u001B[92m+\u001B[0m\u001B[92m0.3%\u001B[0m), pre: 85.8% | 1e-06: acc: 75.8%, (\u001B[92m+\u001B[0m\u001B[92m1.8%\u001B[0m), pre: 77.9% | 1e-06: acc: 84.0%, (\u001B[92m+\u001B[0m\u001B[92m0.3%\u001B[0m), pre: 84.6% |\n",
      "|          | 5e-05: acc: 84.5%, (\u001B[92m+\u001B[0m\u001B[92m0.2%\u001B[0m), pre: 85.2% | 5e-05: acc: 75.1%, (\u001B[92m+\u001B[0m\u001B[92m1.1%\u001B[0m), pre: 76.4% | 5e-05: acc: 83.7%, (\u001B[91m0.0%\u001B[0m), pre: 84.5%  |\n",
      "+----------+----------------------------------------+----------------------------------------+----------------------------------------+\n",
      "| vit_l_32 | 1e-05: acc: 84.9%, (\u001B[92m+\u001B[0m\u001B[92m0.6%\u001B[0m), pre: 85.5% | 1e-05: acc: 75.2%, (\u001B[92m+\u001B[0m\u001B[92m1.2%\u001B[0m), pre: 75.7% | 1e-05: acc: 83.9%, (\u001B[92m+\u001B[0m\u001B[92m0.2%\u001B[0m), pre: 84.9% |\n",
      "|          | 1e-06: acc: 84.3%, (\u001B[91m0.0%\u001B[0m), pre: 85.3%  | 1e-06: acc: 76.7%, (\u001B[92m+\u001B[0m\u001B[92m2.7%\u001B[0m), pre: 78.4% | 1e-06: acc: 83.5%, (\u001B[91m-0.2%\u001B[0m), pre: 84.5% |\n",
      "|          | 5e-05: acc: 84.1%, (\u001B[91m-0.2%\u001B[0m), pre: 84.7% | 5e-05: acc: 74.6%, (\u001B[92m+\u001B[0m\u001B[92m0.6%\u001B[0m), pre: 76.8% | 5e-05: acc: 82.2%, (\u001B[91m-1.5%\u001B[0m), pre: 83.4% |\n",
      "+----------+----------------------------------------+----------------------------------------+----------------------------------------+\n",
      "\n",
      "\n",
      "Main model: Coarse-grain vit_l_16 with both fine and coarse grain secondary models\n",
      "+----------+----------------------------------------+----------------------------------------+----------------------------------------+\n",
      "|          | 1e-06 (74.0%)                          | 1e-05 (84.3%)                          | 5e-05 (83.7%)                          |\n",
      "+==========+========================================+========================================+========================================+\n",
      "| vit_b_16 | 1e-05: acc: 84.1%, (\u001B[91m-0.2%\u001B[0m), pre: 84.6% | 1e-05: acc: 78.1%, (\u001B[92m+\u001B[0m\u001B[92m4.1%\u001B[0m), pre: 79.0% | 1e-05: acc: 83.4%, (\u001B[91m-0.3%\u001B[0m), pre: 84.3% |\n",
      "|          | 1e-06: acc: 84.4%, (\u001B[92m+\u001B[0m\u001B[92m0.1%\u001B[0m), pre: 85.5% | 1e-06: acc: 77.5%, (\u001B[92m+\u001B[0m\u001B[92m3.5%\u001B[0m), pre: 79.1% | 1e-06: acc: 83.8%, (\u001B[92m+\u001B[0m\u001B[92m0.1%\u001B[0m), pre: 84.6% |\n",
      "|          | 5e-05: acc: 84.9%, (\u001B[92m+\u001B[0m\u001B[92m0.6%\u001B[0m), pre: 85.5% | 5e-05: acc: 83.8%, (\u001B[92m+\u001B[0m\u001B[92m9.8%\u001B[0m), pre: 84.1% | 5e-05: acc: 85.4%, (\u001B[92m+\u001B[0m\u001B[92m1.7%\u001B[0m), pre: 86.5% |\n",
      "+----------+----------------------------------------+----------------------------------------+----------------------------------------+\n",
      "| vit_b_32 | 1e-05: acc: 83.3%, (\u001B[91m-1.0%\u001B[0m), pre: 84.2% | 1e-05: acc: 76.8%, (\u001B[92m+\u001B[0m\u001B[92m2.8%\u001B[0m), pre: 77.2% | 1e-05: acc: 82.7%, (\u001B[91m-1.0%\u001B[0m), pre: 83.5% |\n",
      "|          | 1e-06: acc: 84.6%, (\u001B[92m+\u001B[0m\u001B[92m0.3%\u001B[0m), pre: 85.8% | 1e-06: acc: 75.8%, (\u001B[92m+\u001B[0m\u001B[92m1.8%\u001B[0m), pre: 77.9% | 1e-06: acc: 84.0%, (\u001B[92m+\u001B[0m\u001B[92m0.3%\u001B[0m), pre: 84.6% |\n",
      "|          | 5e-05: acc: 84.5%, (\u001B[92m+\u001B[0m\u001B[92m0.2%\u001B[0m), pre: 85.2% | 5e-05: acc: 76.4%, (\u001B[92m+\u001B[0m\u001B[92m2.4%\u001B[0m), pre: 78.2% | 5e-05: acc: 83.3%, (\u001B[91m-0.4%\u001B[0m), pre: 84.2% |\n",
      "+----------+----------------------------------------+----------------------------------------+----------------------------------------+\n",
      "| vit_l_32 | 1e-05: acc: 84.1%, (\u001B[91m-0.2%\u001B[0m), pre: 84.7% | 1e-05: acc: 76.7%, (\u001B[92m+\u001B[0m\u001B[92m2.7%\u001B[0m), pre: 78.6% | 1e-05: acc: 84.5%, (\u001B[92m+\u001B[0m\u001B[92m0.8%\u001B[0m), pre: 85.3% |\n",
      "|          | 1e-06: acc: 84.3%, (\u001B[91m0.0%\u001B[0m), pre: 85.3%  | 1e-06: acc: 75.9%, (\u001B[92m+\u001B[0m\u001B[92m1.9%\u001B[0m), pre: 77.9% | 1e-06: acc: 83.5%, (\u001B[91m-0.2%\u001B[0m), pre: 84.5% |\n",
      "|          | 5e-05: acc: 84.9%, (\u001B[92m+\u001B[0m\u001B[92m0.6%\u001B[0m), pre: 85.3% | 5e-05: acc: 78.3%, (\u001B[92m+\u001B[0m\u001B[92m4.3%\u001B[0m), pre: 79.4% | 5e-05: acc: 83.5%, (\u001B[91m-0.2%\u001B[0m), pre: 84.5% |\n",
      "+----------+----------------------------------------+----------------------------------------+----------------------------------------+\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Main model: Coarse-grain vit_l_32, secondary granularity: coarse\n",
      "+----------+----------------------------------------+-----------------------------------------+\n",
      "|          | 1e-05 (acc: 79.2%, pre: 80.1%)         | 1e-06 (acc: 59.5%, pre: 55.3%)          |\n",
      "+==========+========================================+=========================================+\n",
      "| vit_b_16 | 1e-05: acc: 80.4%, (\u001B[92m+\u001B[0m\u001B[92m1.2%\u001B[0m), pre: 81.2% | 1e-06: acc: 63.2%, (\u001B[92m+\u001B[0m\u001B[92m3.7%\u001B[0m), pre: 58.0%  |\n",
      "|          | 1e-06: acc: 79.2%, (\u001B[91m0.0%\u001B[0m), pre: 80.1%  | 5e-05: acc: 76.2%, (\u001B[92m+\u001B[0m\u001B[92m16.7%\u001B[0m), pre: 69.4% |\n",
      "|          | 5e-05: acc: 79.8%, (\u001B[92m+\u001B[0m\u001B[92m0.6%\u001B[0m), pre: 81.6% |                                         |\n",
      "+----------+----------------------------------------+-----------------------------------------+\n",
      "| vit_b_32 | 1e-05: acc: 78.9%, (\u001B[91m-0.3%\u001B[0m), pre: 80.1% | 1e-05: acc: 72.8%, (\u001B[92m+\u001B[0m\u001B[92m13.3%\u001B[0m), pre: 65.9% |\n",
      "|          | 1e-06: acc: 77.6%, (\u001B[91m-1.6%\u001B[0m), pre: 78.8% | 5e-05: acc: 70.6%, (\u001B[92m+\u001B[0m\u001B[92m11.1%\u001B[0m), pre: 64.2% |\n",
      "|          | 5e-05: acc: 79.1%, (\u001B[91m-0.1%\u001B[0m), pre: 80.3% |                                         |\n",
      "+----------+----------------------------------------+-----------------------------------------+\n",
      "| vit_l_16 | 1e-05: acc: 80.5%, (\u001B[92m+\u001B[0m\u001B[92m1.3%\u001B[0m), pre: 82.4% | 1e-05: acc: 76.7%, (\u001B[92m+\u001B[0m\u001B[92m17.2%\u001B[0m), pre: 69.1% |\n",
      "|          | 1e-06: acc: 78.3%, (\u001B[91m-0.9%\u001B[0m), pre: 79.5% | 1e-06: acc: 68.1%, (\u001B[92m+\u001B[0m\u001B[92m8.6%\u001B[0m), pre: 61.7%  |\n",
      "|          | 5e-05: acc: 82.7%, (\u001B[92m+\u001B[0m\u001B[92m3.5%\u001B[0m), pre: 84.2% | 5e-05: acc: 75.9%, (\u001B[92m+\u001B[0m\u001B[92m16.4%\u001B[0m), pre: 68.5% |\n",
      "+----------+----------------------------------------+-----------------------------------------+\n",
      "\n",
      "\n",
      "Main model: Coarse-grain vit_l_32, secondary granularity: fine\n",
      "+----------+----------------------------------------+-----------------------------------------+----------------------------------------+\n",
      "|          | 1e-05 (acc: 79.2%, pre: 80.1%)         | 1e-06 (acc: 59.5%, pre: 55.3%)          | 5e-05 (acc: 80.8%, pre: 82.9%)         |\n",
      "+==========+========================================+=========================================+========================================+\n",
      "| vit_b_16 | 1e-05: acc: 79.8%, (\u001B[92m+\u001B[0m\u001B[92m0.6%\u001B[0m), pre: 81.4% | 1e-05: acc: 68.9%, (\u001B[92m+\u001B[0m\u001B[92m9.4%\u001B[0m), pre: 64.2%  | 1e-05: acc: 78.7%, (\u001B[91m-2.1%\u001B[0m), pre: 82.5% |\n",
      "|          | 1e-06: acc: 80.0%, (\u001B[92m+\u001B[0m\u001B[92m0.8%\u001B[0m), pre: 82.2% | 1e-06: acc: 71.5%, (\u001B[92m+\u001B[0m\u001B[92m12.0%\u001B[0m), pre: 65.2% | 1e-06: acc: 80.1%, (\u001B[91m-0.7%\u001B[0m), pre: 83.2% |\n",
      "|          | 5e-05: acc: 80.3%, (\u001B[92m+\u001B[0m\u001B[92m1.1%\u001B[0m), pre: 82.0% | 5e-05: acc: 68.9%, (\u001B[92m+\u001B[0m\u001B[92m9.4%\u001B[0m), pre: 64.1%  | 5e-05: acc: 79.8%, (\u001B[91m-1.0%\u001B[0m), pre: 83.0% |\n",
      "+----------+----------------------------------------+-----------------------------------------+----------------------------------------+\n",
      "| vit_b_32 | 1e-05: acc: 79.0%, (\u001B[91m-0.2%\u001B[0m), pre: 80.6% | 1e-05: acc: 66.3%, (\u001B[92m+\u001B[0m\u001B[92m6.8%\u001B[0m), pre: 61.2%  | 1e-05: acc: 79.3%, (\u001B[91m-1.5%\u001B[0m), pre: 82.3% |\n",
      "|          | 1e-06: acc: 78.8%, (\u001B[91m-0.4%\u001B[0m), pre: 81.3% | 1e-06: acc: 69.0%, (\u001B[92m+\u001B[0m\u001B[92m9.5%\u001B[0m), pre: 63.8%  | 1e-06: acc: 79.6%, (\u001B[91m-1.2%\u001B[0m), pre: 82.7% |\n",
      "|          | 5e-05: acc: 79.6%, (\u001B[92m+\u001B[0m\u001B[92m0.4%\u001B[0m), pre: 81.2% | 5e-05: acc: 65.8%, (\u001B[92m+\u001B[0m\u001B[92m6.3%\u001B[0m), pre: 61.2%  | 5e-05: acc: 79.8%, (\u001B[91m-1.0%\u001B[0m), pre: 82.7% |\n",
      "+----------+----------------------------------------+-----------------------------------------+----------------------------------------+\n",
      "| vit_l_16 | 1e-05: acc: 80.2%, (\u001B[92m+\u001B[0m\u001B[92m1.0%\u001B[0m), pre: 82.4% | 1e-05: acc: 70.0%, (\u001B[92m+\u001B[0m\u001B[92m10.5%\u001B[0m), pre: 63.7% | 1e-05: acc: 80.6%, (\u001B[91m-0.2%\u001B[0m), pre: 83.7% |\n",
      "|          | 1e-06: acc: 79.8%, (\u001B[92m+\u001B[0m\u001B[92m0.6%\u001B[0m), pre: 82.3% | 1e-06: acc: 69.5%, (\u001B[92m+\u001B[0m\u001B[92m10.0%\u001B[0m), pre: 64.9% | 1e-06: acc: 78.9%, (\u001B[91m-1.9%\u001B[0m), pre: 82.8% |\n",
      "|          | 5e-05: acc: 80.7%, (\u001B[92m+\u001B[0m\u001B[92m1.5%\u001B[0m), pre: 82.6% | 5e-05: acc: 70.3%, (\u001B[92m+\u001B[0m\u001B[92m10.8%\u001B[0m), pre: 64.9% | 5e-05: acc: 79.7%, (\u001B[91m-1.1%\u001B[0m), pre: 83.1% |\n",
      "+----------+----------------------------------------+-----------------------------------------+----------------------------------------+\n",
      "\n",
      "\n",
      "Main model: Coarse-grain vit_l_32 with both fine and coarse grain secondary models\n",
      "+----------+----------------------------------------+-----------------------------------------+----------------------------------------+\n",
      "|          | 1e-06 (59.5%)                          | 1e-05 (79.2%)                           | 5e-05 (80.8%)                          |\n",
      "+==========+========================================+=========================================+========================================+\n",
      "| vit_b_16 | 1e-05: acc: 81.2%, (\u001B[92m+\u001B[0m\u001B[92m2.0%\u001B[0m), pre: 82.2% | 1e-05: acc: 68.3%, (\u001B[92m+\u001B[0m\u001B[92m8.8%\u001B[0m), pre: 62.9%  | 1e-05: acc: 79.5%, (\u001B[91m-1.3%\u001B[0m), pre: 82.6% |\n",
      "|          | 1e-06: acc: 80.0%, (\u001B[92m+\u001B[0m\u001B[92m0.8%\u001B[0m), pre: 82.2% | 1e-06: acc: 65.1%, (\u001B[92m+\u001B[0m\u001B[92m5.6%\u001B[0m), pre: 62.3%  | 1e-06: acc: 80.1%, (\u001B[91m-0.7%\u001B[0m), pre: 83.2% |\n",
      "|          | 5e-05: acc: 81.6%, (\u001B[92m+\u001B[0m\u001B[92m2.4%\u001B[0m), pre: 83.0% | 5e-05: acc: 75.5%, (\u001B[92m+\u001B[0m\u001B[92m16.0%\u001B[0m), pre: 68.8% | 5e-05: acc: 81.2%, (\u001B[92m+\u001B[0m\u001B[92m0.4%\u001B[0m), pre: 83.8% |\n",
      "+----------+----------------------------------------+-----------------------------------------+----------------------------------------+\n",
      "| vit_b_32 | 1e-05: acc: 79.4%, (\u001B[92m+\u001B[0m\u001B[92m0.2%\u001B[0m), pre: 80.8% | 1e-05: acc: 67.0%, (\u001B[92m+\u001B[0m\u001B[92m7.5%\u001B[0m), pre: 61.0%  | 1e-05: acc: 79.3%, (\u001B[91m-1.5%\u001B[0m), pre: 82.3% |\n",
      "|          | 1e-06: acc: 78.5%, (\u001B[91m-0.7%\u001B[0m), pre: 80.7% | 1e-06: acc: 63.0%, (\u001B[92m+\u001B[0m\u001B[92m3.5%\u001B[0m), pre: 61.0%  | 1e-06: acc: 79.6%, (\u001B[91m-1.2%\u001B[0m), pre: 82.7% |\n",
      "|          | 5e-05: acc: 80.0%, (\u001B[92m+\u001B[0m\u001B[92m0.8%\u001B[0m), pre: 81.8% | 5e-05: acc: 69.4%, (\u001B[92m+\u001B[0m\u001B[92m9.9%\u001B[0m), pre: 63.1%  | 5e-05: acc: 79.4%, (\u001B[91m-1.4%\u001B[0m), pre: 82.3% |\n",
      "+----------+----------------------------------------+-----------------------------------------+----------------------------------------+\n",
      "| vit_l_16 | 1e-05: acc: 79.5%, (\u001B[92m+\u001B[0m\u001B[92m0.3%\u001B[0m), pre: 81.2% | 1e-05: acc: 67.8%, (\u001B[92m+\u001B[0m\u001B[92m8.3%\u001B[0m), pre: 62.4%  | 1e-05: acc: 80.4%, (\u001B[91m-0.4%\u001B[0m), pre: 83.2% |\n",
      "|          | 1e-06: acc: 79.9%, (\u001B[92m+\u001B[0m\u001B[92m0.7%\u001B[0m), pre: 82.2% | 1e-06: acc: 67.8%, (\u001B[92m+\u001B[0m\u001B[92m8.3%\u001B[0m), pre: 62.6%  | 1e-06: acc: 78.9%, (\u001B[91m-1.9%\u001B[0m), pre: 82.8% |\n",
      "|          | 5e-05: acc: 82.2%, (\u001B[92m+\u001B[0m\u001B[92m3.0%\u001B[0m), pre: 83.3% | 5e-05: acc: 70.5%, (\u001B[92m+\u001B[0m\u001B[92m11.0%\u001B[0m), pre: 65.1% | 5e-05: acc: 80.5%, (\u001B[91m-0.3%\u001B[0m), pre: 83.2% |\n",
      "+----------+----------------------------------------+-----------------------------------------+----------------------------------------+\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "######################################## Main granularity: fine ########################################\n",
      "########################################################################################################\n",
      "\n",
      "Main model: Fine-grain vit_b_16, secondary granularity: coarse\n",
      "+----------+---------------------------------------+---------------------------------------+---------------------------------------+\n",
      "|          | 1e-05 (acc: 63.9%, pre: 67.4%)        | 1e-06 (acc: 70.0%, pre: 73.3%)        | 5e-05 (acc: 64.5%, pre: 72.0%)        |\n",
      "+==========+=======================================+=======================================+=======================================+\n",
      "| vit_b_32 | 1e-05: acc: 63.9%, (\u001B[91m0.0%\u001B[0m), pre: 67.4% | 1e-05: acc: 70.0%, (\u001B[91m0.0%\u001B[0m), pre: 73.3% | 1e-05: acc: 64.5%, (\u001B[91m0.0%\u001B[0m), pre: 72.0% |\n",
      "|          | 1e-06: acc: 63.9%, (\u001B[91m0.0%\u001B[0m), pre: 67.4% | 1e-06: acc: 70.0%, (\u001B[91m0.0%\u001B[0m), pre: 73.3% | 1e-06: acc: 64.5%, (\u001B[91m0.0%\u001B[0m), pre: 72.0% |\n",
      "|          | 5e-05: acc: 63.9%, (\u001B[91m0.0%\u001B[0m), pre: 67.4% | 5e-05: acc: 70.0%, (\u001B[91m0.0%\u001B[0m), pre: 73.3% | 5e-05: acc: 64.5%, (\u001B[91m0.0%\u001B[0m), pre: 72.0% |\n",
      "+----------+---------------------------------------+---------------------------------------+---------------------------------------+\n",
      "| vit_l_16 | 1e-05: acc: 63.9%, (\u001B[91m0.0%\u001B[0m), pre: 67.4% | 1e-05: acc: 70.0%, (\u001B[91m0.0%\u001B[0m), pre: 73.3% | 1e-05: acc: 64.5%, (\u001B[91m0.0%\u001B[0m), pre: 72.0% |\n",
      "|          | 1e-06: acc: 63.9%, (\u001B[91m0.0%\u001B[0m), pre: 67.4% | 1e-06: acc: 70.0%, (\u001B[91m0.0%\u001B[0m), pre: 73.3% | 1e-06: acc: 64.5%, (\u001B[91m0.0%\u001B[0m), pre: 72.0% |\n",
      "|          | 5e-05: acc: 63.9%, (\u001B[91m0.0%\u001B[0m), pre: 67.4% | 5e-05: acc: 70.0%, (\u001B[91m0.0%\u001B[0m), pre: 73.3% | 5e-05: acc: 64.5%, (\u001B[91m0.0%\u001B[0m), pre: 72.0% |\n",
      "+----------+---------------------------------------+---------------------------------------+---------------------------------------+\n",
      "| vit_l_32 | 1e-05: acc: 63.9%, (\u001B[91m0.0%\u001B[0m), pre: 67.4% | 1e-05: acc: 70.0%, (\u001B[91m0.0%\u001B[0m), pre: 73.3% | 1e-05: acc: 64.5%, (\u001B[91m0.0%\u001B[0m), pre: 72.0% |\n",
      "|          | 1e-06: acc: 63.9%, (\u001B[91m0.0%\u001B[0m), pre: 67.4% | 1e-06: acc: 70.0%, (\u001B[91m0.0%\u001B[0m), pre: 73.3% | 1e-06: acc: 64.5%, (\u001B[91m0.0%\u001B[0m), pre: 72.0% |\n",
      "|          | 5e-05: acc: 63.9%, (\u001B[91m0.0%\u001B[0m), pre: 67.4% | 5e-05: acc: 70.0%, (\u001B[91m0.0%\u001B[0m), pre: 73.3% | 5e-05: acc: 64.5%, (\u001B[91m0.0%\u001B[0m), pre: 72.0% |\n",
      "+----------+---------------------------------------+---------------------------------------+---------------------------------------+\n",
      "\n",
      "\n",
      "Main model: Fine-grain vit_b_16, secondary granularity: fine\n",
      "+----------+----------------------------------------+----------------------------------------+----------------------------------------+\n",
      "|          | 1e-05 (acc: 63.9%, pre: 67.4%)         | 1e-06 (acc: 70.0%, pre: 73.3%)         | 5e-05 (acc: 64.5%, pre: 72.0%)         |\n",
      "+==========+========================================+========================================+========================================+\n",
      "| vit_b_32 | 1e-05: acc: 63.7%, (\u001B[91m-0.2%\u001B[0m), pre: 67.4% | 1e-05: acc: 70.0%, (\u001B[91m0.0%\u001B[0m), pre: 73.3%  | 1e-05: acc: 64.5%, (\u001B[91m0.0%\u001B[0m), pre: 72.0%  |\n",
      "|          | 1e-06: acc: 65.0%, (\u001B[92m+\u001B[0m\u001B[92m1.1%\u001B[0m), pre: 68.2% | 1e-06: acc: 70.0%, (\u001B[91m0.0%\u001B[0m), pre: 73.2%  | 1e-06: acc: 64.3%, (\u001B[91m-0.2%\u001B[0m), pre: 71.8% |\n",
      "|          | 5e-05: acc: 63.8%, (\u001B[91m-0.1%\u001B[0m), pre: 67.2% | 5e-05: acc: 69.8%, (\u001B[91m-0.2%\u001B[0m), pre: 73.0% | 5e-05: acc: 64.1%, (\u001B[91m-0.4%\u001B[0m), pre: 71.8% |\n",
      "+----------+----------------------------------------+----------------------------------------+----------------------------------------+\n",
      "| vit_l_16 | 1e-05: acc: 65.5%, (\u001B[92m+\u001B[0m\u001B[92m1.6%\u001B[0m), pre: 68.7% | 1e-05: acc: 70.0%, (\u001B[91m0.0%\u001B[0m), pre: 73.3%  | 1e-05: acc: 65.0%, (\u001B[92m+\u001B[0m\u001B[92m0.5%\u001B[0m), pre: 72.4% |\n",
      "|          | 1e-06: acc: 66.1%, (\u001B[92m+\u001B[0m\u001B[92m2.2%\u001B[0m), pre: 68.7% | 1e-06: acc: 70.3%, (\u001B[92m+\u001B[0m\u001B[92m0.3%\u001B[0m), pre: 73.6% | 1e-06: acc: 64.6%, (\u001B[92m+\u001B[0m\u001B[92m0.1%\u001B[0m), pre: 72.4% |\n",
      "|          | 5e-05: acc: 65.8%, (\u001B[92m+\u001B[0m\u001B[92m1.9%\u001B[0m), pre: 68.8% | 5e-05: acc: 70.6%, (\u001B[92m+\u001B[0m\u001B[92m0.6%\u001B[0m), pre: 73.5% | 5e-05: acc: 65.7%, (\u001B[92m+\u001B[0m\u001B[92m1.2%\u001B[0m), pre: 72.1% |\n",
      "+----------+----------------------------------------+----------------------------------------+----------------------------------------+\n",
      "| vit_l_32 | 1e-05: acc: 64.2%, (\u001B[92m+\u001B[0m\u001B[92m0.3%\u001B[0m), pre: 67.2% | 1e-05: acc: 69.9%, (\u001B[91m-0.1%\u001B[0m), pre: 73.2% | 1e-05: acc: 64.7%, (\u001B[92m+\u001B[0m\u001B[92m0.2%\u001B[0m), pre: 72.1% |\n",
      "|          | 1e-06: acc: 64.9%, (\u001B[92m+\u001B[0m\u001B[92m1.0%\u001B[0m), pre: 68.4% | 1e-06: acc: 70.0%, (\u001B[91m0.0%\u001B[0m), pre: 73.2%  | 1e-06: acc: 64.8%, (\u001B[92m+\u001B[0m\u001B[92m0.3%\u001B[0m), pre: 72.2% |\n",
      "|          | 5e-05: acc: 64.2%, (\u001B[92m+\u001B[0m\u001B[92m0.3%\u001B[0m), pre: 67.5% | 5e-05: acc: 69.9%, (\u001B[91m-0.1%\u001B[0m), pre: 73.3% | 5e-05: acc: 64.3%, (\u001B[91m-0.2%\u001B[0m), pre: 72.0% |\n",
      "+----------+----------------------------------------+----------------------------------------+----------------------------------------+\n",
      "\n",
      "\n",
      "Main model: Fine-grain vit_b_16 with both fine and coarse grain secondary models\n",
      "+----------+----------------------------------------+----------------------------------------+----------------------------------------+\n",
      "|          | 1e-06 (70.0%)                          | 1e-05 (63.9%)                          | 5e-05 (64.5%)                          |\n",
      "+==========+========================================+========================================+========================================+\n",
      "| vit_b_32 | 1e-05: acc: 63.0%, (\u001B[91m-0.9%\u001B[0m), pre: 67.4% | 1e-05: acc: 69.5%, (\u001B[91m-0.5%\u001B[0m), pre: 73.2% | 1e-05: acc: 64.4%, (\u001B[91m-0.1%\u001B[0m), pre: 71.8% |\n",
      "|          | 1e-06: acc: 65.2%, (\u001B[92m+\u001B[0m\u001B[92m1.3%\u001B[0m), pre: 68.5% | 1e-06: acc: 69.8%, (\u001B[91m-0.2%\u001B[0m), pre: 73.1% | 1e-06: acc: 63.7%, (\u001B[91m-0.8%\u001B[0m), pre: 72.1% |\n",
      "|          | 5e-05: acc: 63.0%, (\u001B[91m-0.9%\u001B[0m), pre: 66.7% | 5e-05: acc: 69.8%, (\u001B[91m-0.2%\u001B[0m), pre: 72.9% | 5e-05: acc: 62.8%, (\u001B[91m-1.7%\u001B[0m), pre: 71.2% |\n",
      "+----------+----------------------------------------+----------------------------------------+----------------------------------------+\n",
      "| vit_l_16 | 1e-05: acc: 66.9%, (\u001B[92m+\u001B[0m\u001B[92m3.0%\u001B[0m), pre: 71.3% | 1e-05: acc: 70.8%, (\u001B[92m+\u001B[0m\u001B[92m0.8%\u001B[0m), pre: 74.4% | 1e-05: acc: 64.8%, (\u001B[92m+\u001B[0m\u001B[92m0.3%\u001B[0m), pre: 72.8% |\n",
      "|          | 1e-06: acc: 68.2%, (\u001B[92m+\u001B[0m\u001B[92m4.3%\u001B[0m), pre: 72.1% | 1e-06: acc: 70.7%, (\u001B[92m+\u001B[0m\u001B[92m0.7%\u001B[0m), pre: 74.6% | 1e-06: acc: 65.1%, (\u001B[92m+\u001B[0m\u001B[92m0.6%\u001B[0m), pre: 73.2% |\n",
      "|          | 5e-05: acc: 67.7%, (\u001B[92m+\u001B[0m\u001B[92m3.8%\u001B[0m), pre: 70.7% | 5e-05: acc: 71.7%, (\u001B[92m+\u001B[0m\u001B[92m1.7%\u001B[0m), pre: 74.2% | 5e-05: acc: 64.8%, (\u001B[92m+\u001B[0m\u001B[92m0.3%\u001B[0m), pre: 73.1% |\n",
      "+----------+----------------------------------------+----------------------------------------+----------------------------------------+\n",
      "| vit_l_32 | 1e-05: acc: 64.2%, (\u001B[92m+\u001B[0m\u001B[92m0.3%\u001B[0m), pre: 67.5% | 1e-05: acc: 69.5%, (\u001B[91m-0.5%\u001B[0m), pre: 73.0% | 1e-05: acc: 64.0%, (\u001B[91m-0.5%\u001B[0m), pre: 72.3% |\n",
      "|          | 1e-06: acc: 65.3%, (\u001B[92m+\u001B[0m\u001B[92m1.4%\u001B[0m), pre: 70.5% | 1e-06: acc: 69.8%, (\u001B[91m-0.2%\u001B[0m), pre: 73.6% | 1e-06: acc: 65.1%, (\u001B[92m+\u001B[0m\u001B[92m0.6%\u001B[0m), pre: 73.0% |\n",
      "|          | 5e-05: acc: 64.3%, (\u001B[92m+\u001B[0m\u001B[92m0.4%\u001B[0m), pre: 68.2% | 5e-05: acc: 69.2%, (\u001B[91m-0.8%\u001B[0m), pre: 73.3% | 5e-05: acc: 64.0%, (\u001B[91m-0.5%\u001B[0m), pre: 73.0% |\n",
      "+----------+----------------------------------------+----------------------------------------+----------------------------------------+\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Main model: Fine-grain vit_b_32, secondary granularity: coarse\n",
      "+----------+----------------------------------------+----------------------------------------+---------------------------------------+\n",
      "|          | 1e-05 (acc: 55.9%, pre: 61.8%)         | 1e-06 (acc: 63.7%, pre: 68.5%)         | 5e-05 (acc: 53.7%, pre: 65.2%)        |\n",
      "+==========+========================================+========================================+=======================================+\n",
      "| vit_b_16 | 1e-05: acc: 55.9%, (\u001B[91m0.0%\u001B[0m), pre: 61.8%  | 1e-05: acc: 63.7%, (\u001B[91m0.0%\u001B[0m), pre: 68.5%  | 1e-05: acc: 53.7%, (\u001B[91m0.0%\u001B[0m), pre: 65.2% |\n",
      "|          | 1e-06: acc: 55.9%, (\u001B[91m0.0%\u001B[0m), pre: 61.8%  | 1e-06: acc: 63.7%, (\u001B[91m0.0%\u001B[0m), pre: 68.5%  | 1e-06: acc: 53.7%, (\u001B[91m0.0%\u001B[0m), pre: 65.2% |\n",
      "|          | 5e-05: acc: 55.9%, (\u001B[91m0.0%\u001B[0m), pre: 61.8%  | 5e-05: acc: 63.7%, (\u001B[91m0.0%\u001B[0m), pre: 68.5%  | 5e-05: acc: 53.7%, (\u001B[91m0.0%\u001B[0m), pre: 65.2% |\n",
      "+----------+----------------------------------------+----------------------------------------+---------------------------------------+\n",
      "| vit_l_16 | 1e-05: acc: 55.9%, (\u001B[91m0.0%\u001B[0m), pre: 61.8%  | 1e-05: acc: 63.7%, (\u001B[91m0.0%\u001B[0m), pre: 68.5%  | 1e-05: acc: 53.7%, (\u001B[91m0.0%\u001B[0m), pre: 65.2% |\n",
      "|          | 1e-06: acc: 55.9%, (\u001B[91m0.0%\u001B[0m), pre: 61.8%  | 1e-06: acc: 63.7%, (\u001B[91m0.0%\u001B[0m), pre: 68.5%  | 1e-06: acc: 53.7%, (\u001B[91m0.0%\u001B[0m), pre: 65.2% |\n",
      "|          | 5e-05: acc: 55.1%, (\u001B[91m-0.8%\u001B[0m), pre: 61.9% | 5e-05: acc: 62.7%, (\u001B[91m-1.0%\u001B[0m), pre: 68.9% | 5e-05: acc: 53.7%, (\u001B[91m0.0%\u001B[0m), pre: 65.2% |\n",
      "+----------+----------------------------------------+----------------------------------------+---------------------------------------+\n",
      "| vit_l_32 | 1e-05: acc: 55.9%, (\u001B[91m0.0%\u001B[0m), pre: 61.8%  | 1e-05: acc: 63.7%, (\u001B[91m0.0%\u001B[0m), pre: 68.5%  | 1e-05: acc: 53.7%, (\u001B[91m0.0%\u001B[0m), pre: 65.2% |\n",
      "|          | 1e-06: acc: 55.9%, (\u001B[91m0.0%\u001B[0m), pre: 61.8%  | 1e-06: acc: 63.7%, (\u001B[91m0.0%\u001B[0m), pre: 68.5%  | 1e-06: acc: 53.7%, (\u001B[91m0.0%\u001B[0m), pre: 65.2% |\n",
      "|          | 5e-05: acc: 55.2%, (\u001B[91m-0.7%\u001B[0m), pre: 61.9% | 5e-05: acc: 63.0%, (\u001B[91m-0.7%\u001B[0m), pre: 69.1% | 5e-05: acc: 53.7%, (\u001B[91m0.0%\u001B[0m), pre: 65.2% |\n",
      "+----------+----------------------------------------+----------------------------------------+---------------------------------------+\n",
      "\n",
      "\n",
      "Main model: Fine-grain vit_b_32, secondary granularity: fine\n",
      "+----------+----------------------------------------+----------------------------------------+----------------------------------------+\n",
      "|          | 1e-05 (acc: 55.9%, pre: 61.8%)         | 1e-06 (acc: 63.7%, pre: 68.5%)         | 5e-05 (acc: 53.7%, pre: 65.2%)         |\n",
      "+==========+========================================+========================================+========================================+\n",
      "| vit_b_16 | 1e-05: acc: 58.2%, (\u001B[92m+\u001B[0m\u001B[92m2.3%\u001B[0m), pre: 63.4% | 1e-05: acc: 63.8%, (\u001B[92m+\u001B[0m\u001B[92m0.1%\u001B[0m), pre: 69.1% | 1e-05: acc: 55.0%, (\u001B[92m+\u001B[0m\u001B[92m1.3%\u001B[0m), pre: 66.6% |\n",
      "|          | 1e-06: acc: 59.7%, (\u001B[92m+\u001B[0m\u001B[92m3.8%\u001B[0m), pre: 64.5% | 1e-06: acc: 65.8%, (\u001B[92m+\u001B[0m\u001B[92m2.1%\u001B[0m), pre: 69.8% | 1e-06: acc: 56.3%, (\u001B[92m+\u001B[0m\u001B[92m2.6%\u001B[0m), pre: 66.9% |\n",
      "|          | 5e-05: acc: 58.5%, (\u001B[92m+\u001B[0m\u001B[92m2.6%\u001B[0m), pre: 63.9% | 5e-05: acc: 65.6%, (\u001B[92m+\u001B[0m\u001B[92m1.9%\u001B[0m), pre: 69.5% | 5e-05: acc: 58.2%, (\u001B[92m+\u001B[0m\u001B[92m4.5%\u001B[0m), pre: 66.9% |\n",
      "+----------+----------------------------------------+----------------------------------------+----------------------------------------+\n",
      "| vit_l_16 | 1e-05: acc: 60.1%, (\u001B[92m+\u001B[0m\u001B[92m4.2%\u001B[0m), pre: 64.6% | 1e-05: acc: 64.3%, (\u001B[92m+\u001B[0m\u001B[92m0.6%\u001B[0m), pre: 69.1% | 1e-05: acc: 55.9%, (\u001B[92m+\u001B[0m\u001B[92m2.2%\u001B[0m), pre: 66.7% |\n",
      "|          | 1e-06: acc: 59.8%, (\u001B[92m+\u001B[0m\u001B[92m3.9%\u001B[0m), pre: 64.7% | 1e-06: acc: 64.3%, (\u001B[92m+\u001B[0m\u001B[92m0.6%\u001B[0m), pre: 69.3% | 1e-06: acc: 58.5%, (\u001B[92m+\u001B[0m\u001B[92m4.8%\u001B[0m), pre: 67.4% |\n",
      "|          | 5e-05: acc: 58.9%, (\u001B[92m+\u001B[0m\u001B[92m3.0%\u001B[0m), pre: 63.9% | 5e-05: acc: 64.8%, (\u001B[92m+\u001B[0m\u001B[92m1.1%\u001B[0m), pre: 68.9% | 5e-05: acc: 56.8%, (\u001B[92m+\u001B[0m\u001B[92m3.1%\u001B[0m), pre: 66.4% |\n",
      "+----------+----------------------------------------+----------------------------------------+----------------------------------------+\n",
      "| vit_l_32 | 1e-05: acc: 57.4%, (\u001B[92m+\u001B[0m\u001B[92m1.5%\u001B[0m), pre: 62.6% | 1e-05: acc: 63.8%, (\u001B[92m+\u001B[0m\u001B[92m0.1%\u001B[0m), pre: 68.4% | 1e-05: acc: 54.7%, (\u001B[92m+\u001B[0m\u001B[92m1.0%\u001B[0m), pre: 65.7% |\n",
      "|          | 1e-06: acc: 58.3%, (\u001B[92m+\u001B[0m\u001B[92m2.4%\u001B[0m), pre: 63.9% | 1e-06: acc: 64.1%, (\u001B[92m+\u001B[0m\u001B[92m0.4%\u001B[0m), pre: 69.5% | 1e-06: acc: 55.0%, (\u001B[92m+\u001B[0m\u001B[92m1.3%\u001B[0m), pre: 66.7% |\n",
      "|          | 5e-05: acc: 56.4%, (\u001B[92m+\u001B[0m\u001B[92m0.5%\u001B[0m), pre: 62.4% | 5e-05: acc: 63.7%, (\u001B[91m0.0%\u001B[0m), pre: 68.6%  | 5e-05: acc: 54.7%, (\u001B[92m+\u001B[0m\u001B[92m1.0%\u001B[0m), pre: 66.2% |\n",
      "+----------+----------------------------------------+----------------------------------------+----------------------------------------+\n",
      "\n",
      "\n",
      "Main model: Fine-grain vit_b_32 with both fine and coarse grain secondary models\n",
      "+----------+-----------------------------------------+----------------------------------------+-----------------------------------------+\n",
      "|          | 1e-06 (63.7%)                           | 1e-05 (55.9%)                          | 5e-05 (53.7%)                           |\n",
      "+==========+=========================================+========================================+=========================================+\n",
      "| vit_b_16 | 1e-05: acc: 60.8%, (\u001B[92m+\u001B[0m\u001B[92m4.9%\u001B[0m), pre: 65.8%  | 1e-05: acc: 63.8%, (\u001B[92m+\u001B[0m\u001B[92m0.1%\u001B[0m), pre: 70.7% | 1e-05: acc: 57.1%, (\u001B[92m+\u001B[0m\u001B[92m3.4%\u001B[0m), pre: 67.8%  |\n",
      "|          | 1e-06: acc: 69.2%, (\u001B[92m+\u001B[0m\u001B[92m13.3%\u001B[0m), pre: 72.2% | 1e-06: acc: 69.1%, (\u001B[92m+\u001B[0m\u001B[92m5.4%\u001B[0m), pre: 73.3% | 1e-06: acc: 61.9%, (\u001B[92m+\u001B[0m\u001B[92m8.2%\u001B[0m), pre: 71.4%  |\n",
      "|          | 5e-05: acc: 62.8%, (\u001B[92m+\u001B[0m\u001B[92m6.9%\u001B[0m), pre: 67.5%  | 5e-05: acc: 67.2%, (\u001B[92m+\u001B[0m\u001B[92m3.5%\u001B[0m), pre: 70.9% | 5e-05: acc: 63.7%, (\u001B[92m+\u001B[0m\u001B[92m10.0%\u001B[0m), pre: 70.4% |\n",
      "+----------+-----------------------------------------+----------------------------------------+-----------------------------------------+\n",
      "| vit_l_16 | 1e-05: acc: 65.7%, (\u001B[92m+\u001B[0m\u001B[92m9.8%\u001B[0m), pre: 70.7%  | 1e-05: acc: 67.7%, (\u001B[92m+\u001B[0m\u001B[92m4.0%\u001B[0m), pre: 72.5% | 1e-05: acc: 61.5%, (\u001B[92m+\u001B[0m\u001B[92m7.8%\u001B[0m), pre: 70.8%  |\n",
      "|          | 1e-06: acc: 69.2%, (\u001B[92m+\u001B[0m\u001B[92m13.3%\u001B[0m), pre: 72.8% | 1e-06: acc: 68.7%, (\u001B[92m+\u001B[0m\u001B[92m5.0%\u001B[0m), pre: 73.1% | 1e-06: acc: 64.8%, (\u001B[92m+\u001B[0m\u001B[92m11.1%\u001B[0m), pre: 72.7% |\n",
      "|          | 5e-05: acc: 65.6%, (\u001B[92m+\u001B[0m\u001B[92m9.7%\u001B[0m), pre: 70.3%  | 5e-05: acc: 67.2%, (\u001B[92m+\u001B[0m\u001B[92m3.5%\u001B[0m), pre: 72.0% | 5e-05: acc: 62.1%, (\u001B[92m+\u001B[0m\u001B[92m8.4%\u001B[0m), pre: 69.7%  |\n",
      "+----------+-----------------------------------------+----------------------------------------+-----------------------------------------+\n",
      "| vit_l_32 | 1e-05: acc: 58.9%, (\u001B[92m+\u001B[0m\u001B[92m3.0%\u001B[0m), pre: 64.6%  | 1e-05: acc: 63.7%, (\u001B[91m0.0%\u001B[0m), pre: 68.5%  | 1e-05: acc: 55.5%, (\u001B[92m+\u001B[0m\u001B[92m1.8%\u001B[0m), pre: 66.0%  |\n",
      "|          | 1e-06: acc: 63.2%, (\u001B[92m+\u001B[0m\u001B[92m7.3%\u001B[0m), pre: 69.4%  | 1e-06: acc: 65.9%, (\u001B[92m+\u001B[0m\u001B[92m2.2%\u001B[0m), pre: 71.8% | 1e-06: acc: 59.5%, (\u001B[92m+\u001B[0m\u001B[92m5.8%\u001B[0m), pre: 68.9%  |\n",
      "|          | 5e-05: acc: 59.7%, (\u001B[92m+\u001B[0m\u001B[92m3.8%\u001B[0m), pre: 66.3%  | 5e-05: acc: 64.2%, (\u001B[92m+\u001B[0m\u001B[92m0.5%\u001B[0m), pre: 69.8% | 5e-05: acc: 56.9%, (\u001B[92m+\u001B[0m\u001B[92m3.2%\u001B[0m), pre: 67.9%  |\n",
      "+----------+-----------------------------------------+----------------------------------------+-----------------------------------------+\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Main model: Fine-grain vit_l_16, secondary granularity: coarse\n",
      "+----------+---------------------------------------+----------------------------------------+----------------------------------------+\n",
      "|          | 1e-05 (acc: 70.0%, pre: 72.8%)        | 1e-06 (acc: 70.3%, pre: 74.2%)         | 5e-05 (acc: 66.2%, pre: 73.4%)         |\n",
      "+==========+=======================================+========================================+========================================+\n",
      "| vit_b_16 | 1e-05: acc: 70.0%, (\u001B[91m0.0%\u001B[0m), pre: 72.8% | 1e-05: acc: 70.3%, (\u001B[91m0.0%\u001B[0m), pre: 74.2%  | 1e-05: acc: 65.0%, (\u001B[91m-1.2%\u001B[0m), pre: 73.7% |\n",
      "|          | 1e-06: acc: 70.0%, (\u001B[91m0.0%\u001B[0m), pre: 72.8% | 1e-06: acc: 70.3%, (\u001B[91m0.0%\u001B[0m), pre: 74.2%  | 1e-06: acc: 66.2%, (\u001B[91m0.0%\u001B[0m), pre: 73.4%  |\n",
      "|          | 5e-05: acc: 70.0%, (\u001B[91m0.0%\u001B[0m), pre: 72.8% | 5e-05: acc: 70.3%, (\u001B[91m0.0%\u001B[0m), pre: 74.2%  | 5e-05: acc: 66.2%, (\u001B[91m0.0%\u001B[0m), pre: 73.4%  |\n",
      "+----------+---------------------------------------+----------------------------------------+----------------------------------------+\n",
      "| vit_b_32 | 1e-05: acc: 70.0%, (\u001B[91m0.0%\u001B[0m), pre: 72.8% | 1e-05: acc: 70.3%, (\u001B[91m0.0%\u001B[0m), pre: 74.2%  | 1e-05: acc: 65.4%, (\u001B[91m-0.8%\u001B[0m), pre: 73.6% |\n",
      "|          | 1e-06: acc: 70.0%, (\u001B[91m0.0%\u001B[0m), pre: 72.8% | 1e-06: acc: 70.3%, (\u001B[91m0.0%\u001B[0m), pre: 74.2%  | 1e-06: acc: 66.2%, (\u001B[91m0.0%\u001B[0m), pre: 73.4%  |\n",
      "|          | 5e-05: acc: 70.0%, (\u001B[91m0.0%\u001B[0m), pre: 72.8% | 5e-05: acc: 69.6%, (\u001B[91m-0.7%\u001B[0m), pre: 74.2% | 5e-05: acc: 65.6%, (\u001B[91m-0.6%\u001B[0m), pre: 73.5% |\n",
      "+----------+---------------------------------------+----------------------------------------+----------------------------------------+\n",
      "| vit_l_32 | 1e-05: acc: 70.0%, (\u001B[91m0.0%\u001B[0m), pre: 72.8% | 1e-05: acc: 70.3%, (\u001B[91m0.0%\u001B[0m), pre: 74.2%  | 1e-05: acc: 66.2%, (\u001B[91m0.0%\u001B[0m), pre: 73.4%  |\n",
      "|          | 1e-06: acc: 70.0%, (\u001B[91m0.0%\u001B[0m), pre: 72.8% | 1e-06: acc: 70.3%, (\u001B[91m0.0%\u001B[0m), pre: 74.2%  | 1e-06: acc: 66.2%, (\u001B[91m0.0%\u001B[0m), pre: 73.4%  |\n",
      "|          | 5e-05: acc: 70.0%, (\u001B[91m0.0%\u001B[0m), pre: 72.8% | 5e-05: acc: 70.3%, (\u001B[91m0.0%\u001B[0m), pre: 74.2%  | 5e-05: acc: 65.2%, (\u001B[91m-1.0%\u001B[0m), pre: 73.7% |\n",
      "+----------+---------------------------------------+----------------------------------------+----------------------------------------+\n",
      "\n",
      "\n",
      "Main model: Fine-grain vit_l_16, secondary granularity: fine\n",
      "+----------+----------------------------------------+----------------------------------------+----------------------------------------+\n",
      "|          | 1e-05 (acc: 70.0%, pre: 72.8%)         | 1e-06 (acc: 70.3%, pre: 74.2%)         | 5e-05 (acc: 66.2%, pre: 73.4%)         |\n",
      "+==========+========================================+========================================+========================================+\n",
      "| vit_b_16 | 1e-05: acc: 70.0%, (\u001B[91m0.0%\u001B[0m), pre: 72.5%  | 1e-05: acc: 70.0%, (\u001B[91m-0.3%\u001B[0m), pre: 74.2% | 1e-05: acc: 66.5%, (\u001B[92m+\u001B[0m\u001B[92m0.3%\u001B[0m), pre: 73.7% |\n",
      "|          | 1e-06: acc: 69.9%, (\u001B[91m-0.1%\u001B[0m), pre: 72.6% | 1e-06: acc: 71.4%, (\u001B[92m+\u001B[0m\u001B[92m1.1%\u001B[0m), pre: 74.8% | 1e-06: acc: 67.1%, (\u001B[92m+\u001B[0m\u001B[92m0.9%\u001B[0m), pre: 74.0% |\n",
      "|          | 5e-05: acc: 70.1%, (\u001B[92m+\u001B[0m\u001B[92m0.1%\u001B[0m), pre: 72.9% | 5e-05: acc: 70.9%, (\u001B[92m+\u001B[0m\u001B[92m0.6%\u001B[0m), pre: 74.2% | 5e-05: acc: 67.2%, (\u001B[92m+\u001B[0m\u001B[92m1.0%\u001B[0m), pre: 73.8% |\n",
      "+----------+----------------------------------------+----------------------------------------+----------------------------------------+\n",
      "| vit_b_32 | 1e-05: acc: 70.0%, (\u001B[91m0.0%\u001B[0m), pre: 72.8%  | 1e-05: acc: 70.3%, (\u001B[91m0.0%\u001B[0m), pre: 74.2%  | 1e-05: acc: 65.6%, (\u001B[91m-0.6%\u001B[0m), pre: 73.5% |\n",
      "|          | 1e-06: acc: 70.0%, (\u001B[91m0.0%\u001B[0m), pre: 72.6%  | 1e-06: acc: 71.1%, (\u001B[92m+\u001B[0m\u001B[92m0.8%\u001B[0m), pre: 74.4% | 1e-06: acc: 65.7%, (\u001B[91m-0.5%\u001B[0m), pre: 73.4% |\n",
      "|          | 5e-05: acc: 69.8%, (\u001B[91m-0.2%\u001B[0m), pre: 72.5% | 5e-05: acc: 70.4%, (\u001B[92m+\u001B[0m\u001B[92m0.1%\u001B[0m), pre: 74.0% | 5e-05: acc: 65.8%, (\u001B[91m-0.4%\u001B[0m), pre: 73.3% |\n",
      "+----------+----------------------------------------+----------------------------------------+----------------------------------------+\n",
      "| vit_l_32 | 1e-05: acc: 70.0%, (\u001B[91m0.0%\u001B[0m), pre: 72.5%  | 1e-05: acc: 71.2%, (\u001B[92m+\u001B[0m\u001B[92m0.9%\u001B[0m), pre: 74.1% | 1e-05: acc: 66.6%, (\u001B[92m+\u001B[0m\u001B[92m0.4%\u001B[0m), pre: 73.3% |\n",
      "|          | 1e-06: acc: 70.2%, (\u001B[92m+\u001B[0m\u001B[92m0.2%\u001B[0m), pre: 72.7% | 1e-06: acc: 70.7%, (\u001B[92m+\u001B[0m\u001B[92m0.4%\u001B[0m), pre: 74.4% | 1e-06: acc: 66.7%, (\u001B[92m+\u001B[0m\u001B[92m0.5%\u001B[0m), pre: 73.8% |\n",
      "|          | 5e-05: acc: 69.7%, (\u001B[91m-0.3%\u001B[0m), pre: 72.4% | 5e-05: acc: 70.6%, (\u001B[92m+\u001B[0m\u001B[92m0.3%\u001B[0m), pre: 74.1% | 5e-05: acc: 66.1%, (\u001B[91m-0.1%\u001B[0m), pre: 73.4% |\n",
      "+----------+----------------------------------------+----------------------------------------+----------------------------------------+\n",
      "\n",
      "\n",
      "Main model: Fine-grain vit_l_16 with both fine and coarse grain secondary models\n",
      "+----------+----------------------------------------+----------------------------------------+----------------------------------------+\n",
      "|          | 1e-06 (70.3%)                          | 1e-05 (70.0%)                          | 5e-05 (66.2%)                          |\n",
      "+==========+========================================+========================================+========================================+\n",
      "| vit_b_16 | 1e-05: acc: 69.5%, (\u001B[91m-0.5%\u001B[0m), pre: 72.2% | 1e-05: acc: 69.3%, (\u001B[91m-1.0%\u001B[0m), pre: 74.5% | 1e-05: acc: 65.5%, (\u001B[91m-0.7%\u001B[0m), pre: 74.6% |\n",
      "|          | 1e-06: acc: 70.7%, (\u001B[92m+\u001B[0m\u001B[92m0.7%\u001B[0m), pre: 73.7% | 1e-06: acc: 71.7%, (\u001B[92m+\u001B[0m\u001B[92m1.4%\u001B[0m), pre: 75.7% | 1e-06: acc: 68.0%, (\u001B[92m+\u001B[0m\u001B[92m1.8%\u001B[0m), pre: 76.2% |\n",
      "|          | 5e-05: acc: 70.3%, (\u001B[92m+\u001B[0m\u001B[92m0.3%\u001B[0m), pre: 73.1% | 5e-05: acc: 70.8%, (\u001B[92m+\u001B[0m\u001B[92m0.5%\u001B[0m), pre: 74.4% | 5e-05: acc: 67.2%, (\u001B[92m+\u001B[0m\u001B[92m1.0%\u001B[0m), pre: 74.1% |\n",
      "+----------+----------------------------------------+----------------------------------------+----------------------------------------+\n",
      "| vit_b_32 | 1e-05: acc: 70.0%, (\u001B[91m0.0%\u001B[0m), pre: 72.5%  | 1e-05: acc: 69.5%, (\u001B[91m-0.8%\u001B[0m), pre: 74.3% | 1e-05: acc: 64.8%, (\u001B[91m-1.4%\u001B[0m), pre: 73.3% |\n",
      "|          | 1e-06: acc: 69.8%, (\u001B[91m-0.2%\u001B[0m), pre: 72.7% | 1e-06: acc: 69.9%, (\u001B[91m-0.4%\u001B[0m), pre: 74.6% | 1e-06: acc: 64.7%, (\u001B[91m-1.5%\u001B[0m), pre: 74.0% |\n",
      "|          | 5e-05: acc: 69.8%, (\u001B[91m-0.2%\u001B[0m), pre: 72.5% | 5e-05: acc: 69.6%, (\u001B[91m-0.7%\u001B[0m), pre: 74.1% | 5e-05: acc: 64.2%, (\u001B[91m-2.0%\u001B[0m), pre: 73.8% |\n",
      "+----------+----------------------------------------+----------------------------------------+----------------------------------------+\n",
      "| vit_l_32 | 1e-05: acc: 70.0%, (\u001B[91m0.0%\u001B[0m), pre: 72.6%  | 1e-05: acc: 70.7%, (\u001B[92m+\u001B[0m\u001B[92m0.4%\u001B[0m), pre: 74.0% | 1e-05: acc: 65.1%, (\u001B[91m-1.1%\u001B[0m), pre: 74.3% |\n",
      "|          | 1e-06: acc: 69.8%, (\u001B[91m-0.2%\u001B[0m), pre: 73.2% | 1e-06: acc: 70.0%, (\u001B[91m-0.3%\u001B[0m), pre: 75.3% | 1e-06: acc: 65.9%, (\u001B[91m-0.3%\u001B[0m), pre: 74.3% |\n",
      "|          | 5e-05: acc: 69.2%, (\u001B[91m-0.8%\u001B[0m), pre: 72.2% | 5e-05: acc: 70.2%, (\u001B[91m-0.1%\u001B[0m), pre: 74.0% | 5e-05: acc: 63.7%, (\u001B[91m-2.5%\u001B[0m), pre: 74.1% |\n",
      "+----------+----------------------------------------+----------------------------------------+----------------------------------------+\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Main model: Fine-grain vit_l_32, secondary granularity: coarse\n",
      "+----------+----------------------------------------+----------------------------------------+---------------------------------------+\n",
      "|          | 1e-05 (acc: 58.2%, pre: 66.1%)         | 1e-06 (acc: 67.3%, pre: 70.3%)         | 5e-05 (acc: 62.4%, pre: 67.9%)        |\n",
      "+==========+========================================+========================================+=======================================+\n",
      "| vit_b_16 | 1e-05: acc: 57.9%, (\u001B[91m-0.3%\u001B[0m), pre: 66.9% | 1e-05: acc: 67.3%, (\u001B[91m0.0%\u001B[0m), pre: 70.3%  | 1e-05: acc: 62.4%, (\u001B[91m0.0%\u001B[0m), pre: 67.9% |\n",
      "|          | 1e-06: acc: 58.2%, (\u001B[91m0.0%\u001B[0m), pre: 66.1%  | 1e-06: acc: 67.3%, (\u001B[91m0.0%\u001B[0m), pre: 70.3%  | 1e-06: acc: 62.4%, (\u001B[91m0.0%\u001B[0m), pre: 67.9% |\n",
      "|          | 5e-05: acc: 57.9%, (\u001B[91m-0.3%\u001B[0m), pre: 67.0% | 5e-05: acc: 67.3%, (\u001B[91m0.0%\u001B[0m), pre: 70.3%  | 5e-05: acc: 62.4%, (\u001B[91m0.0%\u001B[0m), pre: 67.9% |\n",
      "+----------+----------------------------------------+----------------------------------------+---------------------------------------+\n",
      "| vit_b_32 | 1e-05: acc: 58.0%, (\u001B[91m-0.2%\u001B[0m), pre: 66.6% | 1e-05: acc: 67.3%, (\u001B[91m0.0%\u001B[0m), pre: 70.3%  | 1e-05: acc: 62.4%, (\u001B[91m0.0%\u001B[0m), pre: 67.9% |\n",
      "|          | 1e-06: acc: 58.2%, (\u001B[91m0.0%\u001B[0m), pre: 66.1%  | 1e-06: acc: 67.3%, (\u001B[91m0.0%\u001B[0m), pre: 70.3%  | 1e-06: acc: 62.4%, (\u001B[91m0.0%\u001B[0m), pre: 67.9% |\n",
      "|          | 5e-05: acc: 58.2%, (\u001B[91m0.0%\u001B[0m), pre: 66.8%  | 5e-05: acc: 66.7%, (\u001B[91m-0.6%\u001B[0m), pre: 70.5% | 5e-05: acc: 62.4%, (\u001B[91m0.0%\u001B[0m), pre: 67.9% |\n",
      "+----------+----------------------------------------+----------------------------------------+---------------------------------------+\n",
      "| vit_l_16 | 1e-05: acc: 57.4%, (\u001B[91m-0.8%\u001B[0m), pre: 66.8% | 1e-05: acc: 67.3%, (\u001B[91m0.0%\u001B[0m), pre: 70.3%  | 1e-05: acc: 62.4%, (\u001B[91m0.0%\u001B[0m), pre: 67.9% |\n",
      "|          | 1e-06: acc: 58.2%, (\u001B[91m0.0%\u001B[0m), pre: 66.1%  | 1e-06: acc: 67.3%, (\u001B[91m0.0%\u001B[0m), pre: 70.3%  | 1e-06: acc: 62.4%, (\u001B[91m0.0%\u001B[0m), pre: 67.9% |\n",
      "|          | 5e-05: acc: 57.7%, (\u001B[91m-0.5%\u001B[0m), pre: 66.9% | 5e-05: acc: 67.3%, (\u001B[91m0.0%\u001B[0m), pre: 70.3%  | 5e-05: acc: 62.4%, (\u001B[91m0.0%\u001B[0m), pre: 67.9% |\n",
      "+----------+----------------------------------------+----------------------------------------+---------------------------------------+\n",
      "\n",
      "\n",
      "Main model: Fine-grain vit_l_32, secondary granularity: fine\n",
      "+----------+----------------------------------------+----------------------------------------+----------------------------------------+\n",
      "|          | 1e-05 (acc: 58.2%, pre: 66.1%)         | 1e-06 (acc: 67.3%, pre: 70.3%)         | 5e-05 (acc: 62.4%, pre: 67.9%)         |\n",
      "+==========+========================================+========================================+========================================+\n",
      "| vit_b_16 | 1e-05: acc: 58.5%, (\u001B[92m+\u001B[0m\u001B[92m0.3%\u001B[0m), pre: 66.5% | 1e-05: acc: 67.4%, (\u001B[92m+\u001B[0m\u001B[92m0.1%\u001B[0m), pre: 70.1% | 1e-05: acc: 62.7%, (\u001B[92m+\u001B[0m\u001B[92m0.3%\u001B[0m), pre: 68.5% |\n",
      "|          | 1e-06: acc: 61.1%, (\u001B[92m+\u001B[0m\u001B[92m2.9%\u001B[0m), pre: 67.3% | 1e-06: acc: 68.0%, (\u001B[92m+\u001B[0m\u001B[92m0.7%\u001B[0m), pre: 70.9% | 1e-06: acc: 65.0%, (\u001B[92m+\u001B[0m\u001B[92m2.6%\u001B[0m), pre: 69.2% |\n",
      "|          | 5e-05: acc: 60.1%, (\u001B[92m+\u001B[0m\u001B[92m1.9%\u001B[0m), pre: 67.1% | 5e-05: acc: 67.6%, (\u001B[92m+\u001B[0m\u001B[92m0.3%\u001B[0m), pre: 70.3% | 5e-05: acc: 63.9%, (\u001B[92m+\u001B[0m\u001B[92m1.5%\u001B[0m), pre: 68.8% |\n",
      "+----------+----------------------------------------+----------------------------------------+----------------------------------------+\n",
      "| vit_b_32 | 1e-05: acc: 58.0%, (\u001B[91m-0.2%\u001B[0m), pre: 66.5% | 1e-05: acc: 67.1%, (\u001B[91m-0.2%\u001B[0m), pre: 70.1% | 1e-05: acc: 61.7%, (\u001B[91m-0.7%\u001B[0m), pre: 67.4% |\n",
      "|          | 1e-06: acc: 59.4%, (\u001B[92m+\u001B[0m\u001B[92m1.2%\u001B[0m), pre: 66.7% | 1e-06: acc: 67.1%, (\u001B[91m-0.2%\u001B[0m), pre: 69.6% | 1e-06: acc: 63.9%, (\u001B[92m+\u001B[0m\u001B[92m1.5%\u001B[0m), pre: 68.1% |\n",
      "|          | 5e-05: acc: 58.6%, (\u001B[92m+\u001B[0m\u001B[92m0.4%\u001B[0m), pre: 66.6% | 5e-05: acc: 67.1%, (\u001B[91m-0.2%\u001B[0m), pre: 69.8% | 5e-05: acc: 62.7%, (\u001B[92m+\u001B[0m\u001B[92m0.3%\u001B[0m), pre: 67.8% |\n",
      "+----------+----------------------------------------+----------------------------------------+----------------------------------------+\n",
      "| vit_l_16 | 1e-05: acc: 60.5%, (\u001B[92m+\u001B[0m\u001B[92m2.3%\u001B[0m), pre: 67.7% | 1e-05: acc: 67.8%, (\u001B[92m+\u001B[0m\u001B[92m0.5%\u001B[0m), pre: 70.8% | 1e-05: acc: 63.6%, (\u001B[92m+\u001B[0m\u001B[92m1.2%\u001B[0m), pre: 69.3% |\n",
      "|          | 1e-06: acc: 60.6%, (\u001B[92m+\u001B[0m\u001B[92m2.4%\u001B[0m), pre: 68.4% | 1e-06: acc: 68.3%, (\u001B[92m+\u001B[0m\u001B[92m1.0%\u001B[0m), pre: 70.8% | 1e-06: acc: 63.7%, (\u001B[92m+\u001B[0m\u001B[92m1.3%\u001B[0m), pre: 69.3% |\n",
      "|          | 5e-05: acc: 61.1%, (\u001B[92m+\u001B[0m\u001B[92m2.9%\u001B[0m), pre: 67.9% | 5e-05: acc: 67.4%, (\u001B[92m+\u001B[0m\u001B[92m0.1%\u001B[0m), pre: 70.3% | 5e-05: acc: 64.3%, (\u001B[92m+\u001B[0m\u001B[92m1.9%\u001B[0m), pre: 69.2% |\n",
      "+----------+----------------------------------------+----------------------------------------+----------------------------------------+\n",
      "\n",
      "\n",
      "Main model: Fine-grain vit_l_32 with both fine and coarse grain secondary models\n",
      "+----------+----------------------------------------+----------------------------------------+----------------------------------------+\n",
      "|          | 1e-06 (67.3%)                          | 1e-05 (58.2%)                          | 5e-05 (62.4%)                          |\n",
      "+==========+========================================+========================================+========================================+\n",
      "| vit_b_16 | 1e-05: acc: 58.6%, (\u001B[92m+\u001B[0m\u001B[92m0.4%\u001B[0m), pre: 68.2% | 1e-05: acc: 67.6%, (\u001B[92m+\u001B[0m\u001B[92m0.3%\u001B[0m), pre: 70.7% | 1e-05: acc: 63.5%, (\u001B[92m+\u001B[0m\u001B[92m1.1%\u001B[0m), pre: 69.0% |\n",
      "|          | 1e-06: acc: 66.9%, (\u001B[92m+\u001B[0m\u001B[92m8.7%\u001B[0m), pre: 72.6% | 1e-06: acc: 69.8%, (\u001B[92m+\u001B[0m\u001B[92m2.5%\u001B[0m), pre: 73.2% | 1e-06: acc: 68.0%, (\u001B[92m+\u001B[0m\u001B[92m5.6%\u001B[0m), pre: 71.9% |\n",
      "|          | 5e-05: acc: 64.3%, (\u001B[92m+\u001B[0m\u001B[92m6.1%\u001B[0m), pre: 70.4% | 5e-05: acc: 67.9%, (\u001B[92m+\u001B[0m\u001B[92m0.6%\u001B[0m), pre: 70.8% | 5e-05: acc: 63.7%, (\u001B[92m+\u001B[0m\u001B[92m1.3%\u001B[0m), pre: 69.4% |\n",
      "+----------+----------------------------------------+----------------------------------------+----------------------------------------+\n",
      "| vit_b_32 | 1e-05: acc: 58.3%, (\u001B[92m+\u001B[0m\u001B[92m0.1%\u001B[0m), pre: 67.0% | 1e-05: acc: 66.9%, (\u001B[91m-0.4%\u001B[0m), pre: 69.6% | 1e-05: acc: 61.6%, (\u001B[91m-0.8%\u001B[0m), pre: 67.6% |\n",
      "|          | 1e-06: acc: 61.0%, (\u001B[92m+\u001B[0m\u001B[92m2.8%\u001B[0m), pre: 69.7% | 1e-06: acc: 67.2%, (\u001B[91m-0.1%\u001B[0m), pre: 69.9% | 1e-06: acc: 64.5%, (\u001B[92m+\u001B[0m\u001B[92m2.1%\u001B[0m), pre: 69.0% |\n",
      "|          | 5e-05: acc: 58.9%, (\u001B[92m+\u001B[0m\u001B[92m0.7%\u001B[0m), pre: 67.0% | 5e-05: acc: 66.1%, (\u001B[91m-1.2%\u001B[0m), pre: 69.7% | 5e-05: acc: 62.0%, (\u001B[91m-0.4%\u001B[0m), pre: 67.7% |\n",
      "+----------+----------------------------------------+----------------------------------------+----------------------------------------+\n",
      "| vit_l_16 | 1e-05: acc: 66.9%, (\u001B[92m+\u001B[0m\u001B[92m8.7%\u001B[0m), pre: 72.8% | 1e-05: acc: 69.8%, (\u001B[92m+\u001B[0m\u001B[92m2.5%\u001B[0m), pre: 73.4% | 1e-05: acc: 66.4%, (\u001B[92m+\u001B[0m\u001B[92m4.0%\u001B[0m), pre: 72.1% |\n",
      "|          | 1e-06: acc: 66.7%, (\u001B[92m+\u001B[0m\u001B[92m8.5%\u001B[0m), pre: 74.3% | 1e-06: acc: 71.1%, (\u001B[92m+\u001B[0m\u001B[92m3.8%\u001B[0m), pre: 73.2% | 1e-06: acc: 66.6%, (\u001B[92m+\u001B[0m\u001B[92m4.2%\u001B[0m), pre: 73.0% |\n",
      "|          | 5e-05: acc: 66.9%, (\u001B[92m+\u001B[0m\u001B[92m8.7%\u001B[0m), pre: 72.2% | 5e-05: acc: 68.9%, (\u001B[92m+\u001B[0m\u001B[92m1.6%\u001B[0m), pre: 71.7% | 5e-05: acc: 65.7%, (\u001B[92m+\u001B[0m\u001B[92m3.3%\u001B[0m), pre: 71.0% |\n",
      "+----------+----------------------------------------+----------------------------------------+----------------------------------------+\n",
      "\n",
      "\n",
      "####################################################################################################\n"
     ]
    }
   ],
   "source": [
    "aggregation_method = 'weighted'\n",
    "\n",
    "def get_metrics(test_true: np.array, \n",
    "                prior_predictions: np.array, \n",
    "                post_predictions: np.array) -> dict:\n",
    "    return {prior_or_post: ({'acc': accuracy_score(y_true=test_true, \n",
    "                                                       y_pred=(prior_predictions \n",
    "                                                       if prior_or_post == 'prior' else post_predictions))} | \n",
    "                                {metric_name: metric_value(y_true=test_true, \n",
    "                                                           y_pred=(prior_predictions \n",
    "                                                                   if prior_or_post == 'prior' else post_predictions), \n",
    "                                                           average=aggregation_method) \n",
    "                                 for metric_name, metric_value in {'pre': precision_score, 'rec': recall_score, 'f1': f1_score}.items()})\n",
    "                 for prior_or_post in ['prior', 'post']}\n",
    "\n",
    "\n",
    "def gather_EDCR_data() -> dict:\n",
    "    data = {} \n",
    "    \n",
    "    # Iterate through filenames to collect accuracy data\n",
    "    for filename in os.listdir(EDCR_pipeline.figs_folder):\n",
    "        secondary_granularity_match = re.match(\n",
    "            pattern='main_(fine|coarse)_(.+?)_lr(.+?)_secondary_(fine|coarse)_(.+?)_lr(.+)',\n",
    "            string=filename\n",
    "        )\n",
    "        \n",
    "        if secondary_granularity_match:\n",
    "            (   match,\n",
    "                main_granularity,\n",
    "                main_model_name,\n",
    "                main_lr,\n",
    "                secondary_granularity,\n",
    "                secondary_model_name,\n",
    "                secondary_lr\n",
    "            ) = (secondary_granularity_match.group(i) for i in range(7))\n",
    "            \n",
    "            main_suffix = '_coarse' if main_granularity == 'coarse' else ''\n",
    "            test_true = np.load(os.path.join(EDCR_pipeline.data_folder, f'test_true{main_suffix}.npy'))\n",
    "            \n",
    "            prior_predictions = np.load(os.path.join(EDCR_pipeline.data_folder, rf'{main_model_name}_test_pred_lr{main_lr}_e3{main_suffix}.npy'))\n",
    "            \n",
    "            \n",
    "            secondary_suffix = '_coarse' if secondary_granularity == 'coarse' else ''\n",
    "            post_predictions = np.load(f'figs/{match}/results{secondary_suffix}.npy')\n",
    "\n",
    "            # Store accuracy data in the data dictionary\n",
    "            if main_granularity not in data:\n",
    "                data[main_granularity] = {}\n",
    "            if main_model_name not in data[main_granularity]:\n",
    "                data[main_granularity][main_model_name] = {}\n",
    "            if secondary_granularity not in data[main_granularity][main_model_name]:\n",
    "                data[main_granularity][main_model_name][secondary_granularity] = {}\n",
    "            if secondary_model_name not in data[main_granularity][main_model_name][secondary_granularity]:\n",
    "                data[main_granularity][main_model_name][secondary_granularity][secondary_model_name] = {}\n",
    "            if main_lr not in data[main_granularity][main_model_name][secondary_granularity][secondary_model_name]:\n",
    "                data[main_granularity][main_model_name][secondary_granularity][secondary_model_name][main_lr] = {}\n",
    "                \n",
    "            data[main_granularity][main_model_name][secondary_granularity][secondary_model_name][main_lr][secondary_lr] = get_metrics(test_true=test_true,\n",
    "                                                                                                                                      prior_predictions=prior_predictions,\n",
    "                                                                                                                                      post_predictions=post_predictions)\n",
    "        else:\n",
    "            no_secondary_granularity_match = re.match(pattern='main_(fine|coarse)_(.+)_lr(.+)_secondary_(.+)_lr(.+)',\n",
    "                                                      string=filename)\n",
    "            \n",
    "            if no_secondary_granularity_match:\n",
    "                \n",
    "                (match,\n",
    "                 main_granularity,\n",
    "                 main_model_name,\n",
    "                 main_lr,\n",
    "                 secondary_model_name,\n",
    "                 secondary_lr \n",
    "                ) = (no_secondary_granularity_match.group(i) for i in range(6))\n",
    "                \n",
    "                main_suffix = '_coarse' if main_granularity == 'coarse' else ''\n",
    "                test_true = np.load(os.path.join(EDCR_pipeline.data_folder, f'test_true{main_suffix}.npy'))\n",
    "                \n",
    "                prior_predictions = np.load(os.path.join(EDCR_pipeline.data_folder, rf'{main_model_name}_test_pred_lr{main_lr}_e3{main_suffix}.npy'))\n",
    "                \n",
    "                try:\n",
    "                    post_predictions = np.load(f'figs/{match}/results.npy')\n",
    "                except FileNotFoundError:\n",
    "                    post_predictions = np.load(f'figs/{match}/results_coarse.npy')\n",
    "                    \n",
    "                if main_granularity not in data:\n",
    "                    data[main_granularity] = {}\n",
    "                if main_model_name not in data[main_granularity]:\n",
    "                    data[main_granularity][main_model_name] = {}\n",
    "                if secondary_model_name not in data[main_granularity][main_model_name]:\n",
    "                    data[main_granularity][main_model_name][secondary_model_name] = {}\n",
    "                if main_lr not in data[main_granularity][main_model_name][secondary_model_name]:\n",
    "                    data[main_granularity][main_model_name][secondary_model_name][main_lr] = {}\n",
    "                \n",
    "                data[main_granularity][main_model_name][secondary_model_name][main_lr][secondary_lr] = get_metrics(test_true=test_true,\n",
    "                                                                                                                   prior_predictions=prior_predictions,\n",
    "                                                                                                                   post_predictions=post_predictions)\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_row_addition(secondary_lr: float, \n",
    "                     curr_data: dict,\n",
    "                     max_accuracy: float = None) -> (str, float):\n",
    "    curr_prior_data = curr_data['prior']\n",
    "    curr_post_data = curr_data['post']\n",
    "    \n",
    "    curr_prior_accuracy = round(curr_prior_data['acc'] * 100, 1)\n",
    "    curr_post_accuracy = round(curr_post_data['acc'] * 100, 1)\n",
    "    curr_accuracy_diff = round(curr_post_accuracy - curr_prior_accuracy, 1)\n",
    "    \n",
    "    post_acc_str = (utils.blue_text(curr_post_accuracy) \n",
    "                    if max_accuracy is not None and abs(curr_post_accuracy - max_accuracy) < 1e-5 \n",
    "                    else str(curr_post_accuracy))\n",
    "    acc_diff_sign_str = (utils.green_text('+') if curr_accuracy_diff > 0 else '')\n",
    "    \n",
    "    curr_prior_average_precision = round(curr_prior_data['pre'] * 100, 1)\n",
    "    curr_post_average_precision = round(curr_post_data['pre'] * 100, 1)\n",
    "    curr_average_precision_diff = round(curr_post_average_precision - curr_prior_average_precision, 1)\n",
    "    \n",
    "    row_addition = (f\"{secondary_lr}: acc: {post_acc_str}%, ({acc_diff_sign_str}\"  + \n",
    "                    (utils.green_text(f'{curr_accuracy_diff}%') if curr_accuracy_diff > 0 \n",
    "                     else utils.red_text(f'{curr_accuracy_diff}%')) + f'), pre: {curr_post_average_precision}%' + '\\n')\n",
    "    \n",
    "    return row_addition, curr_prior_accuracy, curr_prior_average_precision\n",
    "\n",
    "\n",
    "def get_row_data(main_lr_data: dict,\n",
    "                 secondary_lr: float) -> (str, float):\n",
    "    curr_data = main_lr_data[secondary_lr]\n",
    "    row_addition, curr_prior_acc, curr_prior_average_precision = get_row_addition(secondary_lr=secondary_lr, \n",
    "                                                                                   curr_data=curr_data)\n",
    "    \n",
    "    return row_addition, curr_prior_acc, curr_prior_average_precision\n",
    "\n",
    "\n",
    "def print_one_secondary_granularity(main_model_data: dict,\n",
    "                                    k: str,\n",
    "                                    main_granularity: str,\n",
    "                                    main_model_name: str):\n",
    "\n",
    "    secondary_granularity_data = main_model_data[k]\n",
    "    main_learning_rates = sorted(secondary_granularity_data[list(secondary_granularity_data.keys())[0]].keys())\n",
    "    header = [''] + main_learning_rates\n",
    "    table_data = [header]\n",
    "    priors = {}\n",
    "\n",
    "    for secondary_model_name in sorted(secondary_granularity_data.keys()):\n",
    "        secondary_model_data = secondary_granularity_data[secondary_model_name]\n",
    "        row = [secondary_model_name]\n",
    "        \n",
    "        for main_lr in sorted(secondary_model_data.keys()):\n",
    "            main_lr_data = secondary_model_data[main_lr]\n",
    "            row_add = ''\n",
    "            \n",
    "            for secondary_lr in sorted(main_lr_data.keys()):\n",
    "                row_addition, curr_prior_acc, curr_prior_average_precision = get_row_data(main_lr_data=main_lr_data,\n",
    "                                                                                      secondary_lr=secondary_lr)\n",
    "                row_add += row_addition\n",
    "                priors[main_lr] = {'acc': curr_prior_acc, 'pre': curr_prior_average_precision}\n",
    "                \n",
    "            row += [row_add]\n",
    "        table_data += [row]\n",
    "    \n",
    "    table_data[0] = [''] + [f\"{main_lr} (acc: {priors[main_lr]['acc']}%, pre: {priors[main_lr]['pre']}%)\" for main_lr in main_learning_rates]\n",
    "    \n",
    "    # Rest of your code to create and print the table remains unchanged\n",
    "    table = tabulate.tabulate(\n",
    "        tabular_data=table_data, \n",
    "        headers='firstrow', \n",
    "        tablefmt='grid'\n",
    "    )\n",
    "    print(f\"Main model: {main_granularity.capitalize()}-grain {main_model_name}, \"\n",
    "          f\"secondary granularity: {k}\")\n",
    "    print(table)\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "def print_two_secondary_granularities(main_model_data: dict,\n",
    "                                      two_secondary_table_data: list,\n",
    "                                      k: str,\n",
    "                                      main_granularity: str,\n",
    "                                      main_model_name: str):\n",
    "    main_learning_rates = sorted(vit_pipeline.lrs)\n",
    "    \n",
    "    priors = {}\n",
    "    \n",
    "    # Initialize the table_data with header if it's empty\n",
    "    if len(two_secondary_table_data) == 0:\n",
    "        header = [''] + main_learning_rates\n",
    "        two_secondary_table_data += [header]\n",
    "        \n",
    "    secondary_model_data = main_model_data[k]\n",
    "    row = [k]\n",
    "    \n",
    "    for main_lr in sorted(secondary_model_data.keys()):\n",
    "        main_lr_data = secondary_model_data[main_lr]\n",
    "        row_add = ''\n",
    "        \n",
    "        for secondary_lr in sorted(main_lr_data.keys()):\n",
    "            row_addition, curr_prior, curr_prior_average_precision = get_row_data(main_lr_data=main_lr_data,\n",
    "                                                    secondary_lr=secondary_lr)\n",
    "            row_add += row_addition\n",
    "            priors[main_lr] = curr_prior\n",
    "    \n",
    "        row += [row_add]\n",
    "\n",
    "    two_secondary_table_data += [row]\n",
    "    \n",
    "    # Modify the generated table data to highlight the cell with the maximal accuracy in blue\n",
    "    \n",
    "    if len(two_secondary_table_data) == len(main_learning_rates) + 1:\n",
    "        \n",
    "        two_secondary_table_data[0] = [''] + [f'{main_lr} ({priors[str(main_lr)]}%)' for main_lr in main_learning_rates]\n",
    "        \n",
    "        # Create the table using tabulate\n",
    "        table = tabulate.tabulate(\n",
    "            tabular_data=two_secondary_table_data,\n",
    "            headers='firstrow',\n",
    "            tablefmt='grid'\n",
    "        )\n",
    "        \n",
    "        # Print the main model name and the corresponding table\n",
    "        print(f\"Main model: {main_granularity.capitalize()}-grain {main_model_name} \"\n",
    "              f\"with both fine and coarse grain secondary models\")\n",
    "        print(table)\n",
    "        print(\"\\n\")\n",
    "    else:\n",
    "        return two_secondary_table_data\n",
    "\n",
    "\n",
    "def print_EDCR_tables():\n",
    "    data = gather_EDCR_data()\n",
    "    \n",
    "    for main_granularity in sorted(data.keys()):\n",
    "        \n",
    "        print('#' * 40 + f' Main granularity: {main_granularity} ' + '#' * 40 + '\\n' + '#' * 104 + '\\n')\n",
    "        main_granularity_data = data[main_granularity]\n",
    "        \n",
    "        for main_model_name in sorted(main_granularity_data.keys()):\n",
    "            main_model_data = main_granularity_data[main_model_name]\n",
    "            two_secondary_table_data = []\n",
    "\n",
    "            for k in (sorted(set(main_model_data.keys()).intersection(data_preprocessing.granularities.values())) + \n",
    "                      sorted(set(main_model_data.keys()).intersection(vit_pipeline.vit_model_names))):\n",
    "            \n",
    "                if k in data_preprocessing.granularities.values():\n",
    "                    print_one_secondary_granularity(main_model_data=main_model_data,\n",
    "                        k=k,\n",
    "                        main_granularity=main_granularity,\n",
    "                        main_model_name=main_model_name)\n",
    "                else:\n",
    "                    two_secondary_table_data = print_two_secondary_granularities(main_model_data=main_model_data,\n",
    "                                                      two_secondary_table_data=two_secondary_table_data,\n",
    "                                                      k=k,\n",
    "                                                      main_granularity=main_granularity,\n",
    "                                                      main_model_name=main_model_name)\n",
    "            print('#' * 100)\n",
    "\n",
    "print_EDCR_tables()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T01:31:15.233211Z",
     "start_time": "2023-11-12T01:31:11.720814Z"
    }
   },
   "id": "3f6e34912281d5e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "aafc09a1612c058d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
