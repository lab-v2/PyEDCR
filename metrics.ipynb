{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score\n",
    "import tabulate\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import data_preprocessing\n",
    "import EDCR_pipeline\n",
    "import vit_pipeline\n",
    "import utils"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-22T17:09:35.012777Z",
     "start_time": "2023-11-22T17:09:29.892073Z"
    }
   },
   "id": "9dc68a5fe4ce4ea7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# EDCR Results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff5d015e77a12310"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################## Main granularity: coarse ########################################\n",
      "########################################################################################################\n",
      "\n",
      "Main model: Coarse-grain vit_b_16, secondary granularity: coarse\n",
      "+----------+--------------------------------------------------+----------------------------------------------------+--------------------------------------------------+\n",
      "|          | main-lr=1e-05 (acc: 80.94%, f1: 80.89%)          | main-lr=1e-06 (acc: 65.64%, f1: 61.96%)            | main-lr=5e-05 (acc: 83.71%, f1: 83.48%)          |\n",
      "+==========+==================================================+====================================================+==================================================+\n",
      "| vit_b_32 | 1e-05: acc: 81.0% (\u001B[92m+\u001B[0m\u001B[92m0.06%\u001B[0m), f1: 80.94% (\u001B[92m+\u001B[0m\u001B[92m0.05%\u001B[0m)  | 1e-05: acc: 73.04% (\u001B[92m+\u001B[0m\u001B[92m7.4%\u001B[0m), f1: 68.94% (\u001B[92m+\u001B[0m\u001B[92m6.98%\u001B[0m)    | 1e-05: acc: 82.36% (\u001B[91m-1.35%\u001B[0m), f1: 82.0% (\u001B[91m-1.48%\u001B[0m)  |\n",
      "|          | 1e-06: acc: 80.94% , f1: 80.89%                  | 1e-06: acc: 65.33% (\u001B[91m-0.31%\u001B[0m), f1: 61.84% (\u001B[91m-0.12%\u001B[0m)   | 1e-06: acc: 83.71% , f1: 83.48%                  |\n",
      "|          | 5e-05: acc: 81.18% (\u001B[92m+\u001B[0m\u001B[92m0.24%\u001B[0m), f1: 81.16% (\u001B[92m+\u001B[0m\u001B[92m0.27%\u001B[0m) | 5e-05: acc: 72.55% (\u001B[92m+\u001B[0m\u001B[92m6.91%\u001B[0m), f1: 68.9% (\u001B[92m+\u001B[0m\u001B[92m6.94%\u001B[0m)    | 5e-05: acc: 83.71% , f1: 83.48%                  |\n",
      "+----------+--------------------------------------------------+----------------------------------------------------+--------------------------------------------------+\n",
      "| vit_l_16 | 1e-05: acc: 82.97% (\u001B[92m+\u001B[0m\u001B[92m2.03%\u001B[0m), f1: 82.71% (\u001B[92m+\u001B[0m\u001B[92m1.82%\u001B[0m) | 1e-05: acc: 76.8% (\u001B[92m+\u001B[0m\u001B[92m11.16%\u001B[0m), f1: 72.95% (\u001B[92m+\u001B[0m\u001B[92m10.99%\u001B[0m)  | 1e-05: acc: 83.78% (\u001B[92m+\u001B[0m\u001B[92m0.07%\u001B[0m), f1: 83.48%          |\n",
      "|          | 1e-06: acc: 78.78% (\u001B[91m-2.16%\u001B[0m), f1: 78.87% (\u001B[91m-2.02%\u001B[0m) | 1e-06: acc: 71.19% (\u001B[92m+\u001B[0m\u001B[92m5.55%\u001B[0m), f1: 67.45% (\u001B[92m+\u001B[0m\u001B[92m5.49%\u001B[0m)   | 1e-06: acc: 83.71% , f1: 83.48%                  |\n",
      "|          | 5e-05: acc: 81.99% (\u001B[92m+\u001B[0m\u001B[92m1.05%\u001B[0m), f1: 82.03% (\u001B[92m+\u001B[0m\u001B[92m1.14%\u001B[0m) | 5e-05: acc: 76.06% (\u001B[92m+\u001B[0m\u001B[92m10.42%\u001B[0m), f1: 72.01% (\u001B[92m+\u001B[0m\u001B[92m10.05%\u001B[0m) | 5e-05: acc: 84.21% (\u001B[92m+\u001B[0m\u001B[92m0.5%\u001B[0m), f1: 84.09% (\u001B[92m+\u001B[0m\u001B[92m0.61%\u001B[0m)  |\n",
      "+----------+--------------------------------------------------+----------------------------------------------------+--------------------------------------------------+\n",
      "| vit_l_32 | 1e-05: acc: 80.81% (\u001B[91m-0.13%\u001B[0m), f1: 80.69% (\u001B[91m-0.2%\u001B[0m)  | 1e-05: acc: 74.15% (\u001B[92m+\u001B[0m\u001B[92m8.51%\u001B[0m), f1: 70.28% (\u001B[92m+\u001B[0m\u001B[92m8.32%\u001B[0m)   | 1e-05: acc: 83.04% (\u001B[91m-0.67%\u001B[0m), f1: 82.72% (\u001B[91m-0.76%\u001B[0m) |\n",
      "|          | 1e-06: acc: 80.94% , f1: 80.89%                  | 1e-06: acc: 66.07% (\u001B[92m+\u001B[0m\u001B[92m0.43%\u001B[0m), f1: 62.49% (\u001B[92m+\u001B[0m\u001B[92m0.53%\u001B[0m)   | 1e-06: acc: 83.71% , f1: 83.48%                  |\n",
      "|          | 5e-05: acc: 81.43% (\u001B[92m+\u001B[0m\u001B[92m0.49%\u001B[0m), f1: 81.53% (\u001B[92m+\u001B[0m\u001B[92m0.64%\u001B[0m) | 5e-05: acc: 75.94% (\u001B[92m+\u001B[0m\u001B[92m10.3%\u001B[0m), f1: 71.93% (\u001B[92m+\u001B[0m\u001B[92m9.97%\u001B[0m)   | 5e-05: acc: 83.53% (\u001B[91m-0.18%\u001B[0m), f1: 83.39% (\u001B[91m-0.09%\u001B[0m) |\n",
      "+----------+--------------------------------------------------+----------------------------------------------------+--------------------------------------------------+\n",
      "\n",
      "\n",
      "Main model: Coarse-grain vit_b_16, secondary granularity: fine\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "|          | main-lr=1e-05 (acc: 80.94%, f1: 80.89%)          | main-lr=1e-06 (acc: 65.64%, f1: 61.96%)          | main-lr=5e-05 (acc: 83.71%, f1: 83.48%)          |\n",
      "+==========+==================================================+==================================================+==================================================+\n",
      "| vit_b_32 | 1e-05: acc: 78.04% (\u001B[91m-2.9%\u001B[0m), f1: 78.27% (\u001B[91m-2.62%\u001B[0m)  | 1e-05: acc: 69.34% (\u001B[92m+\u001B[0m\u001B[92m3.7%\u001B[0m), f1: 65.68% (\u001B[92m+\u001B[0m\u001B[92m3.72%\u001B[0m)  | 1e-05: acc: 82.97% (\u001B[91m-0.74%\u001B[0m), f1: 82.74% (\u001B[91m-0.74%\u001B[0m) |\n",
      "|          | 1e-06: acc: 79.21% (\u001B[91m-1.73%\u001B[0m), f1: 79.37% (\u001B[91m-1.52%\u001B[0m) | 1e-06: acc: 71.01% (\u001B[92m+\u001B[0m\u001B[92m5.37%\u001B[0m), f1: 67.08% (\u001B[92m+\u001B[0m\u001B[92m5.12%\u001B[0m) | 1e-06: acc: 82.97% (\u001B[91m-0.74%\u001B[0m), f1: 82.66% (\u001B[91m-0.82%\u001B[0m) |\n",
      "|          | 5e-05: acc: 79.46% (\u001B[91m-1.48%\u001B[0m), f1: 79.57% (\u001B[91m-1.32%\u001B[0m) | 5e-05: acc: 68.6% (\u001B[92m+\u001B[0m\u001B[92m2.96%\u001B[0m), f1: 64.58% (\u001B[92m+\u001B[0m\u001B[92m2.62%\u001B[0m)  | 5e-05: acc: 83.84% (\u001B[92m+\u001B[0m\u001B[92m0.13%\u001B[0m), f1: 83.62% (\u001B[92m+\u001B[0m\u001B[92m0.14%\u001B[0m) |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "| vit_l_16 | 1e-05: acc: 80.81% (\u001B[91m-0.13%\u001B[0m), f1: 80.87% (\u001B[91m-0.02%\u001B[0m) | 1e-05: acc: 72.42% (\u001B[92m+\u001B[0m\u001B[92m6.78%\u001B[0m), f1: 68.44% (\u001B[92m+\u001B[0m\u001B[92m6.48%\u001B[0m) | 1e-05: acc: 84.45% (\u001B[92m+\u001B[0m\u001B[92m0.74%\u001B[0m), f1: 84.29% (\u001B[92m+\u001B[0m\u001B[92m0.81%\u001B[0m) |\n",
      "|          | 1e-06: acc: 79.52% (\u001B[91m-1.42%\u001B[0m), f1: 79.58% (\u001B[91m-1.31%\u001B[0m) | 1e-06: acc: 73.16% (\u001B[92m+\u001B[0m\u001B[92m7.52%\u001B[0m), f1: 69.18% (\u001B[92m+\u001B[0m\u001B[92m7.22%\u001B[0m) | 1e-06: acc: 82.67% (\u001B[91m-1.04%\u001B[0m), f1: 82.31% (\u001B[91m-1.17%\u001B[0m) |\n",
      "|          | 5e-05: acc: 81.25% (\u001B[92m+\u001B[0m\u001B[92m0.31%\u001B[0m), f1: 81.3% (\u001B[92m+\u001B[0m\u001B[92m0.41%\u001B[0m)  | 5e-05: acc: 72.3% (\u001B[92m+\u001B[0m\u001B[92m6.66%\u001B[0m), f1: 68.28% (\u001B[92m+\u001B[0m\u001B[92m6.32%\u001B[0m)  | 5e-05: acc: 84.39% (\u001B[92m+\u001B[0m\u001B[92m0.68%\u001B[0m), f1: 84.27% (\u001B[92m+\u001B[0m\u001B[92m0.79%\u001B[0m) |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "| vit_l_32 | 1e-05: acc: 81.62% (\u001B[92m+\u001B[0m\u001B[92m0.68%\u001B[0m), f1: 81.84% (\u001B[92m+\u001B[0m\u001B[92m0.95%\u001B[0m) | 1e-05: acc: 68.66% (\u001B[92m+\u001B[0m\u001B[92m3.02%\u001B[0m), f1: 64.44% (\u001B[92m+\u001B[0m\u001B[92m2.48%\u001B[0m) | 1e-05: acc: 83.53% (\u001B[91m-0.18%\u001B[0m), f1: 83.27% (\u001B[91m-0.21%\u001B[0m) |\n",
      "|          | 1e-06: acc: 80.57% (\u001B[91m-0.37%\u001B[0m), f1: 80.83% (\u001B[91m-0.06%\u001B[0m) | 1e-06: acc: 71.75% (\u001B[92m+\u001B[0m\u001B[92m6.11%\u001B[0m), f1: 67.63% (\u001B[92m+\u001B[0m\u001B[92m5.67%\u001B[0m) | 1e-06: acc: 83.04% (\u001B[91m-0.67%\u001B[0m), f1: 82.77% (\u001B[91m-0.71%\u001B[0m) |\n",
      "|          | 5e-05: acc: 79.27% (\u001B[91m-1.67%\u001B[0m), f1: 79.35% (\u001B[91m-1.54%\u001B[0m) | 5e-05: acc: 70.57% (\u001B[92m+\u001B[0m\u001B[92m4.93%\u001B[0m), f1: 66.63% (\u001B[92m+\u001B[0m\u001B[92m4.67%\u001B[0m) | 5e-05: acc: 82.54% (\u001B[91m-1.17%\u001B[0m), f1: 82.23% (\u001B[91m-1.25%\u001B[0m) |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "\n",
      "\n",
      "Main model: Coarse-grain vit_b_16 with both fine and coarse grain secondary models\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "|          | main-lr=1e-06 (acc: 65.64%, f1: 61.96%)          | main-lr=1e-05 (acc: 80.94%, f1: 80.89%)          | main-lr=5e-05 (acc: 83.71%, f1: 83.48%)          |\n",
      "+==========+==================================================+==================================================+==================================================+\n",
      "| vit_b_32 | 1e-05: acc: 78.04% (\u001B[91m-2.9%\u001B[0m), f1: 78.27% (\u001B[91m-2.62%\u001B[0m)  | 1e-05: acc: 69.34% (\u001B[92m+\u001B[0m\u001B[92m3.7%\u001B[0m), f1: 65.68% (\u001B[92m+\u001B[0m\u001B[92m3.72%\u001B[0m)  | 1e-05: acc: 82.97% (\u001B[91m-0.74%\u001B[0m), f1: 82.74% (\u001B[91m-0.74%\u001B[0m) |\n",
      "|          | 1e-06: acc: 79.21% (\u001B[91m-1.73%\u001B[0m), f1: 79.37% (\u001B[91m-1.52%\u001B[0m) | 1e-06: acc: 71.01% (\u001B[92m+\u001B[0m\u001B[92m5.37%\u001B[0m), f1: 67.08% (\u001B[92m+\u001B[0m\u001B[92m5.12%\u001B[0m) | 1e-06: acc: 82.97% (\u001B[91m-0.74%\u001B[0m), f1: 82.66% (\u001B[91m-0.82%\u001B[0m) |\n",
      "|          | 5e-05: acc: 79.46% (\u001B[91m-1.48%\u001B[0m), f1: 79.57% (\u001B[91m-1.32%\u001B[0m) | 5e-05: acc: 68.6% (\u001B[92m+\u001B[0m\u001B[92m2.96%\u001B[0m), f1: 64.58% (\u001B[92m+\u001B[0m\u001B[92m2.62%\u001B[0m)  | 5e-05: acc: 83.84% (\u001B[92m+\u001B[0m\u001B[92m0.13%\u001B[0m), f1: 83.62% (\u001B[92m+\u001B[0m\u001B[92m0.14%\u001B[0m) |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "| vit_l_16 | 1e-05: acc: 80.81% (\u001B[91m-0.13%\u001B[0m), f1: 80.87% (\u001B[91m-0.02%\u001B[0m) | 1e-05: acc: 72.42% (\u001B[92m+\u001B[0m\u001B[92m6.78%\u001B[0m), f1: 68.44% (\u001B[92m+\u001B[0m\u001B[92m6.48%\u001B[0m) | 1e-05: acc: 84.45% (\u001B[92m+\u001B[0m\u001B[92m0.74%\u001B[0m), f1: 84.29% (\u001B[92m+\u001B[0m\u001B[92m0.81%\u001B[0m) |\n",
      "|          | 1e-06: acc: 79.52% (\u001B[91m-1.42%\u001B[0m), f1: 79.58% (\u001B[91m-1.31%\u001B[0m) | 1e-06: acc: 73.16% (\u001B[92m+\u001B[0m\u001B[92m7.52%\u001B[0m), f1: 69.18% (\u001B[92m+\u001B[0m\u001B[92m7.22%\u001B[0m) | 1e-06: acc: 82.67% (\u001B[91m-1.04%\u001B[0m), f1: 82.31% (\u001B[91m-1.17%\u001B[0m) |\n",
      "|          | 5e-05: acc: 81.25% (\u001B[92m+\u001B[0m\u001B[92m0.31%\u001B[0m), f1: 81.3% (\u001B[92m+\u001B[0m\u001B[92m0.41%\u001B[0m)  | 5e-05: acc: 72.3% (\u001B[92m+\u001B[0m\u001B[92m6.66%\u001B[0m), f1: 68.28% (\u001B[92m+\u001B[0m\u001B[92m6.32%\u001B[0m)  | 5e-05: acc: 84.39% (\u001B[92m+\u001B[0m\u001B[92m0.68%\u001B[0m), f1: 84.27% (\u001B[92m+\u001B[0m\u001B[92m0.79%\u001B[0m) |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "| vit_l_32 | 1e-05: acc: 81.62% (\u001B[92m+\u001B[0m\u001B[92m0.68%\u001B[0m), f1: 81.84% (\u001B[92m+\u001B[0m\u001B[92m0.95%\u001B[0m) | 1e-05: acc: 68.66% (\u001B[92m+\u001B[0m\u001B[92m3.02%\u001B[0m), f1: 64.44% (\u001B[92m+\u001B[0m\u001B[92m2.48%\u001B[0m) | 1e-05: acc: 83.53% (\u001B[91m-0.18%\u001B[0m), f1: 83.27% (\u001B[91m-0.21%\u001B[0m) |\n",
      "|          | 1e-06: acc: 80.57% (\u001B[91m-0.37%\u001B[0m), f1: 80.83% (\u001B[91m-0.06%\u001B[0m) | 1e-06: acc: 71.75% (\u001B[92m+\u001B[0m\u001B[92m6.11%\u001B[0m), f1: 67.63% (\u001B[92m+\u001B[0m\u001B[92m5.67%\u001B[0m) | 1e-06: acc: 83.04% (\u001B[91m-0.67%\u001B[0m), f1: 82.77% (\u001B[91m-0.71%\u001B[0m) |\n",
      "|          | 5e-05: acc: 79.27% (\u001B[91m-1.67%\u001B[0m), f1: 79.35% (\u001B[91m-1.54%\u001B[0m) | 5e-05: acc: 70.57% (\u001B[92m+\u001B[0m\u001B[92m4.93%\u001B[0m), f1: 66.63% (\u001B[92m+\u001B[0m\u001B[92m4.67%\u001B[0m) | 5e-05: acc: 82.54% (\u001B[91m-1.17%\u001B[0m), f1: 82.23% (\u001B[91m-1.25%\u001B[0m) |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Main model: Coarse-grain vit_b_32, secondary granularity: coarse\n",
      "+----------+--------------------------------------------------+----------------------------------------------------+--------------------------------------------------+\n",
      "|          | main-lr=1e-05 (acc: 77.05%, f1: 76.3%)           | main-lr=1e-06 (acc: 63.05%, f1: 59.7%)             | main-lr=5e-05 (acc: 76.0%, f1: 75.05%)           |\n",
      "+==========+==================================================+====================================================+==================================================+\n",
      "| vit_b_16 | 1e-05: acc: 79.64% (\u001B[92m+\u001B[0m\u001B[92m2.59%\u001B[0m), f1: 79.21% (\u001B[92m+\u001B[0m\u001B[92m2.91%\u001B[0m) | 1e-05: acc: 74.34% (\u001B[92m+\u001B[0m\u001B[92m11.29%\u001B[0m), f1: 70.26% (\u001B[92m+\u001B[0m\u001B[92m10.56%\u001B[0m) | 1e-05: acc: 78.66% (\u001B[92m+\u001B[0m\u001B[92m2.66%\u001B[0m), f1: 77.86% (\u001B[92m+\u001B[0m\u001B[92m2.81%\u001B[0m) |\n",
      "|          | 1e-06: acc: 77.05% , f1: 76.3%                   | 1e-06: acc: 64.22% (\u001B[92m+\u001B[0m\u001B[92m1.17%\u001B[0m), f1: 60.84% (\u001B[92m+\u001B[0m\u001B[92m1.14%\u001B[0m)   | 1e-06: acc: 75.26% (\u001B[91m-0.74%\u001B[0m), f1: 74.13% (\u001B[91m-0.92%\u001B[0m) |\n",
      "|          | 5e-05: acc: 82.23% (\u001B[92m+\u001B[0m\u001B[92m5.18%\u001B[0m), f1: 82.03% (\u001B[92m+\u001B[0m\u001B[92m5.73%\u001B[0m) | 5e-05: acc: 76.31% (\u001B[92m+\u001B[0m\u001B[92m13.26%\u001B[0m), f1: 72.09% (\u001B[92m+\u001B[0m\u001B[92m12.39%\u001B[0m) | 5e-05: acc: 81.99% (\u001B[92m+\u001B[0m\u001B[92m5.99%\u001B[0m), f1: 81.41% (\u001B[92m+\u001B[0m\u001B[92m6.36%\u001B[0m) |\n",
      "+----------+--------------------------------------------------+----------------------------------------------------+--------------------------------------------------+\n",
      "| vit_l_16 | 1e-05: acc: 82.36% (\u001B[92m+\u001B[0m\u001B[92m5.31%\u001B[0m), f1: 81.63% (\u001B[92m+\u001B[0m\u001B[92m5.33%\u001B[0m) | 1e-05: acc: 76.74% (\u001B[92m+\u001B[0m\u001B[92m13.69%\u001B[0m), f1: 72.77% (\u001B[92m+\u001B[0m\u001B[92m13.07%\u001B[0m) | 1e-05: acc: 80.69% (\u001B[92m+\u001B[0m\u001B[92m4.69%\u001B[0m), f1: 79.77% (\u001B[92m+\u001B[0m\u001B[92m4.72%\u001B[0m) |\n",
      "|          | 1e-06: acc: 76.19% (\u001B[91m-0.86%\u001B[0m), f1: 75.55% (\u001B[91m-0.75%\u001B[0m) | 1e-06: acc: 71.44% (\u001B[92m+\u001B[0m\u001B[92m8.39%\u001B[0m), f1: 67.6% (\u001B[92m+\u001B[0m\u001B[92m7.9%\u001B[0m)     | 1e-06: acc: 75.63% (\u001B[91m-0.37%\u001B[0m), f1: 74.36% (\u001B[91m-0.69%\u001B[0m) |\n",
      "|          | 5e-05: acc: 81.62% (\u001B[92m+\u001B[0m\u001B[92m4.57%\u001B[0m), f1: 81.36% (\u001B[92m+\u001B[0m\u001B[92m5.06%\u001B[0m) | 5e-05: acc: 75.88% (\u001B[92m+\u001B[0m\u001B[92m12.83%\u001B[0m), f1: 71.79% (\u001B[92m+\u001B[0m\u001B[92m12.09%\u001B[0m) | 5e-05: acc: 79.4% (\u001B[92m+\u001B[0m\u001B[92m3.4%\u001B[0m), f1: 78.8% (\u001B[92m+\u001B[0m\u001B[92m3.75%\u001B[0m)    |\n",
      "+----------+--------------------------------------------------+----------------------------------------------------+--------------------------------------------------+\n",
      "| vit_l_32 | 1e-05: acc: 77.73% (\u001B[92m+\u001B[0m\u001B[92m0.68%\u001B[0m), f1: 77.26% (\u001B[92m+\u001B[0m\u001B[92m0.96%\u001B[0m) | 1e-05: acc: 72.42% (\u001B[92m+\u001B[0m\u001B[92m9.37%\u001B[0m), f1: 68.76% (\u001B[92m+\u001B[0m\u001B[92m9.06%\u001B[0m)   | 1e-05: acc: 77.48% (\u001B[92m+\u001B[0m\u001B[92m1.48%\u001B[0m), f1: 76.78% (\u001B[92m+\u001B[0m\u001B[92m1.73%\u001B[0m) |\n",
      "|          | 1e-06: acc: 77.05% , f1: 76.3%                   | 1e-06: acc: 63.6% (\u001B[92m+\u001B[0m\u001B[92m0.55%\u001B[0m), f1: 60.25% (\u001B[92m+\u001B[0m\u001B[92m0.55%\u001B[0m)    | 1e-06: acc: 74.34% (\u001B[91m-1.66%\u001B[0m), f1: 73.06% (\u001B[91m-1.99%\u001B[0m) |\n",
      "|          | 5e-05: acc: 81.31% (\u001B[92m+\u001B[0m\u001B[92m4.26%\u001B[0m), f1: 80.94% (\u001B[92m+\u001B[0m\u001B[92m4.64%\u001B[0m) | 5e-05: acc: 75.02% (\u001B[92m+\u001B[0m\u001B[92m11.97%\u001B[0m), f1: 71.06% (\u001B[92m+\u001B[0m\u001B[92m11.36%\u001B[0m) | 5e-05: acc: 78.84% (\u001B[92m+\u001B[0m\u001B[92m2.84%\u001B[0m), f1: 78.28% (\u001B[92m+\u001B[0m\u001B[92m3.23%\u001B[0m) |\n",
      "+----------+--------------------------------------------------+----------------------------------------------------+--------------------------------------------------+\n",
      "\n",
      "\n",
      "Main model: Coarse-grain vit_b_32, secondary granularity: fine\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "|          | main-lr=1e-05 (acc: 77.05%, f1: 76.3%)           | main-lr=1e-06 (acc: 63.05%, f1: 59.7%)           | main-lr=5e-05 (acc: 76.0%, f1: 75.05%)           |\n",
      "+==========+==================================================+==================================================+==================================================+\n",
      "| vit_b_16 | 1e-05: acc: 77.85% (\u001B[92m+\u001B[0m\u001B[92m0.8%\u001B[0m), f1: 76.8% (\u001B[92m+\u001B[0m\u001B[92m0.5%\u001B[0m)    | 1e-05: acc: 69.83% (\u001B[92m+\u001B[0m\u001B[92m6.78%\u001B[0m), f1: 65.93% (\u001B[92m+\u001B[0m\u001B[92m6.23%\u001B[0m) | 1e-05: acc: 76.8% (\u001B[92m+\u001B[0m\u001B[92m0.8%\u001B[0m), f1: 75.74% (\u001B[92m+\u001B[0m\u001B[92m0.69%\u001B[0m)   |\n",
      "|          | 1e-06: acc: 77.73% (\u001B[92m+\u001B[0m\u001B[92m0.68%\u001B[0m), f1: 76.45% (\u001B[92m+\u001B[0m\u001B[92m0.15%\u001B[0m) | 1e-06: acc: 72.73% (\u001B[92m+\u001B[0m\u001B[92m9.68%\u001B[0m), f1: 68.74% (\u001B[92m+\u001B[0m\u001B[92m9.04%\u001B[0m) | 1e-06: acc: 78.53% (\u001B[92m+\u001B[0m\u001B[92m2.53%\u001B[0m), f1: 77.53% (\u001B[92m+\u001B[0m\u001B[92m2.48%\u001B[0m) |\n",
      "|          | 5e-05: acc: 78.72% (\u001B[92m+\u001B[0m\u001B[92m1.67%\u001B[0m), f1: 77.64% (\u001B[92m+\u001B[0m\u001B[92m1.34%\u001B[0m) | 5e-05: acc: 70.88% (\u001B[92m+\u001B[0m\u001B[92m7.83%\u001B[0m), f1: 66.56% (\u001B[92m+\u001B[0m\u001B[92m6.86%\u001B[0m) | 5e-05: acc: 78.1% (\u001B[92m+\u001B[0m\u001B[92m2.1%\u001B[0m), f1: 76.96% (\u001B[92m+\u001B[0m\u001B[92m1.91%\u001B[0m)   |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "| vit_l_16 | 1e-05: acc: 78.59% (\u001B[92m+\u001B[0m\u001B[92m1.54%\u001B[0m), f1: 77.69% (\u001B[92m+\u001B[0m\u001B[92m1.39%\u001B[0m) | 1e-05: acc: 70.64% (\u001B[92m+\u001B[0m\u001B[92m7.59%\u001B[0m), f1: 66.71% (\u001B[92m+\u001B[0m\u001B[92m7.01%\u001B[0m) | 1e-05: acc: 78.47% (\u001B[92m+\u001B[0m\u001B[92m2.47%\u001B[0m), f1: 77.4% (\u001B[92m+\u001B[0m\u001B[92m2.35%\u001B[0m)  |\n",
      "|          | 1e-06: acc: 78.59% (\u001B[92m+\u001B[0m\u001B[92m1.54%\u001B[0m), f1: 77.66% (\u001B[92m+\u001B[0m\u001B[92m1.36%\u001B[0m) | 1e-06: acc: 70.02% (\u001B[92m+\u001B[0m\u001B[92m6.97%\u001B[0m), f1: 65.81% (\u001B[92m+\u001B[0m\u001B[92m6.11%\u001B[0m) | 1e-06: acc: 77.85% (\u001B[92m+\u001B[0m\u001B[92m1.85%\u001B[0m), f1: 76.82% (\u001B[92m+\u001B[0m\u001B[92m1.77%\u001B[0m) |\n",
      "|          | 5e-05: acc: 78.66% (\u001B[92m+\u001B[0m\u001B[92m1.61%\u001B[0m), f1: 77.64% (\u001B[92m+\u001B[0m\u001B[92m1.34%\u001B[0m) | 5e-05: acc: 70.7% (\u001B[92m+\u001B[0m\u001B[92m7.65%\u001B[0m), f1: 66.67% (\u001B[92m+\u001B[0m\u001B[92m6.97%\u001B[0m)  | 5e-05: acc: 78.59% (\u001B[92m+\u001B[0m\u001B[92m2.59%\u001B[0m), f1: 77.52% (\u001B[92m+\u001B[0m\u001B[92m2.47%\u001B[0m) |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "| vit_l_32 | 1e-05: acc: 78.1% (\u001B[92m+\u001B[0m\u001B[92m1.05%\u001B[0m), f1: 77.28% (\u001B[92m+\u001B[0m\u001B[92m0.98%\u001B[0m)  | 1e-05: acc: 68.17% (\u001B[92m+\u001B[0m\u001B[92m5.12%\u001B[0m), f1: 64.38% (\u001B[92m+\u001B[0m\u001B[92m4.68%\u001B[0m) | 1e-05: acc: 75.39% (\u001B[91m-0.61%\u001B[0m), f1: 74.16% (\u001B[91m-0.89%\u001B[0m) |\n",
      "|          | 1e-06: acc: 77.17% (\u001B[92m+\u001B[0m\u001B[92m0.12%\u001B[0m), f1: 76.23% (\u001B[91m-0.07%\u001B[0m) | 1e-06: acc: 70.39% (\u001B[92m+\u001B[0m\u001B[92m7.34%\u001B[0m), f1: 66.6% (\u001B[92m+\u001B[0m\u001B[92m6.9%\u001B[0m)   | 1e-06: acc: 76.56% (\u001B[92m+\u001B[0m\u001B[92m0.56%\u001B[0m), f1: 75.33% (\u001B[92m+\u001B[0m\u001B[92m0.28%\u001B[0m) |\n",
      "|          | 5e-05: acc: 76.43% (\u001B[91m-0.62%\u001B[0m), f1: 75.36% (\u001B[91m-0.94%\u001B[0m) | 5e-05: acc: 69.4% (\u001B[92m+\u001B[0m\u001B[92m6.35%\u001B[0m), f1: 65.8% (\u001B[92m+\u001B[0m\u001B[92m6.1%\u001B[0m)    | 5e-05: acc: 75.26% (\u001B[91m-0.74%\u001B[0m), f1: 73.94% (\u001B[91m-1.11%\u001B[0m) |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "\n",
      "\n",
      "Main model: Coarse-grain vit_b_32 with both fine and coarse grain secondary models\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "|          | main-lr=1e-06 (acc: 63.05%, f1: 59.7%)           | main-lr=1e-05 (acc: 77.05%, f1: 76.3%)           | main-lr=5e-05 (acc: 76.0%, f1: 75.05%)           |\n",
      "+==========+==================================================+==================================================+==================================================+\n",
      "| vit_b_16 | 1e-05: acc: 77.85% (\u001B[92m+\u001B[0m\u001B[92m0.8%\u001B[0m), f1: 76.8% (\u001B[92m+\u001B[0m\u001B[92m0.5%\u001B[0m)    | 1e-05: acc: 69.83% (\u001B[92m+\u001B[0m\u001B[92m6.78%\u001B[0m), f1: 65.93% (\u001B[92m+\u001B[0m\u001B[92m6.23%\u001B[0m) | 1e-05: acc: 76.8% (\u001B[92m+\u001B[0m\u001B[92m0.8%\u001B[0m), f1: 75.74% (\u001B[92m+\u001B[0m\u001B[92m0.69%\u001B[0m)   |\n",
      "|          | 1e-06: acc: 77.73% (\u001B[92m+\u001B[0m\u001B[92m0.68%\u001B[0m), f1: 76.45% (\u001B[92m+\u001B[0m\u001B[92m0.15%\u001B[0m) | 1e-06: acc: 72.73% (\u001B[92m+\u001B[0m\u001B[92m9.68%\u001B[0m), f1: 68.74% (\u001B[92m+\u001B[0m\u001B[92m9.04%\u001B[0m) | 1e-06: acc: 78.53% (\u001B[92m+\u001B[0m\u001B[92m2.53%\u001B[0m), f1: 77.53% (\u001B[92m+\u001B[0m\u001B[92m2.48%\u001B[0m) |\n",
      "|          | 5e-05: acc: 78.72% (\u001B[92m+\u001B[0m\u001B[92m1.67%\u001B[0m), f1: 77.64% (\u001B[92m+\u001B[0m\u001B[92m1.34%\u001B[0m) | 5e-05: acc: 70.88% (\u001B[92m+\u001B[0m\u001B[92m7.83%\u001B[0m), f1: 66.56% (\u001B[92m+\u001B[0m\u001B[92m6.86%\u001B[0m) | 5e-05: acc: 78.1% (\u001B[92m+\u001B[0m\u001B[92m2.1%\u001B[0m), f1: 76.96% (\u001B[92m+\u001B[0m\u001B[92m1.91%\u001B[0m)   |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "| vit_l_16 | 1e-05: acc: 78.59% (\u001B[92m+\u001B[0m\u001B[92m1.54%\u001B[0m), f1: 77.69% (\u001B[92m+\u001B[0m\u001B[92m1.39%\u001B[0m) | 1e-05: acc: 70.64% (\u001B[92m+\u001B[0m\u001B[92m7.59%\u001B[0m), f1: 66.71% (\u001B[92m+\u001B[0m\u001B[92m7.01%\u001B[0m) | 1e-05: acc: 78.47% (\u001B[92m+\u001B[0m\u001B[92m2.47%\u001B[0m), f1: 77.4% (\u001B[92m+\u001B[0m\u001B[92m2.35%\u001B[0m)  |\n",
      "|          | 1e-06: acc: 78.59% (\u001B[92m+\u001B[0m\u001B[92m1.54%\u001B[0m), f1: 77.66% (\u001B[92m+\u001B[0m\u001B[92m1.36%\u001B[0m) | 1e-06: acc: 70.02% (\u001B[92m+\u001B[0m\u001B[92m6.97%\u001B[0m), f1: 65.81% (\u001B[92m+\u001B[0m\u001B[92m6.11%\u001B[0m) | 1e-06: acc: 77.85% (\u001B[92m+\u001B[0m\u001B[92m1.85%\u001B[0m), f1: 76.82% (\u001B[92m+\u001B[0m\u001B[92m1.77%\u001B[0m) |\n",
      "|          | 5e-05: acc: 78.66% (\u001B[92m+\u001B[0m\u001B[92m1.61%\u001B[0m), f1: 77.64% (\u001B[92m+\u001B[0m\u001B[92m1.34%\u001B[0m) | 5e-05: acc: 70.7% (\u001B[92m+\u001B[0m\u001B[92m7.65%\u001B[0m), f1: 66.67% (\u001B[92m+\u001B[0m\u001B[92m6.97%\u001B[0m)  | 5e-05: acc: 78.59% (\u001B[92m+\u001B[0m\u001B[92m2.59%\u001B[0m), f1: 77.52% (\u001B[92m+\u001B[0m\u001B[92m2.47%\u001B[0m) |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "| vit_l_32 | 1e-05: acc: 78.1% (\u001B[92m+\u001B[0m\u001B[92m1.05%\u001B[0m), f1: 77.28% (\u001B[92m+\u001B[0m\u001B[92m0.98%\u001B[0m)  | 1e-05: acc: 68.17% (\u001B[92m+\u001B[0m\u001B[92m5.12%\u001B[0m), f1: 64.38% (\u001B[92m+\u001B[0m\u001B[92m4.68%\u001B[0m) | 1e-05: acc: 75.39% (\u001B[91m-0.61%\u001B[0m), f1: 74.16% (\u001B[91m-0.89%\u001B[0m) |\n",
      "|          | 1e-06: acc: 77.17% (\u001B[92m+\u001B[0m\u001B[92m0.12%\u001B[0m), f1: 76.23% (\u001B[91m-0.07%\u001B[0m) | 1e-06: acc: 70.39% (\u001B[92m+\u001B[0m\u001B[92m7.34%\u001B[0m), f1: 66.6% (\u001B[92m+\u001B[0m\u001B[92m6.9%\u001B[0m)   | 1e-06: acc: 76.56% (\u001B[92m+\u001B[0m\u001B[92m0.56%\u001B[0m), f1: 75.33% (\u001B[92m+\u001B[0m\u001B[92m0.28%\u001B[0m) |\n",
      "|          | 5e-05: acc: 76.43% (\u001B[91m-0.62%\u001B[0m), f1: 75.36% (\u001B[91m-0.94%\u001B[0m) | 5e-05: acc: 69.4% (\u001B[92m+\u001B[0m\u001B[92m6.35%\u001B[0m), f1: 65.8% (\u001B[92m+\u001B[0m\u001B[92m6.1%\u001B[0m)    | 5e-05: acc: 75.26% (\u001B[91m-0.74%\u001B[0m), f1: 73.94% (\u001B[91m-1.11%\u001B[0m) |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Main model: Coarse-grain vit_l_16, secondary granularity: coarse\n",
      "+----------+--------------------------------------------------+\n",
      "|          | main-lr=1e-05 (acc: 84.27%, f1: 84.33%)          |\n",
      "+==========+==================================================+\n",
      "| vit_b_16 | 1e-05: acc: 83.78% (\u001B[91m-0.49%\u001B[0m), f1: 83.84% (\u001B[91m-0.49%\u001B[0m) |\n",
      "|          | 1e-06: acc: 84.27% , f1: 84.33%                  |\n",
      "|          | 5e-05: acc: 84.33% (\u001B[92m+\u001B[0m\u001B[92m0.06%\u001B[0m), f1: 84.5% (\u001B[92m+\u001B[0m\u001B[92m0.17%\u001B[0m)  |\n",
      "+----------+--------------------------------------------------+\n",
      "| vit_b_32 | 1e-05: acc: 83.65% (\u001B[91m-0.62%\u001B[0m), f1: 83.73% (\u001B[91m-0.6%\u001B[0m)  |\n",
      "|          | 1e-06: acc: 84.27% , f1: 84.33%                  |\n",
      "|          | 5e-05: acc: 84.21% (\u001B[91m-0.06%\u001B[0m), f1: 84.27% (\u001B[91m-0.06%\u001B[0m) |\n",
      "+----------+--------------------------------------------------+\n",
      "| vit_l_32 | 1e-05: acc: 83.59% (\u001B[91m-0.68%\u001B[0m), f1: 83.57% (\u001B[91m-0.76%\u001B[0m) |\n",
      "|          | 1e-06: acc: 84.27% , f1: 84.33%                  |\n",
      "|          | 5e-05: acc: 84.58% (\u001B[92m+\u001B[0m\u001B[92m0.31%\u001B[0m), f1: 84.64% (\u001B[92m+\u001B[0m\u001B[92m0.31%\u001B[0m) |\n",
      "+----------+--------------------------------------------------+\n",
      "\n",
      "\n",
      "Main model: Coarse-grain vit_l_16, secondary granularity: fine\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "|          | main-lr=1e-05 (acc: 84.27%, f1: 84.33%)          | main-lr=1e-06 (acc: 73.97%, f1: 72.73%)          | main-lr=5e-05 (acc: 83.71%, f1: 83.7%)           |\n",
      "+==========+==================================================+==================================================+==================================================+\n",
      "| vit_b_16 | 1e-05: acc: 84.15% (\u001B[91m-0.12%\u001B[0m), f1: 84.3% (\u001B[91m-0.03%\u001B[0m)  | 1e-05: acc: 76.0% (\u001B[92m+\u001B[0m\u001B[92m2.03%\u001B[0m), f1: 74.49% (\u001B[92m+\u001B[0m\u001B[92m1.76%\u001B[0m)  | 1e-05: acc: 83.47% (\u001B[91m-0.24%\u001B[0m), f1: 83.44% (\u001B[91m-0.26%\u001B[0m) |\n",
      "|          | 1e-06: acc: 84.39% (\u001B[92m+\u001B[0m\u001B[92m0.12%\u001B[0m), f1: 84.52% (\u001B[92m+\u001B[0m\u001B[92m0.19%\u001B[0m) | 1e-06: acc: 77.48% (\u001B[92m+\u001B[0m\u001B[92m3.51%\u001B[0m), f1: 75.74% (\u001B[92m+\u001B[0m\u001B[92m3.01%\u001B[0m) | 1e-06: acc: 83.84% (\u001B[92m+\u001B[0m\u001B[92m0.13%\u001B[0m), f1: 83.78% (\u001B[92m+\u001B[0m\u001B[92m0.08%\u001B[0m) |\n",
      "|          | 5e-05: acc: 85.38% (\u001B[92m+\u001B[0m\u001B[92m1.11%\u001B[0m), f1: 85.49% (\u001B[92m+\u001B[0m\u001B[92m1.16%\u001B[0m) | 5e-05: acc: 76.5% (\u001B[92m+\u001B[0m\u001B[92m2.53%\u001B[0m), f1: 74.78% (\u001B[92m+\u001B[0m\u001B[92m2.05%\u001B[0m)  | 5e-05: acc: 84.7% (\u001B[92m+\u001B[0m\u001B[92m0.99%\u001B[0m), f1: 84.71% (\u001B[92m+\u001B[0m\u001B[92m1.01%\u001B[0m)  |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "| vit_b_32 | 1e-05: acc: 83.59% (\u001B[91m-0.68%\u001B[0m), f1: 83.77% (\u001B[91m-0.56%\u001B[0m) | 1e-05: acc: 74.15% (\u001B[92m+\u001B[0m\u001B[92m0.18%\u001B[0m), f1: 72.82% (\u001B[92m+\u001B[0m\u001B[92m0.09%\u001B[0m) | 1e-05: acc: 83.16% (\u001B[91m-0.55%\u001B[0m), f1: 83.13% (\u001B[91m-0.57%\u001B[0m) |\n",
      "|          | 1e-06: acc: 84.64% (\u001B[92m+\u001B[0m\u001B[92m0.37%\u001B[0m), f1: 84.82% (\u001B[92m+\u001B[0m\u001B[92m0.49%\u001B[0m) | 1e-06: acc: 75.82% (\u001B[92m+\u001B[0m\u001B[92m1.85%\u001B[0m), f1: 74.15% (\u001B[92m+\u001B[0m\u001B[92m1.42%\u001B[0m) | 1e-06: acc: 84.02% (\u001B[92m+\u001B[0m\u001B[92m0.31%\u001B[0m), f1: 84.0% (\u001B[92m+\u001B[0m\u001B[92m0.3%\u001B[0m)   |\n",
      "|          | 5e-05: acc: 84.52% (\u001B[92m+\u001B[0m\u001B[92m0.25%\u001B[0m), f1: 84.6% (\u001B[92m+\u001B[0m\u001B[92m0.27%\u001B[0m)  | 5e-05: acc: 75.14% (\u001B[92m+\u001B[0m\u001B[92m1.17%\u001B[0m), f1: 73.62% (\u001B[92m+\u001B[0m\u001B[92m0.89%\u001B[0m) | 5e-05: acc: 83.71% , f1: 83.72% (\u001B[92m+\u001B[0m\u001B[92m0.02%\u001B[0m)         |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "| vit_l_32 | 1e-05: acc: 84.89% (\u001B[92m+\u001B[0m\u001B[92m0.62%\u001B[0m), f1: 84.98% (\u001B[92m+\u001B[0m\u001B[92m0.65%\u001B[0m) | 1e-05: acc: 75.2% (\u001B[92m+\u001B[0m\u001B[92m1.23%\u001B[0m), f1: 73.57% (\u001B[92m+\u001B[0m\u001B[92m0.84%\u001B[0m)  | 1e-05: acc: 83.9% (\u001B[92m+\u001B[0m\u001B[92m0.19%\u001B[0m), f1: 83.91% (\u001B[92m+\u001B[0m\u001B[92m0.21%\u001B[0m)  |\n",
      "|          | 1e-06: acc: 84.27% , f1: 84.39% (\u001B[92m+\u001B[0m\u001B[92m0.06%\u001B[0m)         | 1e-06: acc: 76.74% (\u001B[92m+\u001B[0m\u001B[92m2.77%\u001B[0m), f1: 75.17% (\u001B[92m+\u001B[0m\u001B[92m2.44%\u001B[0m) | 1e-06: acc: 83.47% (\u001B[91m-0.24%\u001B[0m), f1: 83.48% (\u001B[91m-0.22%\u001B[0m) |\n",
      "|          | 5e-05: acc: 84.15% (\u001B[91m-0.12%\u001B[0m), f1: 84.23% (\u001B[91m-0.1%\u001B[0m)  | 5e-05: acc: 74.58% (\u001B[92m+\u001B[0m\u001B[92m0.61%\u001B[0m), f1: 73.19% (\u001B[92m+\u001B[0m\u001B[92m0.46%\u001B[0m) | 5e-05: acc: 82.23% (\u001B[91m-1.48%\u001B[0m), f1: 82.22% (\u001B[91m-1.48%\u001B[0m) |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "\n",
      "\n",
      "Main model: Coarse-grain vit_l_16 with both fine and coarse grain secondary models\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "|          | main-lr=1e-06 (acc: 73.97%, f1: 72.73%)          | main-lr=1e-05 (acc: 84.27%, f1: 84.33%)          | main-lr=5e-05 (acc: 83.71%, f1: 83.7%)           |\n",
      "+==========+==================================================+==================================================+==================================================+\n",
      "| vit_b_16 | 1e-05: acc: 84.15% (\u001B[91m-0.12%\u001B[0m), f1: 84.3% (\u001B[91m-0.03%\u001B[0m)  | 1e-05: acc: 78.1% (\u001B[92m+\u001B[0m\u001B[92m4.13%\u001B[0m), f1: 77.3% (\u001B[92m+\u001B[0m\u001B[92m4.57%\u001B[0m)   | 1e-05: acc: 83.41% (\u001B[91m-0.3%\u001B[0m), f1: 83.35% (\u001B[91m-0.35%\u001B[0m)  |\n",
      "|          | 1e-06: acc: 84.39% (\u001B[92m+\u001B[0m\u001B[92m0.12%\u001B[0m), f1: 84.52% (\u001B[92m+\u001B[0m\u001B[92m0.19%\u001B[0m) | 1e-06: acc: 77.48% (\u001B[92m+\u001B[0m\u001B[92m3.51%\u001B[0m), f1: 75.74% (\u001B[92m+\u001B[0m\u001B[92m3.01%\u001B[0m) | 1e-06: acc: 83.84% (\u001B[92m+\u001B[0m\u001B[92m0.13%\u001B[0m), f1: 83.78% (\u001B[92m+\u001B[0m\u001B[92m0.08%\u001B[0m) |\n",
      "|          | 5e-05: acc: 85.38% (\u001B[92m+\u001B[0m\u001B[92m1.11%\u001B[0m), f1: 85.49% (\u001B[92m+\u001B[0m\u001B[92m1.16%\u001B[0m) | 5e-05: acc: 83.78% (\u001B[92m+\u001B[0m\u001B[92m9.81%\u001B[0m), f1: 83.63% (\u001B[92m+\u001B[0m\u001B[92m10.9%\u001B[0m) | 5e-05: acc: 85.38% (\u001B[92m+\u001B[0m\u001B[92m1.67%\u001B[0m), f1: 85.38% (\u001B[92m+\u001B[0m\u001B[92m1.68%\u001B[0m) |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "| vit_b_32 | 1e-05: acc: 83.59% (\u001B[91m-0.68%\u001B[0m), f1: 83.77% (\u001B[91m-0.56%\u001B[0m) | 1e-05: acc: 76.8% (\u001B[92m+\u001B[0m\u001B[92m2.83%\u001B[0m), f1: 75.96% (\u001B[92m+\u001B[0m\u001B[92m3.23%\u001B[0m)  | 1e-05: acc: 82.67% (\u001B[91m-1.04%\u001B[0m), f1: 82.57% (\u001B[91m-1.13%\u001B[0m) |\n",
      "|          | 1e-06: acc: 84.64% (\u001B[92m+\u001B[0m\u001B[92m0.37%\u001B[0m), f1: 84.82% (\u001B[92m+\u001B[0m\u001B[92m0.49%\u001B[0m) | 1e-06: acc: 75.82% (\u001B[92m+\u001B[0m\u001B[92m1.85%\u001B[0m), f1: 74.15% (\u001B[92m+\u001B[0m\u001B[92m1.42%\u001B[0m) | 1e-06: acc: 84.02% (\u001B[92m+\u001B[0m\u001B[92m0.31%\u001B[0m), f1: 84.0% (\u001B[92m+\u001B[0m\u001B[92m0.3%\u001B[0m)   |\n",
      "|          | 5e-05: acc: 84.52% (\u001B[92m+\u001B[0m\u001B[92m0.25%\u001B[0m), f1: 84.6% (\u001B[92m+\u001B[0m\u001B[92m0.27%\u001B[0m)  | 5e-05: acc: 76.37% (\u001B[92m+\u001B[0m\u001B[92m2.4%\u001B[0m), f1: 75.85% (\u001B[92m+\u001B[0m\u001B[92m3.12%\u001B[0m)  | 5e-05: acc: 83.28% (\u001B[91m-0.43%\u001B[0m), f1: 83.31% (\u001B[91m-0.39%\u001B[0m) |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "| vit_l_32 | 1e-05: acc: 84.89% (\u001B[92m+\u001B[0m\u001B[92m0.62%\u001B[0m), f1: 84.98% (\u001B[92m+\u001B[0m\u001B[92m0.65%\u001B[0m) | 1e-05: acc: 76.68% (\u001B[92m+\u001B[0m\u001B[92m2.71%\u001B[0m), f1: 75.79% (\u001B[92m+\u001B[0m\u001B[92m3.06%\u001B[0m) | 1e-05: acc: 84.52% (\u001B[92m+\u001B[0m\u001B[92m0.81%\u001B[0m), f1: 84.54% (\u001B[92m+\u001B[0m\u001B[92m0.84%\u001B[0m) |\n",
      "|          | 1e-06: acc: 84.27% , f1: 84.39% (\u001B[92m+\u001B[0m\u001B[92m0.06%\u001B[0m)         | 1e-06: acc: 75.94% (\u001B[92m+\u001B[0m\u001B[92m1.97%\u001B[0m), f1: 74.07% (\u001B[92m+\u001B[0m\u001B[92m1.34%\u001B[0m) | 1e-06: acc: 83.47% (\u001B[91m-0.24%\u001B[0m), f1: 83.48% (\u001B[91m-0.22%\u001B[0m) |\n",
      "|          | 5e-05: acc: 84.15% (\u001B[91m-0.12%\u001B[0m), f1: 84.23% (\u001B[91m-0.1%\u001B[0m)  | 5e-05: acc: 78.29% (\u001B[92m+\u001B[0m\u001B[92m4.32%\u001B[0m), f1: 77.32% (\u001B[92m+\u001B[0m\u001B[92m4.59%\u001B[0m) | 5e-05: acc: 83.47% (\u001B[91m-0.24%\u001B[0m), f1: 83.4% (\u001B[91m-0.3%\u001B[0m)   |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Main model: Coarse-grain vit_l_32, secondary granularity: coarse\n",
      "+----------+--------------------------------------------------+----------------------------------------------------+\n",
      "|          | main-lr=1e-05 (acc: 79.21%, f1: 78.9%)           | main-lr=1e-06 (acc: 59.53%, f1: 55.66%)            |\n",
      "+==========+==================================================+====================================================+\n",
      "| vit_b_16 | 1e-05: acc: 80.44% (\u001B[92m+\u001B[0m\u001B[92m1.23%\u001B[0m), f1: 80.11% (\u001B[92m+\u001B[0m\u001B[92m1.21%\u001B[0m) | 1e-06: acc: 63.23% (\u001B[92m+\u001B[0m\u001B[92m3.7%\u001B[0m), f1: 58.56% (\u001B[92m+\u001B[0m\u001B[92m2.9%\u001B[0m)     |\n",
      "|          | 1e-06: acc: 79.21% , f1: 78.9%                   | 5e-05: acc: 76.19% (\u001B[92m+\u001B[0m\u001B[92m16.66%\u001B[0m), f1: 71.9% (\u001B[92m+\u001B[0m\u001B[92m16.24%\u001B[0m)  |\n",
      "|          | 5e-05: acc: 79.83% (\u001B[92m+\u001B[0m\u001B[92m0.62%\u001B[0m), f1: 79.58% (\u001B[92m+\u001B[0m\u001B[92m0.68%\u001B[0m) |                                                    |\n",
      "+----------+--------------------------------------------------+----------------------------------------------------+\n",
      "| vit_b_32 | 1e-05: acc: 78.9% (\u001B[91m-0.31%\u001B[0m), f1: 78.39% (\u001B[91m-0.51%\u001B[0m)  | 1e-05: acc: 72.79% (\u001B[92m+\u001B[0m\u001B[92m13.26%\u001B[0m), f1: 68.64% (\u001B[92m+\u001B[0m\u001B[92m12.98%\u001B[0m) |\n",
      "|          | 1e-06: acc: 77.61% (\u001B[91m-1.6%\u001B[0m), f1: 77.13% (\u001B[91m-1.77%\u001B[0m)  | 5e-05: acc: 70.57% (\u001B[92m+\u001B[0m\u001B[92m11.04%\u001B[0m), f1: 66.77% (\u001B[92m+\u001B[0m\u001B[92m11.11%\u001B[0m) |\n",
      "|          | 5e-05: acc: 79.15% (\u001B[91m-0.06%\u001B[0m), f1: 78.86% (\u001B[91m-0.04%\u001B[0m) |                                                    |\n",
      "+----------+--------------------------------------------------+----------------------------------------------------+\n",
      "| vit_l_16 | 1e-05: acc: 80.51% (\u001B[92m+\u001B[0m\u001B[92m1.3%\u001B[0m), f1: 80.45% (\u001B[92m+\u001B[0m\u001B[92m1.55%\u001B[0m)  | 1e-05: acc: 76.68% (\u001B[92m+\u001B[0m\u001B[92m17.15%\u001B[0m), f1: 72.5% (\u001B[92m+\u001B[0m\u001B[92m16.84%\u001B[0m)  |\n",
      "|          | 1e-06: acc: 78.35% (\u001B[91m-0.86%\u001B[0m), f1: 77.82% (\u001B[91m-1.08%\u001B[0m) | 1e-06: acc: 68.11% (\u001B[92m+\u001B[0m\u001B[92m8.58%\u001B[0m), f1: 63.25% (\u001B[92m+\u001B[0m\u001B[92m7.59%\u001B[0m)   |\n",
      "|          | 5e-05: acc: 82.73% (\u001B[92m+\u001B[0m\u001B[92m3.52%\u001B[0m), f1: 82.83% (\u001B[92m+\u001B[0m\u001B[92m3.93%\u001B[0m) | 5e-05: acc: 75.88% (\u001B[92m+\u001B[0m\u001B[92m16.35%\u001B[0m), f1: 71.7% (\u001B[92m+\u001B[0m\u001B[92m16.04%\u001B[0m)  |\n",
      "+----------+--------------------------------------------------+----------------------------------------------------+\n",
      "\n",
      "\n",
      "Main model: Coarse-grain vit_l_32, secondary granularity: fine\n",
      "+----------+--------------------------------------------------+----------------------------------------------------+--------------------------------------------------+\n",
      "|          | main-lr=1e-05 (acc: 79.21%, f1: 78.9%)           | main-lr=1e-06 (acc: 59.53%, f1: 55.66%)            | main-lr=5e-05 (acc: 80.75%, f1: 80.96%)          |\n",
      "+==========+==================================================+====================================================+==================================================+\n",
      "| vit_b_16 | 1e-05: acc: 79.77% (\u001B[92m+\u001B[0m\u001B[92m0.56%\u001B[0m), f1: 79.37% (\u001B[92m+\u001B[0m\u001B[92m0.47%\u001B[0m) | 1e-05: acc: 68.91% (\u001B[92m+\u001B[0m\u001B[92m9.38%\u001B[0m), f1: 64.98% (\u001B[92m+\u001B[0m\u001B[92m9.32%\u001B[0m)   | 1e-05: acc: 78.72% (\u001B[91m-2.03%\u001B[0m), f1: 79.11% (\u001B[91m-1.85%\u001B[0m) |\n",
      "|          | 1e-06: acc: 79.95% (\u001B[92m+\u001B[0m\u001B[92m0.74%\u001B[0m), f1: 79.58% (\u001B[92m+\u001B[0m\u001B[92m0.68%\u001B[0m) | 1e-06: acc: 71.5% (\u001B[92m+\u001B[0m\u001B[92m11.97%\u001B[0m), f1: 67.46% (\u001B[92m+\u001B[0m\u001B[92m11.8%\u001B[0m)   | 1e-06: acc: 80.14% (\u001B[91m-0.61%\u001B[0m), f1: 80.49% (\u001B[91m-0.47%\u001B[0m) |\n",
      "|          | 5e-05: acc: 80.32% (\u001B[92m+\u001B[0m\u001B[92m1.11%\u001B[0m), f1: 80.01% (\u001B[92m+\u001B[0m\u001B[92m1.11%\u001B[0m) | 5e-05: acc: 68.91% (\u001B[92m+\u001B[0m\u001B[92m9.38%\u001B[0m), f1: 64.76% (\u001B[92m+\u001B[0m\u001B[92m9.1%\u001B[0m)    | 5e-05: acc: 79.77% (\u001B[91m-0.98%\u001B[0m), f1: 80.14% (\u001B[91m-0.82%\u001B[0m) |\n",
      "+----------+--------------------------------------------------+----------------------------------------------------+--------------------------------------------------+\n",
      "| vit_b_32 | 1e-05: acc: 78.96% (\u001B[91m-0.25%\u001B[0m), f1: 78.72% (\u001B[91m-0.18%\u001B[0m) | 1e-05: acc: 66.32% (\u001B[92m+\u001B[0m\u001B[92m6.79%\u001B[0m), f1: 62.32% (\u001B[92m+\u001B[0m\u001B[92m6.66%\u001B[0m)   | 1e-05: acc: 79.27% (\u001B[91m-1.48%\u001B[0m), f1: 79.65% (\u001B[91m-1.31%\u001B[0m) |\n",
      "|          | 1e-06: acc: 78.84% (\u001B[91m-0.37%\u001B[0m), f1: 78.44% (\u001B[91m-0.46%\u001B[0m) | 1e-06: acc: 68.97% (\u001B[92m+\u001B[0m\u001B[92m9.44%\u001B[0m), f1: 64.98% (\u001B[92m+\u001B[0m\u001B[92m9.32%\u001B[0m)   | 1e-06: acc: 79.64% (\u001B[91m-1.11%\u001B[0m), f1: 80.1% (\u001B[91m-0.86%\u001B[0m)  |\n",
      "|          | 5e-05: acc: 79.64% (\u001B[92m+\u001B[0m\u001B[92m0.43%\u001B[0m), f1: 79.33% (\u001B[92m+\u001B[0m\u001B[92m0.43%\u001B[0m) | 5e-05: acc: 65.82% (\u001B[92m+\u001B[0m\u001B[92m6.29%\u001B[0m), f1: 61.87% (\u001B[92m+\u001B[0m\u001B[92m6.21%\u001B[0m)   | 5e-05: acc: 79.83% (\u001B[91m-0.92%\u001B[0m), f1: 80.19% (\u001B[91m-0.77%\u001B[0m) |\n",
      "+----------+--------------------------------------------------+----------------------------------------------------+--------------------------------------------------+\n",
      "| vit_l_16 | 1e-05: acc: 80.2% (\u001B[92m+\u001B[0m\u001B[92m0.99%\u001B[0m), f1: 79.78% (\u001B[92m+\u001B[0m\u001B[92m0.88%\u001B[0m)  | 1e-05: acc: 69.96% (\u001B[92m+\u001B[0m\u001B[92m10.43%\u001B[0m), f1: 65.89% (\u001B[92m+\u001B[0m\u001B[92m10.23%\u001B[0m) | 1e-05: acc: 80.63% (\u001B[91m-0.12%\u001B[0m), f1: 80.92% (\u001B[91m-0.04%\u001B[0m) |\n",
      "|          | 1e-06: acc: 79.83% (\u001B[92m+\u001B[0m\u001B[92m0.62%\u001B[0m), f1: 79.49% (\u001B[92m+\u001B[0m\u001B[92m0.59%\u001B[0m) | 1e-06: acc: 69.46% (\u001B[92m+\u001B[0m\u001B[92m9.93%\u001B[0m), f1: 65.2% (\u001B[92m+\u001B[0m\u001B[92m9.54%\u001B[0m)    | 1e-06: acc: 78.9% (\u001B[91m-1.85%\u001B[0m), f1: 79.29% (\u001B[91m-1.67%\u001B[0m)  |\n",
      "|          | 5e-05: acc: 80.69% (\u001B[92m+\u001B[0m\u001B[92m1.48%\u001B[0m), f1: 80.42% (\u001B[92m+\u001B[0m\u001B[92m1.52%\u001B[0m) | 5e-05: acc: 70.33% (\u001B[92m+\u001B[0m\u001B[92m10.8%\u001B[0m), f1: 66.26% (\u001B[92m+\u001B[0m\u001B[92m10.6%\u001B[0m)   | 5e-05: acc: 79.7% (\u001B[91m-1.05%\u001B[0m), f1: 80.04% (\u001B[91m-0.92%\u001B[0m)  |\n",
      "+----------+--------------------------------------------------+----------------------------------------------------+--------------------------------------------------+\n",
      "\n",
      "\n",
      "Main model: Coarse-grain vit_l_32 with both fine and coarse grain secondary models\n",
      "+----------+--------------------------------------------------+----------------------------------------------------+--------------------------------------------------+\n",
      "|          | main-lr=1e-06 (acc: 59.53%, f1: 55.66%)          | main-lr=1e-05 (acc: 79.21%, f1: 78.9%)             | main-lr=5e-05 (acc: 80.75%, f1: 80.96%)          |\n",
      "+==========+==================================================+====================================================+==================================================+\n",
      "| vit_b_16 | 1e-05: acc: 79.77% (\u001B[92m+\u001B[0m\u001B[92m0.56%\u001B[0m), f1: 79.37% (\u001B[92m+\u001B[0m\u001B[92m0.47%\u001B[0m) | 1e-05: acc: 68.91% (\u001B[92m+\u001B[0m\u001B[92m9.38%\u001B[0m), f1: 64.98% (\u001B[92m+\u001B[0m\u001B[92m9.32%\u001B[0m)   | 1e-05: acc: 79.46% (\u001B[91m-1.29%\u001B[0m), f1: 79.67% (\u001B[91m-1.29%\u001B[0m) |\n",
      "|          | 1e-06: acc: 79.95% (\u001B[92m+\u001B[0m\u001B[92m0.74%\u001B[0m), f1: 79.58% (\u001B[92m+\u001B[0m\u001B[92m0.68%\u001B[0m) | 1e-06: acc: 71.5% (\u001B[92m+\u001B[0m\u001B[92m11.97%\u001B[0m), f1: 67.46% (\u001B[92m+\u001B[0m\u001B[92m11.8%\u001B[0m)   | 1e-06: acc: 80.14% (\u001B[91m-0.61%\u001B[0m), f1: 80.49% (\u001B[91m-0.47%\u001B[0m) |\n",
      "|          | 5e-05: acc: 80.32% (\u001B[92m+\u001B[0m\u001B[92m1.11%\u001B[0m), f1: 80.01% (\u001B[92m+\u001B[0m\u001B[92m1.11%\u001B[0m) | 5e-05: acc: 68.91% (\u001B[92m+\u001B[0m\u001B[92m9.38%\u001B[0m), f1: 64.76% (\u001B[92m+\u001B[0m\u001B[92m9.1%\u001B[0m)    | 5e-05: acc: 81.18% (\u001B[92m+\u001B[0m\u001B[92m0.43%\u001B[0m), f1: 81.35% (\u001B[92m+\u001B[0m\u001B[92m0.39%\u001B[0m) |\n",
      "+----------+--------------------------------------------------+----------------------------------------------------+--------------------------------------------------+\n",
      "| vit_b_32 | 1e-05: acc: 78.96% (\u001B[91m-0.25%\u001B[0m), f1: 78.72% (\u001B[91m-0.18%\u001B[0m) | 1e-05: acc: 66.32% (\u001B[92m+\u001B[0m\u001B[92m6.79%\u001B[0m), f1: 62.32% (\u001B[92m+\u001B[0m\u001B[92m6.66%\u001B[0m)   | 1e-05: acc: 79.27% (\u001B[91m-1.48%\u001B[0m), f1: 79.65% (\u001B[91m-1.31%\u001B[0m) |\n",
      "|          | 1e-06: acc: 78.84% (\u001B[91m-0.37%\u001B[0m), f1: 78.44% (\u001B[91m-0.46%\u001B[0m) | 1e-06: acc: 62.99% (\u001B[92m+\u001B[0m\u001B[92m3.46%\u001B[0m), f1: 59.13% (\u001B[92m+\u001B[0m\u001B[92m3.47%\u001B[0m)   | 1e-06: acc: 79.64% (\u001B[91m-1.11%\u001B[0m), f1: 80.1% (\u001B[91m-0.86%\u001B[0m)  |\n",
      "|          | 5e-05: acc: 79.64% (\u001B[92m+\u001B[0m\u001B[92m0.43%\u001B[0m), f1: 79.33% (\u001B[92m+\u001B[0m\u001B[92m0.43%\u001B[0m) | 5e-05: acc: 65.82% (\u001B[92m+\u001B[0m\u001B[92m6.29%\u001B[0m), f1: 61.87% (\u001B[92m+\u001B[0m\u001B[92m6.21%\u001B[0m)   | 5e-05: acc: 79.4% (\u001B[91m-1.35%\u001B[0m), f1: 79.74% (\u001B[91m-1.22%\u001B[0m)  |\n",
      "+----------+--------------------------------------------------+----------------------------------------------------+--------------------------------------------------+\n",
      "| vit_l_16 | 1e-05: acc: 80.2% (\u001B[92m+\u001B[0m\u001B[92m0.99%\u001B[0m), f1: 79.78% (\u001B[92m+\u001B[0m\u001B[92m0.88%\u001B[0m)  | 1e-05: acc: 69.96% (\u001B[92m+\u001B[0m\u001B[92m10.43%\u001B[0m), f1: 65.89% (\u001B[92m+\u001B[0m\u001B[92m10.23%\u001B[0m) | 1e-05: acc: 80.38% (\u001B[91m-0.37%\u001B[0m), f1: 80.67% (\u001B[91m-0.29%\u001B[0m) |\n",
      "|          | 1e-06: acc: 79.83% (\u001B[92m+\u001B[0m\u001B[92m0.62%\u001B[0m), f1: 79.49% (\u001B[92m+\u001B[0m\u001B[92m0.59%\u001B[0m) | 1e-06: acc: 69.46% (\u001B[92m+\u001B[0m\u001B[92m9.93%\u001B[0m), f1: 65.2% (\u001B[92m+\u001B[0m\u001B[92m9.54%\u001B[0m)    | 1e-06: acc: 78.9% (\u001B[91m-1.85%\u001B[0m), f1: 79.29% (\u001B[91m-1.67%\u001B[0m)  |\n",
      "|          | 5e-05: acc: 80.69% (\u001B[92m+\u001B[0m\u001B[92m1.48%\u001B[0m), f1: 80.42% (\u001B[92m+\u001B[0m\u001B[92m1.52%\u001B[0m) | 5e-05: acc: 70.33% (\u001B[92m+\u001B[0m\u001B[92m10.8%\u001B[0m), f1: 66.26% (\u001B[92m+\u001B[0m\u001B[92m10.6%\u001B[0m)   | 5e-05: acc: 80.51% (\u001B[91m-0.24%\u001B[0m), f1: 80.74% (\u001B[91m-0.22%\u001B[0m) |\n",
      "+----------+--------------------------------------------------+----------------------------------------------------+--------------------------------------------------+\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "######################################## Main granularity: fine ########################################\n",
      "########################################################################################################\n",
      "\n",
      "Main model: Fine-grain vit_b_16, secondary granularity: coarse\n",
      "+----------+------------------------------------------+-------------------------------------------+-------------------------------------------+\n",
      "|          | main-lr=1e-05 (acc: 63.91%, f1: 63.5%)   | main-lr=1e-06 (acc: 69.96%, f1: 70.34%)   | main-lr=5e-05 (acc: 64.53%, f1: 65.01%)   |\n",
      "+==========+==========================================+===========================================+===========================================+\n",
      "| vit_b_32 | 1e-05: acc: 63.91% , f1: 63.5%           | 1e-05: acc: 69.96% , f1: 70.34%           | 1e-05: acc: 64.53% , f1: 65.01%           |\n",
      "|          | 1e-06: acc: 63.91% , f1: 63.5%           | 1e-06: acc: 69.96% , f1: 70.34%           | 1e-06: acc: 64.53% , f1: 65.01%           |\n",
      "|          | 5e-05: acc: 63.91% , f1: 63.5%           | 5e-05: acc: 69.96% , f1: 70.34%           | 5e-05: acc: 64.53% , f1: 65.01%           |\n",
      "+----------+------------------------------------------+-------------------------------------------+-------------------------------------------+\n",
      "| vit_l_16 | 1e-05: acc: 63.91% , f1: 63.5%           | 1e-05: acc: 69.96% , f1: 70.34%           | 1e-05: acc: 64.53% , f1: 65.01%           |\n",
      "|          | 1e-06: acc: 63.91% , f1: 63.5%           | 1e-06: acc: 69.96% , f1: 70.34%           | 1e-06: acc: 64.53% , f1: 65.01%           |\n",
      "|          | 5e-05: acc: 63.91% , f1: 63.5%           | 5e-05: acc: 69.96% , f1: 70.34%           | 5e-05: acc: 64.53% , f1: 65.01%           |\n",
      "+----------+------------------------------------------+-------------------------------------------+-------------------------------------------+\n",
      "| vit_l_32 | 1e-05: acc: 63.91% , f1: 63.5%           | 1e-05: acc: 69.96% , f1: 70.34%           | 1e-05: acc: 64.53% , f1: 65.01%           |\n",
      "|          | 1e-06: acc: 63.91% , f1: 63.5%           | 1e-06: acc: 69.96% , f1: 70.34%           | 1e-06: acc: 64.53% , f1: 65.01%           |\n",
      "|          | 5e-05: acc: 63.91% , f1: 63.5%           | 5e-05: acc: 69.96% , f1: 70.34%           | 5e-05: acc: 64.53% , f1: 65.01%           |\n",
      "+----------+------------------------------------------+-------------------------------------------+-------------------------------------------+\n",
      "\n",
      "\n",
      "Main model: Fine-grain vit_b_16, secondary granularity: fine\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "|          | main-lr=1e-05 (acc: 63.91%, f1: 63.5%)           | main-lr=1e-06 (acc: 69.96%, f1: 70.34%)          | main-lr=5e-05 (acc: 64.53%, f1: 65.01%)          |\n",
      "+==========+==================================================+==================================================+==================================================+\n",
      "| vit_b_32 | 1e-05: acc: 63.66% (\u001B[91m-0.25%\u001B[0m), f1: 63.32% (\u001B[91m-0.18%\u001B[0m) | 1e-05: acc: 69.96% , f1: 70.34%                  | 1e-05: acc: 64.53% , f1: 65.01%                  |\n",
      "|          | 1e-06: acc: 65.02% (\u001B[92m+\u001B[0m\u001B[92m1.11%\u001B[0m), f1: 64.72% (\u001B[92m+\u001B[0m\u001B[92m1.22%\u001B[0m) | 1e-06: acc: 70.02% (\u001B[92m+\u001B[0m\u001B[92m0.06%\u001B[0m), f1: 70.36% (\u001B[92m+\u001B[0m\u001B[92m0.02%\u001B[0m) | 1e-06: acc: 64.34% (\u001B[91m-0.19%\u001B[0m), f1: 64.81% (\u001B[91m-0.2%\u001B[0m)  |\n",
      "|          | 5e-05: acc: 63.85% (\u001B[91m-0.06%\u001B[0m), f1: 63.47% (\u001B[91m-0.03%\u001B[0m) | 5e-05: acc: 69.83% (\u001B[91m-0.13%\u001B[0m), f1: 70.2% (\u001B[91m-0.14%\u001B[0m)  | 5e-05: acc: 64.1% (\u001B[91m-0.43%\u001B[0m), f1: 64.62% (\u001B[91m-0.39%\u001B[0m)  |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "| vit_l_16 | 1e-05: acc: 65.45% (\u001B[92m+\u001B[0m\u001B[92m1.54%\u001B[0m), f1: 65.01% (\u001B[92m+\u001B[0m\u001B[92m1.51%\u001B[0m) | 1e-05: acc: 70.02% (\u001B[92m+\u001B[0m\u001B[92m0.06%\u001B[0m), f1: 70.41% (\u001B[92m+\u001B[0m\u001B[92m0.07%\u001B[0m) | 1e-05: acc: 64.96% (\u001B[92m+\u001B[0m\u001B[92m0.43%\u001B[0m), f1: 65.39% (\u001B[92m+\u001B[0m\u001B[92m0.38%\u001B[0m) |\n",
      "|          | 1e-06: acc: 66.07% (\u001B[92m+\u001B[0m\u001B[92m2.16%\u001B[0m), f1: 65.72% (\u001B[92m+\u001B[0m\u001B[92m2.22%\u001B[0m) | 1e-06: acc: 70.33% (\u001B[92m+\u001B[0m\u001B[92m0.37%\u001B[0m), f1: 70.64% (\u001B[92m+\u001B[0m\u001B[92m0.3%\u001B[0m)  | 1e-06: acc: 64.59% (\u001B[92m+\u001B[0m\u001B[92m0.06%\u001B[0m), f1: 65.04% (\u001B[92m+\u001B[0m\u001B[92m0.03%\u001B[0m) |\n",
      "|          | 5e-05: acc: 65.76% (\u001B[92m+\u001B[0m\u001B[92m1.85%\u001B[0m), f1: 65.42% (\u001B[92m+\u001B[0m\u001B[92m1.92%\u001B[0m) | 5e-05: acc: 70.57% (\u001B[92m+\u001B[0m\u001B[92m0.61%\u001B[0m), f1: 71.01% (\u001B[92m+\u001B[0m\u001B[92m0.67%\u001B[0m) | 5e-05: acc: 65.7% (\u001B[92m+\u001B[0m\u001B[92m1.17%\u001B[0m), f1: 66.49% (\u001B[92m+\u001B[0m\u001B[92m1.48%\u001B[0m)  |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "| vit_l_32 | 1e-05: acc: 64.22% (\u001B[92m+\u001B[0m\u001B[92m0.31%\u001B[0m), f1: 63.9% (\u001B[92m+\u001B[0m\u001B[92m0.4%\u001B[0m)   | 1e-05: acc: 69.9% (\u001B[91m-0.06%\u001B[0m), f1: 70.26% (\u001B[91m-0.08%\u001B[0m)  | 1e-05: acc: 64.71% (\u001B[92m+\u001B[0m\u001B[92m0.18%\u001B[0m), f1: 65.18% (\u001B[92m+\u001B[0m\u001B[92m0.17%\u001B[0m) |\n",
      "|          | 1e-06: acc: 64.9% (\u001B[92m+\u001B[0m\u001B[92m0.99%\u001B[0m), f1: 64.52% (\u001B[92m+\u001B[0m\u001B[92m1.02%\u001B[0m)  | 1e-06: acc: 69.96% , f1: 70.29% (\u001B[91m-0.05%\u001B[0m)         | 1e-06: acc: 64.77% (\u001B[92m+\u001B[0m\u001B[92m0.24%\u001B[0m), f1: 65.27% (\u001B[92m+\u001B[0m\u001B[92m0.26%\u001B[0m) |\n",
      "|          | 5e-05: acc: 64.22% (\u001B[92m+\u001B[0m\u001B[92m0.31%\u001B[0m), f1: 63.95% (\u001B[92m+\u001B[0m\u001B[92m0.45%\u001B[0m) | 5e-05: acc: 69.9% (\u001B[91m-0.06%\u001B[0m), f1: 70.29% (\u001B[91m-0.05%\u001B[0m)  | 5e-05: acc: 64.34% (\u001B[91m-0.19%\u001B[0m), f1: 64.86% (\u001B[91m-0.15%\u001B[0m) |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "\n",
      "\n",
      "Main model: Fine-grain vit_b_16 with both fine and coarse grain secondary models\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "|          | main-lr=1e-06 (acc: 69.96%, f1: 70.34%)          | main-lr=1e-05 (acc: 63.91%, f1: 63.5%)           | main-lr=5e-05 (acc: 64.53%, f1: 65.01%)          |\n",
      "+==========+==================================================+==================================================+==================================================+\n",
      "| vit_b_32 | 1e-05: acc: 62.99% (\u001B[91m-0.92%\u001B[0m), f1: 62.68% (\u001B[91m-0.82%\u001B[0m) | 1e-05: acc: 69.46% (\u001B[91m-0.5%\u001B[0m), f1: 69.91% (\u001B[91m-0.43%\u001B[0m)  | 1e-05: acc: 64.4% (\u001B[91m-0.13%\u001B[0m), f1: 64.84% (\u001B[91m-0.17%\u001B[0m)  |\n",
      "|          | 1e-06: acc: 65.21% (\u001B[92m+\u001B[0m\u001B[92m1.3%\u001B[0m), f1: 64.85% (\u001B[92m+\u001B[0m\u001B[92m1.35%\u001B[0m)  | 1e-06: acc: 69.83% (\u001B[91m-0.13%\u001B[0m), f1: 70.13% (\u001B[91m-0.21%\u001B[0m) | 1e-06: acc: 63.66% (\u001B[91m-0.87%\u001B[0m), f1: 63.98% (\u001B[91m-1.03%\u001B[0m) |\n",
      "|          | 5e-05: acc: 62.99% (\u001B[91m-0.92%\u001B[0m), f1: 62.63% (\u001B[91m-0.87%\u001B[0m) | 5e-05: acc: 69.83% (\u001B[91m-0.13%\u001B[0m), f1: 70.17% (\u001B[91m-0.17%\u001B[0m) | 5e-05: acc: 62.8% (\u001B[91m-1.73%\u001B[0m), f1: 63.04% (\u001B[91m-1.97%\u001B[0m)  |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "| vit_l_16 | 1e-05: acc: 66.93% (\u001B[92m+\u001B[0m\u001B[92m3.02%\u001B[0m), f1: 66.61% (\u001B[92m+\u001B[0m\u001B[92m3.11%\u001B[0m) | 1e-05: acc: 70.76% (\u001B[92m+\u001B[0m\u001B[92m0.8%\u001B[0m), f1: 71.21% (\u001B[92m+\u001B[0m\u001B[92m0.87%\u001B[0m)  | 1e-05: acc: 64.84% (\u001B[92m+\u001B[0m\u001B[92m0.31%\u001B[0m), f1: 65.21% (\u001B[92m+\u001B[0m\u001B[92m0.2%\u001B[0m)  |\n",
      "|          | 1e-06: acc: 68.17% (\u001B[92m+\u001B[0m\u001B[92m4.26%\u001B[0m), f1: 67.99% (\u001B[92m+\u001B[0m\u001B[92m4.49%\u001B[0m) | 1e-06: acc: 70.7% (\u001B[92m+\u001B[0m\u001B[92m0.74%\u001B[0m), f1: 70.89% (\u001B[92m+\u001B[0m\u001B[92m0.55%\u001B[0m)  | 1e-06: acc: 65.14% (\u001B[92m+\u001B[0m\u001B[92m0.61%\u001B[0m), f1: 65.19% (\u001B[92m+\u001B[0m\u001B[92m0.18%\u001B[0m) |\n",
      "|          | 5e-05: acc: 67.74% (\u001B[92m+\u001B[0m\u001B[92m3.83%\u001B[0m), f1: 67.53% (\u001B[92m+\u001B[0m\u001B[92m4.03%\u001B[0m) | 5e-05: acc: 71.75% (\u001B[92m+\u001B[0m\u001B[92m1.79%\u001B[0m), f1: 71.97% (\u001B[92m+\u001B[0m\u001B[92m1.63%\u001B[0m) | 5e-05: acc: 64.84% (\u001B[92m+\u001B[0m\u001B[92m0.31%\u001B[0m), f1: 65.81% (\u001B[92m+\u001B[0m\u001B[92m0.8%\u001B[0m)  |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "| vit_l_32 | 1e-05: acc: 64.22% (\u001B[92m+\u001B[0m\u001B[92m0.31%\u001B[0m), f1: 63.92% (\u001B[92m+\u001B[0m\u001B[92m0.42%\u001B[0m) | 1e-05: acc: 69.46% (\u001B[91m-0.5%\u001B[0m), f1: 69.82% (\u001B[91m-0.52%\u001B[0m)  | 1e-05: acc: 63.97% (\u001B[91m-0.56%\u001B[0m), f1: 64.4% (\u001B[91m-0.61%\u001B[0m)  |\n",
      "|          | 1e-06: acc: 65.33% (\u001B[92m+\u001B[0m\u001B[92m1.42%\u001B[0m), f1: 65.07% (\u001B[92m+\u001B[0m\u001B[92m1.57%\u001B[0m) | 1e-06: acc: 69.83% (\u001B[91m-0.13%\u001B[0m), f1: 70.12% (\u001B[91m-0.22%\u001B[0m) | 1e-06: acc: 65.08% (\u001B[92m+\u001B[0m\u001B[92m0.55%\u001B[0m), f1: 65.24% (\u001B[92m+\u001B[0m\u001B[92m0.23%\u001B[0m) |\n",
      "|          | 5e-05: acc: 64.34% (\u001B[92m+\u001B[0m\u001B[92m0.43%\u001B[0m), f1: 64.24% (\u001B[92m+\u001B[0m\u001B[92m0.74%\u001B[0m) | 5e-05: acc: 69.15% (\u001B[91m-0.81%\u001B[0m), f1: 69.69% (\u001B[91m-0.65%\u001B[0m) | 5e-05: acc: 64.03% (\u001B[91m-0.5%\u001B[0m), f1: 64.29% (\u001B[91m-0.72%\u001B[0m)  |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Main model: Fine-grain vit_b_32, secondary granularity: coarse\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+-------------------------------------------+\n",
      "|          | main-lr=1e-05 (acc: 55.89%, f1: 56.17%)          | main-lr=1e-06 (acc: 63.66%, f1: 64.1%)           | main-lr=5e-05 (acc: 53.73%, f1: 53.66%)   |\n",
      "+==========+==================================================+==================================================+===========================================+\n",
      "| vit_b_16 | 1e-05: acc: 55.89% , f1: 56.17%                  | 1e-05: acc: 63.66% , f1: 64.1%                   | 1e-05: acc: 53.73% , f1: 53.66%           |\n",
      "|          | 1e-06: acc: 55.89% , f1: 56.17%                  | 1e-06: acc: 63.66% , f1: 64.1%                   | 1e-06: acc: 53.73% , f1: 53.66%           |\n",
      "|          | 5e-05: acc: 55.89% , f1: 56.17%                  | 5e-05: acc: 63.66% , f1: 64.1%                   | 5e-05: acc: 53.73% , f1: 53.66%           |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+-------------------------------------------+\n",
      "| vit_l_16 | 1e-05: acc: 55.89% , f1: 56.17%                  | 1e-05: acc: 63.66% , f1: 64.1%                   | 1e-05: acc: 53.73% , f1: 53.66%           |\n",
      "|          | 1e-06: acc: 55.89% , f1: 56.17%                  | 1e-06: acc: 63.66% , f1: 64.1%                   | 1e-06: acc: 53.73% , f1: 53.66%           |\n",
      "|          | 5e-05: acc: 55.09% (\u001B[91m-0.8%\u001B[0m), f1: 55.55% (\u001B[91m-0.62%\u001B[0m)  | 5e-05: acc: 62.68% (\u001B[91m-0.98%\u001B[0m), f1: 63.24% (\u001B[91m-0.86%\u001B[0m) | 5e-05: acc: 53.73% , f1: 53.66%           |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+-------------------------------------------+\n",
      "| vit_l_32 | 1e-05: acc: 55.89% , f1: 56.17%                  | 1e-05: acc: 63.66% , f1: 64.1%                   | 1e-05: acc: 53.73% , f1: 53.66%           |\n",
      "|          | 1e-06: acc: 55.89% , f1: 56.17%                  | 1e-06: acc: 63.66% , f1: 64.1%                   | 1e-06: acc: 53.73% , f1: 53.66%           |\n",
      "|          | 5e-05: acc: 55.21% (\u001B[91m-0.68%\u001B[0m), f1: 55.69% (\u001B[91m-0.48%\u001B[0m) | 5e-05: acc: 62.99% (\u001B[91m-0.67%\u001B[0m), f1: 63.64% (\u001B[91m-0.46%\u001B[0m) | 5e-05: acc: 53.73% , f1: 53.66%           |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+-------------------------------------------+\n",
      "\n",
      "\n",
      "Main model: Fine-grain vit_b_32, secondary granularity: fine\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "|          | main-lr=1e-05 (acc: 55.89%, f1: 56.17%)          | main-lr=1e-06 (acc: 63.66%, f1: 64.1%)           | main-lr=5e-05 (acc: 53.73%, f1: 53.66%)          |\n",
      "+==========+==================================================+==================================================+==================================================+\n",
      "| vit_b_16 | 1e-05: acc: 58.17% (\u001B[92m+\u001B[0m\u001B[92m2.28%\u001B[0m), f1: 58.61% (\u001B[92m+\u001B[0m\u001B[92m2.44%\u001B[0m) | 1e-05: acc: 63.85% (\u001B[92m+\u001B[0m\u001B[92m0.19%\u001B[0m), f1: 64.38% (\u001B[92m+\u001B[0m\u001B[92m0.28%\u001B[0m) | 1e-05: acc: 55.03% (\u001B[92m+\u001B[0m\u001B[92m1.3%\u001B[0m), f1: 54.68% (\u001B[92m+\u001B[0m\u001B[92m1.02%\u001B[0m)  |\n",
      "|          | 1e-06: acc: 59.65% (\u001B[92m+\u001B[0m\u001B[92m3.76%\u001B[0m), f1: 59.85% (\u001B[92m+\u001B[0m\u001B[92m3.68%\u001B[0m) | 1e-06: acc: 65.82% (\u001B[92m+\u001B[0m\u001B[92m2.16%\u001B[0m), f1: 66.46% (\u001B[92m+\u001B[0m\u001B[92m2.36%\u001B[0m) | 1e-06: acc: 56.26% (\u001B[92m+\u001B[0m\u001B[92m2.53%\u001B[0m), f1: 55.46% (\u001B[92m+\u001B[0m\u001B[92m1.8%\u001B[0m)  |\n",
      "|          | 5e-05: acc: 58.48% (\u001B[92m+\u001B[0m\u001B[92m2.59%\u001B[0m), f1: 58.81% (\u001B[92m+\u001B[0m\u001B[92m2.64%\u001B[0m) | 5e-05: acc: 65.64% (\u001B[92m+\u001B[0m\u001B[92m1.98%\u001B[0m), f1: 66.18% (\u001B[92m+\u001B[0m\u001B[92m2.08%\u001B[0m) | 5e-05: acc: 58.17% (\u001B[92m+\u001B[0m\u001B[92m4.44%\u001B[0m), f1: 58.52% (\u001B[92m+\u001B[0m\u001B[92m4.86%\u001B[0m) |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "| vit_l_16 | 1e-05: acc: 60.09% (\u001B[92m+\u001B[0m\u001B[92m4.2%\u001B[0m), f1: 60.14% (\u001B[92m+\u001B[0m\u001B[92m3.97%\u001B[0m)  | 1e-05: acc: 64.34% (\u001B[92m+\u001B[0m\u001B[92m0.68%\u001B[0m), f1: 64.68% (\u001B[92m+\u001B[0m\u001B[92m0.58%\u001B[0m) | 1e-05: acc: 55.89% (\u001B[92m+\u001B[0m\u001B[92m2.16%\u001B[0m), f1: 55.27% (\u001B[92m+\u001B[0m\u001B[92m1.61%\u001B[0m) |\n",
      "|          | 1e-06: acc: 59.78% (\u001B[92m+\u001B[0m\u001B[92m3.89%\u001B[0m), f1: 60.01% (\u001B[92m+\u001B[0m\u001B[92m3.84%\u001B[0m) | 1e-06: acc: 64.28% (\u001B[92m+\u001B[0m\u001B[92m0.62%\u001B[0m), f1: 64.74% (\u001B[92m+\u001B[0m\u001B[92m0.64%\u001B[0m) | 1e-06: acc: 58.48% (\u001B[92m+\u001B[0m\u001B[92m4.75%\u001B[0m), f1: 57.94% (\u001B[92m+\u001B[0m\u001B[92m4.28%\u001B[0m) |\n",
      "|          | 5e-05: acc: 58.91% (\u001B[92m+\u001B[0m\u001B[92m3.02%\u001B[0m), f1: 59.08% (\u001B[92m+\u001B[0m\u001B[92m2.91%\u001B[0m) | 5e-05: acc: 64.77% (\u001B[92m+\u001B[0m\u001B[92m1.11%\u001B[0m), f1: 65.36% (\u001B[92m+\u001B[0m\u001B[92m1.26%\u001B[0m) | 5e-05: acc: 56.82% (\u001B[92m+\u001B[0m\u001B[92m3.09%\u001B[0m), f1: 57.14% (\u001B[92m+\u001B[0m\u001B[92m3.48%\u001B[0m) |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "| vit_l_32 | 1e-05: acc: 57.37% (\u001B[92m+\u001B[0m\u001B[92m1.48%\u001B[0m), f1: 57.78% (\u001B[92m+\u001B[0m\u001B[92m1.61%\u001B[0m) | 1e-05: acc: 63.85% (\u001B[92m+\u001B[0m\u001B[92m0.19%\u001B[0m), f1: 64.2% (\u001B[92m+\u001B[0m\u001B[92m0.1%\u001B[0m)   | 1e-05: acc: 54.72% (\u001B[92m+\u001B[0m\u001B[92m0.99%\u001B[0m), f1: 54.31% (\u001B[92m+\u001B[0m\u001B[92m0.65%\u001B[0m) |\n",
      "|          | 1e-06: acc: 58.3% (\u001B[92m+\u001B[0m\u001B[92m2.41%\u001B[0m), f1: 58.74% (\u001B[92m+\u001B[0m\u001B[92m2.57%\u001B[0m)  | 1e-06: acc: 64.1% (\u001B[92m+\u001B[0m\u001B[92m0.44%\u001B[0m), f1: 64.67% (\u001B[92m+\u001B[0m\u001B[92m0.57%\u001B[0m)  | 1e-06: acc: 54.97% (\u001B[92m+\u001B[0m\u001B[92m1.24%\u001B[0m), f1: 54.53% (\u001B[92m+\u001B[0m\u001B[92m0.87%\u001B[0m) |\n",
      "|          | 5e-05: acc: 56.45% (\u001B[92m+\u001B[0m\u001B[92m0.56%\u001B[0m), f1: 56.72% (\u001B[92m+\u001B[0m\u001B[92m0.55%\u001B[0m) | 5e-05: acc: 63.73% (\u001B[92m+\u001B[0m\u001B[92m0.07%\u001B[0m), f1: 64.15% (\u001B[92m+\u001B[0m\u001B[92m0.05%\u001B[0m) | 5e-05: acc: 54.66% (\u001B[92m+\u001B[0m\u001B[92m0.93%\u001B[0m), f1: 54.1% (\u001B[92m+\u001B[0m\u001B[92m0.44%\u001B[0m)  |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "\n",
      "\n",
      "Main model: Fine-grain vit_b_32 with both fine and coarse grain secondary models\n",
      "+----------+----------------------------------------------------+--------------------------------------------------+---------------------------------------------------+\n",
      "|          | main-lr=1e-06 (acc: 63.66%, f1: 64.1%)             | main-lr=1e-05 (acc: 55.89%, f1: 56.17%)          | main-lr=5e-05 (acc: 53.73%, f1: 53.66%)           |\n",
      "+==========+====================================================+==================================================+===================================================+\n",
      "| vit_b_16 | 1e-05: acc: 60.76% (\u001B[92m+\u001B[0m\u001B[92m4.87%\u001B[0m), f1: 60.8% (\u001B[92m+\u001B[0m\u001B[92m4.63%\u001B[0m)    | 1e-05: acc: 63.79% (\u001B[92m+\u001B[0m\u001B[92m0.13%\u001B[0m), f1: 63.9% (\u001B[91m-0.2%\u001B[0m)   | 1e-05: acc: 57.06% (\u001B[92m+\u001B[0m\u001B[92m3.33%\u001B[0m), f1: 55.88% (\u001B[92m+\u001B[0m\u001B[92m2.22%\u001B[0m)  |\n",
      "|          | 1e-06: acc: 69.22% (\u001B[92m+\u001B[0m\u001B[92m13.33%\u001B[0m), f1: 69.42% (\u001B[92m+\u001B[0m\u001B[92m13.25%\u001B[0m) | 1e-06: acc: 69.09% (\u001B[92m+\u001B[0m\u001B[92m5.43%\u001B[0m), f1: 69.63% (\u001B[92m+\u001B[0m\u001B[92m5.53%\u001B[0m) | 1e-06: acc: 61.88% (\u001B[92m+\u001B[0m\u001B[92m8.15%\u001B[0m), f1: 60.17% (\u001B[92m+\u001B[0m\u001B[92m6.51%\u001B[0m)  |\n",
      "|          | 5e-05: acc: 62.8% (\u001B[92m+\u001B[0m\u001B[92m6.91%\u001B[0m), f1: 62.94% (\u001B[92m+\u001B[0m\u001B[92m6.77%\u001B[0m)    | 5e-05: acc: 67.18% (\u001B[92m+\u001B[0m\u001B[92m3.52%\u001B[0m), f1: 67.61% (\u001B[92m+\u001B[0m\u001B[92m3.51%\u001B[0m) | 5e-05: acc: 63.73% (\u001B[92m+\u001B[0m\u001B[92m10.0%\u001B[0m), f1: 63.18% (\u001B[92m+\u001B[0m\u001B[92m9.52%\u001B[0m)  |\n",
      "+----------+----------------------------------------------------+--------------------------------------------------+---------------------------------------------------+\n",
      "| vit_l_16 | 1e-05: acc: 65.7% (\u001B[92m+\u001B[0m\u001B[92m9.81%\u001B[0m), f1: 65.81% (\u001B[92m+\u001B[0m\u001B[92m9.64%\u001B[0m)    | 1e-05: acc: 67.67% (\u001B[92m+\u001B[0m\u001B[92m4.01%\u001B[0m), f1: 67.72% (\u001B[92m+\u001B[0m\u001B[92m3.62%\u001B[0m) | 1e-05: acc: 61.51% (\u001B[92m+\u001B[0m\u001B[92m7.78%\u001B[0m), f1: 59.87% (\u001B[92m+\u001B[0m\u001B[92m6.21%\u001B[0m)  |\n",
      "|          | 1e-06: acc: 69.22% (\u001B[92m+\u001B[0m\u001B[92m13.33%\u001B[0m), f1: 69.55% (\u001B[92m+\u001B[0m\u001B[92m13.38%\u001B[0m) | 1e-06: acc: 68.66% (\u001B[92m+\u001B[0m\u001B[92m5.0%\u001B[0m), f1: 68.81% (\u001B[92m+\u001B[0m\u001B[92m4.71%\u001B[0m)  | 1e-06: acc: 64.84% (\u001B[92m+\u001B[0m\u001B[92m11.11%\u001B[0m), f1: 63.61% (\u001B[92m+\u001B[0m\u001B[92m9.95%\u001B[0m) |\n",
      "|          | 5e-05: acc: 65.64% (\u001B[92m+\u001B[0m\u001B[92m9.75%\u001B[0m), f1: 66.07% (\u001B[92m+\u001B[0m\u001B[92m9.9%\u001B[0m)    | 5e-05: acc: 67.24% (\u001B[92m+\u001B[0m\u001B[92m3.58%\u001B[0m), f1: 67.55% (\u001B[92m+\u001B[0m\u001B[92m3.45%\u001B[0m) | 5e-05: acc: 62.12% (\u001B[92m+\u001B[0m\u001B[92m8.39%\u001B[0m), f1: 61.49% (\u001B[92m+\u001B[0m\u001B[92m7.83%\u001B[0m)  |\n",
      "+----------+----------------------------------------------------+--------------------------------------------------+---------------------------------------------------+\n",
      "| vit_l_32 | 1e-05: acc: 58.91% (\u001B[92m+\u001B[0m\u001B[92m3.02%\u001B[0m), f1: 59.36% (\u001B[92m+\u001B[0m\u001B[92m3.19%\u001B[0m)   | 1e-05: acc: 63.73% (\u001B[92m+\u001B[0m\u001B[92m0.07%\u001B[0m), f1: 64.04% (\u001B[91m-0.06%\u001B[0m) | 1e-05: acc: 55.52% (\u001B[92m+\u001B[0m\u001B[92m1.79%\u001B[0m), f1: 54.68% (\u001B[92m+\u001B[0m\u001B[92m1.02%\u001B[0m)  |\n",
      "|          | 1e-06: acc: 63.17% (\u001B[92m+\u001B[0m\u001B[92m7.28%\u001B[0m), f1: 63.11% (\u001B[92m+\u001B[0m\u001B[92m6.94%\u001B[0m)   | 1e-06: acc: 65.89% (\u001B[92m+\u001B[0m\u001B[92m2.23%\u001B[0m), f1: 66.09% (\u001B[92m+\u001B[0m\u001B[92m1.99%\u001B[0m) | 1e-06: acc: 59.53% (\u001B[92m+\u001B[0m\u001B[92m5.8%\u001B[0m), f1: 58.03% (\u001B[92m+\u001B[0m\u001B[92m4.37%\u001B[0m)   |\n",
      "|          | 5e-05: acc: 59.72% (\u001B[92m+\u001B[0m\u001B[92m3.83%\u001B[0m), f1: 59.48% (\u001B[92m+\u001B[0m\u001B[92m3.31%\u001B[0m)   | 5e-05: acc: 64.16% (\u001B[92m+\u001B[0m\u001B[92m0.5%\u001B[0m), f1: 64.13% (\u001B[92m+\u001B[0m\u001B[92m0.03%\u001B[0m)  | 5e-05: acc: 56.94% (\u001B[92m+\u001B[0m\u001B[92m3.21%\u001B[0m), f1: 55.78% (\u001B[92m+\u001B[0m\u001B[92m2.12%\u001B[0m)  |\n",
      "+----------+----------------------------------------------------+--------------------------------------------------+---------------------------------------------------+\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Main model: Fine-grain vit_l_16, secondary granularity: coarse\n",
      "+----------+-------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "|          | main-lr=1e-05 (acc: 69.96%, f1: 70.44%)   | main-lr=1e-06 (acc: 70.27%, f1: 70.92%)          | main-lr=5e-05 (acc: 66.19%, f1: 67.18%)          |\n",
      "+==========+===========================================+==================================================+==================================================+\n",
      "| vit_b_16 | 1e-05: acc: 69.96% , f1: 70.44%           | 1e-05: acc: 70.27% , f1: 70.92%                  | 1e-05: acc: 65.02% (\u001B[91m-1.17%\u001B[0m), f1: 66.25% (\u001B[91m-0.93%\u001B[0m) |\n",
      "|          | 1e-06: acc: 69.96% , f1: 70.44%           | 1e-06: acc: 70.27% , f1: 70.92%                  | 1e-06: acc: 66.19% , f1: 67.18%                  |\n",
      "|          | 5e-05: acc: 69.96% , f1: 70.44%           | 5e-05: acc: 70.27% , f1: 70.92%                  | 5e-05: acc: 66.19% , f1: 67.18%                  |\n",
      "+----------+-------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "| vit_b_32 | 1e-05: acc: 69.96% , f1: 70.44%           | 1e-05: acc: 70.27% , f1: 70.92%                  | 1e-05: acc: 65.39% (\u001B[91m-0.8%\u001B[0m), f1: 66.56% (\u001B[91m-0.62%\u001B[0m)  |\n",
      "|          | 1e-06: acc: 69.96% , f1: 70.44%           | 1e-06: acc: 70.27% , f1: 70.92%                  | 1e-06: acc: 66.19% , f1: 67.18%                  |\n",
      "|          | 5e-05: acc: 69.96% , f1: 70.44%           | 5e-05: acc: 69.59% (\u001B[91m-0.68%\u001B[0m), f1: 70.43% (\u001B[91m-0.49%\u001B[0m) | 5e-05: acc: 65.64% (\u001B[91m-0.55%\u001B[0m), f1: 66.74% (\u001B[91m-0.44%\u001B[0m) |\n",
      "+----------+-------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "| vit_l_32 | 1e-05: acc: 69.96% , f1: 70.44%           | 1e-05: acc: 70.27% , f1: 70.92%                  | 1e-05: acc: 66.19% , f1: 67.18%                  |\n",
      "|          | 1e-06: acc: 69.96% , f1: 70.44%           | 1e-06: acc: 70.27% , f1: 70.92%                  | 1e-06: acc: 66.19% , f1: 67.18%                  |\n",
      "|          | 5e-05: acc: 69.96% , f1: 70.44%           | 5e-05: acc: 70.27% , f1: 70.92%                  | 5e-05: acc: 65.21% (\u001B[91m-0.98%\u001B[0m), f1: 66.47% (\u001B[91m-0.71%\u001B[0m) |\n",
      "+----------+-------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "\n",
      "\n",
      "Main model: Fine-grain vit_l_16, secondary granularity: fine\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "|          | main-lr=1e-05 (acc: 69.96%, f1: 70.44%)          | main-lr=1e-06 (acc: 70.27%, f1: 70.92%)          | main-lr=5e-05 (acc: 66.19%, f1: 67.18%)          |\n",
      "+==========+==================================================+==================================================+==================================================+\n",
      "| vit_b_16 | 1e-05: acc: 70.02% (\u001B[92m+\u001B[0m\u001B[92m0.06%\u001B[0m), f1: 70.49% (\u001B[92m+\u001B[0m\u001B[92m0.05%\u001B[0m) | 1e-05: acc: 70.02% (\u001B[91m-0.25%\u001B[0m), f1: 70.76% (\u001B[91m-0.16%\u001B[0m) | 1e-05: acc: 66.5% (\u001B[92m+\u001B[0m\u001B[92m0.31%\u001B[0m), f1: 67.49% (\u001B[92m+\u001B[0m\u001B[92m0.31%\u001B[0m)  |\n",
      "|          | 1e-06: acc: 69.9% (\u001B[91m-0.06%\u001B[0m), f1: 70.38% (\u001B[91m-0.06%\u001B[0m)  | 1e-06: acc: 71.44% (\u001B[92m+\u001B[0m\u001B[92m1.17%\u001B[0m), f1: 72.08% (\u001B[92m+\u001B[0m\u001B[92m1.16%\u001B[0m) | 1e-06: acc: 67.12% (\u001B[92m+\u001B[0m\u001B[92m0.93%\u001B[0m), f1: 67.94% (\u001B[92m+\u001B[0m\u001B[92m0.76%\u001B[0m) |\n",
      "|          | 5e-05: acc: 70.14% (\u001B[92m+\u001B[0m\u001B[92m0.18%\u001B[0m), f1: 70.62% (\u001B[92m+\u001B[0m\u001B[92m0.18%\u001B[0m) | 5e-05: acc: 70.94% (\u001B[92m+\u001B[0m\u001B[92m0.67%\u001B[0m), f1: 71.56% (\u001B[92m+\u001B[0m\u001B[92m0.64%\u001B[0m) | 5e-05: acc: 67.18% (\u001B[92m+\u001B[0m\u001B[92m0.99%\u001B[0m), f1: 68.07% (\u001B[92m+\u001B[0m\u001B[92m0.89%\u001B[0m) |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "| vit_b_32 | 1e-05: acc: 69.96% , f1: 70.44%                  | 1e-05: acc: 70.27% , f1: 70.92%                  | 1e-05: acc: 65.64% (\u001B[91m-0.55%\u001B[0m), f1: 66.66% (\u001B[91m-0.52%\u001B[0m) |\n",
      "|          | 1e-06: acc: 70.02% (\u001B[92m+\u001B[0m\u001B[92m0.06%\u001B[0m), f1: 70.44%          | 1e-06: acc: 71.07% (\u001B[92m+\u001B[0m\u001B[92m0.8%\u001B[0m), f1: 71.71% (\u001B[92m+\u001B[0m\u001B[92m0.79%\u001B[0m)  | 1e-06: acc: 65.7% (\u001B[91m-0.49%\u001B[0m), f1: 66.75% (\u001B[91m-0.43%\u001B[0m)  |\n",
      "|          | 5e-05: acc: 69.83% (\u001B[91m-0.13%\u001B[0m), f1: 70.28% (\u001B[91m-0.16%\u001B[0m) | 5e-05: acc: 70.39% (\u001B[92m+\u001B[0m\u001B[92m0.12%\u001B[0m), f1: 71.02% (\u001B[92m+\u001B[0m\u001B[92m0.1%\u001B[0m)  | 5e-05: acc: 65.82% (\u001B[91m-0.37%\u001B[0m), f1: 66.87% (\u001B[91m-0.31%\u001B[0m) |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "| vit_l_32 | 1e-05: acc: 69.96% , f1: 70.45% (\u001B[92m+\u001B[0m\u001B[92m0.01%\u001B[0m)         | 1e-05: acc: 71.19% (\u001B[92m+\u001B[0m\u001B[92m0.92%\u001B[0m), f1: 71.81% (\u001B[92m+\u001B[0m\u001B[92m0.89%\u001B[0m) | 1e-05: acc: 66.63% (\u001B[92m+\u001B[0m\u001B[92m0.44%\u001B[0m), f1: 67.53% (\u001B[92m+\u001B[0m\u001B[92m0.35%\u001B[0m) |\n",
      "|          | 1e-06: acc: 70.2% (\u001B[92m+\u001B[0m\u001B[92m0.24%\u001B[0m), f1: 70.68% (\u001B[92m+\u001B[0m\u001B[92m0.24%\u001B[0m)  | 1e-06: acc: 70.7% (\u001B[92m+\u001B[0m\u001B[92m0.43%\u001B[0m), f1: 71.25% (\u001B[92m+\u001B[0m\u001B[92m0.33%\u001B[0m)  | 1e-06: acc: 66.69% (\u001B[92m+\u001B[0m\u001B[92m0.5%\u001B[0m), f1: 67.6% (\u001B[92m+\u001B[0m\u001B[92m0.42%\u001B[0m)   |\n",
      "|          | 5e-05: acc: 69.71% (\u001B[91m-0.25%\u001B[0m), f1: 70.15% (\u001B[91m-0.29%\u001B[0m) | 5e-05: acc: 70.57% (\u001B[92m+\u001B[0m\u001B[92m0.3%\u001B[0m), f1: 71.27% (\u001B[92m+\u001B[0m\u001B[92m0.35%\u001B[0m)  | 5e-05: acc: 66.07% (\u001B[91m-0.12%\u001B[0m), f1: 67.03% (\u001B[91m-0.15%\u001B[0m) |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "\n",
      "\n",
      "Main model: Fine-grain vit_l_16 with both fine and coarse grain secondary models\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "|          | main-lr=1e-06 (acc: 70.27%, f1: 70.92%)          | main-lr=1e-05 (acc: 69.96%, f1: 70.44%)          | main-lr=5e-05 (acc: 66.19%, f1: 67.18%)          |\n",
      "+==========+==================================================+==================================================+==================================================+\n",
      "| vit_b_16 | 1e-05: acc: 69.52% (\u001B[91m-0.44%\u001B[0m), f1: 69.93% (\u001B[91m-0.51%\u001B[0m) | 1e-05: acc: 69.28% (\u001B[91m-0.99%\u001B[0m), f1: 70.03% (\u001B[91m-0.89%\u001B[0m) | 1e-05: acc: 65.52% (\u001B[91m-0.67%\u001B[0m), f1: 66.63% (\u001B[91m-0.55%\u001B[0m) |\n",
      "|          | 1e-06: acc: 70.7% (\u001B[92m+\u001B[0m\u001B[92m0.74%\u001B[0m), f1: 71.17% (\u001B[92m+\u001B[0m\u001B[92m0.73%\u001B[0m)  | 1e-06: acc: 71.75% (\u001B[92m+\u001B[0m\u001B[92m1.48%\u001B[0m), f1: 72.37% (\u001B[92m+\u001B[0m\u001B[92m1.45%\u001B[0m) | 1e-06: acc: 68.04% (\u001B[92m+\u001B[0m\u001B[92m1.85%\u001B[0m), f1: 68.73% (\u001B[92m+\u001B[0m\u001B[92m1.55%\u001B[0m) |\n",
      "|          | 5e-05: acc: 70.27% (\u001B[92m+\u001B[0m\u001B[92m0.31%\u001B[0m), f1: 70.74% (\u001B[92m+\u001B[0m\u001B[92m0.3%\u001B[0m)  | 5e-05: acc: 70.82% (\u001B[92m+\u001B[0m\u001B[92m0.55%\u001B[0m), f1: 71.4% (\u001B[92m+\u001B[0m\u001B[92m0.48%\u001B[0m)  | 5e-05: acc: 67.18% (\u001B[92m+\u001B[0m\u001B[92m0.99%\u001B[0m), f1: 67.94% (\u001B[92m+\u001B[0m\u001B[92m0.76%\u001B[0m) |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "| vit_b_32 | 1e-05: acc: 69.96% , f1: 70.38% (\u001B[91m-0.06%\u001B[0m)         | 1e-05: acc: 69.46% (\u001B[91m-0.81%\u001B[0m), f1: 70.19% (\u001B[91m-0.73%\u001B[0m) | 1e-05: acc: 64.84% (\u001B[91m-1.35%\u001B[0m), f1: 65.72% (\u001B[91m-1.46%\u001B[0m) |\n",
      "|          | 1e-06: acc: 69.83% (\u001B[91m-0.13%\u001B[0m), f1: 70.28% (\u001B[91m-0.16%\u001B[0m) | 1e-06: acc: 69.9% (\u001B[91m-0.37%\u001B[0m), f1: 70.66% (\u001B[91m-0.26%\u001B[0m)  | 1e-06: acc: 64.65% (\u001B[91m-1.54%\u001B[0m), f1: 65.55% (\u001B[91m-1.63%\u001B[0m) |\n",
      "|          | 5e-05: acc: 69.83% (\u001B[91m-0.13%\u001B[0m), f1: 70.17% (\u001B[91m-0.27%\u001B[0m) | 5e-05: acc: 69.59% (\u001B[91m-0.68%\u001B[0m), f1: 70.41% (\u001B[91m-0.51%\u001B[0m) | 5e-05: acc: 64.16% (\u001B[91m-2.03%\u001B[0m), f1: 64.94% (\u001B[91m-2.24%\u001B[0m) |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "| vit_l_32 | 1e-05: acc: 69.96% , f1: 70.46% (\u001B[92m+\u001B[0m\u001B[92m0.02%\u001B[0m)         | 1e-05: acc: 70.7% (\u001B[92m+\u001B[0m\u001B[92m0.43%\u001B[0m), f1: 71.38% (\u001B[92m+\u001B[0m\u001B[92m0.46%\u001B[0m)  | 1e-05: acc: 65.14% (\u001B[91m-1.05%\u001B[0m), f1: 66.24% (\u001B[91m-0.94%\u001B[0m) |\n",
      "|          | 1e-06: acc: 69.77% (\u001B[91m-0.19%\u001B[0m), f1: 70.37% (\u001B[91m-0.07%\u001B[0m) | 1e-06: acc: 70.02% (\u001B[91m-0.25%\u001B[0m), f1: 70.73% (\u001B[91m-0.19%\u001B[0m) | 1e-06: acc: 65.89% (\u001B[91m-0.3%\u001B[0m), f1: 66.83% (\u001B[91m-0.35%\u001B[0m)  |\n",
      "|          | 5e-05: acc: 69.22% (\u001B[91m-0.74%\u001B[0m), f1: 69.65% (\u001B[91m-0.79%\u001B[0m) | 5e-05: acc: 70.2% (\u001B[91m-0.07%\u001B[0m), f1: 70.9% (\u001B[91m-0.02%\u001B[0m)   | 5e-05: acc: 63.66% (\u001B[91m-2.53%\u001B[0m), f1: 64.86% (\u001B[91m-2.32%\u001B[0m) |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "Main model: Fine-grain vit_l_32, secondary granularity: coarse\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+-------------------------------------------+\n",
      "|          | main-lr=1e-05 (acc: 58.24%, f1: 58.34%)          | main-lr=1e-06 (acc: 67.3%, f1: 67.79%)           | main-lr=5e-05 (acc: 62.43%, f1: 62.04%)   |\n",
      "+==========+==================================================+==================================================+===========================================+\n",
      "| vit_b_16 | 1e-05: acc: 57.87% (\u001B[91m-0.37%\u001B[0m), f1: 57.84% (\u001B[91m-0.5%\u001B[0m)  | 1e-05: acc: 67.3% , f1: 67.79%                   | 1e-05: acc: 62.43% , f1: 62.04%           |\n",
      "|          | 1e-06: acc: 58.24% , f1: 58.34%                  | 1e-06: acc: 67.3% , f1: 67.79%                   | 1e-06: acc: 62.43% , f1: 62.04%           |\n",
      "|          | 5e-05: acc: 57.87% (\u001B[91m-0.37%\u001B[0m), f1: 57.85% (\u001B[91m-0.49%\u001B[0m) | 5e-05: acc: 67.3% , f1: 67.79%                   | 5e-05: acc: 62.43% , f1: 62.04%           |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+-------------------------------------------+\n",
      "| vit_b_32 | 1e-05: acc: 57.99% (\u001B[91m-0.25%\u001B[0m), f1: 58.07% (\u001B[91m-0.27%\u001B[0m) | 1e-05: acc: 67.3% , f1: 67.79%                   | 1e-05: acc: 62.43% , f1: 62.04%           |\n",
      "|          | 1e-06: acc: 58.24% , f1: 58.34%                  | 1e-06: acc: 67.3% , f1: 67.79%                   | 1e-06: acc: 62.43% , f1: 62.04%           |\n",
      "|          | 5e-05: acc: 58.24% , f1: 58.32% (\u001B[91m-0.02%\u001B[0m)         | 5e-05: acc: 66.75% (\u001B[91m-0.55%\u001B[0m), f1: 67.36% (\u001B[91m-0.43%\u001B[0m) | 5e-05: acc: 62.43% , f1: 62.04%           |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+-------------------------------------------+\n",
      "| vit_l_16 | 1e-05: acc: 57.37% (\u001B[91m-0.87%\u001B[0m), f1: 57.53% (\u001B[91m-0.81%\u001B[0m) | 1e-05: acc: 67.3% , f1: 67.79%                   | 1e-05: acc: 62.43% , f1: 62.04%           |\n",
      "|          | 1e-06: acc: 58.24% , f1: 58.34%                  | 1e-06: acc: 67.3% , f1: 67.79%                   | 1e-06: acc: 62.43% , f1: 62.04%           |\n",
      "|          | 5e-05: acc: 57.74% (\u001B[91m-0.5%\u001B[0m), f1: 57.7% (\u001B[91m-0.64%\u001B[0m)   | 5e-05: acc: 67.3% , f1: 67.79%                   | 5e-05: acc: 62.43% , f1: 62.04%           |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+-------------------------------------------+\n",
      "\n",
      "\n",
      "Main model: Fine-grain vit_l_32, secondary granularity: fine\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "|          | main-lr=1e-05 (acc: 58.24%, f1: 58.34%)          | main-lr=1e-06 (acc: 67.3%, f1: 67.79%)           | main-lr=5e-05 (acc: 62.43%, f1: 62.04%)          |\n",
      "+==========+==================================================+==================================================+==================================================+\n",
      "| vit_b_16 | 1e-05: acc: 58.48% (\u001B[92m+\u001B[0m\u001B[92m0.24%\u001B[0m), f1: 58.51% (\u001B[92m+\u001B[0m\u001B[92m0.17%\u001B[0m) | 1e-05: acc: 67.43% (\u001B[92m+\u001B[0m\u001B[92m0.13%\u001B[0m), f1: 67.97% (\u001B[92m+\u001B[0m\u001B[92m0.18%\u001B[0m) | 1e-05: acc: 62.74% (\u001B[92m+\u001B[0m\u001B[92m0.31%\u001B[0m), f1: 62.36% (\u001B[92m+\u001B[0m\u001B[92m0.32%\u001B[0m) |\n",
      "|          | 1e-06: acc: 61.07% (\u001B[92m+\u001B[0m\u001B[92m2.83%\u001B[0m), f1: 61.12% (\u001B[92m+\u001B[0m\u001B[92m2.78%\u001B[0m) | 1e-06: acc: 68.04% (\u001B[92m+\u001B[0m\u001B[92m0.74%\u001B[0m), f1: 68.57% (\u001B[92m+\u001B[0m\u001B[92m0.78%\u001B[0m) | 1e-06: acc: 65.02% (\u001B[92m+\u001B[0m\u001B[92m2.59%\u001B[0m), f1: 64.93% (\u001B[92m+\u001B[0m\u001B[92m2.89%\u001B[0m) |\n",
      "|          | 5e-05: acc: 60.15% (\u001B[92m+\u001B[0m\u001B[92m1.91%\u001B[0m), f1: 60.28% (\u001B[92m+\u001B[0m\u001B[92m1.94%\u001B[0m) | 5e-05: acc: 67.55% (\u001B[92m+\u001B[0m\u001B[92m0.25%\u001B[0m), f1: 68.06% (\u001B[92m+\u001B[0m\u001B[92m0.27%\u001B[0m) | 5e-05: acc: 63.91% (\u001B[92m+\u001B[0m\u001B[92m1.48%\u001B[0m), f1: 63.74% (\u001B[92m+\u001B[0m\u001B[92m1.7%\u001B[0m)  |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "| vit_b_32 | 1e-05: acc: 57.99% (\u001B[91m-0.25%\u001B[0m), f1: 58.2% (\u001B[91m-0.14%\u001B[0m)  | 1e-05: acc: 67.12% (\u001B[91m-0.18%\u001B[0m), f1: 67.6% (\u001B[91m-0.19%\u001B[0m)  | 1e-05: acc: 61.69% (\u001B[91m-0.74%\u001B[0m), f1: 61.36% (\u001B[91m-0.68%\u001B[0m) |\n",
      "|          | 1e-06: acc: 59.41% (\u001B[92m+\u001B[0m\u001B[92m1.17%\u001B[0m), f1: 59.66% (\u001B[92m+\u001B[0m\u001B[92m1.32%\u001B[0m) | 1e-06: acc: 67.12% (\u001B[91m-0.18%\u001B[0m), f1: 67.54% (\u001B[91m-0.25%\u001B[0m) | 1e-06: acc: 63.91% (\u001B[92m+\u001B[0m\u001B[92m1.48%\u001B[0m), f1: 63.75% (\u001B[92m+\u001B[0m\u001B[92m1.71%\u001B[0m) |\n",
      "|          | 5e-05: acc: 58.61% (\u001B[92m+\u001B[0m\u001B[92m0.37%\u001B[0m), f1: 58.74% (\u001B[92m+\u001B[0m\u001B[92m0.4%\u001B[0m)  | 5e-05: acc: 67.06% (\u001B[91m-0.24%\u001B[0m), f1: 67.5% (\u001B[91m-0.29%\u001B[0m)  | 5e-05: acc: 62.68% (\u001B[92m+\u001B[0m\u001B[92m0.25%\u001B[0m), f1: 62.46% (\u001B[92m+\u001B[0m\u001B[92m0.42%\u001B[0m) |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "| vit_l_16 | 1e-05: acc: 60.46% (\u001B[92m+\u001B[0m\u001B[92m2.22%\u001B[0m), f1: 60.42% (\u001B[92m+\u001B[0m\u001B[92m2.08%\u001B[0m) | 1e-05: acc: 67.8% (\u001B[92m+\u001B[0m\u001B[92m0.5%\u001B[0m), f1: 68.16% (\u001B[92m+\u001B[0m\u001B[92m0.37%\u001B[0m)   | 1e-05: acc: 63.6% (\u001B[92m+\u001B[0m\u001B[92m1.17%\u001B[0m), f1: 63.24% (\u001B[92m+\u001B[0m\u001B[92m1.2%\u001B[0m)   |\n",
      "|          | 1e-06: acc: 60.64% (\u001B[92m+\u001B[0m\u001B[92m2.4%\u001B[0m), f1: 60.6% (\u001B[92m+\u001B[0m\u001B[92m2.26%\u001B[0m)   | 1e-06: acc: 68.29% (\u001B[92m+\u001B[0m\u001B[92m0.99%\u001B[0m), f1: 68.79% (\u001B[92m+\u001B[0m\u001B[92m1.0%\u001B[0m)  | 1e-06: acc: 63.73% (\u001B[92m+\u001B[0m\u001B[92m1.3%\u001B[0m), f1: 63.15% (\u001B[92m+\u001B[0m\u001B[92m1.11%\u001B[0m)  |\n",
      "|          | 5e-05: acc: 61.07% (\u001B[92m+\u001B[0m\u001B[92m2.83%\u001B[0m), f1: 61.16% (\u001B[92m+\u001B[0m\u001B[92m2.82%\u001B[0m) | 5e-05: acc: 67.43% (\u001B[92m+\u001B[0m\u001B[92m0.13%\u001B[0m), f1: 68.03% (\u001B[92m+\u001B[0m\u001B[92m0.24%\u001B[0m) | 5e-05: acc: 64.28% (\u001B[92m+\u001B[0m\u001B[92m1.85%\u001B[0m), f1: 64.23% (\u001B[92m+\u001B[0m\u001B[92m2.19%\u001B[0m) |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "\n",
      "\n",
      "Main model: Fine-grain vit_l_32 with both fine and coarse grain secondary models\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "|          | main-lr=1e-06 (acc: 67.3%, f1: 67.79%)           | main-lr=1e-05 (acc: 58.24%, f1: 58.34%)          | main-lr=5e-05 (acc: 62.43%, f1: 62.04%)          |\n",
      "+==========+==================================================+==================================================+==================================================+\n",
      "| vit_b_16 | 1e-05: acc: 58.61% (\u001B[92m+\u001B[0m\u001B[92m0.37%\u001B[0m), f1: 57.96% (\u001B[91m-0.38%\u001B[0m) | 1e-05: acc: 67.61% (\u001B[92m+\u001B[0m\u001B[92m0.31%\u001B[0m), f1: 68.1% (\u001B[92m+\u001B[0m\u001B[92m0.31%\u001B[0m)  | 1e-05: acc: 63.48% (\u001B[92m+\u001B[0m\u001B[92m1.05%\u001B[0m), f1: 62.55% (\u001B[92m+\u001B[0m\u001B[92m0.51%\u001B[0m) |\n",
      "|          | 1e-06: acc: 66.93% (\u001B[92m+\u001B[0m\u001B[92m8.69%\u001B[0m), f1: 67.3% (\u001B[92m+\u001B[0m\u001B[92m8.96%\u001B[0m)  | 1e-06: acc: 69.83% (\u001B[92m+\u001B[0m\u001B[92m2.53%\u001B[0m), f1: 70.35% (\u001B[92m+\u001B[0m\u001B[92m2.56%\u001B[0m) | 1e-06: acc: 67.98% (\u001B[92m+\u001B[0m\u001B[92m5.55%\u001B[0m), f1: 67.73% (\u001B[92m+\u001B[0m\u001B[92m5.69%\u001B[0m) |\n",
      "|          | 5e-05: acc: 64.34% (\u001B[92m+\u001B[0m\u001B[92m6.1%\u001B[0m), f1: 64.06% (\u001B[92m+\u001B[0m\u001B[92m5.72%\u001B[0m)  | 5e-05: acc: 67.92% (\u001B[92m+\u001B[0m\u001B[92m0.62%\u001B[0m), f1: 68.49% (\u001B[92m+\u001B[0m\u001B[92m0.7%\u001B[0m)  | 5e-05: acc: 63.66% (\u001B[92m+\u001B[0m\u001B[92m1.23%\u001B[0m), f1: 63.44% (\u001B[92m+\u001B[0m\u001B[92m1.4%\u001B[0m)  |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "| vit_b_32 | 1e-05: acc: 58.3% (\u001B[92m+\u001B[0m\u001B[92m0.06%\u001B[0m), f1: 58.47% (\u001B[92m+\u001B[0m\u001B[92m0.13%\u001B[0m)  | 1e-05: acc: 66.93% (\u001B[91m-0.37%\u001B[0m), f1: 67.35% (\u001B[91m-0.44%\u001B[0m) | 1e-05: acc: 61.57% (\u001B[91m-0.86%\u001B[0m), f1: 61.0% (\u001B[91m-1.04%\u001B[0m)  |\n",
      "|          | 1e-06: acc: 61.01% (\u001B[92m+\u001B[0m\u001B[92m2.77%\u001B[0m), f1: 61.07% (\u001B[92m+\u001B[0m\u001B[92m2.73%\u001B[0m) | 1e-06: acc: 67.18% (\u001B[91m-0.12%\u001B[0m), f1: 67.64% (\u001B[91m-0.15%\u001B[0m) | 1e-06: acc: 64.53% (\u001B[92m+\u001B[0m\u001B[92m2.1%\u001B[0m), f1: 64.3% (\u001B[92m+\u001B[0m\u001B[92m2.26%\u001B[0m)   |\n",
      "|          | 5e-05: acc: 58.91% (\u001B[92m+\u001B[0m\u001B[92m0.67%\u001B[0m), f1: 58.76% (\u001B[92m+\u001B[0m\u001B[92m0.42%\u001B[0m) | 5e-05: acc: 66.07% (\u001B[91m-1.23%\u001B[0m), f1: 66.67% (\u001B[91m-1.12%\u001B[0m) | 5e-05: acc: 62.0% (\u001B[91m-0.43%\u001B[0m), f1: 61.66% (\u001B[91m-0.38%\u001B[0m)  |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "| vit_l_16 | 1e-05: acc: 66.87% (\u001B[92m+\u001B[0m\u001B[92m8.63%\u001B[0m), f1: 66.69% (\u001B[92m+\u001B[0m\u001B[92m8.35%\u001B[0m) | 1e-05: acc: 69.77% (\u001B[92m+\u001B[0m\u001B[92m2.47%\u001B[0m), f1: 70.17% (\u001B[92m+\u001B[0m\u001B[92m2.38%\u001B[0m) | 1e-05: acc: 66.38% (\u001B[92m+\u001B[0m\u001B[92m3.95%\u001B[0m), f1: 65.95% (\u001B[92m+\u001B[0m\u001B[92m3.91%\u001B[0m) |\n",
      "|          | 1e-06: acc: 66.75% (\u001B[92m+\u001B[0m\u001B[92m8.51%\u001B[0m), f1: 66.62% (\u001B[92m+\u001B[0m\u001B[92m8.28%\u001B[0m) | 1e-06: acc: 71.07% (\u001B[92m+\u001B[0m\u001B[92m3.77%\u001B[0m), f1: 71.43% (\u001B[92m+\u001B[0m\u001B[92m3.64%\u001B[0m) | 1e-06: acc: 66.56% (\u001B[92m+\u001B[0m\u001B[92m4.13%\u001B[0m), f1: 65.71% (\u001B[92m+\u001B[0m\u001B[92m3.67%\u001B[0m) |\n",
      "|          | 5e-05: acc: 66.87% (\u001B[92m+\u001B[0m\u001B[92m8.63%\u001B[0m), f1: 66.94% (\u001B[92m+\u001B[0m\u001B[92m8.6%\u001B[0m)  | 5e-05: acc: 68.91% (\u001B[92m+\u001B[0m\u001B[92m1.61%\u001B[0m), f1: 69.42% (\u001B[92m+\u001B[0m\u001B[92m1.63%\u001B[0m) | 5e-05: acc: 65.7% (\u001B[92m+\u001B[0m\u001B[92m3.27%\u001B[0m), f1: 65.44% (\u001B[92m+\u001B[0m\u001B[92m3.4%\u001B[0m)   |\n",
      "+----------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "\n",
      "\n",
      "####################################################################################################\n"
     ]
    }
   ],
   "source": [
    "def get_metrics(test_true: np.array, \n",
    "                prior_predictions: np.array, \n",
    "                post_predictions: np.array) -> dict:\n",
    "    assert len(prior_predictions) == len(post_predictions)\n",
    "    \n",
    "    return {prior_or_post: ({'acc': accuracy_score(y_true=test_true, \n",
    "                                                       y_pred=(prior_predictions \n",
    "                                                       if prior_or_post == 'prior' else post_predictions))} | \n",
    "                                {metric_name: metric_value(y_true=test_true, \n",
    "                                                           y_pred=(prior_predictions \n",
    "                                                                   if prior_or_post == 'prior' else post_predictions), \n",
    "                                                           average='weighted') \n",
    "                                 for metric_name, metric_value in {'pre': precision_score, 'rec': recall_score, 'f1': f1_score}.items()})\n",
    "                 for prior_or_post in ['prior', 'post']} | {'len': len(prior_predictions)}\n",
    "\n",
    "\n",
    "def gather_EDCR_data() -> dict:\n",
    "    data = {} \n",
    "    \n",
    "    # Iterate through filenames to collect accuracy data\n",
    "    for filename in os.listdir(EDCR_pipeline.figs_folder):\n",
    "        secondary_granularity_match = re.match(\n",
    "            pattern='main_(fine|coarse)_(.+?)_lr(.+?)_secondary_(fine|coarse)_(.+?)_lr(.+)',\n",
    "            string=filename\n",
    "        )\n",
    "        \n",
    "        if secondary_granularity_match:\n",
    "            (   match,\n",
    "                main_granularity,\n",
    "                main_model_name,\n",
    "                main_lr,\n",
    "                secondary_granularity,\n",
    "                secondary_model_name,\n",
    "                secondary_lr\n",
    "            ) = (secondary_granularity_match.group(i) for i in range(7))\n",
    "            \n",
    "            main_suffix = '_coarse' if main_granularity == 'coarse' else ''\n",
    "            test_true = np.load(os.path.join(EDCR_pipeline.data_folder, f'test_true{main_suffix}.npy'))\n",
    "            \n",
    "            prior_predictions = np.load(os.path.join(EDCR_pipeline.data_folder, rf'{main_model_name}_test_pred_lr{main_lr}_e3{main_suffix}.npy'))\n",
    "            \n",
    "            secondary_suffix = '_coarse' if secondary_granularity == 'coarse' else ''\n",
    "            post_predictions = np.load(f'figs/{match}/results{secondary_suffix}.npy')\n",
    "\n",
    "            # Store accuracy data in the data dictionary\n",
    "            if main_granularity not in data:\n",
    "                data[main_granularity] = {}\n",
    "            if main_model_name not in data[main_granularity]:\n",
    "                data[main_granularity][main_model_name] = {}\n",
    "            if secondary_granularity not in data[main_granularity][main_model_name]:\n",
    "                data[main_granularity][main_model_name][secondary_granularity] = {}\n",
    "            if secondary_model_name not in data[main_granularity][main_model_name][secondary_granularity]:\n",
    "                data[main_granularity][main_model_name][secondary_granularity][secondary_model_name] = {}\n",
    "            if main_lr not in data[main_granularity][main_model_name][secondary_granularity][secondary_model_name]:\n",
    "                data[main_granularity][main_model_name][secondary_granularity][secondary_model_name][main_lr] = {}\n",
    "                \n",
    "            data[main_granularity][main_model_name][secondary_granularity][secondary_model_name][main_lr][secondary_lr] = get_metrics(test_true=test_true,\n",
    "                                                                                                                                      prior_predictions=prior_predictions,\n",
    "                                                                                                                                      post_predictions=post_predictions)\n",
    "        else:\n",
    "            no_secondary_granularity_match = re.match(pattern='main_(fine|coarse)_(.+)_lr(.+)_secondary_(.+)_lr(.+)',\n",
    "                                                      string=filename)\n",
    "            \n",
    "            if no_secondary_granularity_match:\n",
    "                \n",
    "                (match,\n",
    "                 main_granularity,\n",
    "                 main_model_name,\n",
    "                 main_lr,\n",
    "                 secondary_model_name,\n",
    "                 secondary_lr \n",
    "                ) = (no_secondary_granularity_match.group(i) for i in range(6))\n",
    "                \n",
    "                main_suffix = '_coarse' if main_granularity == 'coarse' else ''\n",
    "                test_true = np.load(os.path.join(EDCR_pipeline.data_folder, f'test_true{main_suffix}.npy'))\n",
    "                \n",
    "                prior_predictions = np.load(os.path.join(EDCR_pipeline.data_folder, rf'{main_model_name}_test_pred_lr{main_lr}_e3{main_suffix}.npy'))\n",
    "                \n",
    "                try:\n",
    "                    post_predictions = np.load(f'figs/{match}/results.npy')\n",
    "                except FileNotFoundError:\n",
    "                    post_predictions = np.load(f'figs/{match}/results_coarse.npy')\n",
    "                    \n",
    "                if main_granularity not in data:\n",
    "                    data[main_granularity] = {}\n",
    "                if main_model_name not in data[main_granularity]:\n",
    "                    data[main_granularity][main_model_name] = {}\n",
    "                if secondary_model_name not in data[main_granularity][main_model_name]:\n",
    "                    data[main_granularity][main_model_name][secondary_model_name] = {}\n",
    "                if main_lr not in data[main_granularity][main_model_name][secondary_model_name]:\n",
    "                    data[main_granularity][main_model_name][secondary_model_name][main_lr] = {}\n",
    "                \n",
    "                data[main_granularity][main_model_name][secondary_model_name][main_lr][secondary_lr] = get_metrics(test_true=test_true,\n",
    "                                                                                                                   prior_predictions=prior_predictions,\n",
    "                                                                                                                   post_predictions=post_predictions)\n",
    "    return data\n",
    "\n",
    "def get_diff_str(diff: float) -> str:\n",
    "    return f\"({utils.green_text('+') if diff > 0 else ''}{(utils.green_text(f'{diff}%') if diff > 0  else utils.red_text(f'{diff}%'))})\" if abs(diff) > 0 else ''\n",
    "\n",
    "def get_row_addition(secondary_lr: float, \n",
    "                     curr_data: dict,\n",
    "                     max_accuracy: float = None) -> (str, float):\n",
    "    roundoff = 2\n",
    "    curr_prior_data = curr_data['prior']\n",
    "    curr_post_data = curr_data['post']\n",
    "    \n",
    "    curr_prior_accuracy = round(curr_prior_data['acc'] * 100, roundoff)\n",
    "    curr_post_accuracy = round(curr_post_data['acc'] * 100, roundoff)\n",
    "    curr_accuracy_diff = round(curr_post_accuracy - curr_prior_accuracy, roundoff)\n",
    "    \n",
    "    post_acc_str = (utils.blue_text(curr_post_accuracy) \n",
    "                    if max_accuracy is not None and abs(curr_post_accuracy - max_accuracy) < 1e-5 \n",
    "                    else str(curr_post_accuracy))\n",
    "    \n",
    "    curr_prior_average_f1 = round(curr_prior_data['f1'] * 100, roundoff)\n",
    "    curr_post_average_f1 = round(curr_post_data['f1'] * 100, roundoff)\n",
    "    curr_average_f1_diff = round(curr_post_average_f1 - curr_prior_average_f1, roundoff)\n",
    "    \n",
    "    \n",
    "    acc_str = f'acc: {post_acc_str}% {get_diff_str(curr_accuracy_diff)}'\n",
    "    f1_str = f'f1: {curr_post_average_f1}% {get_diff_str(curr_average_f1_diff)}'\n",
    "    row_addition = f\"{secondary_lr}: {acc_str}, {f1_str}\\n\"\n",
    "\n",
    "    return row_addition, curr_prior_accuracy, curr_prior_average_f1\n",
    "\n",
    "\n",
    "def get_row_data(main_lr_data: dict,\n",
    "                 secondary_lr: float) -> (str, float):\n",
    "    curr_data = main_lr_data[secondary_lr]\n",
    "    row_addition, curr_prior_acc, curr_prior_average_f1 = get_row_addition(secondary_lr=secondary_lr, \n",
    "                                                                                   curr_data=curr_data)\n",
    "    \n",
    "    return row_addition, curr_prior_acc, curr_prior_average_f1\n",
    "\n",
    "\n",
    "def print_one_secondary_granularity(main_model_data: dict,\n",
    "                                    secondary_granularity: str,\n",
    "                                    main_granularity: str,\n",
    "                                    main_model_name: str):\n",
    "\n",
    "    secondary_granularity_data = main_model_data[secondary_granularity]\n",
    "    main_learning_rates = sorted(secondary_granularity_data[list(secondary_granularity_data.keys())[0]].keys())\n",
    "    header = [''] + main_learning_rates\n",
    "    table_data = [header]\n",
    "    priors = {}\n",
    "\n",
    "    for secondary_model_name in sorted(secondary_granularity_data.keys()):\n",
    "        secondary_model_data = secondary_granularity_data[secondary_model_name]\n",
    "        row = [secondary_model_name]\n",
    "        \n",
    "        for main_lr in sorted(secondary_model_data.keys()):\n",
    "            main_lr_data = secondary_model_data[main_lr]\n",
    "            row_add = ''\n",
    "            \n",
    "            for secondary_lr in sorted(main_lr_data.keys()):\n",
    "                row_addition, curr_prior_acc, curr_prior_average_f1 = get_row_data(main_lr_data=main_lr_data,\n",
    "                                                                                      secondary_lr=secondary_lr)\n",
    "                row_add += row_addition\n",
    "                priors[main_lr] = {'acc': curr_prior_acc, 'f1': curr_prior_average_f1}\n",
    "                \n",
    "            row += [row_add]\n",
    "        table_data += [row]\n",
    "    \n",
    "    table_data[0] = [''] + [f\"main-lr={main_lr} (acc: {priors[main_lr]['acc']}%, f1: {priors[main_lr]['f1']}%)\" for main_lr in main_learning_rates]\n",
    "    \n",
    "    # Rest of your code to create and print the table remains unchanged\n",
    "    table = tabulate.tabulate(\n",
    "        tabular_data=table_data, \n",
    "        headers='firstrow', \n",
    "        tablefmt='grid'\n",
    "    )\n",
    "    print(f\"Main model: {main_granularity.capitalize()}-grain {main_model_name}, \"\n",
    "          f\"secondary granularity: {secondary_granularity}\")\n",
    "    print(table)\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "def print_two_secondary_granularities(main_model_data: dict,\n",
    "                                      two_secondary_table_data: list,\n",
    "                                      secondary_model_name: str,\n",
    "                                      main_granularity: str,\n",
    "                                      main_model_name: str):\n",
    "    main_learning_rates = sorted(vit_pipeline.lrs)\n",
    "    \n",
    "    priors = {}\n",
    "    \n",
    "    # Initialize the table_data with header if it's empty\n",
    "    if len(two_secondary_table_data) == 0:\n",
    "        header = [''] + main_learning_rates\n",
    "        two_secondary_table_data += [header]\n",
    "        \n",
    "    secondary_model_data = main_model_data[secondary_model_name]\n",
    "    row = [secondary_model_name]\n",
    "    \n",
    "    for main_lr in sorted(secondary_model_data.keys()):\n",
    "        main_lr_data = secondary_model_data[main_lr]\n",
    "        row_add = ''\n",
    "        \n",
    "        for secondary_lr in sorted(main_lr_data.keys()):\n",
    "            row_addition, curr_prior_acc, curr_prior_average_f1 = get_row_data(main_lr_data=main_lr_data,\n",
    "                                                    secondary_lr=secondary_lr)\n",
    "            row_add += row_addition\n",
    "            priors[main_lr] = {'acc': curr_prior_acc, 'f1': curr_prior_average_f1}\n",
    "    \n",
    "        row += [row_add]\n",
    "\n",
    "    two_secondary_table_data += [row]\n",
    "    \n",
    "    # Modify the generated table data to highlight the cell with the maximal accuracy in blue\n",
    "    \n",
    "    if len(two_secondary_table_data) == len(main_learning_rates) + 1:\n",
    "        two_secondary_table_data[0] = [''] + [f\"main-lr={main_lr} (acc: {priors[str(main_lr)]['acc']}%, f1: {priors[str(main_lr)]['f1']}%)\" for main_lr in main_learning_rates]\n",
    "        \n",
    "        # Create the table using tabulate\n",
    "        table = tabulate.tabulate(\n",
    "            tabular_data=two_secondary_table_data,\n",
    "            headers='firstrow',\n",
    "            tablefmt='grid'\n",
    "        )\n",
    "        \n",
    "        # Print the main model name and the corresponding table\n",
    "        print(f\"Main model: {main_granularity.capitalize()}-grain {main_model_name} \"\n",
    "              f\"with both fine and coarse grain secondary models\")\n",
    "        print(table)\n",
    "        print(\"\\n\")\n",
    "    else:\n",
    "        return two_secondary_table_data\n",
    "\n",
    "\n",
    "def print_EDCR_tables():\n",
    "    data = gather_EDCR_data()\n",
    "    \n",
    "    for main_granularity in sorted(data.keys()):\n",
    "        \n",
    "        print('#' * 40 + f' Main granularity: {main_granularity} ' + '#' * 40 + '\\n' + '#' * 104 + '\\n')\n",
    "        main_granularity_data = data[main_granularity]\n",
    "        \n",
    "        for main_model_name in sorted(main_granularity_data.keys()):\n",
    "            main_model_data = main_granularity_data[main_model_name]\n",
    "            two_secondary_table_data = []\n",
    "\n",
    "            for granularity_or_model in (sorted(set(main_model_data.keys()).intersection(data_preprocessing.granularities.values())) + \n",
    "                      sorted(set(main_model_data.keys()).intersection(vit_pipeline.vit_model_names))):\n",
    "            \n",
    "                if granularity_or_model in data_preprocessing.granularities.values():\n",
    "                    print_one_secondary_granularity(main_model_data=main_model_data,\n",
    "                                                    secondary_granularity=granularity_or_model,\n",
    "                                                    main_granularity=main_granularity,\n",
    "                                                    main_model_name=main_model_name)\n",
    "                else:\n",
    "                    two_secondary_table_data = print_two_secondary_granularities(main_model_data=main_model_data,\n",
    "                                                                                 two_secondary_table_data=two_secondary_table_data,\n",
    "                                                                                 secondary_model_name=granularity_or_model,\n",
    "                                                                                 main_granularity=main_granularity,\n",
    "                                                                                 main_model_name=main_model_name)\n",
    "            print('#' * 100)\n",
    "\n",
    "print_EDCR_tables()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-22T17:09:41.044354Z",
     "start_time": "2023-11-22T17:09:35.019305Z"
    }
   },
   "id": "3f6e34912281d5e"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "{0: 1032,\n 1: 1030,\n 2: 990,\n 3: 989,\n 4: 986,\n 5: 987,\n 6: 980,\n 7: 983,\n 8: 985,\n 9: 984,\n 10: 1004,\n 11: 1009,\n 12: 1022,\n 13: 995,\n 14: 992,\n 15: 997,\n 16: 998,\n 17: 1005,\n 18: 1008,\n 19: 1002,\n 20: 1001,\n 21: 981,\n 22: 982,\n 23: 1026,\n 24: 1006,\n 25: 1007,\n 26: 1003,\n 27: 1000,\n 28: 994,\n 29: 993,\n 30: 996,\n 31: 999,\n 32: 991,\n 33: 988,\n 34: 1011,\n 35: 1019,\n 36: 1018,\n 37: 1010,\n 38: 1015,\n 39: 1024,\n 40: 1025,\n 41: 1033,\n 42: 1028,\n 43: 975,\n 44: 976,\n 45: 1013,\n 46: 1023,\n 47: 1027,\n 48: 1031,\n 49: 1029,\n 50: 1020,\n 51: 1016,\n 52: 1012,\n 53: 1014,\n 54: 977,\n 55: 1021,\n 56: 1017,\n 57: 978,\n 58: 979,\n 59: 133,\n 60: 132,\n 61: 122,\n 62: 121,\n 63: 119,\n 64: 120,\n 65: 115,\n 66: 116,\n 67: 118,\n 68: 117,\n 69: 124,\n 70: 125,\n 71: 130,\n 72: 123,\n 73: 131,\n 74: 126,\n 75: 127,\n 76: 129,\n 77: 128,\n 78: 113,\n 79: 114,\n 80: 1202,\n 81: 1196,\n 82: 1120,\n 83: 1096,\n 84: 1093,\n 85: 1102,\n 86: 1103,\n 87: 1114,\n 88: 1119,\n 89: 1109,\n 90: 1108,\n 91: 1124,\n 92: 1129,\n 93: 1113,\n 94: 1115,\n 95: 1118,\n 96: 1110,\n 97: 1107,\n 98: 1095,\n 99: 1094,\n 100: 1101,\n 101: 1104,\n 102: 1154,\n 103: 1153,\n 104: 1106,\n 105: 1125,\n 106: 1128,\n 107: 1136,\n 108: 1135,\n 109: 1156,\n 110: 1151,\n 111: 1143,\n 112: 1144,\n 113: 1097,\n 114: 1092,\n 115: 1111,\n 116: 1155,\n 117: 1152,\n 118: 1142,\n 119: 1145,\n 120: 1126,\n 121: 1127,\n 122: 1137,\n 123: 1134,\n 124: 1116,\n 125: 1117,\n 126: 1090,\n 127: 1099,\n 128: 1105,\n 129: 1100,\n 130: 1148,\n 131: 1159,\n 132: 1183,\n 133: 1131,\n 134: 1122,\n 135: 1133,\n 136: 1138,\n 137: 1149,\n 138: 1158,\n 139: 1146,\n 140: 1141,\n 141: 1091,\n 142: 1098,\n 143: 1191,\n 144: 1150,\n 145: 1157,\n 146: 1147,\n 147: 1140,\n 148: 1130,\n 149: 1123,\n 150: 1132,\n 151: 1139,\n 152: 1121,\n 153: 1112,\n 154: 1161,\n 155: 1179,\n 156: 1172,\n 157: 1160,\n 158: 1169,\n 159: 1185,\n 160: 1190,\n 161: 1203,\n 162: 1194,\n 163: 1072,\n 164: 1073,\n 165: 1167,\n 166: 1184,\n 167: 1192,\n 168: 1201,\n 169: 1195,\n 170: 1180,\n 171: 1170,\n 172: 1162,\n 173: 1168,\n 174: 1081,\n 175: 1076,\n 176: 1181,\n 177: 1071,\n 178: 1074,\n 179: 1069,\n 180: 1064,\n 181: 1079,\n 182: 1078,\n 183: 1083,\n 184: 1088,\n 185: 1178,\n 186: 1173,\n 187: 1171,\n 188: 1080,\n 189: 1077,\n 190: 1084,\n 191: 1087,\n 192: 1070,\n 193: 1075,\n 194: 1068,\n 195: 1065,\n 196: 1182,\n 197: 1193,\n 198: 1082,\n 199: 1166,\n 200: 1163,\n 201: 1175,\n 202: 1176,\n 203: 1197,\n 204: 1200,\n 205: 1188,\n 206: 1187,\n 207: 1066,\n 208: 1067,\n 209: 1089,\n 210: 1198,\n 211: 1199,\n 212: 1189,\n 213: 1186,\n 214: 1165,\n 215: 1164,\n 216: 1174,\n 217: 1177,\n 218: 1086,\n 219: 1085,\n 220: 370,\n 221: 366,\n 222: 316,\n 223: 315,\n 224: 312,\n 225: 313,\n 226: 306,\n 227: 309,\n 228: 311,\n 229: 310,\n 230: 330,\n 231: 335,\n 232: 355,\n 233: 321,\n 234: 318,\n 235: 323,\n 236: 324,\n 237: 331,\n 238: 334,\n 239: 328,\n 240: 327,\n 241: 307,\n 242: 308,\n 243: 361,\n 244: 332,\n 245: 333,\n 246: 329,\n 247: 326,\n 248: 320,\n 249: 319,\n 250: 322,\n 251: 325,\n 252: 317,\n 253: 314,\n 254: 337,\n 255: 351,\n 256: 346,\n 257: 336,\n 258: 343,\n 259: 357,\n 260: 360,\n 261: 371,\n 262: 364,\n 263: 290,\n 264: 291,\n 265: 341,\n 266: 356,\n 267: 362,\n 268: 369,\n 269: 365,\n 270: 352,\n 271: 344,\n 272: 338,\n 273: 342,\n 274: 299,\n 275: 294,\n 276: 353,\n 277: 289,\n 278: 292,\n 279: 287,\n 280: 283,\n 281: 297,\n 282: 296,\n 283: 301,\n 284: 304,\n 285: 350,\n 286: 347,\n 287: 345,\n 288: 298,\n 289: 295,\n 290: 302,\n 291: 303,\n 292: 288,\n 293: 293,\n 294: 286,\n 295: 284,\n 296: 354,\n 297: 363,\n 298: 300,\n 299: 340,\n 300: 339,\n 301: 348,\n 302: 349,\n 303: 367,\n 304: 368,\n 305: 359,\n 306: 358,\n 307: 285,\n 308: 305,\n 309: 398,\n 310: 397,\n 311: 381,\n 312: 380,\n 313: 378,\n 314: 379,\n 315: 374,\n 316: 375,\n 317: 377,\n 318: 376,\n 319: 387,\n 320: 390,\n 321: 395,\n 322: 383,\n 323: 382,\n 324: 384,\n 325: 385,\n 326: 388,\n 327: 389,\n 328: 386,\n 329: 396,\n 330: 391,\n 331: 392,\n 332: 394,\n 333: 393,\n 334: 372,\n 335: 373,\n 336: 462,\n 337: 460,\n 338: 420,\n 339: 419,\n 340: 416,\n 341: 417,\n 342: 410,\n 343: 413,\n 344: 415,\n 345: 414,\n 346: 434,\n 347: 439,\n 348: 452,\n 349: 425,\n 350: 422,\n 351: 427,\n 352: 428,\n 353: 435,\n 354: 438,\n 355: 432,\n 356: 431,\n 357: 411,\n 358: 412,\n 359: 456,\n 360: 436,\n 361: 437,\n 362: 433,\n 363: 430,\n 364: 424,\n 365: 423,\n 366: 426,\n 367: 429,\n 368: 421,\n 369: 418,\n 370: 441,\n 371: 449,\n 372: 448,\n 373: 440,\n 374: 445,\n 375: 454,\n 376: 455,\n 377: 463,\n 378: 458,\n 379: 402,\n 380: 403,\n 381: 443,\n 382: 453,\n 383: 457,\n 384: 461,\n 385: 459,\n 386: 450,\n 387: 446,\n 388: 442,\n 389: 444,\n 390: 407,\n 391: 405,\n 392: 451,\n 393: 401,\n 394: 404,\n 395: 400,\n 396: 399,\n 397: 406,\n 398: 447,\n 399: 408,\n 400: 409,\n 401: 546,\n 402: 544,\n 403: 496,\n 404: 495,\n 405: 492,\n 406: 493,\n 407: 486,\n 408: 489,\n 409: 491,\n 410: 490,\n 411: 510,\n 412: 515,\n 413: 535,\n 414: 501,\n 415: 498,\n 416: 503,\n 417: 504,\n 418: 511,\n 419: 514,\n 420: 508,\n 421: 507,\n 422: 487,\n 423: 488,\n 424: 539,\n 425: 512,\n 426: 513,\n 427: 509,\n 428: 506,\n 429: 500,\n 430: 499,\n 431: 502,\n 432: 505,\n 433: 497,\n 434: 494,\n 435: 517,\n 436: 531,\n 437: 526,\n 438: 516,\n 439: 523,\n 440: 537,\n 441: 538,\n 442: 547,\n 443: 542,\n 444: 470,\n 445: 471,\n 446: 521,\n 447: 536,\n 448: 540,\n 449: 545,\n 450: 543,\n 451: 532,\n 452: 524,\n 453: 518,\n 454: 522,\n 455: 479,\n 456: 474,\n 457: 533,\n 458: 469,\n 459: 472,\n 460: 467,\n 461: 464,\n 462: 477,\n 463: 476,\n 464: 481,\n 465: 484,\n 466: 530,\n 467: 527,\n 468: 525,\n 469: 478,\n 470: 475,\n 471: 482,\n 472: 483,\n 473: 468,\n 474: 473,\n 475: 466,\n 476: 465,\n 477: 534,\n 478: 541,\n 479: 480,\n 480: 520,\n 481: 519,\n 482: 528,\n 483: 529,\n 484: 485,\n 485: 725,\n 486: 723,\n 487: 683,\n 488: 682,\n 489: 679,\n 490: 680,\n 491: 673,\n 492: 676,\n 493: 678,\n 494: 677,\n 495: 697,\n 496: 702,\n 497: 715,\n 498: 688,\n 499: 685,\n 500: 690,\n 501: 691,\n 502: 698,\n 503: 701,\n 504: 695,\n 505: 694,\n 506: 674,\n 507: 675,\n 508: 719,\n 509: 699,\n 510: 700,\n 511: 696,\n 512: 693,\n 513: 687,\n 514: 686,\n 515: 689,\n 516: 692,\n 517: 684,\n 518: 681,\n 519: 704,\n 520: 712,\n 521: 711,\n 522: 703,\n 523: 708,\n 524: 717,\n 525: 718,\n 526: 726,\n 527: 721,\n 528: 666,\n 529: 667,\n 530: 706,\n 531: 716,\n 532: 720,\n 533: 724,\n 534: 722,\n 535: 713,\n 536: 709,\n 537: 705,\n 538: 707,\n 539: 670,\n 540: 669,\n 541: 714,\n 542: 665,\n 543: 668,\n 544: 664,\n 545: 663,\n 546: 710,\n 547: 671,\n 548: 672,\n 549: 886,\n 550: 876,\n 551: 788,\n 552: 764,\n 553: 761,\n 554: 770,\n 555: 771,\n 556: 782,\n 557: 787,\n 558: 777,\n 559: 776,\n 560: 792,\n 561: 797,\n 562: 781,\n 563: 783,\n 564: 786,\n 565: 778,\n 566: 775,\n 567: 763,\n 568: 762,\n 569: 769,\n 570: 772,\n 571: 822,\n 572: 821,\n 573: 774,\n 574: 793,\n 575: 796,\n 576: 804,\n 577: 803,\n 578: 824,\n 579: 819,\n 580: 811,\n 581: 812,\n 582: 765,\n 583: 760,\n 584: 779,\n 585: 823,\n 586: 820,\n 587: 810,\n 588: 813,\n 589: 794,\n 590: 795,\n 591: 805,\n 592: 802,\n 593: 784,\n 594: 785,\n 595: 758,\n 596: 849,\n 597: 850,\n 598: 836,\n 599: 833,\n 600: 868,\n 601: 863,\n 602: 877,\n 603: 884,\n 604: 738,\n 605: 736,\n 606: 767,\n 607: 869,\n 608: 862,\n 609: 878,\n 610: 883,\n 611: 848,\n 612: 851,\n 613: 835,\n 614: 834,\n 615: 745,\n 616: 746,\n 617: 773,\n 618: 737,\n 619: 768,\n 620: 816,\n 621: 827,\n 622: 859,\n 623: 799,\n 624: 790,\n 625: 801,\n 626: 806,\n 627: 817,\n 628: 826,\n 629: 814,\n 630: 809,\n 631: 759,\n 632: 766,\n 633: 871,\n 634: 818,\n 635: 825,\n 636: 815,\n 637: 808,\n 638: 798,\n 639: 791,\n 640: 800,\n 641: 807,\n 642: 789,\n 643: 780,\n 644: 829,\n 645: 855,\n 646: 844,\n 647: 828,\n 648: 841,\n 649: 861,\n 650: 870,\n 651: 887,\n 652: 874,\n 653: 735,\n 654: 739,\n 655: 839,\n 656: 860,\n 657: 872,\n 658: 885,\n 659: 875,\n 660: 856,\n 661: 842,\n 662: 830,\n 663: 840,\n 664: 749,\n 665: 742,\n 666: 857,\n 667: 734,\n 668: 740,\n 669: 732,\n 670: 727,\n 671: 747,\n 672: 744,\n 673: 751,\n 674: 756,\n 675: 854,\n 676: 845,\n 677: 843,\n 678: 748,\n 679: 743,\n 680: 752,\n 681: 755,\n 682: 733,\n 683: 741,\n 684: 731,\n 685: 728,\n 686: 858,\n 687: 873,\n 688: 750,\n 689: 838,\n 690: 831,\n 691: 847,\n 692: 852,\n 693: 879,\n 694: 882,\n 695: 866,\n 696: 865,\n 697: 729,\n 698: 730,\n 699: 757,\n 700: 880,\n 701: 881,\n 702: 867,\n 703: 864,\n 704: 837,\n 705: 832,\n 706: 846,\n 707: 853,\n 708: 754,\n 709: 753,\n 710: 586,\n 711: 585,\n 712: 559,\n 713: 558,\n 714: 556,\n 715: 557,\n 716: 550,\n 717: 553,\n 718: 555,\n 719: 554,\n 720: 573,\n 721: 578,\n 722: 583,\n 723: 564,\n 724: 561,\n 725: 566,\n 726: 567,\n 727: 574,\n 728: 577,\n 729: 571,\n 730: 570,\n 731: 551,\n 732: 552,\n 733: 584,\n 734: 575,\n 735: 576,\n 736: 572,\n 737: 569,\n 738: 563,\n 739: 562,\n 740: 565,\n 741: 568,\n 742: 560,\n 743: 579,\n 744: 580,\n 745: 582,\n 746: 581,\n 747: 548,\n 748: 549,\n 749: 661,\n 750: 659,\n 751: 617,\n 752: 616,\n 753: 613,\n 754: 614,\n 755: 607,\n 756: 610,\n 757: 612,\n 758: 611,\n 759: 631,\n 760: 636,\n 761: 651,\n 762: 622,\n 763: 619,\n 764: 624,\n 765: 625,\n 766: 632,\n 767: 635,\n 768: 629,\n 769: 628,\n 770: 608,\n 771: 609,\n 772: 655,\n 773: 864,\n 774: 634,\n 775: 630,\n 776: 627,\n 777: 621,\n 778: 620,\n 779: 623,\n 780: 626,\n 781: 618,\n 782: 615,\n 783: 638,\n 784: 648,\n 785: 645,\n 786: 637,\n 787: 642,\n 788: 653,\n 789: 654,\n 790: 883,\n 791: 657,\n 792: 591,\n 793: 592,\n 794: 640,\n 795: 652,\n 796: 656,\n 797: 660,\n 798: 658,\n 799: 649,\n 800: 643,\n 801: 639,\n 802: 641,\n 803: 600,\n 804: 595,\n 805: 650,\n 806: 590,\n 807: 593,\n 808: 588,\n 809: 848,\n 810: 598,\n 811: 597,\n 812: 602,\n 813: 605,\n 814: 647,\n 815: 646,\n 816: 644,\n 817: 599,\n 818: 596,\n 819: 603,\n 820: 604,\n 821: 589,\n 822: 594,\n 823: 601,\n 824: 606,\n 825: 1272,\n 826: 1270,\n 827: 1228,\n 828: 1227,\n 829: 1224,\n 830: 1225,\n 831: 1218,\n 832: 1221,\n 833: 1223,\n 834: 1222,\n 835: 1242,\n 836: 1247,\n 837: 1262,\n 838: 1233,\n 839: 1230,\n 840: 1235,\n 841: 1236,\n 842: 1243,\n 843: 1246,\n 844: 1240,\n 845: 1239,\n 846: 1219,\n 847: 1220,\n 848: 1266,\n 849: 1244,\n 850: 1245,\n 851: 1241,\n 852: 1238,\n 853: 1232,\n 854: 1231,\n 855: 1234,\n 856: 1237,\n 857: 1229,\n 858: 1226,\n 859: 1249,\n 860: 1259,\n 861: 1256,\n 862: 1248,\n 863: 1253,\n 864: 1264,\n 865: 1265,\n 866: 1273,\n 867: 1268,\n 868: 1207,\n 869: 1208,\n 870: 1251,\n 871: 1263,\n 872: 1267,\n 873: 1271,\n 874: 1269,\n 875: 1260,\n 876: 1254,\n 877: 1250,\n 878: 1252,\n 879: 1213,\n 880: 1210,\n 881: 1261,\n 882: 1206,\n 883: 1209,\n 884: 1205,\n 885: 1204,\n 886: 1212,\n 887: 1211,\n 888: 1215,\n 889: 1216,\n 890: 1258,\n 891: 1257,\n 892: 1255,\n 893: 1214,\n 894: 1217,\n 895: 281,\n 896: 275,\n 897: 219,\n 898: 207,\n 899: 206,\n 900: 211,\n 901: 212,\n 902: 218,\n 903: 217,\n 904: 214,\n 905: 215,\n 906: 204,\n 907: 209,\n 908: 213,\n 909: 210,\n 910: 233,\n 911: 238,\n 912: 262,\n 913: 224,\n 914: 221,\n 915: 226,\n 916: 227,\n 917: 234,\n 918: 237,\n 919: 231,\n 920: 230,\n 921: 205,\n 922: 208,\n 923: 270,\n 924: 235,\n 925: 236,\n 926: 232,\n 927: 229,\n 928: 223,\n 929: 222,\n 930: 225,\n 931: 228,\n 932: 220,\n 933: 216,\n 934: 240,\n 935: 258,\n 936: 251,\n 937: 239,\n 938: 248,\n 939: 264,\n 940: 269,\n 941: 282,\n 942: 273,\n 943: 186,\n 944: 187,\n 945: 246,\n 946: 263,\n 947: 271,\n 948: 280,\n 949: 274,\n 950: 259,\n 951: 249,\n 952: 241,\n 953: 247,\n 954: 195,\n 955: 190,\n 956: 260,\n 957: 185,\n 958: 188,\n 959: 183,\n 960: 178,\n 961: 193,\n 962: 192,\n 963: 197,\n 964: 202,\n 965: 257,\n 966: 252,\n 967: 250,\n 968: 194,\n 969: 191,\n 970: 198,\n 971: 201,\n 972: 184,\n 973: 189,\n 974: 182,\n 975: 179,\n 976: 261,\n 977: 272,\n 978: 196,\n 979: 245,\n 980: 242,\n 981: 254,\n 982: 255,\n 983: 276,\n 984: 279,\n 985: 267,\n 986: 266,\n 987: 180,\n 988: 181,\n 989: 203,\n 990: 277,\n 991: 278,\n 992: 268,\n 993: 265,\n 994: 244,\n 995: 243,\n 996: 253,\n 997: 256,\n 998: 200,\n 999: 199,\n ...}"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_coarse_main_model = 'vit_l_16'\n",
    "best_coarse_main_lr = '1e-06'\n",
    "best_coarse_secondary_model = 'vit_b_16'\n",
    "best_coarse_secondary_lr = '5e-05'\n",
    "best_coarse_folder = f'main_coarse_{best_coarse_main_model}_lr{best_coarse_main_lr}_secondary_{best_coarse_secondary_model}_lr{best_coarse_secondary_lr}'\n",
    "best_coarse_results = np.load(rf'{EDCR_pipeline.figs_folder}{best_coarse_folder}/results.npy')\n",
    "coarse_test_true = np.load(os.path.join(EDCR_pipeline.data_folder, f'test_true_coarse.npy'))\n",
    "\n",
    "best_fine_main_model = 'vit_l_16'\n",
    "best_fine_main_lr = '1e-06'\n",
    "best_fine_secondary_model = 'vit_b_16'\n",
    "best_fine_secondary_lr = '1e-06'\n",
    "best_fine_folder = f'main_fine_{best_fine_main_model}_lr{best_fine_main_lr}_secondary_{best_fine_secondary_model}_lr{best_fine_secondary_lr}'\n",
    "best_fine_results = np.load(rf'{EDCR_pipeline.figs_folder}{best_fine_folder}/results.npy')\n",
    "fine_test_true = np.load(os.path.join(EDCR_pipeline.data_folder, f'test_true.npy'))\n",
    "\n",
    "with open('fine_to_coarse.json', 'r') as json_file:\n",
    "    image_fine_to_coarse = json.load(json_file)\n",
    "\n",
    "image_fine_to_coarse = {int(fine): int(coarse) for batch_dict in image_fine_to_coarse for fine, coarse in batch_dict.items()}\n",
    "image_fine_to_coarse\n",
    "\n",
    "# def get_num_of_inconsistencies(coarse_results: np.array, \n",
    "#                                fine_results: np.array) -> int:\n",
    "#     num_of_inconsistencies = 0\n",
    "#     for fine_example_num, fine_prediction_index in enumerate(fine_results):\n",
    "#         coarse_example_num = image_fine_to_coarse[fine_example_num]\n",
    "#         coarse_prediction_index = coarse_results[coarse_example_num]\n",
    "#         \n",
    "#         fine_prediction = EDCR_pipeline.get_classes(granularity='fine')[fine_prediction_index]\n",
    "#         coarse_prediction = EDCR_pipeline.get_classes(granularity='coarse')[coarse_prediction_index]\n",
    "#         derived_coarse_prediction = EDCR_pipeline.fine_to_coarse[fine_prediction]\n",
    "# \n",
    "#         if derived_coarse_prediction != coarse_prediction:\n",
    "#             num_of_inconsistencies += 1\n",
    "# \n",
    "#     return num_of_inconsistencies\n",
    "# \n",
    "# get_num_of_inconsistencies(coarse_results=coarse_test_true,\n",
    "#                            fine_results=fine_test_true)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-22T03:55:18.564992Z",
     "start_time": "2023-11-22T03:55:18.544808Z"
    }
   },
   "id": "bdb3d6545a77e534"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e513314a85b69eef"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
