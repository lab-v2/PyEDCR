{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "import termcolor\n",
    "from tabulate import tabulate\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# from vit_pipeline import lrs, vit_model_names\n",
    "from data_preprocessing import granularities\n",
    "from metacognitive_pipeline import fine_grain_classes, n_classes\n",
    "from context import Plot"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T05:02:26.058301Z",
     "start_time": "2023-11-01T05:02:26.052558Z"
    }
   },
   "id": "9dc68a5fe4ce4ea7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9fa39b654f694621"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-01T05:02:27.333403Z",
     "start_time": "2023-11-01T05:02:26.944033Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = 'results/'  # Set the directory where your .npy files are located\n",
    "all_data = {}\n",
    "\n",
    "for granularity in granularities.values():\n",
    "    \n",
    "    suffix = '_coarse' if granularity == 'coarse' else ''\n",
    "    # Initialize dictionaries to store training and test accuracy data for each model\n",
    "    train_data = {}\n",
    "    test_data = {}\n",
    "    \n",
    "    test_true = np.load(os.path.join(data_dir, f'test_true{suffix}.npy'))\n",
    "    \n",
    "    # Loop through all files in the directory\n",
    "    for filename in os.listdir(data_dir):\n",
    "        train_match = re.match(pattern=rf'(.+?)_train_(loss|acc)_lr(.+?)_e(\\d+?){suffix}.npy',\n",
    "                               string=filename)\n",
    "        test_match = re.match(pattern=rf'(.+?)_test_pred_lr(.+?)_e(\\d+?){suffix}.npy',\n",
    "                              string=filename)\n",
    "    \n",
    "        if train_match:\n",
    "            model_name = train_match.group(1)\n",
    "            metric = train_match.group(2)\n",
    "            lr_value = float(train_match.group(3))\n",
    "            num_epochs = int(train_match.group(4)) + 1\n",
    "    \n",
    "            # Load the data from the .npy file\n",
    "            data = np.load(os.path.join(data_dir, filename))\n",
    "    \n",
    "            # Store the data in the model_data dictionary\n",
    "            if model_name not in train_data:\n",
    "                train_data[model_name] = {}\n",
    "            if metric not in train_data[model_name]:\n",
    "                train_data[model_name][metric] = {}\n",
    "            if lr_value not in train_data[model_name][metric]:\n",
    "                train_data[model_name][metric][lr_value] = {}\n",
    "    \n",
    "            train_data[model_name][metric][lr_value][num_epochs] = data[-1]\n",
    "        elif test_match:\n",
    "            model_name = test_match.group(1)\n",
    "            lr_value = float(test_match.group(2))\n",
    "            num_epochs = int(test_match.group(3)) + 1\n",
    "    \n",
    "            # Load the test data from the .npy file\n",
    "            test_pred = np.load(os.path.join(data_dir, filename))\n",
    "    \n",
    "            # Store the data in the model_test_data dictionary\n",
    "            if model_name not in test_data:\n",
    "                test_data[model_name] = {}\n",
    "            if lr_value not in test_data[model_name]:\n",
    "                test_data[model_name][lr_value] = {}\n",
    "    \n",
    "            test_data[model_name][lr_value][num_epochs] = \\\n",
    "                {'acc': accuracy_score(y_true=test_true, \n",
    "                                       y_pred=test_pred), \n",
    "                 'cm': confusion_matrix(y_true=test_true, \n",
    "                                        y_pred=test_pred),\n",
    "                 'pre': precision_score(y_true=test_true, \n",
    "                                        y_pred=test_pred, \n",
    "                                        labels=range(n_classes), \n",
    "                                        average=None),\n",
    "                 'rec': recall_score(y_true=test_true, \n",
    "                                     y_pred=test_pred, \n",
    "                                     labels=range(n_classes), \n",
    "                                     average=None),\n",
    "                 'f1': f1_score(y_true=test_true, \n",
    "                                y_pred=test_pred, \n",
    "                                labels=range(n_classes), \n",
    "                                average=None)}\n",
    "            \n",
    "    all_data[granularity] = {'train': train_data, 'test': test_data}"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train metrics"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8826ef905a164c15"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def plot_train_metrics(granularity: str):\n",
    "    # Create plots for training metric vs. epoch for each model\n",
    "    for model_name, model_data in sorted(all_data[granularity]['train'].items()):\n",
    "        print('\\n' + '#'* (100 + len(model_name)))\n",
    "        print('#'* 50 + f'{model_name}' + '#'* 50)\n",
    "        print('#'* (100 + len(model_name)) + '\\n')\n",
    "        for metric, metric_data in model_data.items():\n",
    "            with Plot():\n",
    "                plt.title(f\"{model_name} {granularity}-grain training {metric} vs. epoch\")\n",
    "                plt.xlabel('Epoch')\n",
    "                plt.ylabel(metric.capitalize())\n",
    "    \n",
    "                for lr_value, lr_data in sorted(metric_data.items()):\n",
    "                    epochs, data = zip(*sorted(lr_data.items())) # Sort the data based on the number of epochs\n",
    "                    plt.plot(epochs, data, label=f'lr={lr_value}')\n",
    "                    plt.xticks(np.arange(min(epochs), max(epochs)+1, 1)) # Set the x-axis ticks to be integers\n",
    "    \n",
    "                plt.legend()\n",
    "                plt.grid()\n",
    "\n",
    "# plot_train_metrics(granularity='fine')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T05:02:27.873083Z",
     "start_time": "2023-11-01T05:02:27.861595Z"
    }
   },
   "id": "77ea4d8f8e19eb6e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test metrics"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1b4fda72717cd425"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Test Metrics for Granularity: coarse         \n",
      "╒══════════════╤════════════╤════════════╤════════════╕\n",
      "│ Model Name   │   lr=1e-05 │   lr=1e-06 │   lr=5e-05 │\n",
      "╞══════════════╪════════════╪════════════╪════════════╡\n",
      "│ vit_b_16     │   0.809377 │   0.656385 │   0.837138 │\n",
      "├──────────────┼────────────┼────────────┼────────────┤\n",
      "│ vit_b_32     │   0.770512 │   0.630475 │   0.760025 │\n",
      "├──────────────┼────────────┼────────────┼────────────┤\n",
      "│ vit_l_16     │   0.84269  │   0.739667 │   0.837138 │\n",
      "├──────────────┼────────────┼────────────┼────────────┤\n",
      "│ vit_l_32     │   0.792104 │   0.595312 │   0.807526 │\n",
      "╘══════════════╧════════════╧════════════╧════════════╛\n",
      "           Test Metrics for Granularity: fine          \n",
      "╒══════════════╤════════════╤════════════╤════════════╕\n",
      "│ Model Name   │   lr=1e-05 │   lr=1e-06 │   lr=5e-05 │\n",
      "╞══════════════╪════════════╪════════════╪════════════╡\n",
      "│ vit_b_16     │   0.639112 │   0.699568 │   0.645281 │\n",
      "├──────────────┼────────────┼────────────┼────────────┤\n",
      "│ vit_b_32     │   0.558914 │   0.636644 │   0.537323 │\n",
      "├──────────────┼────────────┼────────────┼────────────┤\n",
      "│ vit_l_16     │   0.699568 │   0.702653 │   0.661937 │\n",
      "├──────────────┼────────────┼────────────┼────────────┤\n",
      "│ vit_l_32     │   0.582357 │   0.673041 │   0.624306 │\n",
      "╘══════════════╧════════════╧════════════╧════════════╛\n"
     ]
    }
   ],
   "source": [
    "def plot_test_metrics():\n",
    "    for granularity in granularities.values():\n",
    "        # Create a dictionary to store accuracy values for each model and learning rate\n",
    "        accuracy_data = {}\n",
    "    \n",
    "        # Now, create plots for test accuracy vs. epoch for each model\n",
    "        for model_name, model_data in sorted(all_data[granularity]['test'].items()):\n",
    "            for lr_value, lr_data in sorted(model_data.items()):\n",
    "                # Collect the accuracy after the last epoch\n",
    "                last_epoch = sorted(lr_data.items())[-1][1]\n",
    "                accuracy = last_epoch['acc']\n",
    "    \n",
    "                # Store the accuracy in the dictionary\n",
    "                if model_name not in accuracy_data:\n",
    "                    accuracy_data[model_name] = {}\n",
    "                accuracy_data[model_name][f'lr={lr_value}'] = accuracy\n",
    "    \n",
    "        # Get a list of all learning rates in the data\n",
    "        all_learning_rates = sorted(set(lr for model_data in accuracy_data.values() for lr in model_data))\n",
    "    \n",
    "        # Generate the 2-D table with manual headers\n",
    "        headers = [\"Model Name\"] + all_learning_rates\n",
    "        table = []\n",
    "        \n",
    "        for model_name in accuracy_data:\n",
    "            row = [model_name] + [accuracy_data[model_name].get(lr, \"N/A\") for lr in all_learning_rates]\n",
    "            if \"N/A\" not  in row:\n",
    "                table.append(row)\n",
    "        \n",
    "        # Adding a title to the table\n",
    "        title = f\"Test Metrics for Granularity: {granularity}\"\n",
    "        \n",
    "        # Generate the table using tabulate\n",
    "        table_str = tabulate(table, headers=headers, tablefmt=\"fancy_grid\")\n",
    "    \n",
    "        # Insert the title in the middle of the table\n",
    "        lines = table_str.split('\\n')\n",
    "        lines.insert(0, title.center(len(lines[0])))\n",
    "        updated_table = '\\n'.join(lines)\n",
    "    \n",
    "        # Print the updated table with the title\n",
    "        print(updated_table)\n",
    "\n",
    "plot_test_metrics()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T05:02:28.702825Z",
     "start_time": "2023-11-01T05:02:28.692281Z"
    }
   },
   "id": "473ad4b8260120a1"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def plot_verbose_test_metrics(confusion_matrices: bool = False, \n",
    "                              class_wise_accuracies: bool = False):\n",
    "    # Now, create plots for test accuracy vs. epoch for each model\n",
    "    for granularity in granularities.values():\n",
    "        for model_name, model_data in sorted(all_data[granularity]['test'].items()):\n",
    "            print('\\n' + '#'* (100 + len(model_name)))\n",
    "            print('#'* 50 + f'{model_name}' + '#'* 50)\n",
    "            print('#'* (100 + len(model_name)) + '\\n')\n",
    "            metric = 'Accuracy'\n",
    "            \n",
    "            with Plot():\n",
    "                plt.title(f\"{granularity}-grain {model_name} - Test {metric} vs. Epoch\")\n",
    "                plt.xlabel('Epoch')\n",
    "                plt.ylabel(metric)\n",
    "        \n",
    "                for lr_value, lr_data in sorted(model_data.items()):\n",
    "                    # Sort the data based on the number of epochs\n",
    "                    epochs, epoch_data = zip(*sorted(lr_data.items()))\n",
    "                    plt.plot(epochs, [curr_data['acc'] for curr_data in epoch_data], label=f'lr={lr_value}')\n",
    "                    plt.xticks(np.arange(min(epochs), max(epochs)+1, 1)) # Set the x-axis ticks to be integers\n",
    "        \n",
    "                plt.legend()\n",
    "                plt.grid()\n",
    "            \n",
    "            if confusion_matrices or class_wise_accuracies:\n",
    "                for lr_value, lr_data in sorted(model_data.items()):\n",
    "                    epochs, epoch_data = zip(*sorted(lr_data.items()))\n",
    "                    \n",
    "                    if confusion_matrices:\n",
    "                        with Plot():\n",
    "                            plt.figure(figsize=(12, 9))\n",
    "                            sns.heatmap(epoch_data[-1]['cm'], \n",
    "                                        annot=True, \n",
    "                                        fmt=\"d\",  \n",
    "                                        xticklabels=fine_grain_classes, \n",
    "                                        yticklabels=fine_grain_classes\n",
    "                                        )\n",
    "            \n",
    "                            plt.xlabel('Predicted')\n",
    "                            plt.ylabel('Actual')\n",
    "                            plt.title(f'{granularity}-grain {model_name}, lr={lr_value} Confusion Matrix')\n",
    "                    \n",
    "                    if class_wise_accuracies:\n",
    "                        for class_label, class_name in enumerate(fine_grain_classes):\n",
    "                            precision = epoch_data[-1]['pre'][class_label]\n",
    "                            print(f'{model_name}, lr={lr_value}, {class_name}: Precision = {precision:.2f}')\n",
    "\n",
    "            \n",
    "# plot_verbose_test_metrics()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T05:02:29.190703Z",
     "start_time": "2023-11-01T05:02:29.188125Z"
    }
   },
   "id": "dff362a55920918d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# EDCR Results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff5d015e77a12310"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "models_and_lrs_folders = os.listdir(f'figs')\n",
    "\n",
    "def print_EDCR_results():\n",
    "    for filename in models_and_lrs_folders:\n",
    "        match = re.match(pattern=f'main_(fine|coarse)_(.+?)_lr(.+?)_secondary'\n",
    "                                 f'_(fine|coarse)_(.+?)_lr(.+)',\n",
    "                         string=filename)\n",
    "        \n",
    "        if match:\n",
    "            main_granularity, main_model_name, main_lr, secondary_granularity, secondary_model_name, secondary_lr = (match.group(i) for i in range(1,7))\n",
    "            \n",
    "            test_true = np.load(os.path.join(data_dir, f'test_true{suffix}.npy'))\n",
    "            prior_predictions = np.load(os.path.join(data_dir, \n",
    "                                                     f'{main_model_name}_test_pred_lr{main_lr}_e3{suffix}.npy'))\n",
    "            prior_acc = accuracy_score(y_true=test_true, \n",
    "                                       y_pred=prior_predictions)\n",
    "            \n",
    "            post_predictions = np.load(fr'figs/{match.group(0)}/results{suffix}.npy')\n",
    "            posterior_acc = accuracy_score(y_true=test_true, \n",
    "                                           y_pred=post_predictions)\n",
    "            print('#' * 100 + f'Main: {main_model_name} with lr {main_lr}, '\n",
    "                              f'secondary: {secondary_model_name} with lr {secondary_lr}\\n'\n",
    "                  f'Prior acc:{prior_acc}, post acc: {posterior_acc}\\n')\n",
    "            print(termcolor.colored(f\"Total acc change {'+' if posterior_acc > prior_acc else ''}\"\n",
    "                                    f\"{round((posterior_acc - prior_acc)*100, 3)}%\", \n",
    "                                    'green' if posterior_acc > prior_acc else 'red'))\n",
    "\n",
    "# print_EDCR_results()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T05:02:30.905255Z",
     "start_time": "2023-11-01T05:02:30.902195Z"
    }
   },
   "id": "b2bbfa3c5f3930f9"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'fine'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[34], line 164\u001B[0m\n\u001B[1;32m    157\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    160\u001B[0m     \u001B[38;5;66;03m# Print the maximal accuracy value across all tables (already colored in green)\u001B[39;00m\n\u001B[1;32m    161\u001B[0m     \u001B[38;5;66;03m# print(f\"Overall maximal post accuracy {round(max_accuracy*100, 1)}%\")\u001B[39;00m\n\u001B[1;32m    162\u001B[0m     \u001B[38;5;66;03m# print(max_data)\u001B[39;00m\n\u001B[0;32m--> 164\u001B[0m \u001B[43mprint_EDCR_table\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[34], line 131\u001B[0m, in \u001B[0;36mprint_EDCR_table\u001B[0;34m()\u001B[0m\n\u001B[1;32m    129\u001B[0m \u001B[38;5;66;03m# Get a list of learning rates from the first secondary model\u001B[39;00m\n\u001B[1;32m    130\u001B[0m secondary_granularities \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfine\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcoarse\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m--> 131\u001B[0m main_learning_rates \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msorted\u001B[39m(\u001B[43mgranularity_data\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mfine\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mkeys())\n\u001B[1;32m    133\u001B[0m \u001B[38;5;66;03m# Create the header row with learning rates\u001B[39;00m\n\u001B[1;32m    134\u001B[0m header \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m+\u001B[39m main_learning_rates\n",
      "\u001B[0;31mKeyError\u001B[0m: 'fine'"
     ]
    }
   ],
   "source": [
    "def gather_EDCR_data():\n",
    "    # Sample data structure (replace this with your actual data)\n",
    "    data = {}  # Create an empty dictionary to store the accuracy data\n",
    "    \n",
    "    # Track the maximal accuracy value across all tables\n",
    "    # max_accuracy = -1.0\n",
    "    # max_data = {}\n",
    "    \n",
    "    # Iterate through filenames to collect accuracy data\n",
    "    for filename in models_and_lrs_folders:\n",
    "        match = re.match(\n",
    "            pattern=(\n",
    "                f'main_(fine)_(.+?)_lr(.+?)_secondary'\n",
    "                f'_(fine|coarse)_(.+?)_lr(.+)'\n",
    "            ),\n",
    "            string=filename\n",
    "        )\n",
    "        \n",
    "        if match:\n",
    "            (\n",
    "                main_granularity,\n",
    "                main_model_name,\n",
    "                main_lr,\n",
    "                secondary_granularity,\n",
    "                secondary_model_name,\n",
    "                secondary_lr\n",
    "            ) = (match.group(i) for i in range(1, 7))\n",
    "            \n",
    "            suffix = '_coarse' if main_granularity == 'coarse' else ''\n",
    "            test_true = np.load(os.path.join(data_dir, f'test_true{suffix}.npy'))\n",
    "            \n",
    "            prior_predictions = np.load(os.path.join(data_dir, rf'{main_model_name}_test_pred_lr{main_lr}_e3{suffix}.npy'))\n",
    "            prior_acc = accuracy_score(y_true=test_true, \n",
    "                                       y_pred=prior_predictions)\n",
    "            \n",
    "            suffix = '_coarse' if secondary_granularity == 'coarse' else ''\n",
    "            post_predictions = np.load(f'figs/{match.group(0)}/results{suffix}.npy')\n",
    "            posterior_acc = accuracy_score(y_true=test_true, \n",
    "                                           y_pred=post_predictions)\n",
    "    \n",
    "            # Update the maximal accuracy value\n",
    "            # if posterior_acc > max_accuracy:\n",
    "            #     max_accuracy = posterior_acc\n",
    "            #     max_data = {'main_model_name': main_model_name,\n",
    "            #                 'main_lr': main_lr,\n",
    "            #                 'secondary_model_name': secondary_model_name,\n",
    "            #                 'secondary_lr': secondary_lr}\n",
    "               \n",
    "            # Store accuracy data in the data dictionary\n",
    "            if main_granularity not in data:\n",
    "                data[main_granularity] = {}\n",
    "            if main_model_name not in data[main_granularity]:\n",
    "                data[main_granularity][main_model_name] = {}\n",
    "            if main_lr not in data[main_granularity][main_model_name]:\n",
    "                data[main_granularity][main_model_name][main_lr] = {}\n",
    "            if secondary_granularity not in data[main_granularity][main_model_name][main_lr]:\n",
    "                data[main_granularity][main_model_name][main_lr][secondary_granularity] = {}\n",
    "            if secondary_model_name not in data[main_granularity][main_model_name][main_lr][secondary_granularity]:\n",
    "                data[main_granularity][main_model_name][main_lr][secondary_granularity][secondary_model_name] = {}\n",
    "                \n",
    "            data[main_granularity][main_model_name][main_lr][secondary_granularity][secondary_model_name][secondary_lr] = {'prior': prior_acc, 'post': posterior_acc}\n",
    "            \n",
    "    return data\n",
    "\n",
    "def compose_EDCR_table():\n",
    "    for main_granularity, main_granularity_data in data.items():\n",
    "        for main_model_name, main_model_data in main_granularity_data.items():\n",
    "            table_data = []\n",
    "\n",
    "            # Get a list of learning rates from the first secondary model\n",
    "            learning_rates = sorted(main_model_data.keys())\n",
    "            \n",
    "            header = [''] + learning_rates\n",
    "            table_data.append(header)\n",
    "            \n",
    "            for secondary_granularity, secondary_granularity_data in data.items():\n",
    "                secondary_models_data = list(main_model_data.values())\n",
    "                \n",
    "                # Sort the secondary model names\n",
    "                # sorted_secondary_models = sorted(secondary_models_data[0].keys())\n",
    "    \n",
    "                # Create the header row with learning rates\n",
    "                \n",
    "            \n",
    "            \n",
    "                \n",
    "                # Add rows for each secondary model, ensuring they are sorted\n",
    "                for secondary_model_name in sorted_secondary_models:\n",
    "                    row = [secondary_model_name]\n",
    "                    add = []\n",
    "                    \n",
    "                    for main_lr in learning_rates:\n",
    "                        add_str_list = []\n",
    "                        for secondary_lr in learning_rates:\n",
    "                            curr_data = data[main_granularity][main_model_name][main_lr][secondary_granularity][secondary_model_name][secondary_lr]\n",
    "                            curr_post = curr_data['post']\n",
    "                            curr_prior = curr_data['prior']\n",
    "                            curr_diff = curr_post - curr_prior\n",
    "                            \n",
    "                            add_str_list += [f\"{secondary_lr}: \"\n",
    "                                             f\"{round(curr_post*100, 1)}% \"\n",
    "                                                f\"({round(curr_prior*100, 1)}%, \"\n",
    "                                                + termcolor.colored(f\"{'+' if curr_post > curr_prior else ''}\", color='green') +\n",
    "                                                termcolor.colored(f\"{round(curr_diff*100, 1)}%)\", \n",
    "                                                                  color='green' if curr_post > curr_prior \n",
    "                                                                  else 'red') + '\\n']\n",
    "                        \n",
    "                        add_str = '\\n'.join(add_str_list)\n",
    "                        add += [add_str]\n",
    "                    row += add\n",
    "                    table_data.append(row)\n",
    "    \n",
    "            # Create the table using tabulate\n",
    "            table = tabulate(tabular_data=table_data, \n",
    "                             headers='firstrow', \n",
    "                             tablefmt='grid')\n",
    "\n",
    "            # Print the main model name and the corresponding table\n",
    "            print(f\"Main model: {granularity.capitalize()}-grain {main_model_name}\")\n",
    "            print(table)\n",
    "            print(\"\\n\")\n",
    "            \n",
    "def print_EDCR_table():\n",
    "    data = gather_EDCR_data()\n",
    "    # Loop through each main model and generate a table\n",
    "    for main_model_name, granularity_data in data.items():\n",
    "        table_data = []\n",
    "\n",
    "        # Get a list of learning rates from the first secondary model\n",
    "        secondary_granularities = ['fine', 'coarse']\n",
    "        main_learning_rates = sorted(granularity_data['fine'].keys())\n",
    "\n",
    "        # Create the header row with learning rates\n",
    "        header = [''] + main_learning_rates\n",
    "        table_data.append(header)\n",
    "\n",
    "        for secondary_granularity in secondary_granularities:\n",
    "            secondary_models_data = granularity_data[secondary_granularity]\n",
    "            sorted_secondary_models = sorted(secondary_models_data.keys())\n",
    "\n",
    "            for secondary_model_name in sorted_secondary_models:\n",
    "                row = [f\"{secondary_granularity.capitalize()} - {secondary_model_name}\"] + [\n",
    "                    f\"{secondary_lr}: {round(data[main_model_name][secondary_granularity][secondary_model_name][secondary_lr]['post'] * 100, 1)}% \"\n",
    "                    f\"({round(data[main_model_name][secondary_granularity][secondary_model_name][secondary_lr]['prior'] * 100, 1)}%, \"\n",
    "                    f\"{'+' if data[main_model_name][secondary_granularity][secondary_model_name][secondary_lr]['post'] > data[main_model_name][secondary_granularity][secondary_model_name][secondary_lr]['prior'] else ''}\"\n",
    "                    f\"{round((data[main_model_name][secondary_granularity][secondary_model_name][secondary_lr]['post'] - data[main_model_name][secondary_granularity][secondary_model_name][secondary_lr]['prior']) * 100, 1)}%)\"\n",
    "                    for secondary_lr in main_learning_rates\n",
    "                ]\n",
    "                table_data.append(row)\n",
    "\n",
    "        # Create the table using tabulate\n",
    "        table = tabulate(tabular_data=table_data, headers='firstrow', tablefmt='grid')\n",
    "\n",
    "        # Print the main model name and the corresponding table\n",
    "        print(f\"Fine-grain with main Model: {main_model_name}\")\n",
    "        print(table)\n",
    "        print(\"\\n\")\n",
    "    \n",
    "\n",
    "    # Print the maximal accuracy value across all tables (already colored in green)\n",
    "    # print(f\"Overall maximal post accuracy {round(max_accuracy*100, 1)}%\")\n",
    "    # print(max_data)\n",
    "\n",
    "print_EDCR_table()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T07:59:44.955280Z",
     "start_time": "2023-11-01T07:59:44.797486Z"
    }
   },
   "id": "3f6e34912281d5e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "}# Histograms"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "75dd627d1ecc97d8"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "{'30N6E_13.jpg': 1,\n '30N6E_2.jpg': 1,\n '30N6E_5.jpg': 1,\n '30N6E_8.jpg': 1,\n 'BM-30_112.jpg': 1,\n 'BM-30_18.jpg': 1,\n 'BM-30_89.jpg': 1,\n 'BM-30_92.jpg': 1,\n 'BMD_3.jpg': 1,\n 'BMD_5.jpg': 1,\n 'BMD_83.jpg': 1,\n 'BMD_9.jpg': 1,\n 'BMP-1_18.jpg': 1,\n 'BMP-1_2.jpg': 1,\n 'BMP-1_7.jpg': 1,\n 'BMP-2_0.jpg': 1,\n 'BMP-2_24.jpg': 1,\n 'BMP-2_33.jpg': 1,\n 'BMP-2_5.jpg': 1,\n 'BMP-T15_19.jpg': 1,\n 'BMP-T15_48.jpg': 1,\n 'BMP-T15_75.jpg': 1,\n 'BMP-T15_80.jpg': 1,\n 'BRDM_17.jpg': 1,\n 'BRDM_27.jpg': 1,\n 'BRDM_35.jpg': 1,\n 'BRDM_44.jpg': 1,\n 'BTR-60_103.jpg': 1,\n 'BTR-60_151.jpg': 1,\n 'BTR-60_50.jpg': 1,\n 'BTR-60_70.jpg': 1,\n 'BTR-70_17.jpg': 1,\n 'BTR-70_24.jpg': 1,\n 'BTR-70_5.jpg': 1,\n 'BTR-70_8.jpg': 1,\n 'BTR-80_34.jpg': 1,\n 'BTR-80_37.jpg': 1,\n 'BTR-80_73.jpg': 1,\n 'BTR-80_8.jpg': 1,\n 'D-30_2.jpg': 0,\n 'D-30_50.jpg': 0,\n 'D-30_51.jpg': 1,\n 'D-30_62.jpg': 0,\n 'Iskander_31.jpg': 1,\n 'Iskander_58.jpg': 1,\n 'Iskander_75.jpg': 0,\n 'Iskander_87.jpg': 1,\n 'MT_LB_1.jpg': 1,\n 'MT_LB_27.jpg': 1,\n 'MT_LB_6.jpg': 1,\n 'MT_LB_72.jpg': 1,\n 'Pantsir-S1_12.jpg': 1,\n 'Pantsir-S1_14.jpg': 1,\n 'Pantsir-S1_24.jpg': 1,\n 'Pantsir-S1_4.jpg': 1,\n 'Rs-24_100.jpg': 1,\n 'Rs-24_55.jpg': 1,\n 'Rs-24_73.jpg': 1,\n 'Rs-24_75.jpg': 1,\n 'T-14_12.jpg': 1,\n 'T-14_25.jpg': 0,\n 'T-14_29.jpg': 1,\n 'T-14_43.jpg': 1,\n 'T-62_12.jpg': 1,\n 'T-62_41.jpg': 1,\n 'T-62_45.jpg': 1,\n 'T-62_57.jpg': 1,\n 'T-64_1.jpg': 1,\n 'T-64_13.jpg': 1,\n 'T-64_2.jpg': 1,\n 'T-64_20.jpg': 0,\n 'T-72_0.jpg': 1,\n 'T-72_8.jpg': 0,\n 'T-80_23.jpg': 0,\n 'T-80_29.jpg': 0,\n 'T-80_32.jpg': 0,\n 'T-80_43.jpg': 1,\n 'T-90_16.jpg': 0,\n 'T-90_18.jpg': 1,\n 'T-90_22.jpg': 1,\n 'T-90_42.jpg': 0,\n 'TOS-1_22.jpg': 1,\n 'TOS-1_3.jpg': 1,\n 'TOS-1_30.jpg': 1,\n 'TOS-1_7.jpg': 1,\n 'Tornado_20.jpg': 1,\n 'Tornado_27.jpg': 1,\n 'Tornado_3.jpg': 1,\n '2S19_0.jpg': 0,\n '2S19_1.jpg': 0,\n '2S19_10.jpg': 0,\n '2S19_11.jpg': 0,\n '2S19_12.jpg': 0,\n '2S19_13.jpg': 0,\n '2S19_14.jpg': 0,\n '2S19_15.jpg': 0,\n '2S19_16.jpg': 0,\n '2S19_17.jpg': 0,\n '2S19_18.jpg': 0,\n '2S19_19.jpg': 0,\n '2S19_2.jpg': 0,\n '2S19_20.jpg': 0,\n '2S19_21.jpg': 0,\n '2S19_22.jpg': 0,\n '2S19_23.jpg': 0,\n '2S19_24.jpg': 0,\n '2S19_25.jpg': 0,\n '2S19_26.jpg': 0,\n '2S19_27.jpg': 0,\n '2S19_28.jpg': 0,\n '2S19_29.jpg': 0,\n '2S19_3.jpg': 0,\n '2S19_30.jpg': 0,\n '2S19_31.jpg': 0,\n '2S19_32.jpg': 0,\n '2S19_33.jpg': 0,\n '2S19_34.jpg': 1,\n '2S19_35.jpg': 0,\n '2S19_36.jpg': 0,\n '2S19_37.jpg': 0,\n '2S19_38.jpg': 0,\n '2S19_39.jpg': 0,\n '2S19_4.jpg': 0,\n '2S19_40.jpg': 0,\n '2S19_41.jpg': 0,\n '2S19_42.jpg': 0,\n '2S19_43.jpg': 1,\n '2S19_44.jpg': 0,\n '2S19_45.jpg': 0,\n '2S19_46.jpg': 0,\n '2S19_47.jpg': 0,\n '2S19_48.jpg': 0,\n '2S19_49.jpg': 0,\n '2S19_5.jpg': 0,\n '2S19_50.jpg': 0,\n '2S19_51.jpg': 0,\n '2S19_52.jpg': 0,\n '2S19_53.jpg': 1,\n '2S19_54.jpg': 1,\n '2S19_55.jpg': 0,\n '2S19_56.jpg': 0,\n '2S19_57.jpg': 0,\n '2S19_58.jpg': 0,\n '2S19_6.jpg': 0,\n '2S19_7.jpg': 0,\n '2S19_8.jpg': 0,\n '2S19_9.jpg': 0}"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('json_predictions/2S19_predictions.json') as f:\n",
    "    first = json.load(f)\n",
    "\n",
    "first"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T02:11:43.699176Z",
     "start_time": "2023-10-31T02:11:43.638507Z"
    }
   },
   "id": "f5df57b45a12b970"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3206f04f92a0b498"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
