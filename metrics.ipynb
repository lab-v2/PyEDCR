{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-25T08:32:11.785268Z",
     "start_time": "2023-10-25T08:32:11.593458Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import abc\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "import termcolor\n",
    "from tabulate import tabulate\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from vision_models import lrs, vit_model_names\n",
    "from metacognitive_pipeline import fine_grain_classes, n_classes\n",
    "\n",
    "class Context(abc.ABC):\n",
    "    @abc.abstractmethod\n",
    "    def __enter__(self):\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        pass\n",
    "    \n",
    "class Plot(Context):\n",
    "    def __init__(self,\n",
    "                 fig_sizes: tuple = None):\n",
    "        if fig_sizes:\n",
    "            plt.figure(figsize=fig_sizes)\n",
    "\n",
    "    def __enter__(self):\n",
    "        plt.cla()\n",
    "        plt.clf()\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        plt.show()\n",
    "        plt.cla()\n",
    "        plt.clf()\n",
    "        \n",
    "data_dir = 'results/'  # Set the directory where your .npy files are located\n",
    "\n",
    "# Initialize dictionaries to store training and test accuracy data for each model\n",
    "model_train_data = {}\n",
    "model_test_data = {}\n",
    "\n",
    "test_true = np.load(os.path.join(data_dir, 'test_true.npy'))\n",
    "\n",
    "# Loop through all files in the directory\n",
    "for filename in os.listdir(data_dir):\n",
    "    train_match = re.match(pattern=r'(.+?)_train_(loss|acc)_lr(.+?)_e(\\d+?).npy',\n",
    "                           string=filename)\n",
    "    test_match = re.match(pattern=r'(.+?)_test_pred_lr(.+?)_e(\\d+?).npy',\n",
    "                          string=filename)\n",
    "\n",
    "    if train_match:\n",
    "        model_name = train_match.group(1)\n",
    "        metric = train_match.group(2)\n",
    "        lr_value = float(train_match.group(3))\n",
    "        num_epochs = int(train_match.group(4)) + 1\n",
    "\n",
    "        # Load the data from the .npy file\n",
    "        data = np.load(os.path.join(data_dir, filename))\n",
    "\n",
    "        # Store the data in the model_data dictionary\n",
    "        if model_name not in model_train_data:\n",
    "            model_train_data[model_name] = {}\n",
    "        if metric not in model_train_data[model_name]:\n",
    "            model_train_data[model_name][metric] = {}\n",
    "        if lr_value not in model_train_data[model_name][metric]:\n",
    "            model_train_data[model_name][metric][lr_value] = {}\n",
    "\n",
    "        model_train_data[model_name][metric][lr_value][num_epochs] = data[-1]\n",
    "    elif test_match:\n",
    "        model_name = test_match.group(1)\n",
    "        lr_value = float(test_match.group(2))\n",
    "        num_epochs = int(test_match.group(3)) + 1\n",
    "\n",
    "        # Load the test data from the .npy file\n",
    "        test_pred = np.load(os.path.join(data_dir, filename))\n",
    "\n",
    "        # Store the data in the model_test_data dictionary\n",
    "        if model_name not in model_test_data:\n",
    "            model_test_data[model_name] = {}\n",
    "        if lr_value not in model_test_data[model_name]:\n",
    "            model_test_data[model_name][lr_value] = {}\n",
    "\n",
    "        model_test_data[model_name][lr_value][num_epochs] = \\\n",
    "            {'acc': accuracy_score(test_true, test_pred), \n",
    "             'cm': confusion_matrix(test_true, test_pred),\n",
    "             'pre': precision_score(test_true, test_pred, labels=range(n_classes), average=None),\n",
    "             'rec': recall_score(test_true, test_pred, labels=range(n_classes), average=None),\n",
    "             'f1': f1_score(test_true, test_pred, labels=range(n_classes), average=None)}"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train metrics"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8826ef905a164c15"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "def plot_train_metrics():\n",
    "    # Create plots for training metric vs. epoch for each model\n",
    "    for model_name, model_data in sorted(model_train_data.items()):\n",
    "        print('\\n' + '#'* (100 + len(model_name)))\n",
    "        print('#'* 50 + f'{model_name}' + '#'* 50)\n",
    "        print('#'* (100 + len(model_name)) + '\\n')\n",
    "        for metric, metric_data in model_data.items():\n",
    "            with Plot():\n",
    "                plt.title(f\"{model_name} training {metric} vs. epoch\")\n",
    "                plt.xlabel('Epoch')\n",
    "                plt.ylabel(metric.capitalize())\n",
    "    \n",
    "                for lr_value, lr_data in sorted(metric_data.items()):\n",
    "                    epochs, data = zip(*sorted(lr_data.items())) # Sort the data based on the number of epochs\n",
    "                    plt.plot(epochs, data, label=f'lr={lr_value}')\n",
    "                    plt.xticks(np.arange(min(epochs), max(epochs)+1, 1)) # Set the x-axis ticks to be integers\n",
    "    \n",
    "                plt.legend()\n",
    "                plt.grid()\n",
    "\n",
    "# plot_train_metrics()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T08:32:12.533059Z",
     "start_time": "2023-10-25T08:32:12.507358Z"
    }
   },
   "id": "77ea4d8f8e19eb6e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test metrics"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1b4fda72717cd425"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒══════════════╤════════════╤════════════╤════════════╕\n",
      "│ Model Name   │   lr=1e-05 │   lr=1e-06 │   lr=5e-05 │\n",
      "╞══════════════╪════════════╪════════════╪════════════╡\n",
      "│ vit_b_16     │   0.639112 │   0.699568 │   0.645281 │\n",
      "├──────────────┼────────────┼────────────┼────────────┤\n",
      "│ vit_b_32     │   0.558914 │   0.636644 │   0.537323 │\n",
      "├──────────────┼────────────┼────────────┼────────────┤\n",
      "│ vit_l_16     │   0.699568 │   0.702653 │   0.661937 │\n",
      "├──────────────┼────────────┼────────────┼────────────┤\n",
      "│ vit_l_32     │   0.582357 │   0.673041 │   0.624306 │\n",
      "╘══════════════╧════════════╧════════════╧════════════╛\n"
     ]
    }
   ],
   "source": [
    "def plot_test_metrics():\n",
    "    # Create a dictionary to store accuracy values for each model and learning rate\n",
    "    accuracy_data = {}\n",
    "\n",
    "    # Now, create plots for test accuracy vs. epoch for each model\n",
    "    for model_name, model_data in sorted(model_test_data.items()):\n",
    "        for lr_value, lr_data in sorted(model_data.items()):\n",
    "            # Collect the accuracy after the last epoch\n",
    "            last_epoch = sorted(lr_data.items())[-1][1]\n",
    "            accuracy = last_epoch['acc']\n",
    "\n",
    "            # Store the accuracy in the dictionary\n",
    "            if model_name not in accuracy_data:\n",
    "                accuracy_data[model_name] = {}\n",
    "            accuracy_data[model_name][f'lr={lr_value}'] = accuracy\n",
    "\n",
    "\n",
    "    # Get a list of all learning rates in the data\n",
    "    all_learning_rates = sorted(set(lr for model_data in accuracy_data.values() for lr in model_data))\n",
    "\n",
    "    # Generate the 2-D table with manual headers\n",
    "    headers = [\"Model Name\"] + all_learning_rates\n",
    "    table = []\n",
    "\n",
    "    for model_name in accuracy_data:\n",
    "        row = [model_name] + [accuracy_data[model_name].get(lr, \"N/A\") for lr in all_learning_rates]\n",
    "        table.append(row)\n",
    "\n",
    "    # Print the table using tabulate\n",
    "    print(tabulate(table, headers=headers, tablefmt=\"fancy_grid\"))\n",
    "\n",
    "plot_test_metrics()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T08:32:13.435896Z",
     "start_time": "2023-10-25T08:32:13.424839Z"
    }
   },
   "id": "473ad4b8260120a1"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "def plot_verbose_test_metrics(cms: bool = False, \n",
    "                              class_wise_accuracies: bool = False):\n",
    "    # Now, create plots for test accuracy vs. epoch for each model\n",
    "    for model_name, model_data in sorted(model_test_data.items()):\n",
    "        print('\\n' + '#'* (100 + len(model_name)))\n",
    "        print('#'* 50 + f'{model_name}' + '#'* 50)\n",
    "        print('#'* (100 + len(model_name)) + '\\n')\n",
    "        metric = 'Accuracy'\n",
    "        \n",
    "        with Plot():\n",
    "            plt.title(f\"{model_name} - Test {metric} vs. Epoch\")\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel(metric)\n",
    "    \n",
    "            for lr_value, lr_data in sorted(model_data.items()):\n",
    "                # Sort the data based on the number of epochs\n",
    "                epochs, epoch_data = zip(*sorted(lr_data.items()))\n",
    "                plt.plot(epochs, [curr_data['acc'] for curr_data in epoch_data], label=f'lr={lr_value}')\n",
    "                plt.xticks(np.arange(min(epochs), max(epochs)+1, 1)) # Set the x-axis ticks to be integers\n",
    "    \n",
    "            plt.legend()\n",
    "            plt.grid()\n",
    "        \n",
    "        if cms or class_wise_accuracies:\n",
    "            for lr_value, lr_data in sorted(model_data.items()):\n",
    "                epochs, epoch_data = zip(*sorted(lr_data.items()))\n",
    "                \n",
    "                if cms:\n",
    "                    with Plot():\n",
    "                        plt.figure(figsize=(12, 9))\n",
    "                        sns.heatmap(epoch_data[-1]['cm'], \n",
    "                                    annot=True, \n",
    "                                    fmt=\"d\",  \n",
    "                                    xticklabels=fine_grain_classes, \n",
    "                                    yticklabels=fine_grain_classes\n",
    "                                    )\n",
    "        \n",
    "                        plt.xlabel('Predicted')\n",
    "                        plt.ylabel('Actual')\n",
    "                        plt.title(f'{model_name}, lr={lr_value} Confusion Matrix')\n",
    "                \n",
    "                if class_wise_accuracies:\n",
    "                    for class_label, class_name in enumerate(fine_grain_classes):\n",
    "                        precision = epoch_data[-1]['pre'][class_label]\n",
    "                        print(f'{model_name}, lr={lr_value}, {class_name}: Precision = {precision:.2f}')\n",
    "\n",
    "            \n",
    "# plot_verbose_test_metrics()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T08:32:14.050437Z",
     "start_time": "2023-10-25T08:32:14.029759Z"
    }
   },
   "id": "dff362a55920918d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# EDCR Results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff5d015e77a12310"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "108"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_and_lrs_folders = os.listdir(f'figs')\n",
    "assert (len(vit_model_names) - 1) * (len(vit_model_names) - 2) * len(lrs) ** 2  == len(models_and_lrs_folders) - 1\n",
    "\n",
    "len(models_and_lrs_folders) - 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T08:32:15.154096Z",
     "start_time": "2023-10-25T08:32:15.146157Z"
    }
   },
   "id": "2c57b049b41cafb1"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "def print_EDCR_results():\n",
    "    for filename in models_and_lrs_folders:\n",
    "        match = re.match(pattern=rf'main_(.+?)_lr(.+?)_secondary_(.+?)_lr(.+)',\n",
    "                         string=filename)\n",
    "        if match:\n",
    "            main_model_name, main_lr, secondary_model_name, secondary_lr = (match.group(i) for i in range(1,5))\n",
    "            prior_predictions = np.load(os.path.join(data_dir, \n",
    "                                                     rf'{main_model_name}_test_pred_lr{main_lr}_e3.npy'))\n",
    "            prior_acc = accuracy_score(y_true=test_true, \n",
    "                                       y_pred=prior_predictions)\n",
    "            \n",
    "            post_predictions = np.load(f'{data_dir}/figs/{match.group(0)}/results.npy')\n",
    "            posterior_acc = accuracy_score(y_true=test_true, \n",
    "                                           y_pred=post_predictions)\n",
    "            print('#' * 100 + f'Main: {main_model_name} with lr {main_lr}, '\n",
    "                              f'secondary: {secondary_model_name} with lr {secondary_lr}\\n'\n",
    "                  f'Prior acc:{prior_acc}, post acc: {posterior_acc}\\n')\n",
    "            print(termcolor.colored(f\"Total acc change {'+' if posterior_acc > prior_acc else ''}\"\n",
    "                                    f\"{round((posterior_acc - prior_acc)*100, 3)}%\", \n",
    "                                    'green' if posterior_acc > prior_acc else 'red'))\n",
    "\n",
    "# print_EDCR_results()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T08:32:15.735408Z",
     "start_time": "2023-10-25T08:32:15.714438Z"
    }
   },
   "id": "b2bbfa3c5f3930f9"
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Model: vit_l_16\n",
      "+------+--------------------------------+--------------------------------+--------------------------------+\n",
      "|      | 1e-05                          | 1e-06                          | 5e-05                          |\n",
      "+======+================================+================================+================================+\n",
      "| b_16 | 1e-05: 69.52% (69.96%, \u001B[32m\u001B[0m\u001B[31m-0.43%)\u001B[0m | 1e-05: 69.28% (70.27%, \u001B[32m\u001B[0m\u001B[31m-0.99%)\u001B[0m | 1e-05: 66.26% (66.19%, \u001B[32m+\u001B[0m\u001B[32m0.06%)\u001B[0m |\n",
      "|      |                                |                                |                                |\n",
      "|      | 1e-06: 70.7% (69.96%, \u001B[32m+\u001B[0m\u001B[32m0.74%)\u001B[0m  | 1e-06: 71.75% (70.27%, \u001B[32m+\u001B[0m\u001B[32m1.48%)\u001B[0m | 1e-06: 68.04% (66.19%, \u001B[32m+\u001B[0m\u001B[32m1.85%)\u001B[0m |\n",
      "|      |                                |                                |                                |\n",
      "|      | 5e-05: 70.27% (69.96%, \u001B[32m+\u001B[0m\u001B[32m0.31%)\u001B[0m | 5e-05: 70.82% (70.27%, \u001B[32m+\u001B[0m\u001B[32m0.56%)\u001B[0m | 5e-05: 67.18% (66.19%, \u001B[32m+\u001B[0m\u001B[32m0.99%)\u001B[0m |\n",
      "+------+--------------------------------+--------------------------------+--------------------------------+\n",
      "| b_32 | 1e-05: 69.96% (69.96%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m   | 1e-05: 69.46% (70.27%, \u001B[32m\u001B[0m\u001B[31m-0.8%)\u001B[0m  | 1e-05: 64.84% (66.19%, \u001B[32m\u001B[0m\u001B[31m-1.36%)\u001B[0m |\n",
      "|      |                                |                                |                                |\n",
      "|      | 1e-06: 69.83% (69.96%, \u001B[32m\u001B[0m\u001B[31m-0.12%)\u001B[0m | 1e-06: 69.9% (70.27%, \u001B[32m\u001B[0m\u001B[31m-0.37%)\u001B[0m  | 1e-06: 64.65% (66.19%, \u001B[32m\u001B[0m\u001B[31m-1.54%)\u001B[0m |\n",
      "|      |                                |                                |                                |\n",
      "|      | 5e-05: 69.77% (69.96%, \u001B[32m\u001B[0m\u001B[31m-0.19%)\u001B[0m | 5e-05: 70.08% (70.27%, \u001B[32m\u001B[0m\u001B[31m-0.19%)\u001B[0m | 5e-05: 64.16% (66.19%, \u001B[32m\u001B[0m\u001B[31m-2.04%)\u001B[0m |\n",
      "+------+--------------------------------+--------------------------------+--------------------------------+\n",
      "| l_32 | 1e-05: 69.96% (69.96%, \u001B[32m\u001B[0m\u001B[31m0.0%)\u001B[0m   | 1e-05: 70.7% (70.27%, \u001B[32m+\u001B[0m\u001B[32m0.43%)\u001B[0m  | 1e-05: 65.14% (66.19%, \u001B[32m\u001B[0m\u001B[31m-1.05%)\u001B[0m |\n",
      "|      |                                |                                |                                |\n",
      "|      | 1e-06: 69.77% (69.96%, \u001B[32m\u001B[0m\u001B[31m-0.19%)\u001B[0m | 1e-06: 70.02% (70.27%, \u001B[32m\u001B[0m\u001B[31m-0.25%)\u001B[0m | 1e-06: 65.89% (66.19%, \u001B[32m\u001B[0m\u001B[31m-0.31%)\u001B[0m |\n",
      "|      |                                |                                |                                |\n",
      "|      | 5e-05: 69.22% (69.96%, \u001B[32m\u001B[0m\u001B[31m-0.74%)\u001B[0m | 5e-05: 70.2% (70.27%, \u001B[32m\u001B[0m\u001B[31m-0.06%)\u001B[0m  | 5e-05: 64.77% (66.19%, \u001B[32m\u001B[0m\u001B[31m-1.42%)\u001B[0m |\n",
      "+------+--------------------------------+--------------------------------+--------------------------------+\n",
      "\n",
      "\n",
      "Main Model: vit_b_32\n",
      "+------+---------------------------------+--------------------------------+--------------------------------+\n",
      "|      | 1e-05                           | 1e-06                          | 5e-05                          |\n",
      "+======+=================================+================================+================================+\n",
      "| b_16 | 1e-05: 60.76% (55.89%, \u001B[32m+\u001B[0m\u001B[32m4.87%)\u001B[0m  | 1e-05: 63.79% (63.66%, \u001B[32m+\u001B[0m\u001B[32m0.12%)\u001B[0m | 1e-05: 57.06% (53.73%, \u001B[32m+\u001B[0m\u001B[32m3.33%)\u001B[0m |\n",
      "|      |                                 |                                |                                |\n",
      "|      | 1e-06: 69.22% (55.89%, \u001B[32m+\u001B[0m\u001B[32m13.33%)\u001B[0m | 1e-06: 69.09% (63.66%, \u001B[32m+\u001B[0m\u001B[32m5.43%)\u001B[0m | 1e-06: 61.88% (53.73%, \u001B[32m+\u001B[0m\u001B[32m8.14%)\u001B[0m |\n",
      "|      |                                 |                                |                                |\n",
      "|      | 5e-05: 62.8% (55.89%, \u001B[32m+\u001B[0m\u001B[32m6.91%)\u001B[0m   | 5e-05: 67.18% (63.66%, \u001B[32m+\u001B[0m\u001B[32m3.52%)\u001B[0m | 5e-05: 63.73% (53.73%, \u001B[32m+\u001B[0m\u001B[32m9.99%)\u001B[0m |\n",
      "+------+---------------------------------+--------------------------------+--------------------------------+\n",
      "| l_16 | 1e-05: 65.7% (55.89%, \u001B[32m+\u001B[0m\u001B[32m9.81%)\u001B[0m   | 1e-05: 67.67% (63.66%, \u001B[32m+\u001B[0m\u001B[32m4.01%)\u001B[0m | 1e-05: 61.51% (53.73%, \u001B[32m+\u001B[0m\u001B[32m7.77%)\u001B[0m |\n",
      "|      |                                 |                                |                                |\n",
      "|      | 1e-06: 69.22% (55.89%, \u001B[32m+\u001B[0m\u001B[32m13.33%)\u001B[0m | 1e-06: 68.66% (63.66%, \u001B[32m+\u001B[0m\u001B[32m5.0%)\u001B[0m  | 1e-06: 64.84% (53.73%, \u001B[32m+\u001B[0m\u001B[32m11.1%)\u001B[0m |\n",
      "|      |                                 |                                |                                |\n",
      "|      | 5e-05: 66.07% (55.89%, \u001B[32m+\u001B[0m\u001B[32m10.18%)\u001B[0m | 5e-05: 67.98% (63.66%, \u001B[32m+\u001B[0m\u001B[32m4.32%)\u001B[0m | 5e-05: 62.12% (53.73%, \u001B[32m+\u001B[0m\u001B[32m8.39%)\u001B[0m |\n",
      "+------+---------------------------------+--------------------------------+--------------------------------+\n",
      "| l_32 | 1e-05: 58.91% (55.89%, \u001B[32m+\u001B[0m\u001B[32m3.02%)\u001B[0m  | 1e-05: 63.73% (63.66%, \u001B[32m+\u001B[0m\u001B[32m0.06%)\u001B[0m | 1e-05: 55.52% (53.73%, \u001B[32m+\u001B[0m\u001B[32m1.79%)\u001B[0m |\n",
      "|      |                                 |                                |                                |\n",
      "|      | 1e-06: 63.17% (55.89%, \u001B[32m+\u001B[0m\u001B[32m7.28%)\u001B[0m  | 1e-06: 65.89% (63.66%, \u001B[32m+\u001B[0m\u001B[32m2.22%)\u001B[0m | 1e-06: 59.53% (53.73%, \u001B[32m+\u001B[0m\u001B[32m5.8%)\u001B[0m  |\n",
      "|      |                                 |                                |                                |\n",
      "|      | 5e-05: 60.33% (55.89%, \u001B[32m+\u001B[0m\u001B[32m4.44%)\u001B[0m  | 5e-05: 64.65% (63.66%, \u001B[32m+\u001B[0m\u001B[32m0.99%)\u001B[0m | 5e-05: 56.94% (53.73%, \u001B[32m+\u001B[0m\u001B[32m3.21%)\u001B[0m |\n",
      "+------+---------------------------------+--------------------------------+--------------------------------+\n",
      "\n",
      "\n",
      "Main Model: vit_l_32\n",
      "+------+--------------------------------+-------------------------------+--------------------------------+\n",
      "|      | 1e-05                          | 1e-06                         | 5e-05                          |\n",
      "+======+================================+===============================+================================+\n",
      "| b_16 | 1e-05: 59.41% (58.24%, \u001B[32m+\u001B[0m\u001B[32m1.17%)\u001B[0m | 1e-05: 67.61% (67.3%, \u001B[32m+\u001B[0m\u001B[32m0.31%)\u001B[0m | 1e-05: 63.48% (62.43%, \u001B[32m+\u001B[0m\u001B[32m1.05%)\u001B[0m |\n",
      "|      |                                |                               |                                |\n",
      "|      | 1e-06: 66.93% (58.24%, \u001B[32m+\u001B[0m\u001B[32m8.7%)\u001B[0m  | 1e-06: 69.83% (67.3%, \u001B[32m+\u001B[0m\u001B[32m2.53%)\u001B[0m | 1e-06: 67.98% (62.43%, \u001B[32m+\u001B[0m\u001B[32m5.55%)\u001B[0m |\n",
      "|      |                                |                               |                                |\n",
      "|      | 5e-05: 65.08% (58.24%, \u001B[32m+\u001B[0m\u001B[32m6.85%)\u001B[0m | 5e-05: 67.92% (67.3%, \u001B[32m+\u001B[0m\u001B[32m0.62%)\u001B[0m | 5e-05: 63.66% (62.43%, \u001B[32m+\u001B[0m\u001B[32m1.23%)\u001B[0m |\n",
      "+------+--------------------------------+-------------------------------+--------------------------------+\n",
      "| b_32 | 1e-05: 58.3% (58.24%, \u001B[32m+\u001B[0m\u001B[32m0.06%)\u001B[0m  | 1e-05: 66.93% (67.3%, \u001B[32m\u001B[0m\u001B[31m-0.37%)\u001B[0m | 1e-05: 61.57% (62.43%, \u001B[32m\u001B[0m\u001B[31m-0.86%)\u001B[0m |\n",
      "|      |                                |                               |                                |\n",
      "|      | 1e-06: 61.01% (58.24%, \u001B[32m+\u001B[0m\u001B[32m2.78%)\u001B[0m | 1e-06: 67.18% (67.3%, \u001B[32m\u001B[0m\u001B[31m-0.12%)\u001B[0m | 1e-06: 64.53% (62.43%, \u001B[32m+\u001B[0m\u001B[32m2.1%)\u001B[0m  |\n",
      "|      |                                |                               |                                |\n",
      "|      | 5e-05: 58.91% (58.24%, \u001B[32m+\u001B[0m\u001B[32m0.68%)\u001B[0m | 5e-05: 66.38% (67.3%, \u001B[32m\u001B[0m\u001B[31m-0.93%)\u001B[0m | 5e-05: 62.0% (62.43%, \u001B[32m\u001B[0m\u001B[31m-0.43%)\u001B[0m  |\n",
      "+------+--------------------------------+-------------------------------+--------------------------------+\n",
      "| l_16 | 1e-05: 67.18% (58.24%, \u001B[32m+\u001B[0m\u001B[32m8.95%)\u001B[0m | 1e-05: 69.77% (67.3%, \u001B[32m+\u001B[0m\u001B[32m2.47%)\u001B[0m | 1e-05: 66.38% (62.43%, \u001B[32m+\u001B[0m\u001B[32m3.95%)\u001B[0m |\n",
      "|      |                                |                               |                                |\n",
      "|      | 1e-06: 66.75% (58.24%, \u001B[32m+\u001B[0m\u001B[32m8.51%)\u001B[0m | 1e-06: 71.07% (67.3%, \u001B[32m+\u001B[0m\u001B[32m3.76%)\u001B[0m | 1e-06: 66.56% (62.43%, \u001B[32m+\u001B[0m\u001B[32m4.13%)\u001B[0m |\n",
      "|      |                                |                               |                                |\n",
      "|      | 5e-05: 66.87% (58.24%, \u001B[32m+\u001B[0m\u001B[32m8.64%)\u001B[0m | 5e-05: 68.91% (67.3%, \u001B[32m+\u001B[0m\u001B[32m1.6%)\u001B[0m  | 5e-05: 65.7% (62.43%, \u001B[32m+\u001B[0m\u001B[32m3.27%)\u001B[0m  |\n",
      "+------+--------------------------------+-------------------------------+--------------------------------+\n",
      "\n",
      "\n",
      "Main Model: vit_b_16\n",
      "+------+--------------------------------+--------------------------------+--------------------------------+\n",
      "|      | 1e-05                          | 1e-06                          | 5e-05                          |\n",
      "+======+================================+================================+================================+\n",
      "| b_32 | 1e-05: 62.99% (63.91%, \u001B[32m\u001B[0m\u001B[31m-0.93%)\u001B[0m | 1e-05: 69.46% (69.96%, \u001B[32m\u001B[0m\u001B[31m-0.49%)\u001B[0m | 1e-05: 64.4% (64.53%, \u001B[32m\u001B[0m\u001B[31m-0.12%)\u001B[0m  |\n",
      "|      |                                |                                |                                |\n",
      "|      | 1e-06: 65.21% (63.91%, \u001B[32m+\u001B[0m\u001B[32m1.3%)\u001B[0m  | 1e-06: 69.83% (69.96%, \u001B[32m\u001B[0m\u001B[31m-0.12%)\u001B[0m | 1e-06: 63.66% (64.53%, \u001B[32m\u001B[0m\u001B[31m-0.86%)\u001B[0m |\n",
      "|      |                                |                                |                                |\n",
      "|      | 5e-05: 62.99% (63.91%, \u001B[32m\u001B[0m\u001B[31m-0.93%)\u001B[0m | 5e-05: 69.52% (69.96%, \u001B[32m\u001B[0m\u001B[31m-0.43%)\u001B[0m | 5e-05: 62.62% (64.53%, \u001B[32m\u001B[0m\u001B[31m-1.91%)\u001B[0m |\n",
      "+------+--------------------------------+--------------------------------+--------------------------------+\n",
      "| l_16 | 1e-05: 66.93% (63.91%, \u001B[32m+\u001B[0m\u001B[32m3.02%)\u001B[0m | 1e-05: 70.76% (69.96%, \u001B[32m+\u001B[0m\u001B[32m0.8%)\u001B[0m  | 1e-05: 64.84% (64.53%, \u001B[32m+\u001B[0m\u001B[32m0.31%)\u001B[0m |\n",
      "|      |                                |                                |                                |\n",
      "|      | 1e-06: 68.17% (63.91%, \u001B[32m+\u001B[0m\u001B[32m4.26%)\u001B[0m | 1e-06: 70.7% (69.96%, \u001B[32m+\u001B[0m\u001B[32m0.74%)\u001B[0m  | 1e-06: 65.14% (64.53%, \u001B[32m+\u001B[0m\u001B[32m0.62%)\u001B[0m |\n",
      "|      |                                |                                |                                |\n",
      "|      | 5e-05: 67.74% (63.91%, \u001B[32m+\u001B[0m\u001B[32m3.82%)\u001B[0m | 5e-05: 71.75% (69.96%, \u001B[32m+\u001B[0m\u001B[32m1.79%)\u001B[0m | 5e-05: 64.84% (64.53%, \u001B[32m+\u001B[0m\u001B[32m0.31%)\u001B[0m |\n",
      "+------+--------------------------------+--------------------------------+--------------------------------+\n",
      "| l_32 | 1e-05: 64.22% (63.91%, \u001B[32m+\u001B[0m\u001B[32m0.31%)\u001B[0m | 1e-05: 69.46% (69.96%, \u001B[32m\u001B[0m\u001B[31m-0.49%)\u001B[0m | 1e-05: 63.97% (64.53%, \u001B[32m\u001B[0m\u001B[31m-0.56%)\u001B[0m |\n",
      "|      |                                |                                |                                |\n",
      "|      | 1e-06: 65.33% (63.91%, \u001B[32m+\u001B[0m\u001B[32m1.42%)\u001B[0m | 1e-06: 69.83% (69.96%, \u001B[32m\u001B[0m\u001B[31m-0.12%)\u001B[0m | 1e-06: 65.08% (64.53%, \u001B[32m+\u001B[0m\u001B[32m0.56%)\u001B[0m |\n",
      "|      |                                |                                |                                |\n",
      "|      | 5e-05: 64.34% (63.91%, \u001B[32m+\u001B[0m\u001B[32m0.43%)\u001B[0m | 5e-05: 69.15% (69.96%, \u001B[32m\u001B[0m\u001B[31m-0.8%)\u001B[0m  | 5e-05: 64.03% (64.53%, \u001B[32m\u001B[0m\u001B[31m-0.49%)\u001B[0m |\n",
      "+------+--------------------------------+--------------------------------+--------------------------------+\n",
      "\n",
      "\n",
      "Overall maximal post accuracy 71.746%\n",
      "{'main_model_name': 'vit_b_16', 'main_lr': '1e-06', 'secondary_model_name': 'l_16', 'secondary_lr': '5e-05'}\n"
     ]
    }
   ],
   "source": [
    "# Sample data structure (replace this with your actual data)\n",
    "data = {}  # Create an empty dictionary to store the accuracy data\n",
    "\n",
    "# Track the maximal accuracy value across all tables\n",
    "max_accuracy = -1.0\n",
    "max_data = {}\n",
    "\n",
    "# Iterate through filenames to collect accuracy data\n",
    "for filename in models_and_lrs_folders:\n",
    "    match = re.match(pattern=rf'main_(.+?)_lr(.+?)_secondary_(.+?)_lr(.+)', \n",
    "                     string=filename)\n",
    "    if match:\n",
    "        main_model_name, main_lr, secondary_model_name, secondary_lr = (match.group(i) for i in range(1, 5))\n",
    "        prior_predictions = np.load(os.path.join(data_dir, rf'{main_model_name}_test_pred_lr{main_lr}_e3.npy'))\n",
    "        prior_acc = accuracy_score(y_true=test_true, \n",
    "                                   y_pred=prior_predictions)\n",
    "\n",
    "        post_predictions = np.load(f'figs/{match.group(0)}/results.npy')\n",
    "        posterior_acc = accuracy_score(y_true=test_true, \n",
    "                                       y_pred=post_predictions)\n",
    "\n",
    "        # Update the maximal accuracy value\n",
    "        if posterior_acc > max_accuracy:\n",
    "            max_accuracy = posterior_acc\n",
    "            max_data = {'main_model_name': main_model_name,\n",
    "                        'main_lr': main_lr,\n",
    "                        'secondary_model_name': secondary_model_name,\n",
    "                        'secondary_lr': secondary_lr}\n",
    "\n",
    "        # Store accuracy data in the data dictionary\n",
    "        if main_model_name not in data:\n",
    "            data[main_model_name] = {}\n",
    "        if main_lr not in data[main_model_name]:\n",
    "            data[main_model_name][main_lr] = {}\n",
    "        if secondary_model_name not in data[main_model_name][main_lr]:\n",
    "            data[main_model_name][main_lr][secondary_model_name] = {}\n",
    "            \n",
    "        data[main_model_name][main_lr][secondary_model_name][secondary_lr] = {'prior': prior_acc, \n",
    "                                                                              'post': posterior_acc}\n",
    "\n",
    "# Loop through each main model and generate a table\n",
    "for main_model_name, main_lr_data in data.items():\n",
    "    table_data = []\n",
    "\n",
    "    # Get a list of learning rates from the first secondary model\n",
    "    main_learning_rates = sorted(main_lr_data.keys())\n",
    "    \n",
    "    secondary_models_data = list(main_lr_data.values())\n",
    "    # Sort the secondary model names\n",
    "    sorted_secondary_models = sorted(secondary_models_data[0].keys())\n",
    "\n",
    "    # Create the header row with learning rates\n",
    "    header = [''] + main_learning_rates\n",
    "    table_data.append(header)\n",
    "\n",
    "    # Add rows for each secondary model, ensuring they are sorted\n",
    "    for secondary_model_name in sorted_secondary_models:\n",
    "        curr = {secondary_model_name: v[secondary_model_name] for v in main_lr_data.values()}\n",
    "        accuracy_data = curr[secondary_model_name]\n",
    "        row = [secondary_model_name] + ['\\n'.join([f\"{secondary_lr}: {round(data[main_model_name][main_lr][secondary_model_name][secondary_lr]['post']*100, 2)}% \"\n",
    "                                    f\"({round(data[main_model_name][main_lr][secondary_model_name][secondary_lr]['prior']*100, 2)}%, \"\n",
    "                                    + termcolor.colored(f\"{'+' if data[main_model_name][main_lr][secondary_model_name][secondary_lr]['post'] > data[main_model_name][main_lr][secondary_model_name][secondary_lr]['prior'] else ''}\", color='green') +\n",
    "                                    termcolor.colored(f\"{round((data[main_model_name][main_lr][secondary_model_name][secondary_lr]['post'] - data[main_model_name][main_lr][secondary_model_name][secondary_lr]['prior'])*100, 2)}%)\", color='green' if data[main_model_name][main_lr][secondary_model_name][secondary_lr]['post'] > data[main_model_name][main_lr][secondary_model_name][secondary_lr]['prior'] else 'red')\n",
    "                                    + '\\n' for secondary_lr in main_learning_rates])\n",
    "                                   for main_lr in main_learning_rates]\n",
    "        table_data.append(row)\n",
    "\n",
    "    # Find the maximal accuracy value and its position in the table\n",
    "    max_acc_value = max(max([element.split()[0] for element in row[1:]] for row in table_data[1:]))\n",
    "    # max_acc_row, max_acc_col = [(i, row.index(max_acc_value)) \n",
    "    #                             for i, row in enumerate(table_data) if max_acc_value in row][0]\n",
    "    # \n",
    "    # # Colorize the maximal accuracy cell in green\n",
    "    # table_data[max_acc_row][max_acc_col] = termcolor.colored(text=max_acc_value, \n",
    "    #                                                          color='green')\n",
    "\n",
    "    # Create the table using tabulate\n",
    "    table = tabulate(tabular_data=table_data, \n",
    "                     headers='firstrow', \n",
    "                     tablefmt='grid')\n",
    "\n",
    "    # Print the main model name and the corresponding table\n",
    "    print(f\"Main Model: {main_model_name}\")\n",
    "    print(table)\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Print the maximal accuracy value across all tables (already colored in green)\n",
    "print(f\"Overall maximal post accuracy {round(max_accuracy*100, 3)}%\")\n",
    "print(max_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T09:49:56.519705Z",
     "start_time": "2023-10-25T09:49:56.450870Z"
    }
   },
   "id": "3f6e34912281d5e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "769010a6d1d3af7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
