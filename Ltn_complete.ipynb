{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "DZJ5EN5YTEHB"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install torchinfo\n",
    "!pip install LTNtorch\n",
    "!pip install timm\n",
    "!pip install ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "1gi5XVBtQYhj"
   },
   "outputs": [],
   "source": [
    "# Standard Libraries\n",
    "import os\n",
    "from typing import Tuple, List, Dict\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Data Manipulation and Visualization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from skimage import io, transform\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "\n",
    "# Machine Learning Frameworks\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import Dataset, random_split, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from torchsummary import summary\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    f1_score,\n",
    ")\n",
    "\n",
    "# Computer Vision\n",
    "import cv2\n",
    "\n",
    "# Model Architectures\n",
    "import timm\n",
    "\n",
    "# Experimentation and Optimization\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler, AsyncHyperBandScheduler\n",
    "from ray.tune.search.hyperopt import HyperOptSearch\n",
    "from hyperopt import hp\n",
    "\n",
    "# Logic Tensor Network\n",
    "import ltn\n",
    "\n",
    "# Miscellaneous\n",
    "import requests\n",
    "import re\n",
    "\n",
    "# Parallel Processing\n",
    "from typing import List\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.search.hyperopt import HyperOptSearch\n",
    "\n",
    "# Other\n",
    "from torchvision import datasets\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from abc import ABC\n",
    "import glob\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "bR1C9in6P9Sp"
   },
   "outputs": [],
   "source": [
    "def create_label_dict(category_dict):\n",
    "    # Initialize dictionaries\n",
    "    coarse_label_dict = {}\n",
    "    fine_label_dict = {}\n",
    "    coarse_to_fine = {}\n",
    "\n",
    "    # Assign numerical labels\n",
    "    coarse_label_counter = 0\n",
    "    fine_label_counter = len(category_dict)\n",
    "\n",
    "    # Iterate through the input dictionary\n",
    "    for category, labels in category_dict.items():\n",
    "        # Assign a numerical label to the coarse category\n",
    "        coarse_label_dict[category] = coarse_label_counter\n",
    "\n",
    "        # Create an empty list to store fine labels for this coarse category\n",
    "        coarse_to_fine[coarse_label_counter] = []\n",
    "\n",
    "        # Iterate through labels in the category\n",
    "        for label in labels:\n",
    "            # Assign a numerical label to the fine label\n",
    "            fine_label_dict[label] = fine_label_counter\n",
    "\n",
    "            # Add the fine label to the list of fine labels for this coarse category\n",
    "            coarse_to_fine[coarse_label_counter].append(fine_label_counter)\n",
    "\n",
    "            # Increment the fine label counter\n",
    "            fine_label_counter += 1\n",
    "\n",
    "        # Increment the coarse label counter\n",
    "        coarse_label_counter += 1\n",
    "\n",
    "    # Return the resulting dictionaries\n",
    "    return coarse_label_dict, fine_label_dict, coarse_to_fine\n",
    "\n",
    "\n",
    "def create_one_hot_tensors(fine_label_dict, coarse_label_dict):\n",
    "    l = {}\n",
    "    num_labels = len(coarse_label_dict)+len(fine_label_dict)\n",
    "    for label in range(num_labels):\n",
    "        one_hot = torch.zeros(num_labels)\n",
    "        one_hot[label] = 1.0\n",
    "        l[label] = ltn.Constant(one_hot, trainable=True)\n",
    "    return l\n",
    "\n",
    "\n",
    "def create_inverse_dict(coarse_label_dict, fine_label_dict):\n",
    "    inverse_dict = {}\n",
    "    for label, value in coarse_label_dict.items():\n",
    "        inverse_dict[value] = label\n",
    "\n",
    "    for label, value in fine_label_dict.items():\n",
    "        inverse_dict[value] = label\n",
    "\n",
    "    return inverse_dict\n",
    "\n",
    "\n",
    "def extract_labels(folder_path):\n",
    "    parts = folder_path.split(os.path.sep)\n",
    "    coarse_label = parts[-2]\n",
    "    fine_label = parts[-1]\n",
    "    return coarse_label, fine_label\n",
    "\n",
    "\n",
    "def search_for_images_and_labels(folder):\n",
    "    data = []\n",
    "    for image_path in glob.glob(os.path.join(folder, \"*.jpg\")):\n",
    "        coarse_label, fine_label = extract_labels(folder)\n",
    "        data.append({\n",
    "            'completed_relative_path': os.path.abspath(image_path),\n",
    "            'Coarse label': coarse_label,\n",
    "            'fine label': fine_label\n",
    "        })\n",
    "    for subfolder in os.listdir(folder):\n",
    "        subfolder_path = os.path.join(folder, subfolder)\n",
    "        if os.path.isdir(subfolder_path):\n",
    "            data.extend(search_for_images_and_labels(subfolder_path))\n",
    "    return data\n",
    "\n",
    "\n",
    "def process_image_folders(base_train_folder, base_test_folder):\n",
    "    # Process train folder\n",
    "    train_data = search_for_images_and_labels(base_train_folder)\n",
    "    df_train = pd.DataFrame(train_data)\n",
    "    df_train['Coarse label'] = df_train['Coarse label'].replace(\n",
    "        coarse_label_dict)\n",
    "    df_train['fine label'] = df_train['fine label'].replace(fine_label_dict)\n",
    "\n",
    "    # Filter train dataset\n",
    "    coarse_train_labels = [label for _, label in coarse_label_dict.items()]\n",
    "    fine_train_labels = [label for _, label in fine_label_dict.items()]\n",
    "    filter_train_coarse = df_train['Coarse label'].isin(coarse_train_labels)\n",
    "    filter_train_fine = df_train['fine label'].isin(fine_train_labels)\n",
    "    df_train = df_train[filter_train_coarse &\n",
    "                        filter_train_fine].reset_index(drop=True)\n",
    "\n",
    "    # Process test folder\n",
    "    test_data = search_for_images_and_labels(base_test_folder)\n",
    "    df_test = pd.DataFrame(test_data)\n",
    "    df_test['Coarse label'] = df_test['Coarse label'].replace(\n",
    "        coarse_label_dict)\n",
    "    df_test['fine label'] = df_test['fine label'].replace(fine_label_dict)\n",
    "\n",
    "    # Filter test dataset\n",
    "    coarse_test_labels = [label for _, label in coarse_label_dict.items()]\n",
    "    fine_test_labels = [label for _, label in fine_label_dict.items()]\n",
    "    filter_test_coarse = df_test['Coarse label'].isin(coarse_test_labels)\n",
    "    filter_test_fine = df_test['fine label'].isin(fine_test_labels)\n",
    "    df_test = df_test[filter_test_coarse &\n",
    "                      filter_test_fine].reset_index(drop=True)\n",
    "\n",
    "    return df_train, df_test\n",
    "\n",
    "\n",
    "class DatasetGenerator():\n",
    "    \"\"\"\n",
    "    Create a dataloader to efficiently get data. The argument include:\n",
    "        - dataset: the dataframe containing image_path and label\n",
    "        - image_resize: size of the image\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset, image_resize):\n",
    "        self.dataset = dataset\n",
    "        self.image_resize = image_resize\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Get index\n",
    "        idx = index % len(self.dataset)\n",
    "        image_path = self.dataset['completed_relative_path'][idx]\n",
    "        image = Image.open(image_path)\n",
    "        image_rgb = Image.new(\"RGB\", image.size)\n",
    "        image_rgb.paste(image)\n",
    "\n",
    "        coarse_label = self.dataset['Coarse label'][idx]\n",
    "        fine_label = self.dataset['fine label'][idx]\n",
    "\n",
    "        # Change image to float, resize image and\n",
    "\n",
    "        imagenet_stats = ([0.5] * 3, [0.5] * 3)\n",
    "        preprocess = transforms.Compose([\n",
    "            transforms.Resize((self.image_resize, self.image_resize)),\n",
    "            transforms.RandomResizedCrop(\n",
    "                max((self.image_resize, self.image_resize))),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(*imagenet_stats)\n",
    "        ])\n",
    "\n",
    "        image_rgb = preprocess(image_rgb)\n",
    "\n",
    "        return image_rgb, coarse_label, fine_label, image_path\n",
    "\n",
    "\n",
    "def create_data_loaders(df_train, df_test, image_resize, batch_size, num_coarse_label, num_all_label):\n",
    "    \"\"\"\n",
    "    Create data loaders for the training and testing datasets.\n",
    "\n",
    "    Args:\n",
    "        df_train (pd.DataFrame): Training dataset.\n",
    "        df_test (pd.DataFrame): Testing dataset.\n",
    "        image_resize (int): Size to which images will be resized.\n",
    "        batch_size (int): Number of samples in each batch.\n",
    "        num_coarse_label (int): Number of coarse labels.\n",
    "        num_all_label (int): Total number of labels including fine and coarse labels.\n",
    "\n",
    "    Returns:\n",
    "        DataLoader: Training data loader.\n",
    "        DataLoader: Testing data loader.\n",
    "    \"\"\"\n",
    "    train_dataset = DatasetGenerator(df_train, image_resize)\n",
    "    test_dataset = DatasetGenerator(df_test, image_resize)\n",
    "\n",
    "    # Compute class weights for weighted sampling\n",
    "    fine_distribution = df_train[\"fine label\"].value_counts().tolist()\n",
    "    class_weights = [1 / df_train[\"fine label\"].value_counts()[i]\n",
    "                     for i in range(num_coarse_label, num_all_label)]\n",
    "    class_weights = [0] * num_coarse_label + class_weights\n",
    "    image_weights = [class_weights[i] for i in df_train['fine label']]\n",
    "    weight_sampler = torch.utils.data.WeightedRandomSampler(\n",
    "        image_weights, len(df_train))\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
    "                              num_workers=4, pin_memory=True, sampler=weight_sampler)\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, batch_size=batch_size, num_workers=4, pin_memory=True)\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "class ClearCache:\n",
    "    def __init__(self, device: torch.device):\n",
    "        self.device_backend = {'cuda': torch.cuda,\n",
    "                               'cpu': None}[device]\n",
    "\n",
    "    def __enter__(self):\n",
    "        if self.device_backend:\n",
    "            self.device_backend.empty_cache()\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        if self.device_backend:\n",
    "            self.device_backend.empty_cache()\n",
    "\n",
    "\n",
    "class FineTuner(torch.nn.Module, ABC):\n",
    "    def __str__(self) -> str:\n",
    "        return self.__class__.__name__.split('Fine')[0].lower()\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return sum(p.numel() for p in self.parameters())\n",
    "\n",
    "# TODO: Whenever there is the change in loss function, check the implementation accordingly, to whether include\n",
    "# softmax or sigmoid on classifier or not\n",
    "\n",
    "\n",
    "class VITFineTuner(FineTuner):\n",
    "    def __init__(self,\n",
    "                 vit_model_index: int,\n",
    "                 num_classes: int):\n",
    "        super().__init__()\n",
    "        vit_model_name = ['b_16',\n",
    "                          'b_32',\n",
    "                          'l_16',\n",
    "                          'l_32',\n",
    "                          'h_14']\n",
    "        self.vit_model_name = vit_model_name[vit_model_index]\n",
    "        if self.vit_model_name == 'b_16':\n",
    "            vit_model = torchvision.models.vit_b_16\n",
    "        elif self.vit_model_name == 'b_32':\n",
    "            vit_model = torchvision.models.vit_b_32\n",
    "        elif self.vit_model_name == 'l_16':\n",
    "            vit_model = torchvision.models.vit_l_16\n",
    "        elif self.vit_model_name == 'l_32':\n",
    "            vit_model = torchvision.models.vit_l_32\n",
    "        elif self.vit_model_name == 'h_14':\n",
    "            vit_model = torchvision.models.vit_h_14\n",
    "        else:\n",
    "            # Handle the case when the model name is not recognized\n",
    "            raise ValueError(f\"Invalid vit_model_name: {self.vit_model_name}\")\n",
    "\n",
    "        vit_weights = eval(f\"torchvision.models.ViT_{'_'.join([s.upper() for s in self.vit_model_name.split('_')])}\"\n",
    "                           f\"_Weights.DEFAULT\")\n",
    "        self.vit = vit_model(weights=vit_weights)\n",
    "        self.vit.heads[-1] = torch.nn.Linear(in_features=self.vit.hidden_dim,\n",
    "                                             out_features=num_classes)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.vit(x)\n",
    "        return x\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'{super().__str__()}_{self.vit_model_name}'\n",
    "\n",
    "# TODO: Whenever there is the change in loss function, check the implementation accordingly, to whether include\n",
    "# softmax or sigmoid on classifier or not\n",
    "\n",
    "\n",
    "class LogitsToPredicate(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    This model has inside a logits model, that is a model which compute logits for the classes given an input example x.\n",
    "    The idea of this model is to keep logits and probabilities separated. The logits model returns the logits for an example,\n",
    "    while this model returns the probabilities given the logits model.\n",
    "\n",
    "    In particular, it takes as input an example x and a class label d. It applies the logits model to x to get the logits.\n",
    "    Then, it applies a softmax function to get the probabilities per classes. Finally, it returns only the probability related\n",
    "    to the given class d.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LogitsToPredicate, self).__init__()\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, d):\n",
    "        probs = self.sigmoid(x)\n",
    "        out = torch.sum(probs * d, dim=1)\n",
    "        return out\n",
    "\n",
    "\n",
    "def compute_sat_normally(base_model,\n",
    "                         logits_to_predicate,\n",
    "                         data, labels_coarse, labels_fine,\n",
    "                         coarse_label_dict, fine_label_dict,\n",
    "                         coarse_to_fine, fine_grain_only=False, train_mode=False):\n",
    "    \"\"\"\n",
    "    compute satagg function for rules\n",
    "    argument:\n",
    "      - base_model: get probability of the class\n",
    "      - logits_to_predicate: get the satisfaction of a variable given the label\n",
    "      - data, labels_coarse, labels_fine\n",
    "      - coarse_label_dict, fine_label_dict,\n",
    "      - coarse_to_fine\n",
    "      - fine_grain_only: if true, the sat is changed accordingly\n",
    "      - train: whether to train model again, when data is still not convert to prediction yet\n",
    "\n",
    "    return:\n",
    "      sat_agg: sat_agg for all the rules\n",
    "\n",
    "    \"\"\"\n",
    "    Not = ltn.Connective(ltn.fuzzy_ops.NotStandard())\n",
    "    And = ltn.Connective(ltn.fuzzy_ops.AndProd())\n",
    "    Implies = ltn.Connective(ltn.fuzzy_ops.ImpliesReichenbach())\n",
    "    Forall = ltn.Quantifier(\n",
    "        ltn.fuzzy_ops.AggregPMeanError(p=4), quantifier=\"f\")\n",
    "    SatAgg = ltn.fuzzy_ops.SatAgg()\n",
    "\n",
    "    if train_mode:\n",
    "        prediction = base_model(data)\n",
    "    else:\n",
    "        prediction = data\n",
    "\n",
    "    x = ltn.Variable(\"x\", prediction)\n",
    "\n",
    "    x_variables = {}\n",
    "    for name, label in fine_label_dict.items():\n",
    "        x_variables[label] = ltn.Variable(\n",
    "            name, prediction[labels_fine == label])\n",
    "    for name, label in coarse_label_dict.items():\n",
    "        x_variables[label] = ltn.Variable(\n",
    "            name, prediction[labels_coarse == label])\n",
    "\n",
    "    sat_agg_list = []\n",
    "    sat_agg_label = []\n",
    "\n",
    "    # Coarse labels: for all x[i], x[i] -> l[i]\n",
    "\n",
    "    for i in coarse_label_dict.values():\n",
    "        if x_variables[i].value.numel() != 0:\n",
    "            sat_agg_label.append(\n",
    "                f'for all (coarse label) x[{i}], x[{i}] -> l[{i}]')\n",
    "            sat_agg_list.append(\n",
    "                Forall(x_variables[i], logits_to_predicate(x_variables[i], l[i])))\n",
    "\n",
    "    # TODO: double check the rule\n",
    "    # Coarse Label: for all x[coarse], - {x[different coarse]}\n",
    "\n",
    "    # for i in range(len(coarse_label_dict)):\n",
    "    #     for j in range(len(coarse_label_dict)):\n",
    "    #         if i != j and x_variables[i].value.numel() != 0:\n",
    "    #             sat_agg_list.append(\n",
    "    #                 Forall(x_variables[i], Not(logits_to_predicate(x_variables[i], l[j]))))\n",
    "\n",
    "    # Coarse Label: for all x[coarse], - {x[coarse] and x[different coarse]}\n",
    "        for i in coarse_label_dict.values():\n",
    "            for j in coarse_label_dict.values():\n",
    "                if i != j :\n",
    "                    sat_agg_list.append(Forall(x, Not(And(logits_to_predicate(x, l[i]), logits_to_predicate(x, l[j])))))\n",
    "\n",
    "    # Fine to coarse label: for all x[fine], x[fine] and x[correspond coarse]\n",
    "\n",
    "    for label_coarse, label_fine_list in coarse_to_fine.items():\n",
    "        for label_fine in label_fine_list:\n",
    "            if x_variables[label_fine].value.numel() != 0:\n",
    "              sat_agg_list.append(Forall(x_variables[label_fine],\n",
    "                                            And(logits_to_predicate(x_variables[label_fine], l[label_fine]), logits_to_predicate(x_variables[label_fine], l[label_coarse])))\n",
    "                                    )\n",
    "\n",
    "    # Fine labels: for all x[i], x[i] -> l[i]\n",
    "\n",
    "    for i in fine_label_dict.values():\n",
    "        if x_variables[i].value.numel() != 0:\n",
    "            sat_agg_list.append(\n",
    "                Forall(x_variables[i], logits_to_predicate(x_variables[i], l[i])))\n",
    "\n",
    "    # TODO: Double check the rule\n",
    "    # Fine Label: for all x[fine], - {x[different fine]}\n",
    "\n",
    "    # for i in range(len(fine_label_dict)):\n",
    "    #         for j in range(len(fine_label_dict)):\n",
    "    #             if i != j and x_variables[i].value.numel() != 0:\n",
    "    #                 sat_agg_list.append(\n",
    "    #                     Forall(x_variables[i], Not(logits_to_predicate(x_variables[i], l[j]))))\n",
    "\n",
    "    # Fine Label: for all x[fine], -{x[fine], x[diff_fine]}\n",
    "\n",
    "    for _, label_fine_list in coarse_to_fine.items():\n",
    "        for label_fine in label_fine_list:\n",
    "            for i in label_fine_list:\n",
    "                if (x_variables[label_fine].value.numel() != 0) and (i != label_fine):\n",
    "                    sat_agg_list.append(Forall(x_variables[label_fine],\n",
    "                                        Not(logits_to_predicate(x_variables[label_fine], l[i]))))\n",
    "\n",
    "    sat_agg = SatAgg(\n",
    "        *sat_agg_list\n",
    "    )\n",
    "    return sat_agg\n",
    "\n",
    "\n",
    "def train(dataloader,\n",
    "          base_model: FineTuner, logits_to_predicate,\n",
    "          beta,\n",
    "          epoch,\n",
    "          optimizer,\n",
    "          scheduler,\n",
    "          loss_mode,\n",
    "          fine_grain_only=False, mode='normal',\n",
    "          device=torch.device('cpu'),\n",
    "          coarse_label_dict={}, fine_label_dict={}, coarse_to_fine={}):\n",
    "    \"\"\"\n",
    "    Train the model using the provided dataloader for one epoch.\n",
    "\n",
    "    Args:\n",
    "        dataloader (DataLoader): Dataloader for training data.\n",
    "        base_model (FineTuner): The model to be trained.\n",
    "        logits_to_predicate: Function to convert logits to predicates.\n",
    "        beta (float): specify proportion of ltn and normal loss\n",
    "        epoch (int): training iteration\n",
    "        fine_grain_only (bool): If True, train only on fine-grained labels.\n",
    "        mode (str): Training mode: 'normal', 'ltn_normal', or 'ltn_combine'\n",
    "        coarse_label_dict (dict, optional): Dictionary mapping coarse labels to numerical labels. Default is an empty dictionary.\n",
    "        fine_label_dict (dict, optional): Dictionary mapping fine labels to numerical labels. Default is an empty dictionary.\n",
    "        coarse_to_fine (dict, optional): Dictionary mapping coarse labels to corresponding fine labels. Default is an empty dictionary..\n",
    "\n",
    "    Returns:\n",
    "        float: Running loss.\n",
    "        float: Precision for fine-grained labels.\n",
    "        float: Recall for fine-grained labels.\n",
    "        float: Precision for coarse labels.\n",
    "        float: Recall for coarse labels.\n",
    "    \"\"\"\n",
    "    num_coarse_label = len(coarse_label_dict)\n",
    "    num_fine_label = len(fine_label_dict)\n",
    "    num_all_label = num_fine_label+num_coarse_label\n",
    "    loss_fc = nn.CrossEntropyLoss()\n",
    "\n",
    "    base_model.train()\n",
    "    size = len(dataloader)\n",
    "    running_loss = 0.0\n",
    "\n",
    "    fine_label_ground_truth = []\n",
    "    fine_label_prediction = []\n",
    "    coarse_label_ground_truth = []\n",
    "    coarse_label_prediction = []\n",
    "\n",
    "    with tqdm(total=size) as pbar:\n",
    "        description = \"Epoch \" + str(epoch)\n",
    "        pbar.set_description_str(description)\n",
    "\n",
    "        for batch_idx, (data, labels_coarse, labels_fine, image_path) in enumerate(dataloader):\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            # Put image to device\n",
    "            data, labels_coarse, labels_fine = data.to(\n",
    "                device), labels_coarse.to(device), labels_fine.to(device)\n",
    "            labels_coarse_one_hot = torch.nn.functional.one_hot(\n",
    "                labels_coarse, num_classes=num_all_label).float()\n",
    "            labels_fine_one_hot = torch.nn.functional.one_hot(\n",
    "                labels_fine, num_classes=num_all_label).float()\n",
    "\n",
    "            # make prediction\n",
    "            prediction = base_model(data)\n",
    "\n",
    "            labels_one_hot = labels_fine_one_hot + labels_coarse_one_hot\n",
    "\n",
    "            if mode == 'normal':\n",
    "                if loss_mode == 'binary':\n",
    "                    loss_fc = torch.nn.BCEWithLogitsLoss()\n",
    "                    loss = loss_fc(prediction, labels_one_hot)\n",
    "                elif loss_mode == 'marginal':\n",
    "                    loss_fc = torch.nn.MultiLabelMarginLoss()\n",
    "                    loss = loss_fc(prediction, labels_one_hot.long())\n",
    "                elif loss_mode == 'softmarginal':\n",
    "                    loss_fc = torch.nn.MultiLabelSoftMarginLoss()\n",
    "                    loss = loss_fc(prediction, labels_one_hot)\n",
    "\n",
    "            if mode == 'ltn_normal':\n",
    "                sat_agg = compute_sat_normally(base_model, logits_to_predicate,\n",
    "                                               prediction, labels_coarse, labels_fine,\n",
    "                                               coarse_label_dict, fine_label_dict, coarse_to_fine,\n",
    "                                               fine_grain_only)\n",
    "                loss = 1. - sat_agg\n",
    "\n",
    "            if mode == 'ltn_combine':\n",
    "                sat_agg = compute_sat_normally(base_model, logits_to_predicate,\n",
    "                                               prediction, labels_coarse, labels_fine,\n",
    "                                               coarse_label_dict, fine_label_dict, coarse_to_fine,\n",
    "                                               fine_grain_only)\n",
    "                if loss_mode == 'binary':\n",
    "                    loss_fc = torch.nn.BCEWithLogitsLoss()\n",
    "                    loss = beta*(1. - sat_agg) + (1 - beta) * \\\n",
    "                        (loss_fc(prediction, labels_one_hot))\n",
    "                elif loss_mode == 'marginal':\n",
    "                    loss_fc = torch.nn.MultiLabelMarginLoss()\n",
    "                    loss = beta*(1. - sat_agg) + (1 - beta) * \\\n",
    "                        (loss_fc(prediction, labels_one_hot.long()))\n",
    "\n",
    "                elif loss_mode == 'softmarginal':\n",
    "                    loss_fc = torch.nn.MultiLabelSoftMarginLoss()\n",
    "                    loss = beta*(1. - sat_agg) + (1 - beta) * \\\n",
    "                        (loss_fc(prediction, labels_one_hot))\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Backpropagation\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(base_model.parameters(), 10.0)\n",
    "            optimizer.step()\n",
    "            running_loss += loss\n",
    "\n",
    "            # Accuracy evaluation of coarse and fine grain\n",
    "            prediction = prediction.cpu().detach()\n",
    "\n",
    "            # Get coarse label prediction and ground truth\n",
    "            prediction_coarse_label = prediction[:, :num_coarse_label]\n",
    "            coarse_label_prediction_batch = torch.argmax(\n",
    "                prediction_coarse_label, dim=1)\n",
    "            coarse_label_prediction.extend(coarse_label_prediction_batch)\n",
    "            coarse_label_ground_truth.extend(labels_coarse.cpu().detach())\n",
    "\n",
    "            # Get fine label prediction and ground truth\n",
    "            prediction_fine_label = prediction[:, num_coarse_label:]\n",
    "            fine_label_prediction_batch = torch.argmax(\n",
    "                prediction_fine_label, dim=1)\n",
    "            fine_label_prediction.extend(fine_label_prediction_batch)\n",
    "            fine_label_ground_truth.extend(\n",
    "                labels_fine.cpu().detach() - num_coarse_label)\n",
    "\n",
    "            pbar.update()\n",
    "\n",
    "        # Compute running loss\n",
    "        running_loss = running_loss / size\n",
    "\n",
    "        # Compute evaluation metrics\n",
    "        accuracy_fine = accuracy_score(\n",
    "            fine_label_ground_truth, fine_label_prediction, normalize=True)\n",
    "        precision_fine = precision_score(\n",
    "            fine_label_ground_truth, fine_label_prediction, average='macro')\n",
    "        recall_fine = recall_score(\n",
    "            fine_label_ground_truth, fine_label_prediction, average='macro')\n",
    "        accuracy_coarse = accuracy_score(\n",
    "            coarse_label_ground_truth, coarse_label_prediction, normalize=True)\n",
    "        precision_coarse = precision_score(\n",
    "            coarse_label_ground_truth, coarse_label_prediction, average='macro')\n",
    "        recall_coarse = recall_score(\n",
    "            coarse_label_ground_truth, coarse_label_prediction, average='macro')\n",
    "\n",
    "        # print evaluation metric:\n",
    "\n",
    "        pbar.set_postfix_str(\" epoch %d | loss %.4f | Train coarse acc %.3f |Train coarse Prec %.3f | Train coarse Rec %.3f | Train fine acc %.3f |Train fine Prec %.3f | Train fine Rec %.3f\" %\n",
    "                             (epoch, running_loss, accuracy_coarse, precision_coarse, recall_coarse, accuracy_fine, precision_fine, recall_fine))\n",
    "\n",
    "        # Update learning rate\n",
    "        scheduler.step()\n",
    "\n",
    "        save_metric = [float(running_loss.detach().to(\"cpu\")),\n",
    "                       accuracy_fine, precision_fine, recall_fine,\n",
    "                       accuracy_coarse, precision_coarse, recall_coarse]\n",
    "\n",
    "    return save_metric\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def valid(dataloader,\n",
    "          base_model, logits_to_predicate,\n",
    "          beta,\n",
    "          loss_mode,\n",
    "          fine_grain_only=False, mode='normal',\n",
    "          device=torch.device('cpu'),\n",
    "          coarse_label_dict={}, fine_label_dict={}, coarse_to_fine={},):\n",
    "    \"\"\"\n",
    "    Validate the model using the provided dataloader.\n",
    "\n",
    "    Args:\n",
    "        dataloader (DataLoader): Dataloader for validation data.\n",
    "        base_model (FineTuner): The model to be evaluated.\n",
    "        logits_to_predicate (function): Function to convert logits to predicates.\n",
    "        beta: specify proportion of ltn and normal loss\n",
    "        fine_grain_only (bool, optional): If True, validate only on fine-grained labels. Default is False.\n",
    "        mode (str, optional): Validation mode: 'normal', 'ltn_normal', or 'ltn_combine'. Default is 'normal'.\n",
    "        device (torch.device, optional): Device to perform computations on. Default is 'cuda'.\n",
    "        coarse_label_dict (dict, optional): Dictionary mapping coarse labels to numerical labels. Default is an empty dictionary.\n",
    "        fine_label_dict (dict, optional): Dictionary mapping fine labels to numerical labels. Default is an empty dictionary.\n",
    "        coarse_to_fine (dict, optional): Dictionary mapping coarse labels to corresponding fine labels. Default is an empty dictionary.\n",
    "        model_name (string, optional): Name of the model to save, default is empty string\n",
    "\n",
    "    Returns:\n",
    "        float: Running loss.\n",
    "        float: Precision for fine-grained labels.\n",
    "        float: Recall for fine-grained labels.\n",
    "        float: Precision for coarse labels.\n",
    "        float: Recall for coarse labels.\n",
    "    \"\"\"\n",
    "    num_coarse_label = len(coarse_label_dict)\n",
    "    num_fine_label = len(fine_label_dict)\n",
    "    num_all_label = num_fine_label + num_coarse_label\n",
    "    base_model.eval()\n",
    "    size = len(dataloader)\n",
    "    running_loss = 0.0\n",
    "    fine_label_ground_truth = []\n",
    "    fine_label_prediction = []\n",
    "    coarse_label_ground_truth = []\n",
    "    coarse_label_prediction = []\n",
    "\n",
    "    with tqdm(total=size) as pbar:\n",
    "        description = \"Evaluate test set: \"\n",
    "        pbar.set_description_str(description)\n",
    "\n",
    "        for batch_idx, (data, labels_coarse, labels_fine, image_path) in enumerate(dataloader):\n",
    "            # Put image to device\n",
    "            data, labels_coarse, labels_fine = data.to(\n",
    "                device), labels_coarse.to(device), labels_fine.to(device)\n",
    "\n",
    "            # get ground truth\n",
    "            labels_coarse_one_hot = torch.nn.functional.one_hot(\n",
    "                labels_coarse, num_classes=num_all_label).float()\n",
    "            labels_fine_one_hot = torch.nn.functional.one_hot(\n",
    "                labels_fine, num_classes=num_all_label).float()\n",
    "\n",
    "            # make prediction\n",
    "            prediction = base_model(data)\n",
    "\n",
    "            labels_one_hot = labels_fine_one_hot + labels_coarse_one_hot\n",
    "\n",
    "            if mode == 'normal':\n",
    "                if loss_mode == 'binary':\n",
    "                    loss_fc = torch.nn.BCEWithLogitsLoss()\n",
    "                    loss = loss_fc(prediction, labels_one_hot)\n",
    "                elif loss_mode == 'marginal':\n",
    "                    loss_fc = torch.nn.MultiLabelMarginLoss()\n",
    "                    loss = loss_fc(prediction, labels_one_hot.long())\n",
    "                elif loss_mode == 'softmarginal':\n",
    "                    loss_fc = torch.nn.MultiLabelSoftMarginLoss()\n",
    "                    loss = loss_fc(prediction, labels_one_hot)\n",
    "\n",
    "            if mode == 'ltn_normal':\n",
    "                sat_agg = compute_sat_normally(base_model, logits_to_predicate,\n",
    "                                               prediction, labels_coarse, labels_fine,\n",
    "                                               coarse_label_dict, fine_label_dict, coarse_to_fine,\n",
    "                                               fine_grain_only)\n",
    "                loss = 1. - sat_agg\n",
    "\n",
    "            if mode == 'ltn_combine':\n",
    "                sat_agg = compute_sat_normally(base_model, logits_to_predicate,\n",
    "                                               prediction, labels_coarse, labels_fine,\n",
    "                                               coarse_label_dict, fine_label_dict, coarse_to_fine,\n",
    "                                               fine_grain_only)\n",
    "                if loss_mode == 'binary':\n",
    "                    loss_fc = torch.nn.BCEWithLogitsLoss()\n",
    "                    loss = beta*(1. - sat_agg) + (1 - beta) * \\\n",
    "                        (loss_fc(prediction, labels_one_hot))\n",
    "                elif loss_mode == 'marginal':\n",
    "                    loss_fc = torch.nn.MultiLabelMarginLoss()\n",
    "                    loss = beta*(1. - sat_agg) + (1 - beta) * \\\n",
    "                        (loss_fc(prediction, labels_one_hot.long()))\n",
    "\n",
    "                elif loss_mode == 'softmarginal':\n",
    "                    loss_fc = torch.nn.MultiLabelSoftMarginLoss()\n",
    "                    loss = beta*(1. - sat_agg) + (1 - beta) * \\\n",
    "                        (loss_fc(prediction, labels_one_hot))\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Accuracy evaluation of coarse and fine grain\n",
    "            prediction = prediction.cpu().detach()\n",
    "\n",
    "            prediction_coarse_label = prediction[:, :num_coarse_label]\n",
    "            coarse_label_prediction_batch = torch.argmax(\n",
    "                prediction_coarse_label, dim=1)\n",
    "            coarse_label_prediction.extend(coarse_label_prediction_batch)\n",
    "            coarse_label_ground_truth.extend(labels_coarse.cpu().detach())\n",
    "\n",
    "            prediction_fine_label = prediction[:, num_coarse_label:]\n",
    "            fine_label_prediction_batch = torch.argmax(\n",
    "                prediction_fine_label, dim=1)\n",
    "            fine_label_prediction.extend(fine_label_prediction_batch)\n",
    "            fine_label_ground_truth.extend(\n",
    "                labels_fine.cpu().detach() - num_coarse_label)\n",
    "\n",
    "            pbar.update()\n",
    "\n",
    "        # Compute running loss\n",
    "        running_loss = running_loss / size\n",
    "\n",
    "        # Compute evaluation metrics\n",
    "        accuracy_fine = accuracy_score(\n",
    "            fine_label_ground_truth, fine_label_prediction, normalize=True)\n",
    "        precision_fine = precision_score(\n",
    "            fine_label_ground_truth, fine_label_prediction, average='macro')\n",
    "        recall_fine = recall_score(\n",
    "            fine_label_ground_truth, fine_label_prediction, average='macro')\n",
    "        accuracy_coarse = accuracy_score(\n",
    "            coarse_label_ground_truth, coarse_label_prediction, normalize=True)\n",
    "        precision_coarse = precision_score(\n",
    "            coarse_label_ground_truth, coarse_label_prediction, average='macro')\n",
    "        recall_coarse = recall_score(\n",
    "            coarse_label_ground_truth, coarse_label_prediction, average='macro')\n",
    "\n",
    "        # print the training metrics\n",
    "\n",
    "        pbar.set_postfix_str(\" loss %.4f | Train coarse acc %.3f |Train coarse Prec %.3f | Train coarse Rec %.3f | Train fine acc %.3f |Train fine Prec %.3f | Train fine Rec %.3f\" %\n",
    "                             (running_loss, accuracy_coarse, precision_coarse, recall_coarse, accuracy_fine, precision_fine, recall_fine))\n",
    "\n",
    "        save_metric = [running_loss,\n",
    "                       accuracy_fine, precision_fine, recall_fine,\n",
    "                       accuracy_coarse, precision_coarse, recall_coarse]\n",
    "\n",
    "    return save_metric\n",
    "\n",
    "\n",
    "def transform_evaluation_metric(metric_list):\n",
    "    transformed_metrics = []\n",
    "    for metric_dict in metric_list:\n",
    "        try:\n",
    "            transformed_metrics.append({\n",
    "                'running_loss': metric_dict[0],\n",
    "                'accuracy_fine': metric_dict[1],\n",
    "                'precision_fine': metric_dict[2],\n",
    "                'recall_fine': metric_dict[3],\n",
    "                'accuracy_coarse': metric_dict[4],\n",
    "                'precision_coarse': metric_dict[5],\n",
    "                'recall_coarse': metric_dict[6]\n",
    "            })\n",
    "        except:\n",
    "            print('error in getting some metric')\n",
    "    return transformed_metrics\n",
    "\n",
    "\n",
    "def save_evaluation_metric(evaluation_metric_train_raw, evaluation_metric_valid_raw, path: str, description):\n",
    "    \"\"\"\n",
    "    Save the evaluation metric plot.\n",
    "\n",
    "    Args:\n",
    "        path (str): File path to save the plot.\n",
    "        evaluation_metric_train (list): List of dictionaries containing evaluation metrics for training data.\n",
    "        evaluation_metric_valid (list): List of dictionaries containing evaluation metrics for validation data.\n",
    "        description (str)\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    num_epochs = len(evaluation_metric_train_raw)\n",
    "    evaluation_metric_train = transform_evaluation_metric(\n",
    "        evaluation_metric_train_raw)\n",
    "    evaluation_metric_valid = transform_evaluation_metric(\n",
    "        evaluation_metric_valid_raw)\n",
    "    y_limits = [0.0, 1.0]\n",
    "\n",
    "    for metric in ['running_loss', 'accuracy_fine', 'precision_fine', 'recall_fine', 'accuracy_coarse', 'precision_coarse', 'recall_coarse']:\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(range(num_epochs), [\n",
    "                 element[metric] for element in evaluation_metric_train], label='Training', color='green')\n",
    "        plt.plot(range(num_epochs), [\n",
    "                 element[metric] for element in evaluation_metric_valid], label='Validation', color='blue')\n",
    "        plt.ylim(y_limits)\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Metric Value')\n",
    "        plt.title(f'{metric.capitalize()} Over Epochs')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "        save_path = f'{path}/{description}_{metric.capitalize()}.png'\n",
    "\n",
    "        plt.savefig(save_path)\n",
    "        plt.close()  # Close the plot to clear the memory\n",
    "\n",
    "\n",
    "def calculate_metrics_per_label(y_true: List[int], y_pred: List[int],\n",
    "                                labels: List[int]) -> Tuple[List[float], List[float], List[float], List[List[int]]]:\n",
    "    \"\"\"\n",
    "    Calculates precision, recall, F1 score, and confusion matrix for each label.\n",
    "\n",
    "    Args:\n",
    "        y_true (List[int]): True labels.\n",
    "        y_pred (List[int]): Predicted labels.\n",
    "        labels (List[int]): List of label indices.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[List[float], List[float], List[float], List[List[int]]]: Precision, recall, F1 score, and confusion matrix.\n",
    "\n",
    "    \"\"\"\n",
    "    # accuracy_per_label = accuracy_score(y_true, y_pred)\n",
    "    precision_per_label = precision_score(\n",
    "        y_true, y_pred, average=None, labels=labels)\n",
    "    recall_per_label = recall_score(\n",
    "        y_true, y_pred, average=None, labels=labels)\n",
    "    accuracy_per_label = [precision * recall for precision,\n",
    "                          recall in zip(precision_per_label, recall_per_label)]\n",
    "    f1_per_label = f1_score(y_true, y_pred, average=None, labels=labels)\n",
    "    confusion_mat = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "\n",
    "    return accuracy_per_label, precision_per_label, recall_per_label, f1_per_label, confusion_mat\n",
    "\n",
    "\n",
    "def save_metrics_to_excel(y_true: List[int], y_pred: List[int],\n",
    "                          label_dict: Dict[int, str],\n",
    "                          model_name: str, path: str, description: str) -> None:\n",
    "    \"\"\"\n",
    "    Calculates metrics per label and saves the results to an Excel file.\n",
    "\n",
    "    Args:\n",
    "        y_true (List[int]): True labels.\n",
    "        y_pred (List[int]): Predicted labels.\n",
    "        label_dict (Dict[int, str]): Dictionary mapping label indices to label names.\n",
    "        model_name (str): Name of the model.\n",
    "        path (str): Directory where the Excel file will be saved.\n",
    "        description (str)\n",
    "    \"\"\"\n",
    "    label_temp = [i for i in label_dict.values()]\n",
    "    accuracy, precision, recall, f1, confusion = calculate_metrics_per_label(y_true, y_pred, label_temp)\n",
    "    \n",
    "    # Create a list to store dictionaries with metrics\n",
    "    metrics_list = []\n",
    "    \n",
    "    inverse_dict = {value: key for key, value in label_dict.items()}\n",
    "    \n",
    "    for label_idx, label in enumerate(label_temp):\n",
    "        metrics_dict = {\n",
    "            'Label': inverse_dict[int(label)],\n",
    "            'Accuracy': accuracy[label_idx],\n",
    "            'Precision': precision[label_idx],\n",
    "            'Recall': recall[label_idx],\n",
    "            'F1': f1[label_idx],\n",
    "            'True Positives': confusion[label_idx][label_idx],\n",
    "            'True Negatives': confusion.sum() - confusion[label_idx].sum() - confusion[:, label_idx].sum() + confusion[label_idx][label_idx],\n",
    "            'False Positives': confusion[:, label_idx].sum() - confusion[label_idx][label_idx],\n",
    "            'False Negatives': confusion[label_idx].sum() - confusion[label_idx][label_idx]\n",
    "        }\n",
    "        metrics_list.append(metrics_dict)\n",
    "    \n",
    "    # Create DataFrame from the list of dictionaries\n",
    "    metrics_df = pd.DataFrame(metrics_list, columns=['Label', 'Accuracy', 'Precision', 'Recall', 'F1', 'True Positives', 'True Negatives', 'False Positives', 'False Negatives'])\n",
    "\n",
    "\n",
    "    metrics_df.to_excel(\n",
    "        f'{path}/{description}_coarse_grained_{model_name}_test_metric.xlsx', index=False)\n",
    "\n",
    "\n",
    "def save_confusion_matrices(num_coarse_label: int, num_all_labels: int,\n",
    "                            base_model, test_loader: DataLoader,\n",
    "                            save_path: str,\n",
    "                            fine_grain_only: bool,\n",
    "                            description: str,) -> None:\n",
    "    \"\"\"\n",
    "    Compute and save confusion matrices for coarse and fine labels based on the predictions\n",
    "    from the provided base_model and test_loader. Save the generated matrices as images.\n",
    "\n",
    "    Args:\n",
    "        num_coarse_label (int): Number of coarse labels.\n",
    "        num_all_labels (int): Total number of labels (including coarse and fine labels).\n",
    "        base_model: PyTorch model for prediction.\n",
    "        test_loader (DataLoader): DataLoader containing test data.\n",
    "        save_path (str): Path to save the generated confusion matrix images.\n",
    "        fine_grain_only (bool): Train fine grain only or not\n",
    "        description (str)\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    coarse_index = slice(num_coarse_label)\n",
    "    fine_index = slice(num_coarse_label, num_all_labels)\n",
    "\n",
    "    coarse_label_ground_truth = []\n",
    "    coarse_label_prediction = []\n",
    "    fine_label_ground_truth = []\n",
    "    fine_label_prediction = []\n",
    "    image_path_list = []\n",
    "\n",
    "    print(\"Save confusion matrices\")\n",
    "\n",
    "    # Iterate through the test data and make predictions\n",
    "    for batch_idx, (data, labels_coarse, labels_fine, image_path) in enumerate(test_loader):\n",
    "        data = data.to(device)\n",
    "\n",
    "        prediction = base_model(data).cpu().detach()\n",
    "\n",
    "        prediction_coarse_label = prediction[:, :num_coarse_label]\n",
    "        coarse_label_prediction_batch = torch.argmax(\n",
    "            prediction_coarse_label, dim=1)\n",
    "        coarse_label_prediction.extend(coarse_label_prediction_batch)\n",
    "        coarse_label_ground_truth.extend(labels_coarse)\n",
    "\n",
    "        prediction_fine_label = prediction[:, num_coarse_label:]\n",
    "        fine_label_prediction_batch = torch.argmax(\n",
    "            prediction_fine_label, dim=1) + num_coarse_label\n",
    "        fine_label_prediction.extend(fine_label_prediction_batch)\n",
    "        fine_label_ground_truth.extend(labels_fine)\n",
    "\n",
    "        # get image path\n",
    "        image_path_list.extend(image_path)\n",
    "\n",
    "    # Compute confusion matrix for coarse labels\n",
    "    confusion_matrix_coarse = metrics.confusion_matrix(\n",
    "        coarse_label_ground_truth, coarse_label_prediction)\n",
    "    display_labels_coarse = [str(label)\n",
    "                             for label in range(num_coarse_label)]\n",
    "\n",
    "    # Plot and save coarse label confusion matrix\n",
    "    fig_coarse, ax_coarse = plt.subplots(figsize=(15, 15))\n",
    "    cm_display_coarse = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix_coarse,\n",
    "                                               display_labels=display_labels_coarse)\n",
    "    cm_display_coarse.plot(ax=ax_coarse, values_format='d')\n",
    "    ax_coarse.set_title('Coarse Label Confusion Matrix')\n",
    "    plt.savefig(\n",
    "        f'{save_path}/{description}_coarse_label_confusion_matrix.png')\n",
    "    plt.close(fig_coarse)\n",
    "\n",
    "    print('Saved coarse label confusion matrix successfully')\n",
    "\n",
    "    # Compute confusion matrix for fine labels\n",
    "    confusion_matrix_fine = metrics.confusion_matrix(\n",
    "        fine_label_ground_truth, fine_label_prediction)\n",
    "    display_labels_fine = [str(label) for label in range(\n",
    "        num_coarse_label, num_all_labels)]\n",
    "\n",
    "    # Plot and save fine label confusion matrix\n",
    "    fig_fine, ax_fine = plt.subplots(figsize=(15, 15))\n",
    "    cm_display_fine = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix_fine,\n",
    "                                             display_labels=display_labels_fine)\n",
    "    cm_display_fine.plot(ax=ax_fine, values_format='d')\n",
    "    ax_fine.set_title('Fine Label Confusion Matrix')\n",
    "    plt.savefig(f'{save_path}/{description}_fine_label_confusion_matrix.png')\n",
    "    plt.close(fig_fine)\n",
    "\n",
    "    print('Saved fine label confusion matrix successfully')\n",
    "\n",
    "    if not fine_grain_only:\n",
    "        print('save coarse grain excel file')\n",
    "        save_metrics_to_excel(coarse_label_ground_truth, coarse_label_prediction,\n",
    "                              coarse_label_dict, base_model,\n",
    "                              save_path,\n",
    "                              description + '_coarse'\n",
    "                              )\n",
    "\n",
    "    print('save fine grain excel file')\n",
    "    save_metrics_to_excel(fine_label_ground_truth, fine_label_prediction,\n",
    "                          fine_label_dict, base_model,\n",
    "                          save_path,\n",
    "                          description + '_fine'\n",
    "                          )\n",
    "\n",
    "    print('save excel file successfully')\n",
    "\n",
    "    # Save result for later use\n",
    "\n",
    "    coarse_label_prediction = np.array(coarse_label_prediction)\n",
    "    coarse_label_ground_truth = np.array(coarse_label_ground_truth)\n",
    "    image_path_list = np.array(image_path_list)\n",
    "\n",
    "    # Concatenate the arrays along the second axis (axis=1)\n",
    "    concatenated_array = np.column_stack(\n",
    "        (coarse_label_prediction, coarse_label_ground_truth, image_path_list))\n",
    "\n",
    "    # Save the concatenated array\n",
    "    with open(f'{save_path}/concatenated_data_coarse_{description}.pkl', 'wb') as pickle_file:\n",
    "        pickle.dump(concatenated_array, pickle_file)\n",
    "\n",
    "    print('Save concatenated coarse data successfully!')\n",
    "\n",
    "    fine_label_prediction = np.array(fine_label_prediction)\n",
    "    fine_label_ground_truth = np.array(fine_label_ground_truth)\n",
    "    image_path_list = np.array(image_path_list)\n",
    "\n",
    "    # Concatenate the arrays along the second axis (axis=1)\n",
    "    concatenated_array = np.column_stack(\n",
    "        (fine_label_prediction, fine_label_ground_truth, image_path_list))\n",
    "\n",
    "    # Save the concatenated array\n",
    "    with open(f'{save_path}/concatenated_data_fine_{description}.pkl', 'wb') as pickle_file:\n",
    "        pickle.dump(concatenated_array, pickle_file)\n",
    "\n",
    "    print('Save concatenated fine data successfully!')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "lX_PU42TSbmC"
   },
   "outputs": [],
   "source": [
    "def hyper_parameter_tune(config):\n",
    "    # Load dataset\n",
    "    df_train, df_test = process_image_folders(\n",
    "        base_train_folder, base_test_folder)\n",
    "    train_loader, test_loader = create_data_loaders(\n",
    "        df_train, df_test, image_resize, batch_size, num_coarse_label, num_all_label)\n",
    "\n",
    "    # Model Initialization\n",
    "    base_model = VITFineTuner(vit_model_index, num_output).to(device)\n",
    "    logits_to_predicate = ltn.Predicate(LogitsToPredicate()).to(ltn.device)\n",
    "\n",
    "    # Training Configuration\n",
    "    optimizer = torch.optim.Adam(base_model.parameters(), config['lr'])\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "        optimizer, 2, 0.95)\n",
    "    beta = config['beta']\n",
    "\n",
    "    evaluation_metric_train = []\n",
    "    evaluation_metric_valid = []\n",
    "    accuracy_recent_coarse = []\n",
    "    accuracy_recent_fine = []\n",
    "\n",
    "    # Update description:\n",
    "    description = 'model ' + str(vit_model_index) + \\\n",
    "        ' ' + \"ltn_combine\" + ' ' + \"softmarginal\" + \\\n",
    "        ' ' + str(config['lr']) + ' ' + str(config['beta']) + ' ' + str(datetime.now().strftime(\"%Y-%m-%d\"))\n",
    "    print(description)\n",
    "\n",
    "    for epoch in range(loaded_epoch, num_epochs):\n",
    "        with ClearCache(device):\n",
    "            evaluation_metric_train.append(train(train_loader,\n",
    "                                                  base_model, logits_to_predicate,\n",
    "                                                  beta,\n",
    "                                                  epoch,\n",
    "                                                  optimizer,\n",
    "                                                  scheduler,\n",
    "                                                  loss_mode,\n",
    "                                                  fine_grain_only, mode,\n",
    "                                                  device,\n",
    "                                                  coarse_label_dict, fine_label_dict, coarse_to_fine))\n",
    "            evaluation_metric_valid.append(valid(test_loader,\n",
    "                                                  base_model, logits_to_predicate,\n",
    "                                                  beta,\n",
    "                                                  loss_mode,\n",
    "                                                  fine_grain_only, mode,\n",
    "                                                  device,\n",
    "                                                  coarse_label_dict, fine_label_dict, coarse_to_fine))\n",
    "\n",
    "            accuracy_recent_coarse.append(evaluation_metric_valid[-1][1])\n",
    "            accuracy_recent_fine.append(evaluation_metric_valid[-1][4])\n",
    "\n",
    "            # Save best checkpoint according to sum accuracy\n",
    "            if max(accuracy_recent_coarse) == accuracy_recent_coarse[-1] and max(accuracy_recent_fine) == accuracy_recent_fine[-1]:\n",
    "                torch.save({\"model_state_dict\": base_model.state_dict(),\n",
    "                            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                            \"scheduler\": scheduler.state_dict()},\n",
    "                            f\"{base_path}/model/model_{description}.pth\")\n",
    "                print(f\"Saved PyTorch Model State to {description}\")\n",
    "            \n",
    "            # Saving evaluation_metric_train\n",
    "            with open(f'{base_path}/model/evaluation_metric_train_{description}.pkl', 'wb') as f:\n",
    "                pickle.dump(evaluation_metric_train, f)\n",
    "\n",
    "            # Saving evaluation_metric_valid\n",
    "            with open(f'{base_path}/model/evaluation_metric_valid_{description}.pkl', 'wb') as f:\n",
    "                pickle.dump(evaluation_metric_valid, f)\n",
    "\n",
    "        print('#' * 100)\n",
    "\n",
    "    # Create a folder with the name 'description' inside the 'result' folder\n",
    "    result_folder_path = os.path.join(base_path, \"result\", description)\n",
    "    os.makedirs(result_folder_path, exist_ok=True)\n",
    "\n",
    "    save_evaluation_metric(evaluation_metric_train,\n",
    "                           evaluation_metric_valid, result_folder_path, description)\n",
    "\n",
    "    # Save confusion matrices to the result folder with the description\n",
    "    save_confusion_matrices(num_coarse_label, num_all_label,\n",
    "                            base_model, test_loader, result_folder_path,\n",
    "                            fine_grain_only, description)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2PiAkQp_Qnnu",
    "outputId": "5b6fcf37-967a-4865-b648-c8b68838169a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 0 ltn_combine softmarginal 1e-05 0.8 2023-12-01\n",
      "coarse_label_dict:\n",
      "{'Air Defence': 0, 'BMP': 1, 'BTR': 2, 'Tank': 3, 'SPA': 4, 'BMD': 5, 'MT_LB': 6}\n",
      "\n",
      "fine_label_dict:\n",
      "{'30N6E': 7, 'Iskander': 8, 'Pantsir-S1': 9, 'Rs-24': 10, 'BMP-1': 11, 'BMP-2': 12, 'BMP-T15': 13, 'BRDM': 14, 'BTR-60': 15, 'BTR-70': 16, 'BTR-80': 17, 'T-14': 18, 'T-62': 19, 'T-64': 20, 'T-72': 21, 'T-80': 22, 'T-90': 23, '2S19_MSTA': 24, 'BM-30': 25, 'D-30': 26, 'Tornado': 27, 'TOS-1': 28, 'BMD': 29, 'MT_LB': 30}\n",
      "\n",
      "coarse_to_fine:\n",
      "{0: [7, 8, 9, 10], 1: [11, 12, 13], 2: [14, 15, 16, 17], 3: [18, 19, 20, 21, 22, 23], 4: [24, 25, 26, 27, 28], 5: [29], 6: [30]}\n",
      "Using device:  cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ngocbach/.local/lib/python3.11/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get dataset successfully\n",
      "model initialization successfully\n",
      "train from beginning\n"
     ]
    }
   ],
   "source": [
    "# Assigning argparse values to variables\n",
    "base_path = \"/home/ngocbach\"\n",
    "mode = \"ltn_combine\"\n",
    "vit_model_index = 2\n",
    "beta = 0.8\n",
    "lr = 0.00001\n",
    "fine_grain_only = False\n",
    "loss_mode = \"softmarginal\"\n",
    "load_checkpoint = False\n",
    "num_epochs = 5\n",
    "batch_size = 16\n",
    "description = 'model ' + str(0) + \\\n",
    "    ' ' + \"ltn_combine\" + ' ' + \"softmarginal\" + \\\n",
    "    ' ' + str(0.00001) + ' ' + str(0.8) + \" \" + str(datetime.now().strftime(\"%Y-%m-%d\"))\n",
    "print(description)\n",
    "\n",
    "\n",
    "# All label\n",
    "category_dict = {\n",
    "    'Air Defence': ['30N6E', 'Iskander', 'Pantsir-S1', 'Rs-24'],\n",
    "    'BMP': ['BMP-1', 'BMP-2', 'BMP-T15'],\n",
    "    'BTR': ['BRDM', 'BTR-60', 'BTR-70', 'BTR-80'],\n",
    "    'Tank': ['T-14', 'T-62', 'T-64', 'T-72', 'T-80', 'T-90'],\n",
    "    'SPA': ['2S19_MSTA', 'BM-30', 'D-30', 'Tornado', 'TOS-1'],\n",
    "    'BMD': ['BMD'],\n",
    "    'MT_LB': ['MT_LB']\n",
    "}\n",
    "\n",
    "coarse_label_dict, fine_label_dict, coarse_to_fine = create_label_dict(\n",
    "    category_dict)\n",
    "\n",
    "# Print the resulting dictionaries\n",
    "print(\"coarse_label_dict:\")\n",
    "print(coarse_label_dict)\n",
    "print(\"\\nfine_label_dict:\")\n",
    "print(fine_label_dict)\n",
    "print(\"\\ncoarse_to_fine:\")\n",
    "print(coarse_to_fine)\n",
    "\n",
    "l = create_one_hot_tensors(fine_label_dict, coarse_label_dict)\n",
    "inverse_dict = create_inverse_dict(coarse_label_dict, fine_label_dict)\n",
    "\n",
    "# Constants and Configuration\n",
    "image_resize = 224\n",
    "num_coarse_label = len(coarse_label_dict)\n",
    "num_fine_label = len(fine_label_dict)\n",
    "num_all_label = num_fine_label + num_coarse_label\n",
    "num_output = num_all_label\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using device: ', device)\n",
    "base_train_folder = f\"{base_path}/dataset/train\"\n",
    "base_test_folder = f\"{base_path}/dataset/test\"\n",
    "load_checkpoint_path = f\"{base_path}/model/model_{description}.pth\"\n",
    "\n",
    "# Load dataset\n",
    "df_train, df_test = process_image_folders(\n",
    "    base_train_folder, base_test_folder)\n",
    "train_loader, test_loader = create_data_loaders(\n",
    "    df_train, df_test, image_resize, batch_size, num_coarse_label, num_all_label)\n",
    "\n",
    "print('get dataset successfully')\n",
    "\n",
    "# Model Initialization\n",
    "base_model = VITFineTuner(vit_model_index, num_output).to(device)\n",
    "logits_to_predicate = ltn.Predicate(LogitsToPredicate()).to(ltn.device)\n",
    "print('model initialization successfully')\n",
    "\n",
    "# Training Configuration\n",
    "optimizer = torch.optim.Adam(base_model.parameters(), lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 10, 0.1)\n",
    "\n",
    "if load_checkpoint:\n",
    "    # Load the checkpoint\n",
    "    checkpoint = torch.load(load_checkpoint_path)\n",
    "\n",
    "    # Load model and optimizer states\n",
    "    base_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "\n",
    "    # Load scheduler state, if available in the checkpoint\n",
    "    if 'scheduler' in checkpoint:\n",
    "        scheduler.load_state_dict(checkpoint['scheduler'])\n",
    "\n",
    "        # Retrieve the epoch information if available in the checkpoint\n",
    "        loaded_epoch = scheduler.last_epoch\n",
    "\n",
    "    # Restoring evaluation_metric_train.\n",
    "    with open(f'{base_path}/model/evaluation_metric_train_{description}.pkl', 'rb') as f:\n",
    "        evaluation_metric_train = pickle.load(f)\n",
    "\n",
    "    # Restoring evaluation_metric_valid\n",
    "    with open(f'{base_path}/model/evaluation_metric_valid_{description}.pkl', 'rb') as f:\n",
    "        evaluation_metric_valid = pickle.load(f)\n",
    "\n",
    "    print('load checkpoint successfully')\n",
    "\n",
    "else:\n",
    "    print('train from beginning')\n",
    "    loaded_epoch = 0  # If not loading a checkpoint, start training from epoch 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the hyperparameter search space\n",
    "# TODO: change hyperparameter search space\n",
    "search_space = {\n",
    "    \"lr\": tune.loguniform(1e-6, 1e-5),\n",
    "    \"beta\": tune.quniform(0.2, 0.8, 0.2),\n",
    "}\n",
    "\n",
    "# hyperopt_search = HyperOptSearch(search_space,\n",
    "#                                   metric=\"accuracy_recent_coarse\",\n",
    "#                                   mode=\"max\")\n",
    "search_space = {\n",
    "    \"lr\": tune.grid_search([0.000005]),\n",
    "    \"beta\": tune.grid_search([0.75, 1]),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "hwEYePAPSjuD",
    "outputId": "9218d1ec-458c-4046-f128-655203b50230"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Initialize Ray and start hyperparameter tuning\n",
    "# Resource will be used accordingly. The default is for gg colab notebook\n",
    "ray.shutdown()\n",
    "ray.init(num_cpus=2, num_gpus=1, ignore_reinit_error=True)\n",
    "\n",
    "# define tuner object\n",
    "# TODO: Change metric when necessary\n",
    "results = tune.Tuner(\n",
    "    tune.with_resources(\n",
    "        tune.with_parameters(hyper_parameter_tune),\n",
    "        resources={\"cpu\": 2, \"gpu\": 1}\n",
    "    ),\n",
    "    tune_config=tune.TuneConfig(\n",
    "        num_samples=1,\n",
    "    ),\n",
    "    param_space = search_space\n",
    ")\n",
    "results.fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 2 ltn_combine softmarginal 5e-06 0.75 2023-11-29\n"
     ]
    }
   ],
   "source": [
    "config = {}\n",
    "config['lr'] = 5e-06\n",
    "config['beta'] = 1\n",
    "# Update description:\n",
    "description = 'model ' + str(vit_model_index) + \\\n",
    "    ' ' + \"ltn_combine\" + ' ' + \"softmarginal\" + \\\n",
    "    ' ' + str(config['lr']) + ' ' + str(config['beta']) + ' ' + str(\"2023-11-29\")\n",
    "print(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint successfully\n"
     ]
    }
   ],
   "source": [
    "# Load the checkpoint\n",
    "load_checkpoint_path = \"/home/ngocbach/model/model_model 2 ltn_combine softmarginal 5e-06 1 2023-11-30.pth\"\n",
    "checkpoint = torch.load(load_checkpoint_path)\n",
    "\n",
    "# Load model and optimizer states\n",
    "base_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "\n",
    "# Load scheduler state, if available in the checkpoint\n",
    "if 'scheduler' in checkpoint:\n",
    "    scheduler.load_state_dict(checkpoint['scheduler'])\n",
    "\n",
    "    # Retrieve the epoch information if available in the checkpoint\n",
    "    loaded_epoch = scheduler.last_epoch\n",
    "\n",
    "print('load checkpoint successfully')\n",
    "    \n",
    "# Create a folder with the name 'description' inside the 'result' folder\n",
    "result_folder_path = os.path.join(base_path, \"result\", description)\n",
    "os.makedirs(result_folder_path, exist_ok=True)\n",
    "\n",
    "# # Save confusion matrices to the result folder with the description\n",
    "# save_confusion_matrices(num_coarse_label, num_all_label,\n",
    "#                         base_model, test_loader, result_folder_path,\n",
    "#                         fine_grain_only, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ngocbach/.local/lib/python3.11/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "coarse_index = slice(num_coarse_label)\n",
    "fine_index = slice(num_coarse_label, num_all_label)\n",
    "\n",
    "coarse_label_ground_truth = []\n",
    "coarse_label_prediction = []\n",
    "fine_label_ground_truth = []\n",
    "fine_label_prediction = []\n",
    "image_path_list = []\n",
    "# Iterate through the test data and make predictions\n",
    "for batch_idx, (data, labels_coarse, labels_fine, image_path) in enumerate(test_loader):\n",
    "    data = data.to(device)\n",
    "\n",
    "    prediction = base_model(data).cpu().detach()\n",
    "\n",
    "    prediction_coarse_label = prediction[:, coarse_index]\n",
    "    coarse_label_prediction_batch = torch.argmax(\n",
    "        prediction_coarse_label, dim=1)\n",
    "    coarse_label_prediction.extend(coarse_label_prediction_batch)\n",
    "    coarse_label_ground_truth.extend(labels_coarse)\n",
    "\n",
    "    prediction_fine_label = prediction[:, fine_index]\n",
    "    fine_label_prediction_batch = torch.argmax(\n",
    "        prediction_fine_label, dim=1) + num_coarse_label\n",
    "    fine_label_prediction.extend(fine_label_prediction_batch)\n",
    "    fine_label_ground_truth.extend(labels_fine)\n",
    "\n",
    "    # get image path\n",
    "    image_path_list.extend(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming coarse_label and fine_label are lists of tensors\n",
    "coarse_label = coarse_label_prediction\n",
    "fine_label = fine_label_prediction\n",
    "\n",
    "# Your coarse_to_fine dictionary\n",
    "coarse_to_fine = {0: [7, 8, 9, 10], 1: [11, 12, 13], 2: [14, 15, 16, 17],\n",
    "                  3: [18, 19, 20, 21, 22, 23], 4: [24, 25, 26, 27, 28],\n",
    "                  5: [29], 6: [30]}\n",
    "\n",
    "# Convert tensors to integers\n",
    "coarse_label = [int(label.item()) for label in coarse_label]\n",
    "fine_label = [int(label.item()) for label in fine_label]\n",
    "\n",
    "count = 0\n",
    "# Count of pairs without one-to-one correspondence\n",
    "for i in range(len(coarse_label_prediction)):\n",
    "    if (fine_label[i] in coarse_to_fine[coarse_label[i]]):\n",
    "        count = count + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num consistancy: 0.32510795805058607\n"
     ]
    }
   ],
   "source": [
    "print(\"num consistancy:\" ,count / len(coarse_label_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score for Coarse Labels: 0.7878155753312605\n",
      "Accuracy for Coarse Labels: 0.7896360271437385\n",
      "F1 Score for Fine Labels: 0.3334929576165714\n",
      "Accuracy for Fine Labels: 0.3232572486119679\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Assuming coarse_label, fine_label, coarse_label_ground_truth, and fine_label_ground_truth are lists of tensors\n",
    "# Your coarse_to_fine dictionary\n",
    "coarse_to_fine = {0: [7, 8, 9, 10], 1: [11, 12, 13], 2: [14, 15, 16, 17],\n",
    "                  3: [18, 19, 20, 21, 22, 23], 4: [24, 25, 26, 27, 28],\n",
    "                  5: [29], 6: [30]}\n",
    "\n",
    "# Calculate F1 and accuracy for coarse labels\n",
    "f1_coarse = f1_score(coarse_label_ground_truth, coarse_label_prediction, average='weighted')\n",
    "accuracy_coarse = accuracy_score(coarse_label_ground_truth, coarse_label_prediction)\n",
    "\n",
    "# Calculate F1 and accuracy for fine labels\n",
    "f1_fine = f1_score(fine_label_ground_truth, fine_label_prediction, average='weighted')\n",
    "accuracy_fine = accuracy_score(fine_label_ground_truth, fine_label_prediction)\n",
    "\n",
    "print(f\"F1 Score for Coarse Labels: {f1_coarse}\")\n",
    "print(f\"Accuracy for Coarse Labels: {accuracy_coarse}\")\n",
    "print(f\"F1 Score for Fine Labels: {f1_fine}\")\n",
    "print(f\"Accuracy for Fine Labels: {accuracy_fine}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cxjWFTZ1Orln"
   },
   "source": [
    "# Get consistancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "ph2ZdN-4M37x"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "def load_numpy_array_from_pickle(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        # Load the NumPy array from the pickle file\n",
    "        data = pickle.load(file)\n",
    "    return data\n",
    "\n",
    "# Replace with the actual path to your pickle file\n",
    "file_path_coarse = '/home/ngocbach/result/model 2 ltn_combine softmarginal 5e-06 0 2023-11-28/concatenated_data_coarse_model 2 ltn_combine softmarginal 5e-06 0 2023-11-28.pkl'\n",
    "file_path_fine = \"/home/ngocbach/result/model 2 ltn_combine softmarginal 5e-06 0 2023-11-28/concatenated_data_fine_model 2 ltn_combine softmarginal 5e-06 0 2023-11-28.pkl\"\n",
    "loaded_array_coarse = load_numpy_array_from_pickle(file_path_coarse)\n",
    "loaded_array_fine = load_numpy_array_from_pickle(file_path_fine)\n",
    "\n",
    "# modify loaded_array_fine to get original prediction that match the dictionary (for ltn_fine_coarse only)\n",
    "# loaded_array_fine[:,0] = loaded_array_fine[:,0].astype(np.int32) + 7\n",
    "# loaded_array_fine[:,1] = loaded_array_fine[:,1].astype(np.int32) + 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C-GQRZgSGeli",
    "outputId": "d8fe3492-24eb-4c46-9aa4-e03b7ce74f33"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def process_arrays(input_coarse, input_fine):\n",
    "    # First task: Extract the desired part from image_path for input_coarse\n",
    "    image_paths1 = [path.split('/')[-3:] for path in input_coarse[:, 2]]\n",
    "    image_paths1 = ['/'.join(path) for path in image_paths1]\n",
    "\n",
    "    # Second task: Extract the desired part from image_path for input_fine\n",
    "    image_paths2 = [path.split('/')[-3:] for path in input_fine[:, 2]]\n",
    "    image_paths2 = ['/'.join(path) for path in image_paths2]\n",
    "\n",
    "    # Create DataFrames for input_coarse and input_fine\n",
    "    df = pd.DataFrame({\n",
    "        'image_path': image_paths1,\n",
    "        'ground_truth_coarse': input_coarse[:, 0],\n",
    "        'prediction_coarse': input_coarse[:, 1],\n",
    "        'ground_truth_fine': input_fine[:, 0],\n",
    "        'prediction_fine': input_fine[:, 1]\n",
    "    })\n",
    "\n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "# Assuming 'loaded_array1' and 'loaded_array2' are the NumPy arrays with shape [length_dataset, 3]\n",
    "# Replace 'loaded_array1' and 'loaded_array2' with the actual loaded NumPy arrays in your code\n",
    "df_concatenated = process_arrays(loaded_array_coarse, loaded_array_fine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PtcW8EEvLy_j",
    "outputId": "e043c8fe-1abe-4fe5-d741-2ad8572cb885"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of inconsistencies between coarse grain and fine grain predictions: 0\n",
      "Inconsistency rate: 0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'df' is the DataFrame with the structure you provided\n",
    "# Replace 'df' with the actual DataFrame in your code\n",
    "\n",
    "# Define the coarse_to_fine dictionary\n",
    "coarse_to_fine = {0: [7, 8, 9, 10], 1: [11, 12, 13], 2: [14, 15, 16, 17],\n",
    "                  3: [18, 19, 20, 21, 22, 23], 4: [24, 25, 26, 27, 28],\n",
    "                  5: [29], 6: [30]}\n",
    "\n",
    "# Create a function to calculate inconsistency\n",
    "def calculate_inconsistency(row):\n",
    "    coarse_prediction = int(row['prediction_coarse'])\n",
    "    fine_prediction = int(row['prediction_fine'])\n",
    "\n",
    "    if fine_prediction not in coarse_to_fine[coarse_prediction]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Apply the function to each row in the DataFrame to calculate inconsistency\n",
    "df_concatenated['inconsistency'] = df_concatenated.apply(calculate_inconsistency, axis=1)\n",
    "\n",
    "# Calculate the total inconsistency count\n",
    "total_inconsistency_count = df_concatenated['inconsistency'].sum()\n",
    "\n",
    "# Calculate the inconsistency rate\n",
    "inconsistency_rate = total_inconsistency_count / len(df_concatenated)\n",
    "\n",
    "print(\"Number of inconsistencies between coarse grain and fine grain predictions:\", total_inconsistency_count)\n",
    "print(\"Inconsistency rate:\", inconsistency_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 685
    },
    "id": "1800AuAedytl",
    "outputId": "0e630d8c-083c-4586-eb15-3907df83b4a4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-4cb86ae0-83cc-4c47-83f6-c38493e7eeac\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>ground_truth_coarse</th>\n",
       "      <th>prediction_coarse</th>\n",
       "      <th>ground_truth_fine</th>\n",
       "      <th>prediction_fine</th>\n",
       "      <th>inconsistency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BMD/BMD/6 4.53.52 PM.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMD/BMD/82 4.53.53 PM.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BMD/BMD/55 4.53.52 PM.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BMD/BMD/25 4.53.52 PM.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BMD/BMD/57 4.53.52 PM.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1616</th>\n",
       "      <td>BTR/BRDM/35.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1617</th>\n",
       "      <td>BTR/BRDM/28.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1618</th>\n",
       "      <td>BTR/BRDM/61.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1619</th>\n",
       "      <td>BTR/BRDM/51.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1620</th>\n",
       "      <td>BTR/BRDM/25.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1621 rows  6 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4cb86ae0-83cc-4c47-83f6-c38493e7eeac')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-4cb86ae0-83cc-4c47-83f6-c38493e7eeac button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-4cb86ae0-83cc-4c47-83f6-c38493e7eeac');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-3a22d0f7-7420-4e4e-ae4c-b57716dac7a2\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3a22d0f7-7420-4e4e-ae4c-b57716dac7a2')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-3a22d0f7-7420-4e4e-ae4c-b57716dac7a2 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                     image_path ground_truth_coarse prediction_coarse  \\\n",
       "0      BMD/BMD/6 4.53.52 PM.jpg                   1                 5   \n",
       "1     BMD/BMD/82 4.53.53 PM.jpg                   3                 5   \n",
       "2     BMD/BMD/55 4.53.52 PM.jpg                   3                 5   \n",
       "3     BMD/BMD/25 4.53.52 PM.jpg                   1                 5   \n",
       "4     BMD/BMD/57 4.53.52 PM.jpg                   3                 5   \n",
       "...                         ...                 ...               ...   \n",
       "1616            BTR/BRDM/35.jpg                   4                 2   \n",
       "1617            BTR/BRDM/28.jpg                   2                 2   \n",
       "1618            BTR/BRDM/61.jpg                   2                 2   \n",
       "1619            BTR/BRDM/51.jpg                   3                 2   \n",
       "1620            BTR/BRDM/25.jpg                   2                 2   \n",
       "\n",
       "     ground_truth_fine prediction_fine  inconsistency  \n",
       "0                   30              29              0  \n",
       "1                   24              29              0  \n",
       "2                   29              29              0  \n",
       "3                   29              29              0  \n",
       "4                   29              29              0  \n",
       "...                ...             ...            ...  \n",
       "1616                14              14              0  \n",
       "1617                14              14              0  \n",
       "1618                14              14              0  \n",
       "1619                18              14              0  \n",
       "1620                14              14              0  \n",
       "\n",
       "[1621 rows x 6 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concatenated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q3ysEGUqfksq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
