{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c72514e-f325-49a6-86cd-0a69e3ca7299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEAD is now at 8688d0f3 13.12 update\n",
      "Already up to date.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Input GitHub username and PAT\n",
    "github_username = \"lab-v2\"\n",
    "token = \"\"\n",
    "\n",
    "os.environ[\"GITHUB_AUTH\"] = f\"{github_username}:{token}\" # Set up GitHub credentials\n",
    "\n",
    "#Clone the private repository\n",
    "github_repo = 'metacognitive_error_detection_and_correction_v2'\n",
    "\n",
    "local_username = 'jkrichel'\n",
    "if os.getcwd().split('/')[-1] != local_username:\n",
    "        os.chdir('..')\n",
    "\n",
    "commit_SHA = ''\n",
    "\n",
    "if os.path.exists(github_repo) and os.path.isdir(github_repo):\n",
    "    os.chdir(github_repo)\n",
    "    if len(commit_SHA):\n",
    "        ! git reset --hard {commit_SHA}\n",
    "        ! git cherry-pick {commit_SHA}\n",
    "    else:\n",
    "        ! git reset --hard HEAD\n",
    "        ! git pull\n",
    "else:\n",
    "    ! git clone https://{os.environ[\"GITHUB_AUTH\"]}@github.com/{github_username}/{github_repo}.git\n",
    "    os.chdir(github_repo)\n",
    "    ! git config pull.rebase false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce0d5bee-f172-4c4e-b247-677c5b7ba8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models: ['vit_l_16']\n",
      "Epochs num: 10\n",
      "Learning rates: [0.0001]\n",
      "Total number of train images: 7823\n",
      "Total number of test images: 1621\n",
      "Using cuda\n",
      "Fine-tuning vit_l_16 with 303333407 parameters for 10 epochs using lr=0.0001 on cuda...\n",
      "####################################################################################################\n",
      "\n",
      "Completed batch num 10/245 in 1.52 seconds. Batch fine-grain loss: 2.94, batch coarse-grain loss: 2.95, alpha value: 0.93\n",
      "Completed batch num 20/245 in 1.52 seconds. Batch fine-grain loss: 2.68, batch coarse-grain loss: 2.2, alpha value: 0.89\n",
      "Completed batch num 30/245 in 1.53 seconds. Batch fine-grain loss: 2.36, batch coarse-grain loss: 1.73, alpha value: 0.93\n",
      "Completed batch num 40/245 in 1.53 seconds. Batch fine-grain loss: 2.38, batch coarse-grain loss: 1.44, alpha value: 0.97\n",
      "Completed batch num 50/245 in 1.54 seconds. Batch fine-grain loss: 1.84, batch coarse-grain loss: 1.27, alpha value: 1.01\n",
      "Completed batch num 60/245 in 1.54 seconds. Batch fine-grain loss: 2.23, batch coarse-grain loss: 1.56, alpha value: 1.02\n",
      "Completed batch num 70/245 in 1.54 seconds. Batch fine-grain loss: 1.89, batch coarse-grain loss: 1.75, alpha value: 1.01\n",
      "Completed batch num 80/245 in 1.54 seconds. Batch fine-grain loss: 2.2, batch coarse-grain loss: 2.08, alpha value: 0.99\n",
      "Completed batch num 90/245 in 1.55 seconds. Batch fine-grain loss: 2.09, batch coarse-grain loss: 1.26, alpha value: 0.98\n",
      "Completed batch num 100/245 in 1.55 seconds. Batch fine-grain loss: 1.75, batch coarse-grain loss: 1.16, alpha value: 0.99\n",
      "Completed batch num 110/245 in 1.55 seconds. Batch fine-grain loss: 1.5, batch coarse-grain loss: 1.3, alpha value: 1.0\n",
      "Completed batch num 120/245 in 1.55 seconds. Batch fine-grain loss: 1.76, batch coarse-grain loss: 1.43, alpha value: 0.99\n",
      "Completed batch num 130/245 in 1.55 seconds. Batch fine-grain loss: 1.64, batch coarse-grain loss: 1.48, alpha value: 0.99\n",
      "Completed batch num 140/245 in 1.55 seconds. Batch fine-grain loss: 2.16, batch coarse-grain loss: 1.43, alpha value: 0.99\n",
      "Completed batch num 150/245 in 1.55 seconds. Batch fine-grain loss: 2.11, batch coarse-grain loss: 1.58, alpha value: 1.0\n",
      "Completed batch num 160/245 in 1.55 seconds. Batch fine-grain loss: 1.63, batch coarse-grain loss: 1.27, alpha value: 1.0\n",
      "Completed batch num 170/245 in 1.55 seconds. Batch fine-grain loss: 1.96, batch coarse-grain loss: 1.4, alpha value: 1.0\n",
      "Completed batch num 180/245 in 1.55 seconds. Batch fine-grain loss: 1.61, batch coarse-grain loss: 1.33, alpha value: 1.0\n",
      "Completed batch num 190/245 in 1.55 seconds. Batch fine-grain loss: 1.78, batch coarse-grain loss: 1.29, alpha value: 1.0\n",
      "Completed batch num 200/245 in 1.55 seconds. Batch fine-grain loss: 1.57, batch coarse-grain loss: 1.19, alpha value: 1.0\n",
      "Completed batch num 210/245 in 1.55 seconds. Batch fine-grain loss: 1.6, batch coarse-grain loss: 1.3, alpha value: 1.0\n",
      "Completed batch num 220/245 in 1.55 seconds. Batch fine-grain loss: 1.32, batch coarse-grain loss: 1.22, alpha value: 1.0\n",
      "Completed batch num 230/245 in 1.55 seconds. Batch fine-grain loss: 1.55, batch coarse-grain loss: 1.23, alpha value: 1.0\n",
      "Completed batch num 240/245 in 1.55 seconds. Batch fine-grain loss: 1.79, batch coarse-grain loss: 1.37, alpha value: 1.0\n",
      "\n",
      "Epoch 1/10 done in 6 minutes, \n",
      "Training fine loss: 1.97\n",
      "training coarse loss: 1.52\n",
      "training fine accuracy: 39.15, fine f1: 38.44%\n",
      "training coarse accuracy: 47.36%, coarse f1: 38.33%\n",
      "\n",
      "Testing vit_l_16 on cuda...\n",
      "\n",
      "Test fine accuracy: \u001B[92m57.8\u001B[0m%, fine f1: \u001B[92m54.94\u001B[0m%\n",
      "Test coarse accuracy: \u001B[92m60.52\u001B[0m%, coarse f1: \u001B[92m53.77\u001B[0m%\n",
      "\n",
      "Total prior inconsistencies \u001B[91m553\u001B[0m/\u001B[91m1621\u001B[0m which is \u001B[91m34.11\u001B[0m%\n",
      "####################################################################################################\n",
      "Completed batch num 10/245 in 1.55 seconds. Batch fine-grain loss: 1.38, batch coarse-grain loss: 0.93, alpha value: 0.95\n",
      "Completed batch num 20/245 in 1.55 seconds. Batch fine-grain loss: 1.06, batch coarse-grain loss: 0.82, alpha value: 0.99\n",
      "Completed batch num 30/245 in 1.55 seconds. Batch fine-grain loss: 1.09, batch coarse-grain loss: 1.18, alpha value: 1.01\n",
      "Completed batch num 40/245 in 1.55 seconds. Batch fine-grain loss: 1.45, batch coarse-grain loss: 1.22, alpha value: 1.05\n",
      "Completed batch num 50/245 in 1.55 seconds. Batch fine-grain loss: 1.19, batch coarse-grain loss: 1.02, alpha value: 1.05\n",
      "Completed batch num 60/245 in 1.55 seconds. Batch fine-grain loss: 1.11, batch coarse-grain loss: 0.98, alpha value: 1.05\n",
      "Completed batch num 70/245 in 1.55 seconds. Batch fine-grain loss: 1.75, batch coarse-grain loss: 1.79, alpha value: 1.01\n",
      "Completed batch num 80/245 in 1.55 seconds. Batch fine-grain loss: 1.48, batch coarse-grain loss: 1.33, alpha value: 0.99\n",
      "Completed batch num 90/245 in 1.55 seconds. Batch fine-grain loss: 1.01, batch coarse-grain loss: 1.22, alpha value: 0.96\n",
      "Completed batch num 100/245 in 1.55 seconds. Batch fine-grain loss: 1.05, batch coarse-grain loss: 1.04, alpha value: 0.94\n",
      "Completed batch num 110/245 in 1.55 seconds. Batch fine-grain loss: 1.34, batch coarse-grain loss: 0.92, alpha value: 0.95\n",
      "Completed batch num 120/245 in 1.55 seconds. Batch fine-grain loss: 1.57, batch coarse-grain loss: 0.96, alpha value: 0.95\n",
      "Completed batch num 130/245 in 1.55 seconds. Batch fine-grain loss: 1.62, batch coarse-grain loss: 1.0, alpha value: 0.96\n",
      "Completed batch num 140/245 in 1.55 seconds. Batch fine-grain loss: 1.56, batch coarse-grain loss: 0.86, alpha value: 0.98\n",
      "Completed batch num 150/245 in 1.55 seconds. Batch fine-grain loss: 1.24, batch coarse-grain loss: 0.59, alpha value: 0.99\n",
      "Completed batch num 160/245 in 1.55 seconds. Batch fine-grain loss: 1.76, batch coarse-grain loss: 0.85, alpha value: 1.01\n",
      "Completed batch num 170/245 in 1.55 seconds. Batch fine-grain loss: 1.37, batch coarse-grain loss: 0.99, alpha value: 1.02\n",
      "Completed batch num 180/245 in 1.55 seconds. Batch fine-grain loss: 1.55, batch coarse-grain loss: 0.81, alpha value: 1.03\n",
      "Completed batch num 190/245 in 1.55 seconds. Batch fine-grain loss: 1.24, batch coarse-grain loss: 0.84, alpha value: 1.04\n",
      "Completed batch num 200/245 in 1.55 seconds. Batch fine-grain loss: 1.35, batch coarse-grain loss: 1.01, alpha value: 1.05\n",
      "Completed batch num 210/245 in 1.55 seconds. Batch fine-grain loss: 1.49, batch coarse-grain loss: 1.23, alpha value: 1.04\n",
      "Completed batch num 220/245 in 1.55 seconds. Batch fine-grain loss: 1.11, batch coarse-grain loss: 1.34, alpha value: 1.03\n",
      "Completed batch num 230/245 in 1.55 seconds. Batch fine-grain loss: 1.59, batch coarse-grain loss: 1.54, alpha value: 1.01\n",
      "Completed batch num 240/245 in 1.55 seconds. Batch fine-grain loss: 1.04, batch coarse-grain loss: 2.06, alpha value: 0.97\n",
      "\n",
      "Epoch 2/10 done in 6 minutes, \n",
      "Training fine loss: 1.36\n",
      "training coarse loss: 1.09\n",
      "training fine accuracy: 57.86, fine f1: 57.77%\n",
      "training coarse accuracy: 65.59%, coarse f1: 52.95%\n",
      "\n",
      "Testing vit_l_16 on cuda...\n",
      "\n",
      "Test fine accuracy: \u001B[92m59.35\u001B[0m%, fine f1: \u001B[92m57.87\u001B[0m%\n",
      "Test coarse accuracy: \u001B[92m50.22\u001B[0m%, coarse f1: \u001B[92m64.79\u001B[0m%\n",
      "\n",
      "Total prior inconsistencies \u001B[91m808\u001B[0m/\u001B[91m1621\u001B[0m which is \u001B[91m49.85\u001B[0m%\n",
      "####################################################################################################\n",
      "Completed batch num 10/245 in 1.55 seconds. Batch fine-grain loss: 0.76, batch coarse-grain loss: 0.68, alpha value: 0.79\n",
      "Completed batch num 20/245 in 1.55 seconds. Batch fine-grain loss: 1.03, batch coarse-grain loss: 0.54, alpha value: 0.94\n",
      "Completed batch num 30/245 in 1.55 seconds. Batch fine-grain loss: 0.89, batch coarse-grain loss: 0.6, alpha value: 1.05\n",
      "Completed batch num 40/245 in 1.55 seconds. Batch fine-grain loss: 0.89, batch coarse-grain loss: 0.53, alpha value: 1.09\n",
      "Completed batch num 50/245 in 1.55 seconds. Batch fine-grain loss: 0.81, batch coarse-grain loss: 0.6, alpha value: 1.1\n",
      "Completed batch num 60/245 in 1.55 seconds. Batch fine-grain loss: 1.06, batch coarse-grain loss: 1.15, alpha value: 1.08\n",
      "Completed batch num 70/245 in 1.55 seconds. Batch fine-grain loss: 0.93, batch coarse-grain loss: 1.31, alpha value: 1.01\n",
      "Completed batch num 80/245 in 1.55 seconds. Batch fine-grain loss: 1.25, batch coarse-grain loss: 1.23, alpha value: 0.95\n",
      "Completed batch num 90/245 in 1.55 seconds. Batch fine-grain loss: 1.37, batch coarse-grain loss: 1.09, alpha value: 0.94\n",
      "Completed batch num 100/245 in 1.55 seconds. Batch fine-grain loss: 0.86, batch coarse-grain loss: 0.93, alpha value: 0.94\n",
      "Completed batch num 110/245 in 1.55 seconds. Batch fine-grain loss: 0.78, batch coarse-grain loss: 0.56, alpha value: 0.96\n",
      "Completed batch num 120/245 in 1.55 seconds. Batch fine-grain loss: 1.53, batch coarse-grain loss: 0.89, alpha value: 0.99\n",
      "Completed batch num 130/245 in 1.55 seconds. Batch fine-grain loss: 0.97, batch coarse-grain loss: 0.89, alpha value: 1.0\n",
      "Completed batch num 140/245 in 1.55 seconds. Batch fine-grain loss: 1.21, batch coarse-grain loss: 0.7, alpha value: 1.01\n",
      "Completed batch num 150/245 in 1.55 seconds. Batch fine-grain loss: 1.08, batch coarse-grain loss: 0.97, alpha value: 1.02\n",
      "Completed batch num 160/245 in 1.55 seconds. Batch fine-grain loss: 1.68, batch coarse-grain loss: 1.06, alpha value: 1.03\n",
      "Completed batch num 170/245 in 1.55 seconds. Batch fine-grain loss: 1.32, batch coarse-grain loss: 0.61, alpha value: 1.04\n",
      "Completed batch num 180/245 in 1.55 seconds. Batch fine-grain loss: 1.29, batch coarse-grain loss: 0.91, alpha value: 1.05\n",
      "Completed batch num 190/245 in 1.55 seconds. Batch fine-grain loss: 1.26, batch coarse-grain loss: 0.94, alpha value: 1.05\n",
      "Completed batch num 200/245 in 1.55 seconds. Batch fine-grain loss: 1.49, batch coarse-grain loss: 1.12, alpha value: 1.04\n",
      "Completed batch num 210/245 in 1.55 seconds. Batch fine-grain loss: 0.95, batch coarse-grain loss: 1.12, alpha value: 1.02\n",
      "Completed batch num 220/245 in 1.55 seconds. Batch fine-grain loss: 0.97, batch coarse-grain loss: 1.28, alpha value: 0.99\n",
      "Completed batch num 230/245 in 1.55 seconds. Batch fine-grain loss: 1.41, batch coarse-grain loss: 1.61, alpha value: 0.97\n",
      "Completed batch num 240/245 in 1.55 seconds. Batch fine-grain loss: 1.27, batch coarse-grain loss: 1.0, alpha value: 0.96\n",
      "\n",
      "Epoch 3/10 done in 6 minutes, \n",
      "Training fine loss: 1.12\n",
      "training coarse loss: 0.9\n",
      "training fine accuracy: 64.8, fine f1: 64.76%\n",
      "training coarse accuracy: 71.3%, coarse f1: 65.32%\n",
      "\n",
      "Testing vit_l_16 on cuda...\n",
      "\n",
      "Test fine accuracy: \u001B[92m64.84\u001B[0m%, fine f1: \u001B[92m62.36\u001B[0m%\n",
      "Test coarse accuracy: \u001B[92m73.29\u001B[0m%, coarse f1: \u001B[92m59.81\u001B[0m%\n",
      "\n",
      "Total prior inconsistencies \u001B[91m295\u001B[0m/\u001B[91m1621\u001B[0m which is \u001B[91m18.2\u001B[0m%\n",
      "####################################################################################################\n",
      "Completed batch num 10/245 in 1.55 seconds. Batch fine-grain loss: 0.45, batch coarse-grain loss: 0.42, alpha value: 0.8\n",
      "Completed batch num 20/245 in 1.55 seconds. Batch fine-grain loss: 0.62, batch coarse-grain loss: 0.65, alpha value: 0.91\n",
      "Completed batch num 30/245 in 1.55 seconds. Batch fine-grain loss: 0.7, batch coarse-grain loss: 0.53, alpha value: 0.98\n",
      "Completed batch num 40/245 in 1.55 seconds. Batch fine-grain loss: 0.73, batch coarse-grain loss: 0.48, alpha value: 1.02\n",
      "Completed batch num 50/245 in 1.55 seconds. Batch fine-grain loss: 0.93, batch coarse-grain loss: 0.81, alpha value: 1.03\n",
      "Completed batch num 60/245 in 1.55 seconds. Batch fine-grain loss: 1.21, batch coarse-grain loss: 0.82, alpha value: 1.04\n",
      "Completed batch num 70/245 in 1.55 seconds. Batch fine-grain loss: 0.76, batch coarse-grain loss: 0.78, alpha value: 1.04\n",
      "Completed batch num 80/245 in 1.55 seconds. Batch fine-grain loss: 0.97, batch coarse-grain loss: 0.62, alpha value: 1.03\n",
      "Completed batch num 90/245 in 1.55 seconds. Batch fine-grain loss: 0.74, batch coarse-grain loss: 0.99, alpha value: 1.01\n",
      "Completed batch num 100/245 in 1.55 seconds. Batch fine-grain loss: 0.77, batch coarse-grain loss: 0.85, alpha value: 0.99\n",
      "Completed batch num 110/245 in 1.55 seconds. Batch fine-grain loss: 0.98, batch coarse-grain loss: 0.8, alpha value: 0.96\n",
      "Completed batch num 120/245 in 1.55 seconds. Batch fine-grain loss: 1.1, batch coarse-grain loss: 0.79, alpha value: 0.96\n",
      "Completed batch num 130/245 in 1.55 seconds. Batch fine-grain loss: 1.06, batch coarse-grain loss: 0.77, alpha value: 0.98\n",
      "Completed batch num 140/245 in 1.55 seconds. Batch fine-grain loss: 0.99, batch coarse-grain loss: 0.83, alpha value: 0.99\n",
      "Completed batch num 150/245 in 1.55 seconds. Batch fine-grain loss: 1.06, batch coarse-grain loss: 0.64, alpha value: 0.99\n",
      "Completed batch num 160/245 in 1.55 seconds. Batch fine-grain loss: 1.06, batch coarse-grain loss: 0.74, alpha value: 1.0\n",
      "Completed batch num 170/245 in 1.55 seconds. Batch fine-grain loss: 0.99, batch coarse-grain loss: 0.54, alpha value: 1.02\n",
      "Completed batch num 180/245 in 1.55 seconds. Batch fine-grain loss: 0.74, batch coarse-grain loss: 0.74, alpha value: 1.02\n",
      "Completed batch num 190/245 in 1.55 seconds. Batch fine-grain loss: 1.19, batch coarse-grain loss: 0.59, alpha value: 1.02\n",
      "Completed batch num 200/245 in 1.55 seconds. Batch fine-grain loss: 0.97, batch coarse-grain loss: 0.98, alpha value: 1.02\n",
      "Completed batch num 210/245 in 1.55 seconds. Batch fine-grain loss: 1.19, batch coarse-grain loss: 0.73, alpha value: 1.02\n",
      "Completed batch num 220/245 in 1.55 seconds. Batch fine-grain loss: 1.35, batch coarse-grain loss: 0.96, alpha value: 1.01\n",
      "Completed batch num 230/245 in 1.55 seconds. Batch fine-grain loss: 1.44, batch coarse-grain loss: 1.12, alpha value: 1.01\n",
      "Completed batch num 240/245 in 1.55 seconds. Batch fine-grain loss: 1.04, batch coarse-grain loss: 0.88, alpha value: 1.01\n",
      "\n",
      "Epoch 4/10 done in 6 minutes, \n",
      "Training fine loss: 0.94\n",
      "training coarse loss: 0.73\n",
      "training fine accuracy: 71.28, fine f1: 71.21%\n",
      "training coarse accuracy: 78.32%, coarse f1: 74.78%\n",
      "\n",
      "Testing vit_l_16 on cuda...\n",
      "\n",
      "Test fine accuracy: \u001B[92m62.31\u001B[0m%, fine f1: \u001B[92m60.42\u001B[0m%\n",
      "Test coarse accuracy: \u001B[92m72.92\u001B[0m%, coarse f1: \u001B[92m60.22\u001B[0m%\n",
      "\n",
      "Total prior inconsistencies \u001B[91m331\u001B[0m/\u001B[91m1621\u001B[0m which is \u001B[91m20.42\u001B[0m%\n",
      "####################################################################################################\n",
      "Completed batch num 10/245 in 1.55 seconds. Batch fine-grain loss: 0.98, batch coarse-grain loss: 0.72, alpha value: 0.9\n",
      "Completed batch num 20/245 in 1.55 seconds. Batch fine-grain loss: 0.89, batch coarse-grain loss: 0.68, alpha value: 0.91\n",
      "Completed batch num 30/245 in 1.55 seconds. Batch fine-grain loss: 0.69, batch coarse-grain loss: 0.67, alpha value: 0.95\n",
      "Completed batch num 40/245 in 1.55 seconds. Batch fine-grain loss: 0.87, batch coarse-grain loss: 0.45, alpha value: 1.0\n",
      "Completed batch num 50/245 in 1.55 seconds. Batch fine-grain loss: 0.7, batch coarse-grain loss: 0.59, alpha value: 1.01\n",
      "Completed batch num 60/245 in 1.55 seconds. Batch fine-grain loss: 1.2, batch coarse-grain loss: 0.58, alpha value: 1.04\n",
      "Completed batch num 70/245 in 1.55 seconds. Batch fine-grain loss: 0.93, batch coarse-grain loss: 0.57, alpha value: 1.05\n",
      "Completed batch num 80/245 in 1.55 seconds. Batch fine-grain loss: 1.05, batch coarse-grain loss: 0.61, alpha value: 1.02\n",
      "Completed batch num 90/245 in 1.55 seconds. Batch fine-grain loss: 0.63, batch coarse-grain loss: 0.57, alpha value: 1.02\n",
      "Completed batch num 100/245 in 1.55 seconds. Batch fine-grain loss: 0.59, batch coarse-grain loss: 0.58, alpha value: 1.0\n",
      "Completed batch num 110/245 in 1.55 seconds. Batch fine-grain loss: 0.92, batch coarse-grain loss: 0.84, alpha value: 1.0\n",
      "Completed batch num 120/245 in 1.55 seconds. Batch fine-grain loss: 0.89, batch coarse-grain loss: 0.78, alpha value: 0.99\n",
      "Completed batch num 130/245 in 1.55 seconds. Batch fine-grain loss: 0.76, batch coarse-grain loss: 0.59, alpha value: 0.98\n",
      "Completed batch num 140/245 in 1.55 seconds. Batch fine-grain loss: 1.09, batch coarse-grain loss: 0.77, alpha value: 0.97\n",
      "Completed batch num 150/245 in 1.55 seconds. Batch fine-grain loss: 1.03, batch coarse-grain loss: 0.67, alpha value: 0.98\n",
      "Completed batch num 160/245 in 1.55 seconds. Batch fine-grain loss: 0.6, batch coarse-grain loss: 0.76, alpha value: 0.98\n",
      "Completed batch num 170/245 in 1.55 seconds. Batch fine-grain loss: 0.97, batch coarse-grain loss: 0.5, alpha value: 0.99\n",
      "Completed batch num 180/245 in 1.55 seconds. Batch fine-grain loss: 0.81, batch coarse-grain loss: 0.46, alpha value: 1.0\n",
      "Completed batch num 190/245 in 1.55 seconds. Batch fine-grain loss: 0.91, batch coarse-grain loss: 0.58, alpha value: 1.01\n",
      "Completed batch num 200/245 in 1.55 seconds. Batch fine-grain loss: 0.88, batch coarse-grain loss: 0.77, alpha value: 1.01\n",
      "Completed batch num 210/245 in 1.55 seconds. Batch fine-grain loss: 0.71, batch coarse-grain loss: 0.65, alpha value: 1.01\n",
      "Completed batch num 220/245 in 1.55 seconds. Batch fine-grain loss: 0.97, batch coarse-grain loss: 0.65, alpha value: 1.01\n",
      "Completed batch num 230/245 in 1.55 seconds. Batch fine-grain loss: 1.03, batch coarse-grain loss: 0.69, alpha value: 1.02\n",
      "Completed batch num 240/245 in 1.55 seconds. Batch fine-grain loss: 1.04, batch coarse-grain loss: 0.73, alpha value: 1.02\n",
      "\n",
      "Epoch 5/10 done in 6 minutes, \n",
      "Training fine loss: 0.84\n",
      "training coarse loss: 0.64\n",
      "training fine accuracy: 73.91, fine f1: 74.0%\n",
      "training coarse accuracy: 81.98%, coarse f1: 78.88%\n",
      "\n",
      "Testing vit_l_16 on cuda...\n",
      "\n",
      "Test fine accuracy: \u001B[92m63.79\u001B[0m%, fine f1: \u001B[92m61.25\u001B[0m%\n",
      "Test coarse accuracy: \u001B[92m78.04\u001B[0m%, coarse f1: \u001B[92m59.45\u001B[0m%\n",
      "\n",
      "Total prior inconsistencies \u001B[91m252\u001B[0m/\u001B[91m1621\u001B[0m which is \u001B[91m15.55\u001B[0m%\n",
      "####################################################################################################\n",
      "Completed batch num 10/245 in 1.55 seconds. Batch fine-grain loss: 1.05, batch coarse-grain loss: 0.7, alpha value: 1.03\n",
      "Completed batch num 20/245 in 1.55 seconds. Batch fine-grain loss: 0.76, batch coarse-grain loss: 0.55, alpha value: 1.01\n",
      "Completed batch num 30/245 in 1.55 seconds. Batch fine-grain loss: 1.1, batch coarse-grain loss: 0.53, alpha value: 1.13\n",
      "Completed batch num 40/245 in 1.55 seconds. Batch fine-grain loss: 0.69, batch coarse-grain loss: 0.77, alpha value: 1.08\n",
      "Completed batch num 50/245 in 1.55 seconds. Batch fine-grain loss: 0.6, batch coarse-grain loss: 0.54, alpha value: 1.05\n",
      "Completed batch num 60/245 in 1.55 seconds. Batch fine-grain loss: 0.86, batch coarse-grain loss: 0.86, alpha value: 0.95\n",
      "Completed batch num 70/245 in 1.55 seconds. Batch fine-grain loss: 0.61, batch coarse-grain loss: 0.44, alpha value: 0.9\n",
      "Completed batch num 80/245 in 1.55 seconds. Batch fine-grain loss: 0.65, batch coarse-grain loss: 0.37, alpha value: 0.91\n",
      "Completed batch num 90/245 in 1.55 seconds. Batch fine-grain loss: 0.37, batch coarse-grain loss: 0.51, alpha value: 0.92\n",
      "Completed batch num 100/245 in 1.55 seconds. Batch fine-grain loss: 0.89, batch coarse-grain loss: 0.47, alpha value: 0.94\n",
      "Completed batch num 110/245 in 1.55 seconds. Batch fine-grain loss: 0.74, batch coarse-grain loss: 0.4, alpha value: 0.96\n",
      "Completed batch num 120/245 in 1.55 seconds. Batch fine-grain loss: 0.89, batch coarse-grain loss: 0.43, alpha value: 0.97\n",
      "Completed batch num 130/245 in 1.55 seconds. Batch fine-grain loss: 0.81, batch coarse-grain loss: 0.62, alpha value: 0.98\n",
      "Completed batch num 140/245 in 1.55 seconds. Batch fine-grain loss: 0.32, batch coarse-grain loss: 0.29, alpha value: 0.98\n",
      "Completed batch num 150/245 in 1.55 seconds. Batch fine-grain loss: 0.78, batch coarse-grain loss: 0.79, alpha value: 0.99\n",
      "Completed batch num 160/245 in 1.55 seconds. Batch fine-grain loss: 0.72, batch coarse-grain loss: 0.41, alpha value: 1.0\n",
      "Completed batch num 170/245 in 1.55 seconds. Batch fine-grain loss: 0.92, batch coarse-grain loss: 0.53, alpha value: 1.0\n",
      "Completed batch num 180/245 in 1.55 seconds. Batch fine-grain loss: 0.24, batch coarse-grain loss: 0.36, alpha value: 0.99\n",
      "Completed batch num 190/245 in 1.55 seconds. Batch fine-grain loss: 1.23, batch coarse-grain loss: 0.97, alpha value: 1.0\n",
      "Completed batch num 200/245 in 1.55 seconds. Batch fine-grain loss: 0.97, batch coarse-grain loss: 0.78, alpha value: 1.01\n",
      "Completed batch num 210/245 in 1.55 seconds. Batch fine-grain loss: 0.74, batch coarse-grain loss: 0.41, alpha value: 1.01\n",
      "Completed batch num 220/245 in 1.55 seconds. Batch fine-grain loss: 0.69, batch coarse-grain loss: 0.31, alpha value: 1.02\n",
      "Completed batch num 230/245 in 1.55 seconds. Batch fine-grain loss: 0.82, batch coarse-grain loss: 0.56, alpha value: 1.02\n",
      "Completed batch num 240/245 in 1.55 seconds. Batch fine-grain loss: 0.66, batch coarse-grain loss: 0.43, alpha value: 1.03\n",
      "\n",
      "Epoch 6/10 done in 6 minutes, \n",
      "Training fine loss: 0.75\n",
      "training coarse loss: 0.56\n",
      "training fine accuracy: 77.04, fine f1: 77.17%\n",
      "training coarse accuracy: 83.43%, coarse f1: 80.27%\n",
      "\n",
      "Testing vit_l_16 on cuda...\n",
      "\n",
      "Test fine accuracy: \u001B[92m62.68\u001B[0m%, fine f1: \u001B[92m60.92\u001B[0m%\n",
      "Test coarse accuracy: \u001B[92m80.32\u001B[0m%, coarse f1: \u001B[92m59.39\u001B[0m%\n",
      "\n",
      "Total prior inconsistencies \u001B[91m190\u001B[0m/\u001B[91m1621\u001B[0m which is \u001B[91m11.72\u001B[0m%\n",
      "####################################################################################################\n",
      "Completed batch num 10/245 in 1.55 seconds. Batch fine-grain loss: 0.58, batch coarse-grain loss: 0.52, alpha value: 0.92\n",
      "Completed batch num 20/245 in 1.55 seconds. Batch fine-grain loss: 0.58, batch coarse-grain loss: 0.52, alpha value: 1.0\n",
      "Completed batch num 30/245 in 1.55 seconds. Batch fine-grain loss: 0.59, batch coarse-grain loss: 0.59, alpha value: 0.99\n",
      "Completed batch num 40/245 in 1.55 seconds. Batch fine-grain loss: 0.66, batch coarse-grain loss: 0.46, alpha value: 0.99\n",
      "Completed batch num 50/245 in 1.55 seconds. Batch fine-grain loss: 0.76, batch coarse-grain loss: 0.45, alpha value: 1.05\n",
      "Completed batch num 60/245 in 1.55 seconds. Batch fine-grain loss: 0.48, batch coarse-grain loss: 0.44, alpha value: 1.06\n",
      "Completed batch num 70/245 in 1.55 seconds. Batch fine-grain loss: 0.66, batch coarse-grain loss: 0.47, alpha value: 1.04\n",
      "Completed batch num 80/245 in 1.55 seconds. Batch fine-grain loss: 0.8, batch coarse-grain loss: 0.53, alpha value: 1.03\n",
      "Completed batch num 90/245 in 1.55 seconds. Batch fine-grain loss: 0.73, batch coarse-grain loss: 0.74, alpha value: 1.0\n",
      "Completed batch num 100/245 in 1.55 seconds. Batch fine-grain loss: 0.67, batch coarse-grain loss: 0.69, alpha value: 1.0\n",
      "Completed batch num 110/245 in 1.55 seconds. Batch fine-grain loss: 0.65, batch coarse-grain loss: 0.6, alpha value: 0.99\n",
      "Completed batch num 120/245 in 1.55 seconds. Batch fine-grain loss: 0.7, batch coarse-grain loss: 0.59, alpha value: 0.98\n",
      "Completed batch num 130/245 in 1.55 seconds. Batch fine-grain loss: 0.8, batch coarse-grain loss: 0.45, alpha value: 0.99\n",
      "Completed batch num 140/245 in 1.55 seconds. Batch fine-grain loss: 0.62, batch coarse-grain loss: 0.43, alpha value: 0.99\n",
      "Completed batch num 150/245 in 1.55 seconds. Batch fine-grain loss: 0.73, batch coarse-grain loss: 0.48, alpha value: 0.99\n",
      "Completed batch num 160/245 in 1.55 seconds. Batch fine-grain loss: 0.67, batch coarse-grain loss: 0.68, alpha value: 0.99\n",
      "Completed batch num 170/245 in 1.55 seconds. Batch fine-grain loss: 0.86, batch coarse-grain loss: 0.66, alpha value: 0.99\n",
      "Completed batch num 180/245 in 1.55 seconds. Batch fine-grain loss: 0.66, batch coarse-grain loss: 0.3, alpha value: 0.99\n",
      "Completed batch num 190/245 in 1.55 seconds. Batch fine-grain loss: 0.67, batch coarse-grain loss: 0.59, alpha value: 0.99\n",
      "Completed batch num 200/245 in 1.55 seconds. Batch fine-grain loss: 0.96, batch coarse-grain loss: 0.72, alpha value: 0.99\n",
      "Completed batch num 210/245 in 1.55 seconds. Batch fine-grain loss: 0.92, batch coarse-grain loss: 0.54, alpha value: 0.99\n",
      "Completed batch num 220/245 in 1.55 seconds. Batch fine-grain loss: 0.94, batch coarse-grain loss: 0.46, alpha value: 1.0\n",
      "Completed batch num 230/245 in 1.55 seconds. Batch fine-grain loss: 0.68, batch coarse-grain loss: 0.6, alpha value: 1.0\n",
      "Completed batch num 240/245 in 1.55 seconds. Batch fine-grain loss: 0.71, batch coarse-grain loss: 0.38, alpha value: 1.01\n",
      "\n",
      "Epoch 7/10 done in 6 minutes, \n",
      "Training fine loss: 0.68\n",
      "training coarse loss: 0.52\n",
      "training fine accuracy: 79.15, fine f1: 79.35%\n",
      "training coarse accuracy: 84.67%, coarse f1: 82.27%\n",
      "\n",
      "Testing vit_l_16 on cuda...\n",
      "\n",
      "Test fine accuracy: \u001B[92m65.08\u001B[0m%, fine f1: \u001B[92m62.27\u001B[0m%\n",
      "Test coarse accuracy: \u001B[92m81.68\u001B[0m%, coarse f1: \u001B[92m63.21\u001B[0m%\n",
      "\n",
      "Total prior inconsistencies \u001B[91m172\u001B[0m/\u001B[91m1621\u001B[0m which is \u001B[91m10.61\u001B[0m%\n",
      "####################################################################################################\n",
      "Completed batch num 10/245 in 1.55 seconds. Batch fine-grain loss: 0.49, batch coarse-grain loss: 0.44, alpha value: 0.88\n",
      "Completed batch num 20/245 in 1.55 seconds. Batch fine-grain loss: 0.42, batch coarse-grain loss: 0.2, alpha value: 0.94\n",
      "Completed batch num 30/245 in 1.55 seconds. Batch fine-grain loss: 1.04, batch coarse-grain loss: 0.43, alpha value: 1.02\n",
      "Completed batch num 40/245 in 1.55 seconds. Batch fine-grain loss: 0.79, batch coarse-grain loss: 0.45, alpha value: 1.0\n",
      "Completed batch num 50/245 in 1.55 seconds. Batch fine-grain loss: 0.51, batch coarse-grain loss: 0.35, alpha value: 1.01\n",
      "Completed batch num 60/245 in 1.55 seconds. Batch fine-grain loss: 0.59, batch coarse-grain loss: 0.54, alpha value: 1.03\n",
      "Completed batch num 70/245 in 1.55 seconds. Batch fine-grain loss: 0.37, batch coarse-grain loss: 0.24, alpha value: 1.04\n",
      "Completed batch num 80/245 in 1.55 seconds. Batch fine-grain loss: 0.62, batch coarse-grain loss: 0.61, alpha value: 1.03\n",
      "Completed batch num 90/245 in 1.55 seconds. Batch fine-grain loss: 0.41, batch coarse-grain loss: 0.43, alpha value: 1.02\n",
      "Completed batch num 100/245 in 1.55 seconds. Batch fine-grain loss: 0.44, batch coarse-grain loss: 0.48, alpha value: 1.02\n",
      "Completed batch num 110/245 in 1.55 seconds. Batch fine-grain loss: 0.53, batch coarse-grain loss: 0.52, alpha value: 0.99\n",
      "Completed batch num 120/245 in 1.55 seconds. Batch fine-grain loss: 0.48, batch coarse-grain loss: 0.39, alpha value: 1.0\n",
      "Completed batch num 130/245 in 1.55 seconds. Batch fine-grain loss: 0.62, batch coarse-grain loss: 0.4, alpha value: 0.99\n",
      "Completed batch num 140/245 in 1.55 seconds. Batch fine-grain loss: 0.66, batch coarse-grain loss: 0.53, alpha value: 0.98\n",
      "Completed batch num 150/245 in 1.55 seconds. Batch fine-grain loss: 0.58, batch coarse-grain loss: 0.39, alpha value: 0.99\n",
      "Completed batch num 160/245 in 1.55 seconds. Batch fine-grain loss: 0.78, batch coarse-grain loss: 0.6, alpha value: 1.0\n",
      "Completed batch num 170/245 in 1.55 seconds. Batch fine-grain loss: 0.57, batch coarse-grain loss: 0.45, alpha value: 0.99\n",
      "Completed batch num 180/245 in 1.55 seconds. Batch fine-grain loss: 0.49, batch coarse-grain loss: 0.5, alpha value: 0.98\n",
      "Completed batch num 190/245 in 1.55 seconds. Batch fine-grain loss: 0.72, batch coarse-grain loss: 0.47, alpha value: 0.99\n",
      "Completed batch num 200/245 in 1.55 seconds. Batch fine-grain loss: 0.46, batch coarse-grain loss: 0.49, alpha value: 0.99\n",
      "Completed batch num 210/245 in 1.55 seconds. Batch fine-grain loss: 0.48, batch coarse-grain loss: 0.36, alpha value: 1.0\n",
      "Completed batch num 220/245 in 1.55 seconds. Batch fine-grain loss: 0.97, batch coarse-grain loss: 0.82, alpha value: 1.0\n",
      "Completed batch num 230/245 in 1.55 seconds. Batch fine-grain loss: 0.59, batch coarse-grain loss: 0.52, alpha value: 1.01\n",
      "Completed batch num 240/245 in 1.55 seconds. Batch fine-grain loss: 0.6, batch coarse-grain loss: 0.43, alpha value: 1.01\n",
      "\n",
      "Epoch 8/10 done in 6 minutes, \n",
      "Training fine loss: 0.61\n",
      "training coarse loss: 0.47\n",
      "training fine accuracy: 81.36, fine f1: 81.45%\n",
      "training coarse accuracy: 86.62%, coarse f1: 84.44%\n",
      "\n",
      "Testing vit_l_16 on cuda...\n",
      "\n",
      "Test fine accuracy: \u001B[92m63.29\u001B[0m%, fine f1: \u001B[92m61.33\u001B[0m%\n",
      "Test coarse accuracy: \u001B[92m81.37\u001B[0m%, coarse f1: \u001B[92m61.28\u001B[0m%\n",
      "\n",
      "Total prior inconsistencies \u001B[91m164\u001B[0m/\u001B[91m1621\u001B[0m which is \u001B[91m10.12\u001B[0m%\n",
      "####################################################################################################\n",
      "Completed batch num 10/245 in 1.55 seconds. Batch fine-grain loss: 0.38, batch coarse-grain loss: 0.48, alpha value: 0.91\n",
      "Completed batch num 20/245 in 1.55 seconds. Batch fine-grain loss: 0.35, batch coarse-grain loss: 0.44, alpha value: 0.86\n",
      "Completed batch num 30/245 in 1.55 seconds. Batch fine-grain loss: 0.6, batch coarse-grain loss: 0.47, alpha value: 0.93\n",
      "Completed batch num 40/245 in 1.55 seconds. Batch fine-grain loss: 0.22, batch coarse-grain loss: 0.36, alpha value: 0.96\n",
      "Completed batch num 50/245 in 1.55 seconds. Batch fine-grain loss: 0.24, batch coarse-grain loss: 0.26, alpha value: 1.02\n",
      "Completed batch num 60/245 in 1.55 seconds. Batch fine-grain loss: 0.38, batch coarse-grain loss: 0.31, alpha value: 1.04\n",
      "Completed batch num 70/245 in 1.55 seconds. Batch fine-grain loss: 0.7, batch coarse-grain loss: 0.59, alpha value: 1.03\n",
      "Completed batch num 80/245 in 1.55 seconds. Batch fine-grain loss: 0.36, batch coarse-grain loss: 0.5, alpha value: 1.04\n",
      "Completed batch num 90/245 in 1.55 seconds. Batch fine-grain loss: 1.12, batch coarse-grain loss: 0.52, alpha value: 1.04\n",
      "Completed batch num 100/245 in 1.55 seconds. Batch fine-grain loss: 0.35, batch coarse-grain loss: 0.36, alpha value: 1.02\n",
      "Completed batch num 110/245 in 1.55 seconds. Batch fine-grain loss: 0.39, batch coarse-grain loss: 0.39, alpha value: 1.01\n",
      "Completed batch num 120/245 in 1.55 seconds. Batch fine-grain loss: 0.55, batch coarse-grain loss: 0.32, alpha value: 1.02\n",
      "Completed batch num 130/245 in 1.55 seconds. Batch fine-grain loss: 0.43, batch coarse-grain loss: 0.53, alpha value: 1.01\n",
      "Completed batch num 140/245 in 1.55 seconds. Batch fine-grain loss: 0.74, batch coarse-grain loss: 0.47, alpha value: 1.0\n",
      "Completed batch num 150/245 in 1.55 seconds. Batch fine-grain loss: 0.66, batch coarse-grain loss: 0.4, alpha value: 1.01\n",
      "Completed batch num 160/245 in 1.55 seconds. Batch fine-grain loss: 0.69, batch coarse-grain loss: 0.46, alpha value: 1.01\n",
      "Completed batch num 170/245 in 1.55 seconds. Batch fine-grain loss: 0.68, batch coarse-grain loss: 0.55, alpha value: 1.01\n",
      "Completed batch num 180/245 in 1.55 seconds. Batch fine-grain loss: 0.62, batch coarse-grain loss: 0.5, alpha value: 1.02\n",
      "Completed batch num 190/245 in 1.55 seconds. Batch fine-grain loss: 0.64, batch coarse-grain loss: 0.53, alpha value: 1.01\n",
      "Completed batch num 200/245 in 1.55 seconds. Batch fine-grain loss: 0.57, batch coarse-grain loss: 0.53, alpha value: 1.0\n",
      "Completed batch num 210/245 in 1.55 seconds. Batch fine-grain loss: 0.56, batch coarse-grain loss: 0.42, alpha value: 1.0\n",
      "Completed batch num 220/245 in 1.55 seconds. Batch fine-grain loss: 0.94, batch coarse-grain loss: 0.58, alpha value: 0.99\n",
      "Completed batch num 230/245 in 1.55 seconds. Batch fine-grain loss: 0.64, batch coarse-grain loss: 0.47, alpha value: 0.99\n",
      "Completed batch num 240/245 in 1.55 seconds. Batch fine-grain loss: 0.78, batch coarse-grain loss: 0.63, alpha value: 0.99\n",
      "\n",
      "Epoch 9/10 done in 6 minutes, \n",
      "Training fine loss: 0.58\n",
      "training coarse loss: 0.46\n",
      "training fine accuracy: 82.04, fine f1: 81.91%\n",
      "training coarse accuracy: 86.55%, coarse f1: 84.78%\n",
      "\n",
      "Testing vit_l_16 on cuda...\n",
      "\n",
      "Test fine accuracy: \u001B[92m62.99\u001B[0m%, fine f1: \u001B[92m60.82\u001B[0m%\n",
      "Test coarse accuracy: \u001B[92m80.14\u001B[0m%, coarse f1: \u001B[92m57.83\u001B[0m%\n",
      "\n",
      "Total prior inconsistencies \u001B[91m180\u001B[0m/\u001B[91m1621\u001B[0m which is \u001B[91m11.1\u001B[0m%\n",
      "####################################################################################################\n",
      "Completed batch num 10/245 in 1.55 seconds. Batch fine-grain loss: 0.62, batch coarse-grain loss: 0.51, alpha value: 1.01\n",
      "Completed batch num 20/245 in 1.55 seconds. Batch fine-grain loss: 0.44, batch coarse-grain loss: 0.53, alpha value: 0.94\n",
      "Completed batch num 30/245 in 1.55 seconds. Batch fine-grain loss: 0.58, batch coarse-grain loss: 0.41, alpha value: 0.93\n",
      "Completed batch num 40/245 in 1.55 seconds. Batch fine-grain loss: 0.19, batch coarse-grain loss: 0.29, alpha value: 0.92\n",
      "Completed batch num 50/245 in 1.55 seconds. Batch fine-grain loss: 0.51, batch coarse-grain loss: 0.33, alpha value: 0.95\n",
      "Completed batch num 60/245 in 1.55 seconds. Batch fine-grain loss: 0.26, batch coarse-grain loss: 0.14, alpha value: 0.97\n",
      "Completed batch num 70/245 in 1.55 seconds. Batch fine-grain loss: 0.24, batch coarse-grain loss: 0.21, alpha value: 0.98\n",
      "Completed batch num 80/245 in 1.55 seconds. Batch fine-grain loss: 0.49, batch coarse-grain loss: 0.32, alpha value: 1.0\n",
      "Completed batch num 90/245 in 1.55 seconds. Batch fine-grain loss: 0.27, batch coarse-grain loss: 0.28, alpha value: 1.01\n",
      "Completed batch num 100/245 in 1.56 seconds. Batch fine-grain loss: 0.56, batch coarse-grain loss: 0.43, alpha value: 1.05\n",
      "Completed batch num 110/245 in 1.55 seconds. Batch fine-grain loss: 0.66, batch coarse-grain loss: 0.42, alpha value: 1.04\n",
      "Completed batch num 120/245 in 1.55 seconds. Batch fine-grain loss: 0.21, batch coarse-grain loss: 0.15, alpha value: 1.04\n",
      "Completed batch num 130/245 in 1.55 seconds. Batch fine-grain loss: 0.49, batch coarse-grain loss: 0.33, alpha value: 1.06\n",
      "Completed batch num 140/245 in 1.55 seconds. Batch fine-grain loss: 0.37, batch coarse-grain loss: 0.45, alpha value: 1.06\n",
      "Completed batch num 150/245 in 1.55 seconds. Batch fine-grain loss: 0.61, batch coarse-grain loss: 0.37, alpha value: 1.06\n",
      "Completed batch num 160/245 in 1.55 seconds. Batch fine-grain loss: 0.77, batch coarse-grain loss: 0.62, alpha value: 1.05\n",
      "Completed batch num 170/245 in 1.55 seconds. Batch fine-grain loss: 1.11, batch coarse-grain loss: 0.62, alpha value: 1.05\n",
      "Completed batch num 180/245 in 1.55 seconds. Batch fine-grain loss: 0.49, batch coarse-grain loss: 0.54, alpha value: 1.04\n",
      "Completed batch num 190/245 in 1.55 seconds. Batch fine-grain loss: 0.76, batch coarse-grain loss: 0.95, alpha value: 1.01\n",
      "Completed batch num 200/245 in 1.55 seconds. Batch fine-grain loss: 0.52, batch coarse-grain loss: 0.65, alpha value: 0.97\n",
      "Completed batch num 210/245 in 1.55 seconds. Batch fine-grain loss: 0.48, batch coarse-grain loss: 0.49, alpha value: 0.96\n",
      "Completed batch num 220/245 in 1.55 seconds. Batch fine-grain loss: 0.29, batch coarse-grain loss: 0.32, alpha value: 0.95\n",
      "Completed batch num 230/245 in 1.55 seconds. Batch fine-grain loss: 0.41, batch coarse-grain loss: 0.47, alpha value: 0.96\n",
      "Completed batch num 240/245 in 1.55 seconds. Batch fine-grain loss: 0.48, batch coarse-grain loss: 0.22, alpha value: 0.96\n",
      "\n",
      "Epoch 10/10 done in 6 minutes, \n",
      "Training fine loss: 0.56\n",
      "training coarse loss: 0.45\n",
      "training fine accuracy: 83.05, fine f1: 83.06%\n",
      "training coarse accuracy: 86.41%, coarse f1: 84.06%\n",
      "\n",
      "Testing vit_l_16 on cuda...\n",
      "\n",
      "Test fine accuracy: \u001B[92m63.36\u001B[0m%, fine f1: \u001B[92m61.43\u001B[0m%\n",
      "Test coarse accuracy: \u001B[92m80.38\u001B[0m%, coarse f1: \u001B[92m58.14\u001B[0m%\n",
      "\n",
      "Total prior inconsistencies \u001B[91m127\u001B[0m/\u001B[91m1621\u001B[0m which is \u001B[91m7.83\u001B[0m%\n",
      "####################################################################################################\n",
      "####################################################################################################\n"
     ]
    }
   ],
   "source": [
    "from sol_runner import run\n",
    "\n",
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ae115fc-f199-49e0-84a7-8c1d61eef167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: individual_results/ (stored 0%)\n",
      "  adding: individual_results/vit_l_16_test_pred_lr1e-06_e8_fine_individual.npy (deflated 90%)\n",
      "  adding: individual_results/vit_l_16_test_pred_lr0.0001_e5_coarse_individual.npy (deflated 95%)\n",
      "  adding: individual_results/vit_l_16_test_pred_lr0.0001_e8_coarse_individual.npy (deflated 95%)\n",
      "  adding: individual_results/vit_l_16_test_pred_lr0.0001_e4_coarse_individual.npy (deflated 95%)\n",
      "  adding: individual_results/vit_l_16_test_pred_lr0.0001_e5_fine_individual.npy (deflated 91%)\n",
      "  adding: individual_results/vit_l_16_test_pred_lr1e-06_e3_coarse_individual.npy (deflated 95%)\n",
      "  adding: individual_results/vit_l_16_test_pred_lr0.0001_e1_coarse_individual.npy (deflated 95%)\n",
      "  adding: individual_results/test_true.npy (deflated 99%)\n",
      "  adding: individual_results/vit_b_16_test_pred_lr0.0001_e8_fine_individual.npy (deflated 91%)\n",
      "  adding: individual_results/vit_l_16_test_pred_lr0.0001_e9_fine_individual.npy (deflated 91%)\n",
      "  adding: individual_results/vit_l_16_test_pred_lr1e-06_e3_fine_individual.npy (deflated 91%)\n",
      "  adding: individual_results/test_true_coarse.npy (deflated 99%)\n",
      "  adding: individual_results/vit_b_16_test_pred_lr0.0001_e0_coarse_individual.npy (deflated 95%)\n",
      "  adding: individual_results/vit_b_16_test_pred_lr0.0001_e2_coarse_individual.npy (deflated 95%)\n",
      "  adding: individual_results/vit_b_16_test_pred_lr0.0001_e1_fine_individual.npy (deflated 91%)\n",
      "  adding: individual_results/vit_l_16_test_pred_lr1e-06_e9_fine_individual.npy (deflated 90%)\n",
      "  adding: individual_results/vit_l_16_test_pred_lr1e-06_e5_fine_individual.npy (deflated 90%)\n",
      "  adding: individual_results/vit_l_16_test_pred_lr0.0001_e1_fine_individual.npy (deflated 91%)\n",
      "  adding: individual_results/vit_l_16_test_pred_lr1e-06_e2_coarse_individual.npy (deflated 95%)\n",
      "  adding: individual_results/vit_b_16_test_pred_lr0.0001_e2_fine_individual.npy (deflated 91%)\n",
      "  adding: individual_results/vit_l_16_test_pred_lr1e-06_e5_coarse_individual.npy (deflated 94%)\n",
      "  adding: individual_results/vit_l_16_test_pred_lr0.0001_e0_coarse_individual.npy (deflated 94%)\n",
      "  adding: individual_results/vit_l_16_test_pred_lr1e-06_e4_fine_individual.npy (deflated 91%)\n",
      "  adding: individual_results/vit_b_16_test_pred_lr0.0001_e4_fine_individual.npy (deflated 91%)\n",
      "  adding: individual_results/vit_l_16_test_pred_lr1e-06_e6_coarse_individual.npy (deflated 94%)\n",
      "  adding: individual_results/vit_b_16_test_pred_lr0.0001_e9_fine_individual.npy (deflated 91%)\n",
      "  adding: individual_results/vit_l_16_test_pred_lr1e-06_e7_fine_individual.npy (deflated 90%)\n",
      "  adding: individual_results/vit_l_16_test_pred_lr1e-06_e6_fine_individual.npy (deflated 90%)\n",
      "  adding: individual_results/vit_l_16_test_pred_lr1e-06_e1_fine_individual.npy (deflated 91%)\n",
      "  adding: individual_results/vit_l_16_test_pred_lr0.0001_e3_fine_individual.npy (deflated 91%)\n",
      "  adding: individual_results/vit_l_16_test_pred_lr0.0001_e3_coarse_individual.npy (deflated 95%)\n",
      "  adding: individual_results/vit_b_16_test_pred_lr0.0001_e7_fine_individual.npy (deflated 91%)\n",
      "  adding: individual_results/vit_l_16_test_pred_lr0.0001_e6_coarse_individual.npy (deflated 95%)\n",
      "  adding: individual_results/vit_l_16_test_pred_lr1e-06_e0_fine_individual.npy (deflated 91%)\n",
      "  adding: individual_results/vit_l_16_test_pred_lr1e-06_e8_coarse_individual.npy (deflated 94%)\n",
      "  adding: individual_results/vit_b_16_test_pred_lr0.0001_e8_coarse_individual.npy (deflated 95%)\n",
      "  adding: individual_results/vit_l_16_test_pred_lr1e-06_e2_fine_individual.npy (deflated 91%)\n",
      "  adding: individual_results/vit_l_16_test_pred_lr0.0001_e0_fine_individual.npy (deflated 90%)\n",
      "  adding: individual_results/vit_b_16_test_pred_lr0.0001_e5_coarse_individual.npy (deflated 95%)\n",
      "  adding: individual_results/vit_l_16_test_pred_lr1e-06_e7_coarse_individual.npy (deflated 94%)\n",
      "  adding: individual_results/vit_b_16_test_pred_lr0.0001_e0_fine_individual.npy (deflated 91%)\n",
      "  adding: individual_results/vit_l_16_test_pred_lr1e-06_e4_coarse_individual.npy (deflated 95%)\n",
      "  adding: individual_results/vit_b_16_test_pred_lr0.0001_e3_coarse_individual.npy (deflated 95%)\n",
      "  adding: individual_results/vit_l_16_test_pred_lr0.0001_e8_fine_individual.npy (deflated 91%)\n",
      "  adding: individual_results/vit_b_16_test_pred_lr0.0001_e3_fine_individual.npy (deflated 91%)\n",
      "  adding: individual_results/vit_b_16_test_pred_lr0.0001_e7_coarse_individual.npy (deflated 95%)\n",
      "  adding: individual_results/vit_b_16_test_pred_lr0.0001_e5_fine_individual.npy (deflated 91%)\n",
      "  adding: individual_results/vit_b_16_test_pred_lr0.0001_e1_coarse_individual.npy (deflated 95%)\n",
      "  adding: individual_results/vit_l_16_test_pred_lr0.0001_e4_fine_individual.npy (deflated 91%)\n",
      "  adding: individual_results/vit_l_16_test_pred_lr0.0001_e7_fine_individual.npy (deflated 91%)\n",
      "  adding: individual_results/vit_l_16_test_pred_lr1e-06_e9_coarse_individual.npy (deflated 95%)\n",
      "  adding: individual_results/vit_b_16_test_pred_lr0.0001_e9_coarse_individual.npy (deflated 95%)\n",
      "  adding: individual_results/vit_l_16_test_pred_lr0.0001_e9_coarse_individual.npy (deflated 94%)\n",
      "  adding: individual_results/test_true_fine_individual.npy (deflated 47%)\n",
      "  adding: individual_results/vit_l_16_test_pred_lr1e-06_e1_coarse_individual.npy (deflated 95%)\n",
      "  adding: individual_results/vit_l_16_test_pred_lr0.0001_e2_fine_individual.npy (deflated 91%)\n",
      "  adding: individual_results/vit_l_16_test_pred_lr1e-06_e3.npy (deflated 92%)\n",
      "  adding: individual_results/test_true_coarse_individual.npy (deflated 47%)\n",
      "  adding: individual_results/vit_b_16_test_pred_lr0.0001_e6_coarse_individual.npy (deflated 95%)\n",
      "  adding: individual_results/vit_l_16_test_pred_lr0.0001_e7_coarse_individual.npy (deflated 95%)\n",
      "  adding: individual_results/vit_l_16_test_pred_lr0.0001_e2_coarse_individual.npy (deflated 95%)\n",
      "  adding: individual_results/vit_l_16_test_pred_lr1e-06_e0_coarse_individual.npy (deflated 95%)\n",
      "  adding: individual_results/vit_b_16_test_pred_lr0.0001_e4_coarse_individual.npy (deflated 95%)\n",
      "  adding: individual_results/vit_b_16_test_pred_lr0.0001_e6_fine_individual.npy (deflated 91%)\n",
      "  adding: individual_results/vit_l_16_test_pred_lr1e-05_e3_coarse.npy (deflated 95%)\n",
      "  adding: individual_results/vit_l_16_test_pred_lr0.0001_e6_fine_individual.npy (deflated 91%)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "github_repo = 'metacognitive_error_detection_and_correction_v2'\n",
    "\n",
    "if os.path.exists(github_repo) and os.path.isdir(github_repo):\n",
    "    os.chdir(github_repo)\n",
    "    \n",
    "! zip -r individual_results.zip individual_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f46c4ff-5c83-4dd2-b582-cc035474cd2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu-1.13.1",
   "language": "python",
   "name": "pytorch-gpu-1.13.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
